cuda is  True
loading data.....
size of reactant dic: 9766
size of template dic: 5567
size of fgm_trees: 20080
size of rxn_trees: 20080
size of fragment dic: 273
hidden size: 200 latent_size: 100 batch size: 1000 depth: 2
beta: 1.0 lr: 1e-05
size of data pairs: 20080
trainng size: 19079
valid size: 1000
loss:  144.6132049560547 1.3356435298919678
loss:  144.4968719482422 1.3343820571899414
loss:  145.51931762695312 1.3458083868026733
loss:  146.7862091064453 1.338283658027649
loss:  148.2331085205078 1.333168625831604
loss:  144.06056213378906 1.3278510570526123
loss:  144.13677978515625 1.3439922332763672
loss:  146.5401153564453 1.3154253959655762
loss:  147.26016235351562 1.331477165222168
loss:  146.60520935058594 1.317164659500122
loss:  145.9217529296875 1.3176875114440918
loss:  146.3302459716797 1.3173989057540894
loss:  145.72756958007812 1.3200416564941406
loss:  146.8666534423828 1.3162181377410889
loss:  145.22238159179688 1.30912184715271
loss:  147.9844970703125 1.307605266571045
loss:  143.68142700195312 1.3012840747833252
loss:  143.35302734375 1.3180547952651978
loss:  145.2501983642578 1.3234813213348389
loss:  140.30992126464844 1.3539352416992188
*******************Epoch 0 ****************** 20 0.00095
Validation Loss
*** pred loss:  92.80419158935547 pred acc: 0.00048309177509509027
*** stop loss:  21.675378799438477 stop acc: 0.5844645500183105
*** template loss:  8.63618278503418 template acc: tensor(0., device='cuda:0')
*** label loss:  9.193614959716797 label acc: tensor(0., device='cuda:0')
Train Loss
---> pred loss: 103.2582763671875 pred acc: 0.0003074568974625436
---> stop loss: 24.33166961669922 stop acc: 0.5637820959091187
---> template loss: 8.643456268310548 tempalte acc: 8.836599299684167e-05
---> molecule label loss: 9.210928344726563 molecule acc: 2.439400414004922e-05
---> kl loss: 1.325401210784912
---> reconstruction loss: 145.4436993649435
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-1-with.npy
loss:  144.7393341064453 1.3075364828109741
loss:  146.66807556152344 1.3053252696990967
loss:  143.83631896972656 1.2951430082321167
loss:  146.3014678955078 1.300455093383789
loss:  145.5841827392578 1.3137824535369873
loss:  144.17958068847656 1.2924253940582275
loss:  145.84454345703125 1.3102723360061646
loss:  144.68536376953125 1.3096753358840942
loss:  147.4442901611328 1.3038365840911865
loss:  143.29092407226562 1.3103138208389282
loss:  145.60128784179688 1.3041808605194092
loss:  142.8129119873047 1.3063983917236328
loss:  143.906982421875 1.2962007522583008
loss:  143.10643005371094 1.3035917282104492
loss:  146.0806427001953 1.3034273386001587
loss:  144.43942260742188 1.2975680828094482
loss:  144.06373596191406 1.3194503784179688
loss:  141.8390655517578 1.3031272888183594
loss:  141.6603546142578 1.3169548511505127
loss:  145.04238891601562 1.2834323644638062
*******************Epoch 1 ****************** 40 0.0019500000000000001
Validation Loss
*** pred loss:  92.05978393554688 pred acc: 0.001932367100380361
*** stop loss:  21.396604537963867 stop acc: 0.5862390995025635
*** template loss:  8.627033233642578 template acc: tensor(0.0004, device='cuda:0')
*** label loss:  9.1570405960083 label acc: tensor(0., device='cuda:0')
Train Loss
---> pred loss: 102.710400390625 pred acc: 0.0009286807762691751
---> stop loss: 24.048411560058593 stop acc: 0.574298369884491
---> template loss: 8.6244140625 tempalte acc: 0.0001929059042595327
---> molecule label loss: 9.171211242675781 molecule acc: 3.2637035474181175e-05
---> kl loss: 1.3041549682617188
---> reconstruction loss: 144.5538289681244
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-2-with.npy
loss:  141.08209228515625 1.309389591217041
loss:  142.77401733398438 1.3104586601257324
loss:  143.1938934326172 1.298006296157837
loss:  145.40309143066406 1.3002018928527832
loss:  145.3974151611328 1.31051504611969
loss:  142.2250213623047 1.3113876581192017
loss:  144.95565795898438 1.30060875415802
loss:  143.0494842529297 1.3148874044418335
loss:  143.2737579345703 1.3085256814956665
loss:  145.42352294921875 1.3152132034301758
loss:  144.86093139648438 1.3236006498336792
loss:  141.5850372314453 1.3215296268463135
loss:  142.94976806640625 1.314323902130127
loss:  142.3123321533203 1.3147985935211182
loss:  141.43460083007812 1.3182047605514526
loss:  143.69374084472656 1.3303436040878296
loss:  145.3311004638672 1.3204832077026367
loss:  142.4728546142578 1.3420605659484863
loss:  141.82827758789062 1.3410722017288208
loss:  150.92994689941406 1.30892813205719
*******************Epoch 2 ****************** 60 0.00295
Validation Loss
*** pred loss:  91.27802276611328 pred acc: 0.044323671609163284
*** stop loss:  21.125322341918945 stop acc: 0.593866765499115
*** template loss:  8.616159439086914 template acc: tensor(0.0007, device='cuda:0')
*** label loss:  9.112051010131836 label acc: tensor(0.0015, device='cuda:0')
Train Loss
---> pred loss: 102.17435302734376 pred acc: 0.013207323756068945
---> stop loss: 23.79845428466797 stop acc: 0.581348431110382
---> template loss: 8.60543441772461 tempalte acc: 0.0003118433989584446
---> molecule label loss: 9.12732162475586 molecule acc: 0.0001461803214624524
---> kl loss: 1.3157269477844238
---> reconstruction loss: 143.70495649612903
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-3-with.npy
loss:  142.87460327148438 1.3213260173797607
loss:  144.963134765625 1.3477795124053955
loss:  141.1226043701172 1.3415111303329468
loss:  143.98667907714844 1.3500795364379883
loss:  143.09603881835938 1.352878212928772
loss:  142.1128387451172 1.3387880325317383
loss:  141.90020751953125 1.3460077047348022
loss:  140.92860412597656 1.3629101514816284
loss:  142.9795684814453 1.3599133491516113
loss:  141.039306640625 1.3689041137695312
loss:  140.30746459960938 1.364493727684021
loss:  142.12249755859375 1.3819364309310913
loss:  141.4419403076172 1.3835828304290771
loss:  141.79156494140625 1.3741437196731567
loss:  143.0160369873047 1.392665147781372
loss:  142.57977294921875 1.3845407962799072
loss:  139.4440460205078 1.3791797161102295
loss:  141.6725311279297 1.4013264179229736
loss:  142.2768096923828 1.4064102172851562
loss:  149.30860900878906 1.4496073722839355
*******************Epoch 3 ****************** 80 0.00395
Validation Loss
*** pred loss:  90.4441146850586 pred acc: 0.15181158483028412
*** stop loss:  20.84739112854004 stop acc: 0.6080012917518616
*** template loss:  8.59961223602295 template acc: tensor(0., device='cuda:0')
*** label loss:  9.052077293395996 label acc: tensor(0.1222, device='cuda:0')
Train Loss
---> pred loss: 101.30396118164063 pred acc: 0.0836331071332097
---> stop loss: 23.487582397460937 stop acc: 0.5958146989345551
---> template loss: 8.582847595214844 tempalte acc: 0.0005031040403991937
---> molecule label loss: 9.069083404541015 molecule acc: 0.043243950605392455
---> kl loss: 1.3703991889953613
---> reconstruction loss: 142.44284131773472
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-4-with.npy
loss:  141.9306640625 1.4163258075714111
loss:  143.42796325683594 1.426111102104187
loss:  141.7700653076172 1.4191920757293701
loss:  139.1800079345703 1.4275264739990234
loss:  141.91188049316406 1.4403083324432373
loss:  138.5716094970703 1.4391449689865112
loss:  143.37606811523438 1.4477448463439941
loss:  140.11898803710938 1.4393055438995361
loss:  143.01385498046875 1.4553158283233643
loss:  140.80374145507812 1.4762282371520996
loss:  142.1340789794922 1.468188762664795
loss:  142.91885375976562 1.4924731254577637
loss:  138.83193969726562 1.477802038192749
loss:  138.94764709472656 1.5005569458007812
loss:  138.6128692626953 1.4951190948486328
loss:  138.193359375 1.4833834171295166
loss:  140.69186401367188 1.5064445734024048
loss:  137.71102905273438 1.5209336280822754
loss:  142.00155639648438 1.5349149703979492
loss:  143.11178588867188 1.5618135929107666
*******************Epoch 4 ****************** 100 0.0049499999999999995
Validation Loss
*** pred loss:  89.52716827392578 pred acc: 0.21908211708068848
*** stop loss:  20.549720764160156 stop acc: 0.621699869632721
*** template loss:  8.587651252746582 template acc: tensor(0.0004, device='cuda:0')
*** label loss:  8.971915245056152 label acc: tensor(0.3171, device='cuda:0')
Train Loss
---> pred loss: 100.19395751953125 pred acc: 0.1705889083445072
---> stop loss: 23.121873474121095 stop acc: 0.6127114504575729
---> template loss: 8.55159683227539 tempalte acc: 0.0008318630047142505
---> molecule label loss: 8.988960266113281 molecule acc: 0.27126760482788087
---> kl loss: 1.471441650390625
---> reconstruction loss: 140.85569243804932
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-5-with.npy
loss:  140.6769256591797 1.5517501831054688
loss:  140.3814239501953 1.5617671012878418
loss:  138.37574768066406 1.5590747594833374
loss:  140.7270050048828 1.5610814094543457
loss:  138.12794494628906 1.5610499382019043
loss:  139.39166259765625 1.6029064655303955
loss:  138.31988525390625 1.5828466415405273
loss:  139.23602294921875 1.6029303073883057
loss:  143.0435028076172 1.619274616241455
loss:  137.93516540527344 1.6000406742095947
loss:  139.31956481933594 1.6311872005462646
loss:  137.30934143066406 1.6454401016235352
loss:  140.722412109375 1.6520097255706787
loss:  138.96560668945312 1.6635788679122925
loss:  139.124267578125 1.6712031364440918
loss:  137.43675231933594 1.6734052896499634
loss:  139.4122772216797 1.7043497562408447
loss:  139.03927612304688 1.7237519025802612
loss:  137.66250610351562 1.7133793830871582
loss:  140.6885223388672 1.7359521389007568
*******************Epoch 5 ****************** 120 0.0059499999999999996
Validation Loss
*** pred loss:  88.4878158569336 pred acc: 0.25628018379211426
*** stop loss:  20.244720458984375 stop acc: 0.6347447037696838
*** template loss:  8.566658973693848 template acc: tensor(0.0007, device='cuda:0')
*** label loss:  8.867713928222656 label acc: tensor(0.3436, device='cuda:0')
Train Loss
---> pred loss: 99.10119018554687 pred acc: 0.2220810152590275
---> stop loss: 22.7821044921875 stop acc: 0.6296189099550247
---> template loss: 8.518279266357421 tempalte acc: 0.0010094281286001205
---> molecule label loss: 8.884268951416015 molecule acc: 0.37216553688049314
---> kl loss: 1.6308488845825195
---> reconstruction loss: 139.28508404679297
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-6-with.npy
loss:  139.36866760253906 1.7582424879074097
loss:  136.8453826904297 1.7657620906829834
loss:  137.2982940673828 1.7650840282440186
loss:  137.18666076660156 1.7794550657272339
loss:  138.94229125976562 1.7983388900756836
loss:  136.30506896972656 1.8038805723190308
loss:  135.80679321289062 1.8086395263671875
loss:  137.2324981689453 1.81121826171875
loss:  137.14158630371094 1.8423182964324951
loss:  139.47967529296875 1.867746114730835
loss:  138.2255401611328 1.8726916313171387
loss:  135.70726013183594 1.8890005350112915
loss:  138.93365478515625 1.923705816268921
loss:  137.2932586669922 1.9337760210037231
loss:  137.73797607421875 1.943148136138916
loss:  137.74667358398438 1.9503264427185059
loss:  136.5629425048828 1.976080060005188
loss:  137.60906982421875 1.990735411643982
loss:  137.71974182128906 1.9746443033218384
loss:  131.5973358154297 1.9983923435211182
*******************Epoch 6 ****************** 140 0.00695
Validation Loss
*** pred loss:  87.32904052734375 pred acc: 0.2794685959815979
*** stop loss:  19.909313201904297 stop acc: 0.6528331637382507
*** template loss:  8.545767784118652 template acc: tensor(0.0004, device='cuda:0')
*** label loss:  8.736004829406738 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 97.64700927734376 pred acc: 0.24966953992843627
---> stop loss: 22.352418518066408 stop acc: 0.648872834444046
---> template loss: 8.475957489013672 tempalte acc: 0.0015234058722853661
---> molecule label loss: 8.749483489990235 molecule acc: 0.38205685615539553
---> kl loss: 1.8726593017578126
---> reconstruction loss: 137.22400894363403
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-7-with.npy
loss:  136.22157287597656 2.0569727420806885
loss:  137.41693115234375 2.070040702819824
loss:  136.72427368164062 2.089867115020752
loss:  135.90060424804688 2.1281399726867676
loss:  135.27394104003906 2.0995874404907227
loss:  136.755859375 2.1563143730163574
loss:  137.97262573242188 2.176849842071533
loss:  135.90945434570312 2.17404842376709
loss:  135.9303436279297 2.1957356929779053
loss:  136.1620635986328 2.2064671516418457
loss:  133.47811889648438 2.2436351776123047
loss:  134.59371948242188 2.2322916984558105
loss:  136.4571533203125 2.2900137901306152
loss:  134.73760986328125 2.2924141883850098
loss:  133.69589233398438 2.307105541229248
loss:  134.66346740722656 2.3274495601654053
loss:  134.61679077148438 2.3545727729797363
loss:  135.5647430419922 2.416475296020508
loss:  134.34912109375 2.41843843460083
loss:  126.86971282958984 2.3391456604003906
*******************Epoch 7 ****************** 160 0.00795
Validation Loss
*** pred loss:  86.00897979736328 pred acc: 0.29365941882133484
*** stop loss:  19.556814193725586 stop acc: 0.6685865521430969
*** template loss:  8.521568298339844 template acc: tensor(0.0007, device='cuda:0')
*** label loss:  8.569005012512207 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 96.20944213867188 pred acc: 0.26618834808468816
---> stop loss: 21.93914031982422 stop acc: 0.6663595467805863
---> template loss: 8.423316192626952 tempalte acc: 0.0016150671988725662
---> molecule label loss: 8.576116943359375 molecule acc: 0.3822946071624756
---> kl loss: 2.228778076171875
---> reconstruction loss: 135.1469662728882
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-8-with.npy
loss:  133.05999755859375 2.497377634048462
loss:  134.65713500976562 2.489847183227539
loss:  135.71755981445312 2.544900894165039
loss:  133.15240478515625 2.546189308166504
loss:  133.87652587890625 2.567445755004883
loss:  134.73497009277344 2.610333204269409
loss:  134.19989013671875 2.6307406425476074
loss:  132.8685760498047 2.6419029235839844
loss:  135.22189331054688 2.7089037895202637
loss:  134.66949462890625 2.7331278324127197
loss:  132.03175354003906 2.756411552429199
loss:  133.56085205078125 2.776214599609375
loss:  132.30523681640625 2.7449798583984375
loss:  133.5326690673828 2.848886013031006
loss:  130.46392822265625 2.8747382164001465
loss:  133.24502563476562 2.9213597774505615
loss:  131.18824768066406 2.9376683235168457
loss:  133.2981414794922 2.9588146209716797
loss:  131.5611114501953 3.0028038024902344
loss:  138.45518493652344 3.215817451477051
*******************Epoch 8 ****************** 180 0.00895
Validation Loss
*** pred loss:  84.51982116699219 pred acc: 0.29897341132164
*** stop loss:  19.188514709472656 stop acc: 0.6816625595092773
*** template loss:  8.496569633483887 template acc: tensor(0., device='cuda:0')
*** label loss:  8.358174324035645 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 95.2141845703125 pred acc: 0.27763743996620177
---> stop loss: 21.639968872070312 stop acc: 0.6830501824617385
---> template loss: 8.362676239013672 tempalte acc: 0.0018431050702929497
---> molecule label loss: 8.34984130859375 molecule acc: 0.38228583335876465
---> kl loss: 2.750423049926758
---> reconstruction loss: 133.56539836214066
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-9-with.npy
loss:  131.61318969726562 3.131319522857666
loss:  131.54885864257812 3.051758289337158
loss:  132.05203247070312 3.129390239715576
loss:  133.38949584960938 3.2150702476501465
loss:  134.1215057373047 3.235053539276123
loss:  131.0996551513672 3.2814254760742188
loss:  131.060791015625 3.309861660003662
loss:  132.052978515625 3.3828535079956055
loss:  130.10047912597656 3.3417787551879883
loss:  131.6468963623047 3.4457669258117676
loss:  130.29776000976562 3.485258102416992
loss:  129.53977966308594 3.4575655460357666
loss:  131.19053649902344 3.533970355987549
loss:  129.16302490234375 3.5638861656188965
loss:  127.0729751586914 3.590024471282959
loss:  129.2590789794922 3.6762235164642334
loss:  130.56280517578125 3.73801851272583
loss:  129.3260498046875 3.7895169258117676
loss:  130.01544189453125 3.7743453979492188
loss:  136.4130859375 3.8786768913269043
*******************Epoch 9 ****************** 200 0.00995
Validation Loss
*** pred loss:  82.79108428955078 pred acc: 0.2996980547904968
*** stop loss:  18.81608772277832 stop acc: 0.6940847039222717
*** template loss:  8.464271545410156 template acc: tensor(0.0007, device='cuda:0')
*** label loss:  8.09948444366455 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 93.46622924804687 pred acc: 0.28005305081605913
---> stop loss: 21.21454620361328 stop acc: 0.6961795091629028
---> template loss: 8.293234252929688 tempalte acc: 0.002894306741654873
---> molecule label loss: 8.069541931152344 molecule acc: 0.3829669713973999
---> kl loss: 3.4505882263183594
---> reconstruction loss: 131.0419727994919
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-10-with.npy
loss:  127.89236450195312 3.925065755844116
loss:  129.3318634033203 3.9191439151763916
loss:  129.72195434570312 4.022387504577637
loss:  128.8567352294922 3.998129367828369
loss:  128.99818420410156 4.0998101234436035
loss:  130.36569213867188 4.140530586242676
loss:  127.3565444946289 4.2127366065979
loss:  126.09215545654297 4.238993167877197
loss:  129.3275909423828 4.294800758361816
loss:  126.98292541503906 4.396825790405273
loss:  128.20054626464844 4.488521575927734
loss:  129.0706787109375 4.437210559844971
loss:  127.91047668457031 4.577657699584961
loss:  127.36547088623047 4.592807769775391
loss:  125.47258758544922 4.659751892089844
loss:  124.70101165771484 4.6743927001953125
loss:  128.83099365234375 4.789362907409668
loss:  128.18289184570312 4.831857681274414
loss:  126.2593765258789 4.926268577575684
loss:  131.1116180419922 4.858245372772217
*******************Epoch 10 ****************** 220 0.01095
Validation Loss
*** pred loss:  80.80055236816406 pred acc: 0.2997584342956543
*** stop loss:  18.442569732666016 stop acc: 0.7054172158241272
*** template loss:  8.43541145324707 template acc: tensor(0.0014, device='cuda:0')
*** label loss:  7.790971755981445 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 91.36676025390625 pred acc: 0.28135893791913985
---> stop loss: 20.751437377929687 stop acc: 0.7088573127985001
---> template loss: 8.20835189819336 tempalte acc: 0.003282487764954567
---> molecule label loss: 7.728814697265625 molecule acc: 0.38238797187805174
---> kl loss: 4.404224395751953
---> reconstruction loss: 128.05334844989778
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-11-with.npy
loss:  126.3438720703125 5.070379257202148
loss:  125.88611602783203 5.118526458740234
loss:  124.25294494628906 5.04066801071167
loss:  125.6081771850586 5.2008514404296875
loss:  125.7413330078125 5.336215019226074
loss:  125.70366668701172 5.349651336669922
loss:  123.96134185791016 5.42569637298584
loss:  127.02322387695312 5.557524681091309
loss:  126.72418212890625 5.530447959899902
loss:  124.48532104492188 5.543606281280518
loss:  123.89824676513672 5.731594085693359
loss:  124.919921875 5.907177925109863
loss:  123.49815368652344 5.813941478729248
loss:  122.8403549194336 5.906243324279785
loss:  125.4267349243164 6.003143787384033
loss:  122.87947845458984 6.132250785827637
loss:  123.85429382324219 6.054250717163086
loss:  124.84229278564453 6.231928825378418
loss:  122.94915771484375 6.270117282867432
loss:  115.85269165039062 6.15841007232666
*******************Epoch 11 ****************** 240 0.01195
Validation Loss
*** pred loss:  78.54935455322266 pred acc: 0.2999396026134491
*** stop loss:  18.076574325561523 stop acc: 0.714383602142334
*** template loss:  8.404460906982422 template acc: tensor(0.0032, device='cuda:0')
*** label loss:  7.4371514320373535 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 88.60274658203124 pred acc: 0.2814379706978798
---> stop loss: 20.208956909179687 stop acc: 0.7193360656499863
---> template loss: 8.123416137695312 tempalte acc: 0.005179985985159874
---> molecule label loss: 7.334294128417969 molecule acc: 0.3834606409072876
---> kl loss: 5.669131088256836
---> reconstruction loss: 124.26683640302659
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-12-with.npy
loss:  122.94525146484375 6.3839521408081055
loss:  121.51307678222656 6.464667797088623
loss:  122.93770599365234 6.719794273376465
loss:  121.6697769165039 6.636502265930176
loss:  121.60511779785156 6.83419132232666
loss:  122.84390258789062 6.92699670791626
loss:  122.2098617553711 7.064004421234131
loss:  121.03328704833984 7.1931304931640625
loss:  120.24353790283203 7.103303909301758
loss:  122.53856658935547 7.317699432373047
loss:  121.93807220458984 7.3784918785095215
loss:  119.13916778564453 7.3189897537231445
loss:  120.36752319335938 7.513045787811279
loss:  120.3956298828125 7.539160251617432
loss:  121.05944061279297 7.610193252563477
loss:  118.07478332519531 7.752843856811523
loss:  119.71392059326172 7.83202600479126
loss:  121.38317108154297 7.9420061111450195
loss:  121.24005126953125 8.051227569580078
loss:  119.14144134521484 8.438390731811523
*******************Epoch 12 ****************** 260 0.01295
Validation Loss
*** pred loss:  75.9854965209961 pred acc: 0.2998792231082916
*** stop loss:  17.73263931274414 stop acc: 0.7203300595283508
*** template loss:  8.383063316345215 template acc: tensor(0.0049, device='cuda:0')
*** label loss:  7.085824012756348 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 86.25006713867188 pred acc: 0.28078472167253493
---> stop loss: 19.827677917480468 stop acc: 0.7284032344818115
---> template loss: 8.020906066894531 tempalte acc: 0.006657832115888595
---> molecule label loss: 6.909786224365234 molecule acc: 0.38216140270233157
---> kl loss: 7.3010307312011715
---> reconstruction loss: 121.00510985515595
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-13-with.npy
loss:  117.81674194335938 8.125835418701172
loss:  118.87179565429688 8.434749603271484
loss:  119.55390167236328 8.448636054992676
loss:  118.58354187011719 8.454436302185059
loss:  118.38258361816406 8.6023588180542
loss:  119.77426147460938 8.806611061096191
loss:  119.8377685546875 8.989368438720703
loss:  117.30276489257812 8.966985702514648
loss:  116.56851959228516 8.897539138793945
loss:  117.01399230957031 8.916863441467285
loss:  117.23741912841797 9.381633758544922
loss:  115.62759399414062 9.174349784851074
loss:  117.99354553222656 9.465216636657715
loss:  116.68034362792969 9.569787979125977
loss:  117.41458892822266 9.571173667907715
loss:  114.42958068847656 9.609430313110352
loss:  115.59244537353516 9.857805252075195
loss:  116.1418228149414 9.811824798583984
loss:  116.26873779296875 9.791353225708008
loss:  120.80859375 10.80566120147705
*******************Epoch 13 ****************** 280 0.01395
Validation Loss
*** pred loss:  73.17221069335938 pred acc: 0.2997584342956543
*** stop loss:  17.417804718017578 stop acc: 0.7267123460769653
*** template loss:  8.366860389709473 template acc: tensor(0.0067, device='cuda:0')
*** label loss:  6.851564884185791 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 83.50978393554688 pred acc: 0.2823930040001869
---> stop loss: 19.50401153564453 stop acc: 0.7360880732536316
---> template loss: 7.927813720703125 tempalte acc: 0.009824347496032716
---> molecule label loss: 6.529491424560547 molecule acc: 0.38307125568389894
---> kl loss: 9.184080505371094
---> reconstruction loss: 117.46690160820008
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-14-with.npy
loss:  115.24665069580078 10.189205169677734
loss:  114.41709899902344 10.163939476013184
loss:  115.11811065673828 10.491063117980957
loss:  115.46294403076172 10.520182609558105
loss:  115.87633514404297 10.561014175415039
loss:  113.55384063720703 10.785118103027344
loss:  114.35830688476562 10.758081436157227
loss:  111.53214263916016 10.651688575744629
loss:  111.6505355834961 10.832115173339844
loss:  115.95354461669922 11.026140213012695
loss:  114.4810562133789 11.187602996826172
loss:  112.95722198486328 11.104317665100098
loss:  114.51898193359375 11.216323852539062
loss:  111.7221908569336 11.40538215637207
loss:  111.03108215332031 11.454707145690918
loss:  112.31822204589844 11.491296768188477
loss:  113.39466094970703 11.899765014648438
loss:  112.81840515136719 11.685810089111328
loss:  112.90636444091797 11.729377746582031
loss:  115.17439270019531 12.05993938446045
*******************Epoch 14 ****************** 300 0.014950000000000001
Validation Loss
*** pred loss:  70.20308685302734 pred acc: 0.2997584342956543
*** stop loss:  17.13142967224121 stop acc: 0.7319427132606506
*** template loss:  8.36189079284668 template acc: tensor(0.0091, device='cuda:0')
*** label loss:  6.785924911499023 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 80.29288940429687 pred acc: 0.28083227276802064
---> stop loss: 19.094349670410157 stop acc: 0.7429219901561737
---> template loss: 7.844548034667969 tempalte acc: 0.010499912500381469
---> molecule label loss: 6.332560348510742 molecule acc: 0.3831945896148682
---> kl loss: 11.060653686523438
---> reconstruction loss: 113.55925260238648
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-15-with.npy
loss:  111.3239517211914 11.837508201599121
loss:  112.40389251708984 12.121438980102539
loss:  111.47089385986328 12.137004852294922
loss:  108.94194030761719 12.23013973236084
loss:  111.70622253417969 12.277179718017578
loss:  110.10234069824219 12.480766296386719
loss:  110.69178771972656 12.553234100341797
loss:  110.7083969116211 12.66450309753418
loss:  110.2028579711914 12.473065376281738
loss:  109.57785034179688 12.59935474395752
loss:  109.70027923583984 12.721185684204102
loss:  109.49268341064453 12.97379207611084
loss:  108.23182678222656 12.801214218139648
loss:  109.98393249511719 13.09139347076416
loss:  109.42337799072266 13.056075096130371
loss:  109.90245819091797 13.148902893066406
loss:  108.11344146728516 13.347511291503906
loss:  109.59256744384766 13.177820205688477
loss:  108.05376434326172 13.297261238098145
loss:  108.0616455078125 12.924715995788574
*******************Epoch 15 ****************** 320 0.01595
Validation Loss
*** pred loss:  67.29751586914062 pred acc: 0.2997584342956543
*** stop loss:  16.88649559020996 stop acc: 0.7402241826057434
*** template loss:  8.354016304016113 template acc: tensor(0.0098, device='cuda:0')
*** label loss:  6.765563488006592 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 76.91132202148438 pred acc: 0.28118916004896166
---> stop loss: 18.722047424316408 stop acc: 0.74981589615345
---> template loss: 7.774966430664063 tempalte acc: 0.011248230189085006
---> molecule label loss: 6.279387283325195 molecule acc: 0.38276970386505127
---> kl loss: 12.695702362060548
---> reconstruction loss: 109.68180530513763
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-16-with.npy
loss:  109.56655883789062 13.463231086730957
loss:  107.4581298828125 13.600332260131836
loss:  108.27607727050781 13.749000549316406
loss:  106.92682647705078 13.649391174316406
loss:  108.6030044555664 13.7703275680542
loss:  108.49829864501953 13.908185958862305
loss:  105.05054473876953 13.927935600280762
loss:  105.77410125732422 13.959287643432617
loss:  105.88184356689453 13.854969024658203
loss:  105.21276092529297 13.958499908447266
loss:  107.11383056640625 14.063019752502441
loss:  105.47115325927734 14.321354866027832
loss:  105.86622619628906 14.07567310333252
loss:  105.43264770507812 14.321529388427734
loss:  106.97313690185547 14.464486122131348
loss:  104.53268432617188 14.405071258544922
loss:  104.77268981933594 14.419466972351074
loss:  105.47320556640625 14.6139497756958
loss:  105.91912841796875 14.477945327758789
loss:  105.54924011230469 14.592860221862793
*******************Epoch 16 ****************** 340 0.01695
Validation Loss
*** pred loss:  64.55394744873047 pred acc: 0.29981884360313416
*** stop loss:  16.656631469726562 stop acc: 0.7465131282806396
*** template loss:  8.352914810180664 template acc: tensor(0.0098, device='cuda:0')
*** label loss:  6.729664325714111 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 73.78602294921875 pred acc: 0.2826859161257744
---> stop loss: 18.440943908691406 stop acc: 0.7567631363868713
---> template loss: 7.71716079711914 tempalte acc: 0.012173332273960114
---> molecule label loss: 6.24140739440918 molecule acc: 0.3823375225067139
---> kl loss: 14.079826354980469
---> reconstruction loss: 106.17896168937683
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-17-with.npy
loss:  103.70502471923828 14.74771499633789
loss:  103.51509094238281 14.754100799560547
loss:  105.06656646728516 15.027559280395508
loss:  103.49047088623047 14.736701965332031
loss:  103.71509552001953 15.010918617248535
loss:  103.46493530273438 15.041192054748535
loss:  104.0367431640625 15.098165512084961
loss:  103.81099700927734 15.156460762023926
loss:  104.840576171875 15.395630836486816
loss:  104.54208374023438 15.241738319396973
loss:  102.6907730102539 15.059920310974121
loss:  102.53052520751953 15.488618850708008
loss:  102.18026733398438 15.427990913391113
loss:  103.24813079833984 15.306780815124512
loss:  101.66960144042969 15.64058780670166
loss:  101.99764251708984 15.54952621459961
loss:  101.94863891601562 15.725478172302246
loss:  102.50198364257812 15.616813659667969
loss:  102.26493072509766 15.64106273651123
loss:  100.0243911743164 15.17171573638916
*******************Epoch 17 ****************** 360 0.01795
Validation Loss
*** pred loss:  62.094303131103516 pred acc: 0.2997584342956543
*** stop loss:  16.450220108032227 stop acc: 0.7515566945075989
*** template loss:  8.3536376953125 template acc: tensor(0.0106, device='cuda:0')
*** label loss:  6.692071437835693 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 70.76734008789063 pred acc: 0.28186453878879547
---> stop loss: 18.160804748535156 stop acc: 0.7630170822143555
---> template loss: 7.669010925292969 tempalte acc: 0.012112609297037124
---> molecule label loss: 6.198636627197265 molecule acc: 0.3823269844055176
---> kl loss: 15.241934204101563
---> reconstruction loss: 102.78862651931762
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-18-with.npy
loss:  101.32352447509766 15.692733764648438
loss:  101.5938720703125 15.908828735351562
loss:  101.2435302734375 15.769559860229492
loss:  101.13240051269531 16.102134704589844
loss:  100.89990234375 15.932586669921875
loss:  101.25253295898438 16.167675018310547
loss:  99.68995666503906 16.124290466308594
loss:  100.79552459716797 16.382539749145508
loss:  100.50642395019531 16.362533569335938
loss:  101.29608154296875 16.415077209472656
loss:  100.33355712890625 16.56992530822754
loss:  100.00298309326172 16.091266632080078
loss:  99.31654357910156 16.4826717376709
loss:  99.19334411621094 16.638450622558594
loss:  99.99466705322266 16.85202407836914
loss:  99.18403625488281 16.392452239990234
loss:  99.86811065673828 16.711219787597656
loss:  99.25440979003906 16.69402313232422
loss:  98.60273742675781 16.778045654296875
loss:  101.55139923095703 17.396848678588867
*******************Epoch 18 ****************** 380 0.01895
Validation Loss
*** pred loss:  59.92631149291992 pred acc: 0.2997584342956543
*** stop loss:  16.245458602905273 stop acc: 0.7589975595474243
*** template loss:  8.35521125793457 template acc: tensor(0.0091, device='cuda:0')
*** label loss:  6.660058498382568 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 68.36152954101563 pred acc: 0.28193605989217757
---> stop loss: 17.918136596679688 stop acc: 0.7707820326089859
---> template loss: 7.620230865478516 tempalte acc: 0.012526454031467437
---> molecule label loss: 6.149278259277343 molecule acc: 0.3823049545288086
---> kl loss: 16.373245239257812
---> reconstruction loss: 100.04150922927857
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-19-with.npy
loss:  98.94570922851562 16.871429443359375
loss:  98.87672424316406 16.976591110229492
loss:  97.6161880493164 16.935815811157227
loss:  97.10057067871094 16.948728561401367
loss:  99.56132507324219 17.077241897583008
loss:  97.9919662475586 17.137996673583984
loss:  97.81947326660156 17.14664649963379
loss:  97.5578842163086 17.409574508666992
loss:  98.4249038696289 17.087411880493164
loss:  96.2820816040039 17.011892318725586
loss:  98.0103530883789 17.48687171936035
loss:  98.07247161865234 17.434539794921875
loss:  98.11454010009766 17.643672943115234
loss:  97.39571380615234 17.509502410888672
loss:  95.89083862304688 17.319656372070312
loss:  96.65794372558594 17.598060607910156
loss:  98.5079345703125 17.683218002319336
loss:  96.73741149902344 17.480331420898438
loss:  96.58929443359375 17.813432693481445
loss:  97.09223937988281 17.621091842651367
*******************Epoch 19 ****************** 400 0.019950000000000002
Validation Loss
*** pred loss:  57.98592758178711 pred acc: 0.2997584342956543
*** stop loss:  16.05594253540039 stop acc: 0.7656911611557007
*** template loss:  8.363447189331055 template acc: tensor(0.0109, device='cuda:0')
*** label loss:  6.631853103637695 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 65.96155395507813 pred acc: 0.2827334403991699
---> stop loss: 17.66736602783203 stop acc: 0.7758267939090728
---> template loss: 7.591825103759765 tempalte acc: 0.013470052182674408
---> molecule label loss: 6.104363632202149 molecule acc: 0.3834435701370239
---> kl loss: 17.30968475341797
---> reconstruction loss: 97.31695206260682
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-20-with.npy
loss:  112.515869140625 17.55438232421875
loss:  113.28213500976562 17.87662696838379
loss:  113.0093765258789 17.620824813842773
loss:  112.34503173828125 17.435382843017578
loss:  112.11996459960938 17.048843383789062
loss:  113.42839050292969 17.148971557617188
loss:  112.04962158203125 16.608057022094727
loss:  112.6155014038086 16.26615333557129
loss:  111.74340057373047 16.129371643066406
loss:  110.2366943359375 15.916274070739746
loss:  110.95931243896484 15.680427551269531
loss:  109.7906265258789 15.2828950881958
loss:  109.35086059570312 14.927824020385742
loss:  110.01128387451172 14.820895195007324
loss:  109.547607421875 14.53781795501709
loss:  109.42842102050781 14.178548812866211
loss:  108.39152526855469 13.886241912841797
loss:  107.88558959960938 13.684996604919434
loss:  108.40782165527344 13.098800659179688
loss:  109.864501953125 12.688285827636719
*******************Epoch 20 ****************** 420 1.0
Validation Loss
*** pred loss:  56.61925506591797 pred acc: 0.2997584342956543
*** stop loss:  15.910205841064453 stop acc: 0.7662827372550964
*** template loss:  8.323210716247559 template acc: tensor(0.0095, device='cuda:0')
*** label loss:  6.613491535186768 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 64.12025146484375 pred acc: 0.2820362761616707
---> stop loss: 17.456240844726562 stop acc: 0.7793217599391937
---> template loss: 7.573239135742187 tempalte acc: 0.015166732668876647
---> molecule label loss: 6.079875183105469 molecule acc: 0.38280296325683594
---> kl loss: 15.619580078125
---> reconstruction loss: 95.22958984375
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-21-with.npy
loss:  107.14129638671875 12.634201049804688
loss:  106.7904052734375 12.340643882751465
loss:  105.42073822021484 11.97293758392334
loss:  107.25433349609375 11.856143951416016
loss:  107.04547119140625 11.61215591430664
loss:  105.87136840820312 11.254523277282715
loss:  103.65851593017578 11.023037910461426
loss:  105.13715362548828 10.683647155761719
loss:  103.62574005126953 10.498570442199707
loss:  103.00350189208984 10.211740493774414
loss:  102.70722198486328 10.186575889587402
loss:  104.17704010009766 9.895087242126465
loss:  103.7343521118164 9.669769287109375
loss:  102.95848083496094 9.474305152893066
loss:  102.29122924804688 9.189026832580566
loss:  100.4835433959961 8.851652145385742
loss:  101.12452697753906 8.666303634643555
loss:  101.60733795166016 8.642854690551758
loss:  100.73774719238281 8.389281272888184
loss:  99.76618194580078 8.13279914855957
*******************Epoch 21 ****************** 440 1.0
Validation Loss
*** pred loss:  55.48858642578125 pred acc: 0.30078500509262085
*** stop loss:  15.784747123718262 stop acc: 0.7694894671440125
*** template loss:  8.303838729858398 template acc: tensor(0.0106, device='cuda:0')
*** label loss:  6.609039306640625 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 62.52926025390625 pred acc: 0.282031375169754
---> stop loss: 17.244613647460938 stop acc: 0.7823985785245895
---> template loss: 7.601810455322266 tempalte acc: 0.016657212376594545
---> molecule label loss: 6.091864013671875 molecule acc: 0.382737135887146
---> kl loss: 10.259262847900391
---> reconstruction loss: 93.46754379272461
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-22-with.npy
loss:  99.69161224365234 7.885805606842041
loss:  100.58633422851562 7.778563499450684
loss:  100.55084991455078 7.592625617980957
loss:  100.22206115722656 7.278045177459717
loss:  99.56727600097656 7.198063373565674
loss:  98.77938842773438 7.029367923736572
loss:  99.46891784667969 6.843301296234131
loss:  99.3478012084961 6.6848249435424805
loss:  99.50592041015625 6.712508678436279
loss:  98.24616241455078 6.414577960968018
loss:  98.09679412841797 6.253648281097412
loss:  97.79467010498047 6.114052772521973
loss:  98.72625732421875 6.046512603759766
loss:  98.7142562866211 5.972477436065674
loss:  98.58850860595703 5.659963130950928
loss:  97.52286529541016 5.499576091766357
loss:  97.54136657714844 5.431312084197998
loss:  96.39404296875 5.277514934539795
loss:  95.42682647705078 5.271855354309082
loss:  93.7912826538086 4.7781267166137695
*******************Epoch 22 ****************** 460 1.0
Validation Loss
*** pred loss:  54.466766357421875 pred acc: 0.3050120770931244
*** stop loss:  15.667593955993652 stop acc: 0.7724159955978394
*** template loss:  8.297724723815918 template acc: tensor(0.0109, device='cuda:0')
*** label loss:  6.584561347961426 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 61.25797119140625 pred acc: 0.2840037316083908
---> stop loss: 17.074728393554686 stop acc: 0.7842595487833023
---> template loss: 7.6222373962402346 tempalte acc: 0.01895444095134735
---> molecule label loss: 6.087088394165039 molecule acc: 0.38238546848297117
---> kl loss: 6.386136245727539
---> reconstruction loss: 92.04201927185058
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-23-with.npy
loss:  97.012451171875 4.915077209472656
loss:  95.98260498046875 4.832241058349609
loss:  97.15472412109375 4.836398601531982
loss:  96.46834564208984 4.697018146514893
loss:  95.7647933959961 4.55861234664917
loss:  96.10016632080078 4.383728504180908
loss:  96.60833740234375 4.427972316741943
loss:  94.45401763916016 4.205523490905762
loss:  94.78817749023438 4.1305155754089355
loss:  94.87103271484375 4.0548906326293945
loss:  94.49627685546875 3.9811172485351562
loss:  94.35980224609375 3.868619441986084
loss:  95.35953521728516 3.831160545349121
loss:  94.57738494873047 3.738482713699341
loss:  94.56002044677734 3.652428388595581
loss:  93.60106658935547 3.4359230995178223
loss:  93.89672088623047 3.5450751781463623
loss:  92.92493438720703 3.402026891708374
loss:  92.23323822021484 3.4003167152404785
loss:  94.08489990234375 3.264425039291382
*******************Epoch 23 ****************** 480 1.0
Validation Loss
*** pred loss:  53.52521896362305 pred acc: 0.3074275255203247
*** stop loss:  15.543607711791992 stop acc: 0.775280237197876
*** template loss:  8.296778678894043 template acc: tensor(0.0098, device='cuda:0')
*** label loss:  6.552419185638428 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 60.20088500976563 pred acc: 0.2879903867840767
---> stop loss: 17.01990509033203 stop acc: 0.7865775108337403
---> template loss: 7.6301322937011715 tempalte acc: 0.019701370596885683
---> molecule label loss: 6.055935668945312 molecule acc: 0.38212883472442627
---> kl loss: 4.058077239990235
---> reconstruction loss: 90.9068519592285
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-24-with.npy
loss:  94.44781494140625 3.2264716625213623
loss:  95.18730163574219 3.2336440086364746
loss:  93.32443237304688 3.0735998153686523
loss:  93.03858184814453 3.00521183013916
loss:  92.8882064819336 2.935906171798706
loss:  91.86398315429688 2.8861312866210938
loss:  92.09654998779297 2.8439550399780273
loss:  92.88676452636719 2.71287202835083
loss:  92.18876647949219 2.735891819000244
loss:  93.0595703125 2.7481307983398438
loss:  92.2203369140625 2.5623090267181396
loss:  91.70108795166016 2.5752744674682617
loss:  91.15327453613281 2.487931728363037
loss:  91.14179229736328 2.4516825675964355
loss:  91.71852111816406 2.405055046081543
loss:  90.74579620361328 2.3667962551116943
loss:  92.25086975097656 2.315208911895752
loss:  92.09107971191406 2.335474967956543
loss:  91.94676208496094 2.223677635192871
loss:  88.42727661132812 2.138314723968506
*******************Epoch 24 ****************** 500 1.0
Validation Loss
*** pred loss:  52.68807601928711 pred acc: 0.30905795097351074
*** stop loss:  15.413461685180664 stop acc: 0.7775529623031616
*** template loss:  8.29664421081543 template acc: tensor(0.0095, device='cuda:0')
*** label loss:  6.5207839012146 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 59.14329223632812 pred acc: 0.2888228267431259
---> stop loss: 16.784255981445312 stop acc: 0.7909348368644714
---> template loss: 7.625115966796875 tempalte acc: 0.020680047571659088
---> molecule label loss: 6.003095245361328 molecule acc: 0.3836002588272095
---> kl loss: 2.663176918029785
---> reconstruction loss: 89.5557683944702
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-25-with.npy
loss:  91.0383071899414 2.121755599975586
loss:  91.5323257446289 2.1231467723846436
loss:  89.83729553222656 2.068249225616455
loss:  90.57904052734375 2.0355358123779297
loss:  90.85173034667969 1.9725533723831177
loss:  90.75365447998047 1.9704023599624634
loss:  92.1703872680664 1.9318346977233887
loss:  89.7279052734375 1.8884475231170654
loss:  90.2438735961914 1.841596245765686
loss:  90.14027404785156 1.8384530544281006
loss:  91.36254119873047 1.7999157905578613
loss:  90.33644104003906 1.7789487838745117
loss:  90.00128936767578 1.7483075857162476
loss:  91.0204086303711 1.7080585956573486
loss:  91.2047348022461 1.6687535047531128
loss:  88.9510498046875 1.6323646306991577
loss:  89.31668853759766 1.580251932144165
loss:  90.25480651855469 1.5790194272994995
loss:  89.13735961914062 1.558779001235962
loss:  92.06333923339844 1.5042415857315063
*******************Epoch 25 ****************** 520 1.0
Validation Loss
*** pred loss:  51.90650177001953 pred acc: 0.309299498796463
*** stop loss:  15.278297424316406 stop acc: 0.7810087203979492
*** template loss:  8.298683166503906 template acc: tensor(0.0106, device='cuda:0')
*** label loss:  6.49592924118042 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 58.428314208984375 pred acc: 0.28910530507564547
---> stop loss: 16.682620239257812 stop acc: 0.7938023209571838
---> template loss: 7.629679870605469 tempalte acc: 0.021206437051296233
---> molecule label loss: 5.96801986694336 molecule acc: 0.3827218770980835
---> kl loss: 1.8175308227539062
---> reconstruction loss: 88.7086410522461
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-26-with.npy
loss:  89.62931060791016 1.4853101968765259
loss:  90.71810150146484 1.4894378185272217
loss:  89.11373138427734 1.467122197151184
loss:  90.15568542480469 1.4293856620788574
loss:  89.95964050292969 1.404382586479187
loss:  88.54093933105469 1.360215187072754
loss:  89.45573425292969 1.3524701595306396
loss:  88.52030181884766 1.3419564962387085
loss:  89.35679626464844 1.300307035446167
loss:  87.95389556884766 1.281198263168335
loss:  90.25196838378906 1.300750494003296
loss:  87.35596466064453 1.2561843395233154
loss:  89.02991485595703 1.2282887697219849
loss:  87.64883422851562 1.214162826538086
loss:  88.19915008544922 1.1625276803970337
loss:  88.99858856201172 1.1816959381103516
loss:  88.50714111328125 1.1409939527511597
loss:  88.27648162841797 1.1549310684204102
loss:  88.12592315673828 1.0813100337982178
loss:  85.31302642822266 1.103082299232483
*******************Epoch 26 ****************** 540 1.0
Validation Loss
*** pred loss:  51.24612045288086 pred acc: 0.3102053105831146
*** stop loss:  15.132648468017578 stop acc: 0.7825965285301208
*** template loss:  8.303092956542969 template acc: tensor(0.0106, device='cuda:0')
*** label loss:  6.476191997528076 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 57.4372802734375 pred acc: 0.2905989959836006
---> stop loss: 16.481777954101563 stop acc: 0.7965289503335953
---> template loss: 7.610643768310547 tempalte acc: 0.021526271104812623
---> molecule label loss: 5.939063262939453 molecule acc: 0.38272743225097655
---> kl loss: 1.28678560256958
---> reconstruction loss: 87.4687747001648
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-27-with.npy
loss:  87.34754943847656 1.080354928970337
loss:  88.40630340576172 1.081023931503296
loss:  88.5898666381836 1.0490803718566895
loss:  86.16919708251953 1.0346907377243042
loss:  87.83172607421875 1.015754222869873
loss:  88.8337631225586 1.011011004447937
loss:  88.2916030883789 1.0019571781158447
loss:  87.52289581298828 0.9669808149337769
loss:  88.03111267089844 0.9671986699104309
loss:  86.82569885253906 0.9625707864761353
loss:  88.06611633300781 0.9193750023841858
loss:  87.61930084228516 0.9288743734359741
loss:  88.54922485351562 0.9208039045333862
loss:  87.67619323730469 0.886838436126709
loss:  87.14646911621094 0.8753035068511963
loss:  87.14938354492188 0.8697470426559448
loss:  87.61688995361328 0.8702603578567505
loss:  86.79082489013672 0.8615500330924988
loss:  87.63037872314453 0.8504714965820312
loss:  84.61039733886719 0.8182891607284546
*******************Epoch 27 ****************** 560 1.0
Validation Loss
*** pred loss:  50.660579681396484 pred acc: 0.3100241422653198
*** stop loss:  15.009397506713867 stop acc: 0.7844645380973816
*** template loss:  8.303339958190918 template acc: tensor(0.0123, device='cuda:0')
*** label loss:  6.457396984100342 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 56.75679321289063 pred acc: 0.29047818332910535
---> stop loss: 16.31511993408203 stop acc: 0.8000511705875397
---> template loss: 7.594454956054688 tempalte acc: 0.02195860892534256
---> molecule label loss: 5.920272445678711 molecule acc: 0.38199458122253416
---> kl loss: 0.9486067771911622
---> reconstruction loss: 86.58663492202759
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-28-with.npy
loss:  86.83538055419922 0.8176138401031494
loss:  86.32147216796875 0.8084242343902588
loss:  87.8282699584961 0.8081433773040771
loss:  86.5352783203125 0.7810044288635254
loss:  86.8694076538086 0.7876684069633484
loss:  86.20211029052734 0.7659133672714233
loss:  86.63302612304688 0.7640429735183716
loss:  88.30215454101562 0.7619283199310303
loss:  88.5979995727539 0.7589663863182068
loss:  87.25286865234375 0.7356914281845093
loss:  86.9289321899414 0.7199544906616211
loss:  86.68333435058594 0.7166146039962769
loss:  85.56733703613281 0.7006602883338928
loss:  86.09068298339844 0.7014804482460022
loss:  86.09242248535156 0.6888184547424316
loss:  86.01759338378906 0.6827943325042725
loss:  86.1754379272461 0.6844807863235474
loss:  85.43904113769531 0.6535172462463379
loss:  86.10726928710938 0.6526609063148499
loss:  86.06707000732422 0.6007994413375854
*******************Epoch 28 ****************** 580 1.0
Validation Loss
*** pred loss:  50.15170669555664 pred acc: 0.31032606959342957
*** stop loss:  14.879085540771484 stop acc: 0.7859589457511902
*** template loss:  8.30925178527832 template acc: tensor(0.0120, device='cuda:0')
*** label loss:  6.439756870269775 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 56.2623779296875 pred acc: 0.2899382129311562
---> stop loss: 16.166777038574217 stop acc: 0.8033366203308105
---> template loss: 7.584038543701172 tempalte acc: 0.022149382531642912
---> molecule label loss: 5.884592819213867 molecule acc: 0.38363358974456785
---> kl loss: 0.7295589923858643
---> reconstruction loss: 85.8977969646454
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-29-with.npy
loss:  87.32361602783203 0.6528403759002686
loss:  86.37896728515625 0.6521320939064026
loss:  84.30375671386719 0.6308261156082153
loss:  86.64712524414062 0.6327351331710815
loss:  86.36455535888672 0.6279445290565491
loss:  84.76924133300781 0.6071244478225708
loss:  85.46099853515625 0.6075700521469116
loss:  85.15949249267578 0.5997417569160461
loss:  85.79557800292969 0.5859798789024353
loss:  85.72916412353516 0.5892360806465149
loss:  86.7093734741211 0.5766807198524475
loss:  84.98274230957031 0.5727409720420837
loss:  86.15257263183594 0.5643503665924072
loss:  85.99443817138672 0.5652673244476318
loss:  85.07579803466797 0.5513405203819275
loss:  86.28579711914062 0.5426086187362671
loss:  86.38851165771484 0.5576364994049072
loss:  85.00701141357422 0.5452497005462646
loss:  85.05555725097656 0.5297858119010925
loss:  89.99273681640625 0.545245885848999
*******************Epoch 29 ****************** 600 1.0
Validation Loss
*** pred loss:  49.711212158203125 pred acc: 0.31092995405197144
*** stop loss:  14.75352954864502 stop acc: 0.7890722751617432
*** template loss:  8.313030242919922 template acc: tensor(0.0123, device='cuda:0')
*** label loss:  6.421969413757324 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 55.92067260742188 pred acc: 0.2911588504910469
---> stop loss: 16.054420471191406 stop acc: 0.8056443750858306
---> template loss: 7.560214233398438 tempalte acc: 0.022645352780818938
---> molecule label loss: 5.8566947937011715 molecule acc: 0.3836494445800781
---> kl loss: 0.5868518829345704
---> reconstruction loss: 85.39199333190918
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-30-with.npy
loss:  85.56218719482422 0.5259453058242798
loss:  84.82007598876953 0.5184112191200256
loss:  86.2461929321289 0.5200598835945129
loss:  84.97109985351562 0.5206719636917114
loss:  86.07447814941406 0.5087790489196777
loss:  84.5601806640625 0.49458181858062744
loss:  85.7287826538086 0.48866981267929077
loss:  84.56072998046875 0.4936458468437195
loss:  84.39835357666016 0.48351746797561646
loss:  84.85867309570312 0.493515282869339
loss:  84.91098022460938 0.47891566157341003
loss:  85.73009490966797 0.4692600965499878
loss:  84.38383483886719 0.466972678899765
loss:  83.9610824584961 0.46039876341819763
loss:  85.47114562988281 0.46344226598739624
loss:  85.52326965332031 0.46881264448165894
loss:  84.02793884277344 0.4607335925102234
loss:  84.91990661621094 0.46366655826568604
loss:  85.18775939941406 0.4588280916213989
loss:  81.18832397460938 0.4428977966308594
*******************Epoch 30 ****************** 620 1.0
Validation Loss
*** pred loss:  49.325069427490234 pred acc: 0.31050723791122437
*** stop loss:  14.620979309082031 stop acc: 0.7913138270378113
*** template loss:  8.315484046936035 template acc: tensor(0.0120, device='cuda:0')
*** label loss:  6.405808448791504 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 55.14451904296875 pred acc: 0.2917874321341515
---> stop loss: 15.841693115234374 stop acc: 0.8081187665462494
---> template loss: 7.5431884765625 tempalte acc: 0.022741946578025817
---> molecule label loss: 5.840760803222656 molecule acc: 0.38305752277374266
---> kl loss: 0.4840863227844238
---> reconstruction loss: 84.37017393112183
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-31-with.npy
loss:  84.41320037841797 0.4341101050376892
loss:  84.18901824951172 0.4373862147331238
loss:  83.6349868774414 0.4353315830230713
loss:  84.47705841064453 0.42714864015579224
loss:  85.38658142089844 0.4317656457424164
loss:  83.61514282226562 0.42541277408599854
loss:  84.46422576904297 0.4263736605644226
loss:  83.48839569091797 0.4246954321861267
loss:  84.43098449707031 0.42044562101364136
loss:  84.49271392822266 0.4104514718055725
loss:  84.58109283447266 0.4136441648006439
loss:  84.1160888671875 0.40525978803634644
loss:  85.03898620605469 0.4061427116394043
loss:  85.53694915771484 0.39775097370147705
loss:  84.17810821533203 0.40768370032310486
loss:  83.18131256103516 0.3871142566204071
loss:  84.2538833618164 0.3944980204105377
loss:  83.74102783203125 0.38580459356307983
loss:  85.46796417236328 0.3811121881008148
loss:  87.7413101196289 0.3792131543159485
*******************Epoch 31 ****************** 640 1.0
Validation Loss
*** pred loss:  48.97146987915039 pred acc: 0.31074878573417664
*** stop loss:  14.489724159240723 stop acc: 0.7946139574050903
*** template loss:  8.324149131774902 template acc: tensor(0.0113, device='cuda:0')
*** label loss:  6.391752243041992 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 55.004119873046875 pred acc: 0.2920141264796257
---> stop loss: 15.753837585449219 stop acc: 0.8106366008520126
---> template loss: 7.531511688232422 tempalte acc: 0.022820749878883363
---> molecule label loss: 5.820416259765625 molecule acc: 0.38247971534729003
---> kl loss: 0.41156721115112305
---> reconstruction loss: 84.10988664627075
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-32-with.npy
loss:  83.78588104248047 0.3834332525730133
loss:  83.70410919189453 0.375921368598938
loss:  85.04947662353516 0.3772507607936859
loss:  83.8074951171875 0.37129902839660645
loss:  83.90116119384766 0.3701781630516052
loss:  83.90339660644531 0.3668957054615021
loss:  83.68159484863281 0.36783367395401
loss:  82.64640808105469 0.3642381429672241
loss:  83.53807830810547 0.3662164509296417
loss:  84.04264831542969 0.36117058992385864
loss:  83.74574279785156 0.35052916407585144
loss:  83.26719665527344 0.35058099031448364
loss:  83.88276672363281 0.35141080617904663
loss:  83.11381530761719 0.3594667613506317
loss:  83.38465881347656 0.3438596725463867
loss:  83.9594955444336 0.34697479009628296
loss:  84.38579559326172 0.3378862738609314
loss:  84.0531005859375 0.3377956748008728
loss:  83.96957397460938 0.3424184322357178
loss:  81.57005310058594 0.3582320213317871
*******************Epoch 32 ****************** 660 1.0
Validation Loss
*** pred loss:  48.66031265258789 pred acc: 0.3109903335571289
*** stop loss:  14.376774787902832 stop acc: 0.7952989339828491
*** template loss:  8.32724666595459 template acc: tensor(0.0127, device='cuda:0')
*** label loss:  6.3779683113098145 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 54.444647216796874 pred acc: 0.2917808905243874
---> stop loss: 15.54622802734375 stop acc: 0.8127556085586548
---> template loss: 7.516862487792968 tempalte acc: 0.02352260649204254
---> molecule label loss: 5.802714538574219 molecule acc: 0.38224718570709226
---> kl loss: 0.35917956829071046
---> reconstruction loss: 83.31043713092804
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-33-with.npy
loss:  84.30929565429688 0.33381375670433044
loss:  82.3794174194336 0.33475393056869507
loss:  83.8967514038086 0.330772340297699
loss:  83.33303833007812 0.3327183723449707
loss:  83.0296630859375 0.3228537142276764
loss:  83.20523071289062 0.3306765556335449
loss:  83.76529693603516 0.3226816654205322
loss:  82.49983215332031 0.31906238198280334
loss:  82.96919250488281 0.3217536211013794
loss:  82.9544677734375 0.31997913122177124
loss:  83.9672622680664 0.32179102301597595
loss:  84.57108306884766 0.30748122930526733
loss:  83.79654693603516 0.31150370836257935
loss:  83.44034576416016 0.3119499683380127
loss:  82.5284423828125 0.3159908950328827
loss:  82.96819305419922 0.31137019395828247
loss:  82.08112335205078 0.3054125905036926
loss:  82.77437591552734 0.29821106791496277
loss:  82.71684265136719 0.29929739236831665
loss:  86.42597961425781 0.3256986141204834
*******************Epoch 33 ****************** 680 1.0
Validation Loss
*** pred loss:  48.383480072021484 pred acc: 0.3111715018749237
*** stop loss:  14.248611450195312 stop acc: 0.7974159717559814
*** template loss:  8.330686569213867 template acc: tensor(0.0130, device='cuda:0')
*** label loss:  6.365130424499512 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 54.26563720703125 pred acc: 0.2921145990490913
---> stop loss: 15.523928833007812 stop acc: 0.8143977105617524
---> template loss: 7.498117828369141 tempalte acc: 0.023004317283630372
---> molecule label loss: 5.774048614501953 molecule acc: 0.3833984613418579
---> kl loss: 0.31888861656188966
---> reconstruction loss: 83.06173272132874
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-34-with.npy
loss:  84.04714965820312 0.30428868532180786
loss:  82.92667388916016 0.3032861351966858
loss:  83.22146606445312 0.29005151987075806
loss:  84.25255584716797 0.2924811840057373
loss:  82.72563171386719 0.2963848114013672
loss:  81.97711181640625 0.29330193996429443
loss:  82.27976989746094 0.283672571182251
loss:  82.39075469970703 0.2904384136199951
loss:  81.86048126220703 0.29415857791900635
loss:  82.4464340209961 0.2869149446487427
loss:  82.35458374023438 0.2770324945449829
loss:  83.61661529541016 0.28161415457725525
loss:  82.1409683227539 0.28341394662857056
loss:  82.99581909179688 0.27919822931289673
loss:  81.44457244873047 0.2798249125480652
loss:  82.45121002197266 0.28167176246643066
loss:  82.73808288574219 0.27627426385879517
loss:  82.30400848388672 0.2768482565879822
loss:  83.9029769897461 0.27997463941574097
loss:  83.40953063964844 0.28145796060562134
*******************Epoch 34 ****************** 700 1.0
Validation Loss
*** pred loss:  48.14564895629883 pred acc: 0.31189611554145813
*** stop loss:  14.138985633850098 stop acc: 0.7990348935127258
*** template loss:  8.338393211364746 template acc: tensor(0.0137, device='cuda:0')
*** label loss:  6.353814125061035 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 53.893304443359376 pred acc: 0.292084838449955
---> stop loss: 15.327403259277343 stop acc: 0.816710090637207
---> template loss: 7.5021614074707035 tempalte acc: 0.023370008170604705
---> molecule label loss: 5.764834976196289 molecule acc: 0.3824377298355103
---> kl loss: 0.2866144418716431
---> reconstruction loss: 82.48769586086273
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-35-with.npy
loss:  81.59435272216797 0.26231446862220764
loss:  82.33006286621094 0.27405935525894165
loss:  82.64080047607422 0.27372533082962036
loss:  82.80133056640625 0.26521265506744385
loss:  83.35327911376953 0.2674786448478699
loss:  82.440673828125 0.2705293297767639
loss:  82.38566589355469 0.26806455850601196
loss:  82.3126449584961 0.2646307647228241
loss:  82.84898376464844 0.2637895345687866
loss:  81.71748352050781 0.25917646288871765
loss:  83.11001586914062 0.26161259412765503
loss:  82.2926254272461 0.26569658517837524
loss:  82.83570861816406 0.2568708062171936
loss:  80.7009048461914 0.2605218291282654
loss:  83.04271697998047 0.2588256597518921
loss:  81.42900085449219 0.2503904104232788
loss:  82.77020263671875 0.24767464399337769
loss:  81.9526138305664 0.2525893747806549
loss:  80.9712905883789 0.2447449266910553
loss:  81.4214859008789 0.2548863887786865
*******************Epoch 35 ****************** 720 1.0
Validation Loss
*** pred loss:  47.909690856933594 pred acc: 0.3115941882133484
*** stop loss:  14.02115535736084 stop acc: 0.8004047870635986
*** template loss:  8.343213081359863 template acc: tensor(0.0130, device='cuda:0')
*** label loss:  6.342239856719971 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 53.55552978515625 pred acc: 0.2939549282193184
---> stop loss: 15.2072021484375 stop acc: 0.8183167308568955
---> template loss: 7.4817756652832035 tempalte acc: 0.023712830245494844
---> molecule label loss: 5.741941452026367 molecule acc: 0.3834184169769287
---> kl loss: 0.2611397266387939
---> reconstruction loss: 81.98645548820497
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-36-with.npy
loss:  81.62275695800781 0.2513878047466278
loss:  81.77029418945312 0.2506919205188751
loss:  81.15867614746094 0.24889540672302246
loss:  83.27012634277344 0.24943473935127258
loss:  82.4014663696289 0.2430105209350586
loss:  83.39079284667969 0.23934602737426758
loss:  82.46570587158203 0.23683299124240875
loss:  81.31905364990234 0.2458438277244568
loss:  82.26385498046875 0.24316206574440002
loss:  82.32585906982422 0.23974326252937317
loss:  80.98918151855469 0.2461281418800354
loss:  81.38103485107422 0.23663564026355743
loss:  81.53495025634766 0.23766013979911804
loss:  82.34412384033203 0.24055880308151245
loss:  81.00801086425781 0.23498541116714478
loss:  80.93020629882812 0.22846004366874695
loss:  81.36466217041016 0.2329208254814148
loss:  82.51493072509766 0.23628464341163635
loss:  80.93695068359375 0.2332163155078888
loss:  84.8269271850586 0.2444598376750946
*******************Epoch 36 ****************** 740 1.0
Validation Loss
*** pred loss:  47.70131301879883 pred acc: 0.31183573603630066
*** stop loss:  13.913741111755371 stop acc: 0.8025529384613037
*** template loss:  8.352396965026855 template acc: tensor(0.0123, device='cuda:0')
*** label loss:  6.330504894256592 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 53.50004272460937 pred acc: 0.2920662447810173
---> stop loss: 15.060604858398438 stop acc: 0.82043916285038
---> template loss: 7.463249206542969 tempalte acc: 0.02377230077981949
---> molecule label loss: 5.7260997772216795 molecule acc: 0.3825516223907471
---> kl loss: 0.24098291397094726
---> reconstruction loss: 81.74998388290405
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-37-with.npy
loss:  82.0661392211914 0.22635748982429504
loss:  80.79472351074219 0.23101985454559326
loss:  83.53160095214844 0.23104959726333618
loss:  80.43627166748047 0.22913764417171478
loss:  82.64141082763672 0.22760608792304993
loss:  80.67961120605469 0.23154401779174805
loss:  80.93492889404297 0.2290477752685547
loss:  80.52228546142578 0.22144219279289246
loss:  81.8180923461914 0.22479110956192017
loss:  81.60511779785156 0.22553013265132904
loss:  81.75203704833984 0.2211032509803772
loss:  81.06117248535156 0.21909794211387634
loss:  80.96591186523438 0.21950583159923553
loss:  81.20265197753906 0.21743915975093842
loss:  81.09465789794922 0.22063994407653809
loss:  80.9188003540039 0.21714460849761963
loss:  81.59122467041016 0.2200087010860443
loss:  81.31666564941406 0.21817371249198914
loss:  82.37680053710938 0.2214038372039795
loss:  82.25437927246094 0.22003993391990662
*******************Epoch 37 ****************** 760 1.0
Validation Loss
*** pred loss:  47.486202239990234 pred acc: 0.31262075901031494
*** stop loss:  13.804863929748535 stop acc: 0.8036737442016602
*** template loss:  8.358003616333008 template acc: tensor(0.0127, device='cuda:0')
*** label loss:  6.3203887939453125 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 53.12333984375 pred acc: 0.29381455928087236
---> stop loss: 14.9531982421875 stop acc: 0.821166455745697
---> template loss: 7.461016082763672 tempalte acc: 0.024357348680496216
---> molecule label loss: 5.717064285278321 molecule acc: 0.3822519302368164
---> kl loss: 0.22360413074493407
---> reconstruction loss: 81.25461852550507
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-38-with.npy
loss:  81.16349029541016 0.21567124128341675
loss:  80.91156768798828 0.21350917220115662
loss:  81.09697723388672 0.21010752022266388
loss:  81.64395141601562 0.22089818120002747
loss:  81.41170501708984 0.21524909138679504
loss:  80.56239318847656 0.2165852189064026
loss:  81.82911682128906 0.21486113965511322
loss:  80.88391876220703 0.21379327774047852
loss:  81.71188354492188 0.21472963690757751
loss:  80.43148803710938 0.2095516175031662
loss:  82.33291625976562 0.20399026572704315
loss:  80.72686767578125 0.20839542150497437
loss:  80.25374603271484 0.2123430073261261
loss:  80.24008178710938 0.20302604138851166
loss:  80.53192138671875 0.20808303356170654
loss:  81.06503295898438 0.19980859756469727
loss:  81.1089859008789 0.20242586731910706
loss:  81.06845092773438 0.19897808134555817
loss:  81.2402572631836 0.20004373788833618
loss:  80.53504180908203 0.1893874704837799
*******************Epoch 38 ****************** 780 1.0
Validation Loss
*** pred loss:  47.313934326171875 pred acc: 0.31334540247917175
*** stop loss:  13.710241317749023 stop acc: 0.8048568367958069
*** template loss:  8.361836433410645 template acc: tensor(0.0130, device='cuda:0')
*** label loss:  6.3100996017456055 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 52.86103515625 pred acc: 0.2944472908973694
---> stop loss: 14.814944458007812 stop acc: 0.8226633787155151
---> template loss: 7.452493286132812 tempalte acc: 0.023481330275535582
---> molecule label loss: 5.700448608398437 molecule acc: 0.38227319717407227
---> kl loss: 0.2085718870162964
---> reconstruction loss: 80.82891590595246
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-39-with.npy
loss:  80.93757629394531 0.2056286334991455
loss:  80.65438842773438 0.20132847130298615
loss:  81.56586456298828 0.20058190822601318
loss:  80.26216125488281 0.2009296417236328
loss:  81.35260772705078 0.19431814551353455
loss:  81.02485656738281 0.19375094771385193
loss:  81.15135955810547 0.20331770181655884
loss:  81.250732421875 0.19907720386981964
loss:  79.57839965820312 0.19979526102542877
loss:  81.2081069946289 0.19241347908973694
loss:  81.21812438964844 0.19817161560058594
loss:  80.43152618408203 0.1892905831336975
loss:  79.93809509277344 0.19174297153949738
loss:  79.5750732421875 0.20067043602466583
loss:  80.61742401123047 0.1912110447883606
loss:  80.63660430908203 0.19550268352031708
loss:  80.59642791748047 0.197655588388443
loss:  79.94114685058594 0.19897571206092834
loss:  80.93659210205078 0.19466155767440796
loss:  82.74385070800781 0.16341069340705872
*******************Epoch 39 ****************** 800 1.0
Validation Loss
*** pred loss:  47.11623764038086 pred acc: 0.31352657079696655
*** stop loss:  13.599616050720215 stop acc: 0.8068493604660034
*** template loss:  8.367270469665527 template acc: tensor(0.0134, device='cuda:0')
*** label loss:  6.299149990081787 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 52.759759521484376 pred acc: 0.2947783634066582
---> stop loss: 14.701132202148438 stop acc: 0.8257277071475982
---> template loss: 7.438910675048828 tempalte acc: 0.023767252266407014
---> molecule label loss: 5.685614776611328 molecule acc: 0.38223001956939695
---> kl loss: 0.19562171697616576
---> reconstruction loss: 80.58543297052384
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-40-with.npy
loss:  80.71179962158203 0.19298559427261353
loss:  80.08998107910156 0.18421366810798645
loss:  79.7186050415039 0.19500134885311127
loss:  80.43164825439453 0.19447177648544312
loss:  79.71809387207031 0.1875465363264084
loss:  81.38352966308594 0.18424788117408752
loss:  79.83021545410156 0.19502855837345123
loss:  80.48453521728516 0.18650414049625397
loss:  79.778564453125 0.1825782060623169
loss:  80.61341094970703 0.19240552186965942
loss:  79.30158996582031 0.18509002029895782
loss:  80.9339828491211 0.18332946300506592
loss:  79.4541244506836 0.18450161814689636
loss:  81.55387115478516 0.17940929532051086
loss:  79.96349334716797 0.1889740228652954
loss:  79.90538024902344 0.17666307091712952
loss:  80.60990905761719 0.1770516335964203
loss:  80.84771728515625 0.18809588253498077
loss:  81.14096069335938 0.18540939688682556
loss:  78.40860748291016 0.17266127467155457
*******************Epoch 40 ****************** 820 1.0
Validation Loss
*** pred loss:  46.9615364074707 pred acc: 0.3150966167449951
*** stop loss:  13.498067855834961 stop acc: 0.8076276779174805
*** template loss:  8.37852668762207 template acc: tensor(0.0127, device='cuda:0')
*** label loss:  6.292564392089844 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 52.38837890625 pred acc: 0.2958600282669067
---> stop loss: 14.550736999511718 stop acc: 0.8268053293228149
---> template loss: 7.453168487548828 tempalte acc: 0.022896188497543334
---> molecule label loss: 5.66590461730957 molecule acc: 0.3833913803100586
---> kl loss: 0.18580845594406128
---> reconstruction loss: 80.05818568468095
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-41-with.npy
loss:  79.72734832763672 0.17674702405929565
loss:  81.12445068359375 0.1764359176158905
loss:  80.34424591064453 0.1851692646741867
loss:  80.44226837158203 0.17619803547859192
loss:  80.3109130859375 0.18081039190292358
loss:  80.37942504882812 0.1777971088886261
loss:  80.15032196044922 0.18307214975357056
loss:  79.7398910522461 0.18323083221912384
loss:  79.92525482177734 0.1808977872133255
loss:  79.58781433105469 0.17924395203590393
loss:  79.5194320678711 0.1718253493309021
loss:  79.90560913085938 0.18075108528137207
loss:  80.23335266113281 0.17246603965759277
loss:  79.65885162353516 0.17611688375473022
loss:  79.60774993896484 0.17066770792007446
loss:  79.34263610839844 0.17632433772087097
loss:  78.80382537841797 0.1738218069076538
loss:  80.94345092773438 0.17069685459136963
loss:  79.88993072509766 0.1716371476650238
loss:  82.05298614501953 0.20575019717216492
*******************Epoch 41 ****************** 840 1.0
Validation Loss
*** pred loss:  46.773719787597656 pred acc: 0.31600239872932434
*** stop loss:  13.397340774536133 stop acc: 0.8100560903549194
*** template loss:  8.383193969726562 template acc: tensor(0.0130, device='cuda:0')
*** label loss:  6.286455154418945 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 52.342767333984376 pred acc: 0.2956830978393555
---> stop loss: 14.45507354736328 stop acc: 0.8284893423318863
---> template loss: 7.440410614013672 tempalte acc: 0.023743484914302827
---> molecule label loss: 5.667749404907227 molecule acc: 0.3821988821029663
---> kl loss: 0.17848299741744994
---> reconstruction loss: 79.9060018658638
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-42-with.npy
loss:  79.66450500488281 0.1763446033000946
loss:  79.92536163330078 0.1708325743675232
loss:  80.78211212158203 0.17349621653556824
loss:  78.13093566894531 0.17345234751701355
loss:  78.89492797851562 0.1718345433473587
loss:  79.67459106445312 0.16620762646198273
loss:  79.70413970947266 0.17309123277664185
loss:  80.6827392578125 0.17143875360488892
loss:  79.14863586425781 0.16470283269882202
loss:  79.84494018554688 0.16621997952461243
loss:  80.56682586669922 0.17326946556568146
loss:  80.30522918701172 0.16407378017902374
loss:  79.71674346923828 0.16225340962409973
loss:  80.5970230102539 0.1650288999080658
loss:  79.87825775146484 0.1683330535888672
loss:  79.82614135742188 0.17156025767326355
loss:  78.54412841796875 0.16933104395866394
loss:  78.61534118652344 0.1577734649181366
loss:  79.0439682006836 0.1686357855796814
loss:  77.80567169189453 0.16528788208961487
*******************Epoch 42 ****************** 860 1.0
Validation Loss
*** pred loss:  46.62079620361328 pred acc: 0.31600239872932434
*** stop loss:  13.303154945373535 stop acc: 0.8119863271713257
*** template loss:  8.389906883239746 template acc: tensor(0.0127, device='cuda:0')
*** label loss:  6.278191089630127 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 52.002923583984376 pred acc: 0.29741674214601516
---> stop loss: 14.328352355957032 stop acc: 0.8307953894138336
---> template loss: 7.420832824707031 tempalte acc: 0.023536890745162964
---> molecule label loss: 5.646839904785156 molecule acc: 0.3831455230712891
---> kl loss: 0.16865838766098024
---> reconstruction loss: 79.39896246194839
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-43-with.npy
loss:  78.08512115478516 0.1636805236339569
loss:  79.82767486572266 0.16618388891220093
loss:  79.20526885986328 0.1664135754108429
loss:  78.00077056884766 0.1673879325389862
loss:  78.75233459472656 0.16172420978546143
loss:  79.6163558959961 0.1544254720211029
loss:  79.54439544677734 0.16179543733596802
loss:  79.24810791015625 0.1676071286201477
loss:  80.486328125 0.15474678575992584
loss:  80.11687469482422 0.16205842792987823
loss:  79.2066421508789 0.15961173176765442
loss:  79.11862182617188 0.1589491218328476
loss:  78.81060791015625 0.1664179563522339
loss:  79.47332000732422 0.15869590640068054
loss:  79.60147857666016 0.16178098320960999
loss:  79.21668243408203 0.1591164618730545
loss:  79.66658020019531 0.16441410779953003
loss:  79.39361572265625 0.15963026881217957
loss:  79.93519592285156 0.15300852060317993
loss:  78.72057342529297 0.1556749790906906
*******************Epoch 43 ****************** 880 1.0
Validation Loss
*** pred loss:  46.450801849365234 pred acc: 0.3167874217033386
*** stop loss:  13.211004257202148 stop acc: 0.8132005333900452
*** template loss:  8.392315864562988 template acc: tensor(0.0137, device='cuda:0')
*** label loss:  6.273680210113525 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 51.86700439453125 pred acc: 0.29837990999221803
---> stop loss: 14.230152893066407 stop acc: 0.8321030020713807
---> template loss: 7.416645812988281 tempalte acc: 0.023979753255844116
---> molecule label loss: 5.626355743408203 molecule acc: 0.38381452560424806
---> kl loss: 0.16116617918014525
---> reconstruction loss: 79.14015218019486
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-44-with.npy
loss:  80.27859497070312 0.15909914672374725
loss:  78.81829071044922 0.16194689273834229
loss:  79.50027465820312 0.15471014380455017
loss:  78.81130981445312 0.158147931098938
loss:  78.29444122314453 0.15603744983673096
loss:  80.31362915039062 0.15676890313625336
loss:  79.02808380126953 0.15621279180049896
loss:  77.93596649169922 0.15319858491420746
loss:  79.15457916259766 0.1556934118270874
loss:  78.4969253540039 0.15083327889442444
loss:  78.46542358398438 0.15348075330257416
loss:  78.98579406738281 0.15683460235595703
loss:  78.65518188476562 0.16127561032772064
loss:  78.04248046875 0.15428301692008972
loss:  79.99839782714844 0.15319937467575073
loss:  80.36185455322266 0.1477113664150238
loss:  77.96263122558594 0.1455220729112625
loss:  79.56798553466797 0.15445846319198608
loss:  78.6409912109375 0.15230274200439453
loss:  77.9312515258789 0.14201778173446655
*******************Epoch 44 ****************** 900 1.0
Validation Loss
*** pred loss:  46.288883209228516 pred acc: 0.3189009726047516
*** stop loss:  13.110514640808105 stop acc: 0.8145081400871277
*** template loss:  8.400047302246094 template acc: tensor(0.0137, device='cuda:0')
*** label loss:  6.269540786743164 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 51.66481323242188 pred acc: 0.29779485762119295
---> stop loss: 14.11865692138672 stop acc: 0.8327051997184753
---> template loss: 7.407996368408203 tempalte acc: 0.024151915311813356
---> molecule label loss: 5.616543579101562 molecule acc: 0.3836242198944092
---> kl loss: 0.15418672561645508
---> reconstruction loss: 78.80802030563355
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-45-with.npy
loss:  77.81455993652344 0.15191656351089478
loss:  79.02163696289062 0.15325722098350525
loss:  79.23561096191406 0.15601137280464172
loss:  79.5988540649414 0.1513747274875641
loss:  78.7571792602539 0.14539971947669983
loss:  78.5881118774414 0.14820387959480286
loss:  78.83797454833984 0.14892980456352234
loss:  78.12712860107422 0.14125418663024902
loss:  78.5379867553711 0.15569522976875305
loss:  78.83583068847656 0.1522149294614792
loss:  79.102294921875 0.14721278846263885
loss:  78.06156921386719 0.1439201831817627
loss:  78.71376037597656 0.1467181295156479
loss:  78.78266143798828 0.14900153875350952
loss:  78.5877914428711 0.14662949740886688
loss:  78.88793182373047 0.14728021621704102
loss:  78.4012222290039 0.14323225617408752
loss:  79.22848510742188 0.1522800624370575
loss:  78.19239044189453 0.1472625881433487
loss:  78.98590850830078 0.1093435287475586
*******************Epoch 45 ****************** 920 1.0
Validation Loss
*** pred loss:  46.139095306396484 pred acc: 0.319625586271286
*** stop loss:  13.022184371948242 stop acc: 0.8162827491760254
*** template loss:  8.406031608581543 template acc: tensor(0.0141, device='cuda:0')
*** label loss:  6.265839099884033 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 51.53641967773437 pred acc: 0.299870590865612
---> stop loss: 14.020556640625 stop acc: 0.8342812806367874
---> template loss: 7.393832397460938 tempalte acc: 0.023620909452438353
---> molecule label loss: 5.617280960083008 molecule acc: 0.38253805637359617
---> kl loss: 0.1468569278717041
---> reconstruction loss: 78.56809058189391
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-46-with.npy
loss:  78.1024398803711 0.14758653938770294
loss:  78.71089172363281 0.14620688557624817
loss:  79.0785903930664 0.14245003461837769
loss:  78.27875518798828 0.14384397864341736
loss:  78.37071228027344 0.14231446385383606
loss:  78.8664779663086 0.15292271971702576
loss:  78.52986907958984 0.13775314390659332
loss:  78.27056121826172 0.1445559561252594
loss:  78.44078826904297 0.13701166212558746
loss:  77.77481079101562 0.14187923073768616
loss:  79.04893493652344 0.14615215361118317
loss:  79.32674407958984 0.14359326660633087
loss:  78.67092895507812 0.14030472934246063
loss:  77.95144653320312 0.14435002207756042
loss:  78.32227325439453 0.14078465104103088
loss:  78.7709732055664 0.1385756880044937
loss:  77.83850860595703 0.1469402015209198
loss:  77.301025390625 0.14142963290214539
loss:  77.8527603149414 0.14348018169403076
loss:  79.21705627441406 0.15300080180168152
*******************Epoch 46 ****************** 940 1.0
Validation Loss
*** pred loss:  45.97774887084961 pred acc: 0.32216182351112366
*** stop loss:  12.929534912109375 stop acc: 0.817123293876648
*** template loss:  8.40932559967041 template acc: tensor(0.0137, device='cuda:0')
*** label loss:  6.263612270355225 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 51.34278564453125 pred acc: 0.3018100902438164
---> stop loss: 13.932887268066406 stop acc: 0.8346828609704972
---> template loss: 7.401902770996093 tempalte acc: 0.02429604232311249
---> molecule label loss: 5.614895629882812 molecule acc: 0.3823620080947876
---> kl loss: 0.14375679492950438
---> reconstruction loss: 78.2924736738205
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-47-with.npy
loss:  78.96074676513672 0.13827352225780487
loss:  80.08360290527344 0.14265167713165283
loss:  77.68605041503906 0.14271268248558044
loss:  78.05001068115234 0.1409367024898529
loss:  77.30770874023438 0.13943208754062653
loss:  78.5317611694336 0.13708610832691193
loss:  77.7216796875 0.1407942920923233
loss:  77.37886810302734 0.13883453607559204
loss:  77.08271789550781 0.1400725245475769
loss:  78.5293197631836 0.1378697156906128
loss:  78.9872055053711 0.1302737444639206
loss:  78.22076416015625 0.13712775707244873
loss:  77.71062469482422 0.1315891295671463
loss:  77.6826171875 0.1468941867351532
loss:  79.15324401855469 0.13648945093154907
loss:  77.5266342163086 0.138698548078537
loss:  78.00591278076172 0.13413912057876587
loss:  78.3504409790039 0.1403236836194992
loss:  77.1362075805664 0.1369100958108902
loss:  74.15677642822266 0.13983577489852905
*******************Epoch 47 ****************** 960 1.0
Validation Loss
*** pred loss:  45.8192253112793 pred acc: 0.32572463154792786
*** stop loss:  12.857625961303711 stop acc: 0.8179638981819153
*** template loss:  8.418776512145996 template acc: tensor(0.0137, device='cuda:0')
*** label loss:  6.259185314178467 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 50.97160034179687 pred acc: 0.3044186532497406
---> stop loss: 13.801095581054687 stop acc: 0.8361187279224396
---> template loss: 7.390069580078125 tempalte acc: 0.02374504804611206
---> molecule label loss: 5.6118316650390625 molecule acc: 0.3824711084365845
---> kl loss: 0.13854727745056153
---> reconstruction loss: 77.77458748817445
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-48-with.npy
loss:  78.22872924804688 0.1363946795463562
loss:  77.11978149414062 0.13282595574855804
loss:  78.15829467773438 0.13038143515586853
loss:  77.43157958984375 0.13628001511096954
loss:  77.62549591064453 0.1379859745502472
loss:  77.97261047363281 0.13363409042358398
loss:  78.45037841796875 0.13735266029834747
loss:  77.92694091796875 0.13844165205955505
loss:  78.07369232177734 0.12999340891838074
loss:  77.86211395263672 0.1306157410144806
loss:  78.81710052490234 0.13712066411972046
loss:  77.44120788574219 0.13443949818611145
loss:  77.84397888183594 0.13698367774486542
loss:  76.8440170288086 0.1352277547121048
loss:  78.07829284667969 0.12918029725551605
loss:  77.0859603881836 0.13448670506477356
loss:  77.19344329833984 0.1340242624282837
loss:  77.83422088623047 0.12927770614624023
loss:  78.2471923828125 0.13084127008914948
loss:  76.36245727539062 0.13436031341552734
*******************Epoch 48 ****************** 980 1.0
Validation Loss
*** pred loss:  45.66701889038086 pred acc: 0.32820048928260803
*** stop loss:  12.765088081359863 stop acc: 0.8208593130111694
*** template loss:  8.42051887512207 template acc: tensor(0.0144, device='cuda:0')
*** label loss:  6.2574076652526855 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 50.899862670898436 pred acc: 0.3069747626781464
---> stop loss: 13.711592102050782 stop acc: 0.8370404452085495
---> template loss: 7.39276123046875 tempalte acc: 0.024211949110031127
---> molecule label loss: 5.591664123535156 molecule acc: 0.3830927610397339
---> kl loss: 0.13399238586425782
---> reconstruction loss: 77.59587821960449
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-49-with.npy
loss:  77.87628173828125 0.13029301166534424
loss:  77.76203918457031 0.1325792521238327
loss:  77.16658782958984 0.1339685469865799
loss:  76.97509765625 0.1343022733926773
loss:  78.32656860351562 0.12326153367757797
loss:  76.87632751464844 0.13250380754470825
loss:  78.08187866210938 0.13330495357513428
loss:  78.27428436279297 0.13236793875694275
loss:  78.028076171875 0.12946881353855133
loss:  77.91073608398438 0.13204048573970795
loss:  77.03269958496094 0.1256110966205597
loss:  76.45021057128906 0.1376619040966034
loss:  77.55128479003906 0.12457656860351562
loss:  76.64727020263672 0.12614847719669342
loss:  77.4165267944336 0.13450957834720612
loss:  78.28753662109375 0.12010923773050308
loss:  75.7880859375 0.13047049939632416
loss:  78.05907440185547 0.12508530914783478
loss:  78.05760192871094 0.12699171900749207
loss:  77.15354919433594 0.13753999769687653
*******************Epoch 49 ****************** 1000 1.0
Validation Loss
*** pred loss:  45.49797439575195 pred acc: 0.33061593770980835
*** stop loss:  12.68213176727295 stop acc: 0.8216687440872192
*** template loss:  8.429935455322266 template acc: tensor(0.0144, device='cuda:0')
*** label loss:  6.255728721618652 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 50.75426330566406 pred acc: 0.3097273364663124
---> stop loss: 13.63873748779297 stop acc: 0.8379481971263886
---> template loss: 7.382224273681641 tempalte acc: 0.0239782452583313
---> molecule label loss: 5.580715560913086 molecule acc: 0.38427436351776123
---> kl loss: 0.13013975620269774
---> reconstruction loss: 77.3559442281723
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-50-with.npy
loss:  77.37971496582031 0.1267867237329483
loss:  77.72842407226562 0.12582479417324066
loss:  77.1627197265625 0.12258841097354889
loss:  76.2579574584961 0.12166833877563477
loss:  76.58389282226562 0.1307220309972763
loss:  78.04155731201172 0.12638604640960693
loss:  78.5763931274414 0.12716417014598846
loss:  77.57144927978516 0.1278482973575592
loss:  76.83556365966797 0.12520159780979156
loss:  77.75990295410156 0.1237054392695427
loss:  77.68401336669922 0.1252116560935974
loss:  76.64907836914062 0.13116192817687988
loss:  77.09954833984375 0.1255558282136917
loss:  77.45613098144531 0.12377673387527466
loss:  77.30467224121094 0.1206182911992073
loss:  76.83937072753906 0.12484671175479889
loss:  76.6756591796875 0.12595751881599426
loss:  76.97126007080078 0.12910234928131104
loss:  76.34603881835938 0.12950405478477478
loss:  79.27622985839844 0.109040766954422
*******************Epoch 50 ****************** 1020 1.0
Validation Loss
*** pred loss:  45.36188888549805 pred acc: 0.3344202935695648
*** stop loss:  12.59748363494873 stop acc: 0.8221980333328247
*** template loss:  8.4306058883667 template acc: tensor(0.0141, device='cuda:0')
*** label loss:  6.254003047943115 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 50.681704711914065 pred acc: 0.31083447486162186
---> stop loss: 13.554269409179687 stop acc: 0.8392529249191284
---> template loss: 7.374111938476562 tempalte acc: 0.023383814096450805
---> molecule label loss: 5.5747638702392575 molecule acc: 0.38329472541809084
---> kl loss: 0.12513357400894165
---> reconstruction loss: 77.18485177755356
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-51-with.npy
loss:  77.79735565185547 0.12451279163360596
loss:  76.64522552490234 0.1303609311580658
loss:  76.33354949951172 0.12279675900936127
loss:  77.23214721679688 0.11993415653705597
loss:  75.81127166748047 0.12541994452476501
loss:  77.704833984375 0.1181146651506424
loss:  76.39813232421875 0.12468014657497406
loss:  76.55329895019531 0.11907041072845459
loss:  76.60098266601562 0.12422704696655273
loss:  76.62278747558594 0.12053203582763672
loss:  77.10822296142578 0.1252848207950592
loss:  78.56825256347656 0.12371979653835297
loss:  77.39881134033203 0.11946422606706619
loss:  76.8873519897461 0.11997252702713013
loss:  76.95750427246094 0.11860889196395874
loss:  76.82479095458984 0.12421179562807083
loss:  76.89884185791016 0.1312790960073471
loss:  76.94892120361328 0.12140383571386337
loss:  75.98560333251953 0.11263282597064972
loss:  79.83683013916016 0.1084413155913353
*******************Epoch 51 ****************** 1040 1.0
Validation Loss
*** pred loss:  45.192867279052734 pred acc: 0.33774152398109436
*** stop loss:  12.522831916809082 stop acc: 0.823630154132843
*** template loss:  8.436260223388672 template acc: tensor(0.0144, device='cuda:0')
*** label loss:  6.251357555389404 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 50.5248779296875 pred acc: 0.31353702694177626
---> stop loss: 13.460110473632813 stop acc: 0.8398053646087646
---> template loss: 7.370401763916016 tempalte acc: 0.023964104056358338
---> molecule label loss: 5.578611373901367 molecule acc: 0.3826024055480957
---> kl loss: 0.12173340320587159
---> reconstruction loss: 76.93400390148163
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-52-with.npy
loss:  76.43450164794922 0.12162438035011292
loss:  75.5604248046875 0.11828309297561646
loss:  76.40396118164062 0.12417387217283249
loss:  77.08194732666016 0.11973784863948822
loss:  77.17135620117188 0.12060314416885376
loss:  76.717041015625 0.11433492600917816
loss:  77.07876586914062 0.12364945560693741
loss:  77.44989013671875 0.12319744378328323
loss:  76.11540985107422 0.11725344508886337
loss:  76.23892211914062 0.12263628095388412
loss:  77.07276153564453 0.1203097552061081
loss:  76.82392883300781 0.1139087826013565
loss:  76.22699737548828 0.11827312409877777
loss:  76.51374053955078 0.12203174829483032
loss:  76.20938873291016 0.1183345764875412
loss:  76.61469268798828 0.10906489938497543
loss:  76.91316986083984 0.12015359848737717
loss:  77.74691009521484 0.11772491037845612
loss:  75.65054321289062 0.11575953662395477
loss:  78.82568359375 0.12335886806249619
*******************Epoch 52 ****************** 1060 1.0
Validation Loss
*** pred loss:  45.04533767700195 pred acc: 0.3395531177520752
*** stop loss:  12.444092750549316 stop acc: 0.8257472515106201
*** template loss:  8.435548782348633 template acc: tensor(0.0141, device='cuda:0')
*** label loss:  6.252190113067627 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 50.28722229003906 pred acc: 0.31791517734527586
---> stop loss: 13.408787536621094 stop acc: 0.8401403903961182
---> template loss: 7.362806701660157 tempalte acc: 0.024721498787403106
---> molecule label loss: 5.564461135864258 molecule acc: 0.38293521404266356
---> kl loss: 0.1192206859588623
---> reconstruction loss: 76.62328419685363
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-53-with.npy
loss:  76.6684799194336 0.11616656184196472
loss:  76.95096588134766 0.11750005185604095
loss:  75.99662780761719 0.11705831438302994
loss:  76.6682357788086 0.11570075154304504
loss:  75.68547821044922 0.1170351430773735
loss:  76.42924499511719 0.11807554960250854
loss:  75.92744445800781 0.12194487452507019
loss:  76.72509765625 0.11452315747737885
loss:  75.95640563964844 0.11027100682258606
loss:  76.61256408691406 0.11296287178993225
loss:  76.61669921875 0.10960501432418823
loss:  76.5447769165039 0.1137852892279625
loss:  76.72108459472656 0.11416464298963547
loss:  76.29788208007812 0.1180025115609169
loss:  75.97493743896484 0.11297665536403656
loss:  76.4046859741211 0.1170852780342102
loss:  75.36741638183594 0.12150277942419052
loss:  77.60079193115234 0.11433246731758118
loss:  75.99041748046875 0.11989036202430725
loss:  71.64921569824219 0.13112692534923553
*******************Epoch 53 ****************** 1080 1.0
Validation Loss
*** pred loss:  44.89920425415039 pred acc: 0.3408816456794739
*** stop loss:  12.359243392944336 stop acc: 0.826151967048645
*** template loss:  8.44169807434082 template acc: tensor(0.0148, device='cuda:0')
*** label loss:  6.2502264976501465 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 49.864132690429685 pred acc: 0.3188464313745499
---> stop loss: 13.223416137695313 stop acc: 0.8417949646711349
---> template loss: 7.367361450195313 tempalte acc: 0.024075610935688017
---> molecule label loss: 5.5678253173828125 molecule acc: 0.3821094274520874
---> kl loss: 0.11668550968170166
---> reconstruction loss: 76.02274320125579
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-54-with.npy
loss:  74.55218505859375 0.11944577842950821
loss:  75.9381332397461 0.11496102809906006
loss:  76.4223403930664 0.11488242447376251
loss:  77.13614654541016 0.11457718908786774
loss:  75.57830047607422 0.11203619837760925
loss:  75.96699523925781 0.11136269569396973
loss:  76.38311767578125 0.11523723602294922
loss:  75.60677337646484 0.11186778545379639
loss:  76.4263916015625 0.11303509771823883
loss:  76.91268920898438 0.11157762259244919
loss:  76.22359466552734 0.1122916042804718
loss:  76.32562255859375 0.1139708161354065
loss:  76.41728973388672 0.10883219540119171
loss:  75.85778045654297 0.11094015836715698
loss:  75.92344665527344 0.1109657734632492
loss:  76.58512115478516 0.11290320008993149
loss:  75.51970672607422 0.11399731040000916
loss:  75.21266174316406 0.11491339653730392
loss:  76.46083068847656 0.11279510706663132
loss:  78.89138793945312 0.10597161948680878
*******************Epoch 54 ****************** 1100 1.0
Validation Loss
*** pred loss:  44.74547576904297 pred acc: 0.34221014380455017
*** stop loss:  12.291288375854492 stop acc: 0.8281444907188416
*** template loss:  8.444188117980957 template acc: tensor(0.0144, device='cuda:0')
*** label loss:  6.251328468322754 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 49.936221313476565 pred acc: 0.3198655962944031
---> stop loss: 13.26764373779297 stop acc: 0.8423028022050858
---> template loss: 7.350227355957031 tempalte acc: 0.024654267728328703
---> molecule label loss: 5.550095748901367 molecule acc: 0.38392229080200196
---> kl loss: 0.11282820701599121
---> reconstruction loss: 76.10418839454651
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-55-with.npy
loss:  76.31670379638672 0.1136329174041748
loss:  76.1680679321289 0.1074577197432518
loss:  75.45101928710938 0.110307477414608
loss:  75.45673370361328 0.10871048271656036
loss:  75.98066711425781 0.11113137006759644
loss:  75.87094116210938 0.11184197664260864
loss:  75.94681549072266 0.11261025816202164
loss:  75.16091918945312 0.11539626121520996
loss:  76.23248291015625 0.11464238166809082
loss:  76.10702514648438 0.10665321350097656
loss:  76.28282928466797 0.10610920190811157
loss:  76.39754486083984 0.1138249933719635
loss:  75.9944839477539 0.10950155556201935
loss:  75.1390609741211 0.10894196480512619
loss:  75.2877197265625 0.10438413172960281
loss:  75.058837890625 0.10814563184976578
loss:  75.90796661376953 0.10546117275953293
loss:  75.93060302734375 0.11422686278820038
loss:  75.81959533691406 0.11271965503692627
loss:  74.8028335571289 0.12260862439870834
*******************Epoch 55 ****************** 1120 1.0
Validation Loss
*** pred loss:  44.57897186279297 pred acc: 0.3423912823200226
*** stop loss:  12.206341743469238 stop acc: 0.8288916945457458
*** template loss:  8.45138931274414 template acc: tensor(0.0151, device='cuda:0')
*** label loss:  6.248982906341553 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 49.665277099609376 pred acc: 0.3205320104956627
---> stop loss: 13.096359252929688 stop acc: 0.843613225221634
---> template loss: 7.340813446044922 tempalte acc: 0.02511097490787506
---> molecule label loss: 5.552276611328125 molecule acc: 0.38306758403778074
---> kl loss: 0.11091538667678832
---> reconstruction loss: 75.65472792387008
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-56-with.npy
loss:  74.969970703125 0.10920649021863937
loss:  75.42544555664062 0.10598983615636826
loss:  75.52717590332031 0.10914592444896698
loss:  74.82819366455078 0.11141534894704819
loss:  76.90097045898438 0.10380056500434875
loss:  75.08181762695312 0.10948796570301056
loss:  75.76447296142578 0.1046808734536171
loss:  74.6963119506836 0.10789243876934052
loss:  75.73233032226562 0.10311375558376312
loss:  74.11221313476562 0.1067354679107666
loss:  76.38335418701172 0.10538788139820099
loss:  77.38632202148438 0.10695771872997284
loss:  75.9290542602539 0.11046814918518066
loss:  76.80028533935547 0.10216660797595978
loss:  75.25743103027344 0.11149708926677704
loss:  74.76886749267578 0.11246378719806671
loss:  75.49156951904297 0.1129765659570694
loss:  75.00907135009766 0.10941072553396225
loss:  75.22781372070312 0.10846352577209473
loss:  77.45503997802734 0.08764877915382385
*******************Epoch 56 ****************** 1140 1.0
Validation Loss
*** pred loss:  44.41802978515625 pred acc: 0.342934787273407
*** stop loss:  12.144769668579102 stop acc: 0.8297945261001587
*** template loss:  8.45231819152832 template acc: tensor(0.0148, device='cuda:0')
*** label loss:  6.252310276031494 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 49.56739196777344 pred acc: 0.32171477675437926
---> stop loss: 13.090371704101562 stop acc: 0.8447360187768936
---> template loss: 7.332724761962891 tempalte acc: 0.02490948438644409
---> molecule label loss: 5.539949798583985 molecule acc: 0.38385207653045655
---> kl loss: 0.10694549083709717
---> reconstruction loss: 75.53043854236603
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-57-with.npy
loss:  74.5304183959961 0.10511046648025513
loss:  76.7529296875 0.1073494553565979
loss:  75.92735290527344 0.10968232154846191
loss:  74.54788970947266 0.1070270985364914
loss:  75.27476501464844 0.10411808639764786
loss:  76.09292602539062 0.10857916623353958
loss:  75.50535583496094 0.10274061560630798
loss:  74.83394622802734 0.1019560843706131
loss:  75.66064453125 0.10845007002353668
loss:  74.85618591308594 0.10329048335552216
loss:  75.63809204101562 0.10677071660757065
loss:  74.7645263671875 0.10783277451992035
loss:  74.76903533935547 0.09956933557987213
loss:  75.02935791015625 0.10199730843305588
loss:  75.12879180908203 0.10490937530994415
loss:  74.99028778076172 0.10129201412200928
loss:  74.90858459472656 0.10380162298679352
loss:  76.05462646484375 0.11358756572008133
loss:  75.1829605102539 0.10403025150299072
loss:  74.135498046875 0.11474856734275818
*******************Epoch 57 ****************** 1160 1.0
Validation Loss
*** pred loss:  44.280609130859375 pred acc: 0.34317630529403687
*** stop loss:  12.0697021484375 stop acc: 0.8313823342323303
*** template loss:  8.452530860900879 template acc: tensor(0.0151, device='cuda:0')
*** label loss:  6.250041961669922 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 49.28886413574219 pred acc: 0.3226456791162491
---> stop loss: 12.955729675292968 stop acc: 0.8451044142246247
---> template loss: 7.3357398986816404 tempalte acc: 0.025024539232254027
---> molecule label loss: 5.543037414550781 molecule acc: 0.38282184600830077
---> kl loss: 0.10584216117858887
---> reconstruction loss: 75.12336316108704
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-58-with.npy
loss:  74.45541381835938 0.10944630205631256
loss:  75.63037109375 0.10257554054260254
loss:  75.08417510986328 0.10413296520709991
loss:  73.83204650878906 0.10207220911979675
loss:  74.33031463623047 0.10479936748743057
loss:  74.86285400390625 0.10074187815189362
loss:  75.03132629394531 0.10255101323127747
loss:  75.45220184326172 0.10724250972270966
loss:  73.89038848876953 0.10692290961742401
loss:  73.97090911865234 0.10528938472270966
loss:  75.48240661621094 0.09899760782718658
loss:  74.02915954589844 0.10615059733390808
loss:  75.19204711914062 0.1084514856338501
loss:  75.99395751953125 0.09410424530506134
loss:  74.99834442138672 0.10051533579826355
loss:  76.01202392578125 0.09770581871271133
loss:  76.67915344238281 0.0994100272655487
loss:  75.78990936279297 0.10212297737598419
loss:  74.40511322021484 0.10458089411258698
loss:  77.9564437866211 0.11553193628787994
*******************Epoch 58 ****************** 1180 1.0
Validation Loss
*** pred loss:  44.13826370239258 pred acc: 0.3432367146015167
*** stop loss:  12.013842582702637 stop acc: 0.831693708896637
*** template loss:  8.458457946777344 template acc: tensor(0.0158, device='cuda:0')
*** label loss:  6.251476287841797 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 49.20060424804687 pred acc: 0.3234214290976524
---> stop loss: 12.978204345703125 stop acc: 0.8455640971660614
---> template loss: 7.332328033447266 tempalte acc: 0.02458137720823288
---> molecule label loss: 5.539119720458984 molecule acc: 0.38282482624053954
---> kl loss: 0.1036672592163086
---> reconstruction loss: 75.05025730133056
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-59-with.npy
loss:  74.49820709228516 0.10423482954502106
loss:  75.81107330322266 0.10415080189704895
loss:  74.44744110107422 0.10377681255340576
loss:  74.60879516601562 0.10405676066875458
loss:  74.38591003417969 0.0976237803697586
loss:  75.07563781738281 0.10587695240974426
loss:  74.76130676269531 0.10141102969646454
loss:  75.14189147949219 0.10158295929431915
loss:  75.65668487548828 0.10514236986637115
loss:  74.66023254394531 0.09517588466405869
loss:  74.50049591064453 0.09969346225261688
loss:  75.08621215820312 0.0953793153166771
loss:  74.07180786132812 0.09793911874294281
loss:  74.39274597167969 0.09891843050718307
loss:  74.74052429199219 0.10006806254386902
loss:  73.97219848632812 0.09758985787630081
loss:  75.57854461669922 0.10166681557893753
loss:  74.48019409179688 0.09969447553157806
loss:  74.61067199707031 0.1023806557059288
loss:  73.22730255126953 0.0995047390460968
*******************Epoch 59 ****************** 1200 1.0
Validation Loss
*** pred loss:  43.985328674316406 pred acc: 0.34371981024742126
*** stop loss:  11.928909301757812 stop acc: 0.8336239457130432
*** template loss:  8.461647033691406 template acc: tensor(0.0155, device='cuda:0')
*** label loss:  6.2511515617370605 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 48.9184326171875 pred acc: 0.32364179790019987
---> stop loss: 12.814311218261718 stop acc: 0.8462473005056381
---> template loss: 7.320890045166015 tempalte acc: 0.025031778216362
---> molecule label loss: 5.530968475341797 molecule acc: 0.3831494808197021
---> kl loss: 0.10079336166381836
---> reconstruction loss: 74.58458871841431
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-60-with.npy
loss:  74.98101806640625 0.09782908856868744
loss:  74.81053924560547 0.09865599870681763
loss:  75.2352294921875 0.10317367315292358
loss:  74.20280456542969 0.09748837351799011
loss:  75.23632049560547 0.09878181666135788
loss:  75.53176879882812 0.10085488110780716
loss:  74.12471008300781 0.0990644097328186
loss:  74.32299041748047 0.09961763024330139
loss:  73.96800994873047 0.09891827404499054
loss:  73.80835723876953 0.09440672397613525
loss:  74.98743438720703 0.09916171431541443
loss:  74.51477813720703 0.09682716429233551
loss:  74.54735565185547 0.10376936942338943
loss:  73.54798889160156 0.09634833037853241
loss:  75.00424194335938 0.09669670462608337
loss:  74.75788879394531 0.10037557780742645
loss:  74.53857421875 0.09729808568954468
loss:  73.28697967529297 0.09919779002666473
loss:  74.39106750488281 0.09853790700435638
loss:  69.6996841430664 0.11388454586267471
*******************Epoch 60 ****************** 1220 1.0
Validation Loss
*** pred loss:  43.840511322021484 pred acc: 0.34396135807037354
*** stop loss:  11.867512702941895 stop acc: 0.8346201777458191
*** template loss:  8.464730262756348 template acc: tensor(0.0144, device='cuda:0')
*** label loss:  6.252209663391113 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 48.640167236328125 pred acc: 0.32372585237026213
---> stop loss: 12.687266540527343 stop acc: 0.847106671333313
---> template loss: 7.323386383056641 tempalte acc: 0.024758298695087434
---> molecule label loss: 5.52452392578125 molecule acc: 0.38398764133453367
---> kl loss: 0.09954440593719482
---> reconstruction loss: 74.17535183429717
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-61-with.npy
loss:  75.78475189208984 0.1015697568655014
loss:  75.3516616821289 0.09693378955125809
loss:  74.17182922363281 0.10194235295057297
loss:  75.37911224365234 0.09781758487224579
loss:  75.63239288330078 0.09392407536506653
loss:  74.48521423339844 0.09739412367343903
loss:  74.15152740478516 0.09992069751024246
loss:  75.48939514160156 0.094968281686306
loss:  73.7008285522461 0.0954214483499527
loss:  75.33167266845703 0.09168070554733276
loss:  73.27954864501953 0.09064008295536041
loss:  73.37796783447266 0.09537957608699799
loss:  73.91829681396484 0.09431317448616028
loss:  73.60533905029297 0.0983368456363678
loss:  73.6005630493164 0.09383782744407654
loss:  72.94713592529297 0.09332506358623505
loss:  73.0967025756836 0.09725946933031082
loss:  73.96556854248047 0.10638869553804398
loss:  73.10724639892578 0.0990336686372757
loss:  73.96392822265625 0.10079317539930344
*******************Epoch 61 ****************** 1240 1.0
Validation Loss
*** pred loss:  43.68697738647461 pred acc: 0.34432366490364075
*** stop loss:  11.80201244354248 stop acc: 0.8358966708183289
*** template loss:  8.468111991882324 template acc: tensor(0.0151, device='cuda:0')
*** label loss:  6.251007080078125 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 48.61454467773437 pred acc: 0.32513048350811
---> stop loss: 12.66244888305664 stop acc: 0.8483497619628906
---> template loss: 7.313161468505859 tempalte acc: 0.024585963785648347
---> molecule label loss: 5.529835510253906 molecule acc: 0.38324751853942873
---> kl loss: 0.09704402089118958
---> reconstruction loss: 74.11998478770256
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-62-with.npy
loss:  73.83444213867188 0.09597074240446091
loss:  74.45993041992188 0.09411042928695679
loss:  74.80607604980469 0.1004611924290657
loss:  74.1470947265625 0.0981312170624733
loss:  73.83118438720703 0.09634898602962494
loss:  74.51380157470703 0.09447166323661804
loss:  73.35729217529297 0.09317834675312042
loss:  74.35218811035156 0.09582094848155975
loss:  74.4676284790039 0.09378933161497116
loss:  73.62776184082031 0.09802722930908203
loss:  73.20787048339844 0.08906536549329758
loss:  74.3189468383789 0.09420543909072876
loss:  74.30142974853516 0.09622614830732346
loss:  73.81749725341797 0.09397746622562408
loss:  74.51538848876953 0.09497731924057007
loss:  73.06621551513672 0.09020811319351196
loss:  73.69490814208984 0.09325939416885376
loss:  73.99272918701172 0.09798607230186462
loss:  73.22335815429688 0.09519213438034058
loss:  72.90866088867188 0.08689508587121964
*******************Epoch 62 ****************** 1260 1.0
Validation Loss
*** pred loss:  43.538604736328125 pred acc: 0.3463164269924164
*** stop loss:  11.743463516235352 stop acc: 0.835585355758667
*** template loss:  8.472543716430664 template acc: tensor(0.0151, device='cuda:0')
*** label loss:  6.250993251800537 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 48.40101318359375 pred acc: 0.3257626801729202
---> stop loss: 12.571579742431641 stop acc: 0.8494509547948838
---> template loss: 7.312889099121094 tempalte acc: 0.024678544700145723
---> molecule label loss: 5.542120742797851 molecule acc: 0.38133902549743653
---> kl loss: 0.09461511969566345
---> reconstruction loss: 73.82760778069496
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-63-with.npy
loss:  74.01859283447266 0.10053897649049759
loss:  72.7513198852539 0.09786403924226761
loss:  74.45734405517578 0.09302730858325958
loss:  74.05915832519531 0.09542913734912872
loss:  73.8866958618164 0.09794555604457855
loss:  73.63097381591797 0.09447485208511353
loss:  73.36493682861328 0.09160767495632172
loss:  72.90325164794922 0.0927838459610939
loss:  73.71794128417969 0.08857876062393188
loss:  73.84930419921875 0.09649467468261719
loss:  74.94610595703125 0.09551163762807846
loss:  74.71529388427734 0.08832448720932007
loss:  74.06304931640625 0.09063967317342758
loss:  74.10468292236328 0.09382982552051544
loss:  73.15675354003906 0.09167036414146423
loss:  72.6682357788086 0.09062634408473969
loss:  73.985595703125 0.08699347078800201
loss:  73.6663589477539 0.09223644435405731
loss:  72.95352172851562 0.09153693914413452
loss:  71.6428451538086 0.1019488051533699
*******************Epoch 63 ****************** 1280 1.0
Validation Loss
*** pred loss:  43.39475631713867 pred acc: 0.34692028164863586
*** stop loss:  11.690719604492188 stop acc: 0.8364881873130798
*** template loss:  8.469545364379883 template acc: tensor(0.0158, device='cuda:0')
*** label loss:  6.251647472381592 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 48.198281860351564 pred acc: 0.32571026086807253
---> stop loss: 12.51641387939453 stop acc: 0.8493490070104599
---> template loss: 7.298066711425781 tempalte acc: 0.02490426301956177
---> molecule label loss: 5.520735168457032 molecule acc: 0.38259689807891845
---> kl loss: 0.09360315203666687
---> reconstruction loss: 73.53349645733833
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-64-with.npy
loss:  73.28380584716797 0.09160101413726807
loss:  74.01382446289062 0.0879058912396431
loss:  74.2099609375 0.08603639900684357
loss:  74.06745147705078 0.09418345987796783
loss:  73.25204467773438 0.09257738292217255
loss:  72.96100616455078 0.08385521918535233
loss:  73.31837463378906 0.09574467688798904
loss:  72.92371368408203 0.09607376158237457
loss:  73.02164459228516 0.08946790546178818
loss:  72.42843627929688 0.09510203450918198
loss:  72.96298217773438 0.08571243286132812
loss:  74.15621948242188 0.09323394298553467
loss:  74.65599822998047 0.09023407846689224
loss:  72.80511474609375 0.09403566271066666
loss:  73.45455932617188 0.09156873822212219
loss:  73.308837890625 0.09450406581163406
loss:  73.05614471435547 0.0937245786190033
loss:  73.96105194091797 0.0869593396782875
loss:  73.89250946044922 0.09651907533407211
loss:  76.54767608642578 0.08263079822063446
*******************Epoch 64 ****************** 1300 1.0
Validation Loss
*** pred loss:  43.25386047363281 pred acc: 0.34806761145591736
*** stop loss:  11.644286155700684 stop acc: 0.8370797038078308
*** template loss:  8.476271629333496 template acc: tensor(0.0151, device='cuda:0')
*** label loss:  6.2546844482421875 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 48.239968872070314 pred acc: 0.32639458030462265
---> stop loss: 12.464893341064453 stop acc: 0.8506889969110489
---> template loss: 7.303739166259765 tempalte acc: 0.024635882675647737
---> molecule label loss: 5.514378356933594 molecule acc: 0.38384988307952883
---> kl loss: 0.09108352065086364
---> reconstruction loss: 73.52298508286475
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-65-with.npy
loss:  73.86738586425781 0.08670686185359955
loss:  72.83743286132812 0.09263452887535095
loss:  72.79135131835938 0.0874951034784317
loss:  73.14949035644531 0.09532678127288818
loss:  73.82386779785156 0.09395129978656769
loss:  73.8603744506836 0.08825092017650604
loss:  72.86933898925781 0.08880556374788284
loss:  72.5298080444336 0.09221106767654419
loss:  73.67535400390625 0.08567453175783157
loss:  72.44817352294922 0.0921236202120781
loss:  72.66547393798828 0.09031987190246582
loss:  73.4944076538086 0.0943356454372406
loss:  72.942626953125 0.08656349778175354
loss:  74.09874725341797 0.09195366501808167
loss:  72.97394561767578 0.08447265625
loss:  73.68780517578125 0.08933163434267044
loss:  73.78453063964844 0.0929398164153099
loss:  72.88931274414062 0.08517665416002274
loss:  72.67057037353516 0.08780404180288315
loss:  75.34523010253906 0.09368637204170227
*******************Epoch 65 ****************** 1320 1.0
Validation Loss
*** pred loss:  43.11502456665039 pred acc: 0.3489130437374115
*** stop loss:  11.568160057067871 stop acc: 0.8387297987937927
*** template loss:  8.477654457092285 template acc: tensor(0.0151, device='cuda:0')
*** label loss:  6.253928184509277 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 48.01173400878906 pred acc: 0.3274389237165451
---> stop loss: 12.400399017333985 stop acc: 0.851986414194107
---> template loss: 7.2873779296875 tempalte acc: 0.024096739292144776
---> molecule label loss: 5.53076171875 molecule acc: 0.382092022895813
---> kl loss: 0.08998820781707764
---> reconstruction loss: 73.23026936054231
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-66-with.npy
loss:  73.18952178955078 0.08771485090255737
loss:  74.0981216430664 0.08812183141708374
loss:  73.06293487548828 0.08779947459697723
loss:  72.09317779541016 0.09074921905994415
loss:  72.65005493164062 0.08614589273929596
loss:  72.83477783203125 0.09059955179691315
loss:  73.2058334350586 0.0821266770362854
loss:  73.67770385742188 0.08706586062908173
loss:  71.34734344482422 0.0871075913310051
loss:  73.09298706054688 0.0871487408876419
loss:  72.83841705322266 0.08658582717180252
loss:  73.02639770507812 0.08971823006868362
loss:  72.97594451904297 0.09319105744361877
loss:  74.14029693603516 0.09360578656196594
loss:  72.5911865234375 0.0849439948797226
loss:  73.22686004638672 0.08655324578285217
loss:  72.90807342529297 0.08344916254281998
loss:  71.888427734375 0.08885320276021957
loss:  73.494873046875 0.09496323764324188
loss:  74.18681335449219 0.09516893327236176
*******************Epoch 66 ****************** 1340 1.0
Validation Loss
*** pred loss:  42.9641227722168 pred acc: 0.3508453965187073
*** stop loss:  11.512459754943848 stop acc: 0.8398506045341492
*** template loss:  8.477365493774414 template acc: tensor(0.0148, device='cuda:0')
*** label loss:  6.25592041015625 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 47.791586303710936 pred acc: 0.32741995006799696
---> stop loss: 12.339730072021485 stop acc: 0.8522318214178085
---> template loss: 7.28893814086914 tempalte acc: 0.024393750727176665
---> molecule label loss: 5.517651748657227 molecule acc: 0.38339838981628416
---> kl loss: 0.0885806143283844
---> reconstruction loss: 72.93790253996849
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-67-with.npy
loss:  73.08702087402344 0.08975133299827576
loss:  72.27887725830078 0.0874495655298233
loss:  72.1355209350586 0.08146516978740692
loss:  73.67085266113281 0.08563382178544998
loss:  73.27423858642578 0.08782283961772919
loss:  72.79161071777344 0.08833608031272888
loss:  74.41678619384766 0.09156571328639984
loss:  72.34089660644531 0.08569052815437317
loss:  72.38227081298828 0.08845965564250946
loss:  71.28632354736328 0.08540572971105576
loss:  72.7834243774414 0.08732758462429047
loss:  72.62686157226562 0.0859532430768013
loss:  72.87554168701172 0.08938130736351013
loss:  73.0437240600586 0.09055767953395844
loss:  73.25065612792969 0.08594517409801483
loss:  72.29273223876953 0.08253075927495956
loss:  72.72061920166016 0.08627393841743469
loss:  72.86639404296875 0.08090721070766449
loss:  71.77338409423828 0.08625911921262741
loss:  72.62055206298828 0.10009227693080902
*******************Epoch 67 ****************** 1360 1.0
Validation Loss
*** pred loss:  42.817874908447266 pred acc: 0.35199275612831116
*** stop loss:  11.46156120300293 stop acc: 0.8402242064476013
*** template loss:  8.481990814208984 template acc: tensor(0.0151, device='cuda:0')
*** label loss:  6.254422664642334 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 47.59996337890625 pred acc: 0.3278095290064812
---> stop loss: 12.241630554199219 stop acc: 0.8534540504217147
---> template loss: 7.284648895263672 tempalte acc: 0.024810744822025298
---> molecule label loss: 5.512328720092773 molecule acc: 0.38299453258514404
---> kl loss: 0.08734043836593627
---> reconstruction loss: 72.6385750889778
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-68-with.npy
loss:  72.3897705078125 0.09178486466407776
loss:  72.94105529785156 0.08560275286436081
loss:  72.57189178466797 0.08647552877664566
loss:  73.34785461425781 0.08119562268257141
loss:  71.780517578125 0.0877435952425003
loss:  71.42454528808594 0.08803701400756836
loss:  71.83001708984375 0.08867515623569489
loss:  72.79981994628906 0.08029055595397949
loss:  72.63957214355469 0.08576743304729462
loss:  73.50934600830078 0.09077616035938263
loss:  72.95925903320312 0.0849958062171936
loss:  71.95174407958984 0.084520623087883
loss:  72.13636779785156 0.08577341586351395
loss:  73.01318359375 0.08262087404727936
loss:  72.78138732910156 0.08096492290496826
loss:  72.74566650390625 0.08127684891223907
loss:  72.88580322265625 0.08174565434455872
loss:  71.70828247070312 0.08741503953933716
loss:  72.09089660644531 0.08384698629379272
loss:  70.30341339111328 0.09470123052597046
*******************Epoch 68 ****************** 1380 1.0
Validation Loss
*** pred loss:  42.68348693847656 pred acc: 0.35163041949272156
*** stop loss:  11.412957191467285 stop acc: 0.8399440050125122
*** template loss:  8.483683586120605 template acc: tensor(0.0155, device='cuda:0')
*** label loss:  6.257429599761963 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 47.354315185546874 pred acc: 0.32735540717840195
---> stop loss: 12.17602081298828 stop acc: 0.8532876521348953
---> template loss: 7.269989013671875 tempalte acc: 0.025586265325546264
---> molecule label loss: 5.504483795166015 molecule acc: 0.38303585052490235
---> kl loss: 0.08571051359176636
---> reconstruction loss: 72.30481072664261
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-69-with.npy
loss:  72.31672668457031 0.0886024683713913
loss:  72.25648498535156 0.08390791714191437
loss:  72.09949493408203 0.08282797038555145
loss:  72.20696258544922 0.08994048833847046
loss:  72.13874816894531 0.0774519294500351
loss:  73.1562271118164 0.08545747399330139
loss:  72.01826477050781 0.09094201773405075
loss:  72.29769134521484 0.08290661871433258
loss:  71.90282440185547 0.0806594118475914
loss:  71.79878234863281 0.08772894740104675
loss:  71.84162902832031 0.08729217946529388
loss:  72.09500122070312 0.08294198662042618
loss:  71.87258911132812 0.07854796200990677
loss:  73.36825561523438 0.08551336079835892
loss:  72.28982543945312 0.08016064018011093
loss:  71.56341552734375 0.08000844717025757
loss:  72.74469757080078 0.08365535736083984
loss:  72.02300262451172 0.08253239095211029
loss:  72.83844757080078 0.08284015953540802
loss:  71.76664733886719 0.08028614521026611
*******************Epoch 69 ****************** 1400 1.0
Validation Loss
*** pred loss:  42.54170227050781 pred acc: 0.3530193269252777
*** stop loss:  11.367377281188965 stop acc: 0.8405666351318359
*** template loss:  8.486127853393555 template acc: tensor(0.0155, device='cuda:0')
*** label loss:  6.257125377655029 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 47.23221435546875 pred acc: 0.3295049384236336
---> stop loss: 12.13089599609375 stop acc: 0.8547420710325241
---> template loss: 7.270436859130859 tempalte acc: 0.024973832070827484
---> molecule label loss: 5.512528610229492 molecule acc: 0.3827859878540039
---> kl loss: 0.08371019959449769
---> reconstruction loss: 72.14607495665551
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-70-with.npy
loss:  71.67518615722656 0.08328234404325485
loss:  72.71126556396484 0.07889269292354584
loss:  72.49942779541016 0.08335462212562561
loss:  71.84896850585938 0.08410583436489105
loss:  71.8580551147461 0.08351549506187439
loss:  71.40740966796875 0.08267427980899811
loss:  71.66889953613281 0.08152914047241211
loss:  72.16785430908203 0.08198558539152145
loss:  71.8660888671875 0.08783021569252014
loss:  72.45753479003906 0.08454658836126328
loss:  72.7193374633789 0.08138684928417206
loss:  72.44705963134766 0.08507455885410309
loss:  71.4346694946289 0.08215473592281342
loss:  71.13008880615234 0.07816187292337418
loss:  71.49894714355469 0.0829107016324997
loss:  72.20635223388672 0.0785994902253151
loss:  72.76187896728516 0.08163084089756012
loss:  72.63996887207031 0.08257676661014557
loss:  71.27821350097656 0.0838203951716423
loss:  72.19955444335938 0.0688055157661438
*******************Epoch 70 ****************** 1420 1.0
Validation Loss
*** pred loss:  42.382225036621094 pred acc: 0.353804349899292
*** stop loss:  11.299385070800781 stop acc: 0.8429639339447021
*** template loss:  8.489606857299805 template acc: tensor(0.0144, device='cuda:0')
*** label loss:  6.2592339515686035 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 47.086428833007815 pred acc: 0.33043711483478544
---> stop loss: 12.074030303955078 stop acc: 0.8555010437965394
---> template loss: 7.265969848632812 tempalte acc: 0.02659975290298462
---> molecule label loss: 5.515570831298828 molecule acc: 0.38222312927246094
---> kl loss: 0.08184190988540649
---> reconstruction loss: 71.94199231863021
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-71-with.npy
loss:  72.97626495361328 0.08643406629562378
loss:  72.71028900146484 0.07931371033191681
loss:  71.6541748046875 0.08287692070007324
loss:  70.39389038085938 0.08220592141151428
loss:  71.59132385253906 0.07780905067920685
loss:  71.42974090576172 0.08316115289926529
loss:  71.6793212890625 0.0787523165345192
loss:  71.41902160644531 0.07963401079177856
loss:  71.55755615234375 0.08141811192035675
loss:  71.6994400024414 0.0801960825920105
loss:  71.47811889648438 0.08353227376937866
loss:  71.38931274414062 0.08275586366653442
loss:  71.20926666259766 0.08193056285381317
loss:  71.0711441040039 0.08306659013032913
loss:  71.54576873779297 0.07995067536830902
loss:  71.94708251953125 0.08073107898235321
loss:  72.32475280761719 0.07705903053283691
loss:  72.97671508789062 0.08102299273014069
loss:  72.7288589477539 0.08047018200159073
loss:  70.84686279296875 0.07592891901731491
*******************Epoch 71 ****************** 1440 1.0
Validation Loss
*** pred loss:  42.23921203613281 pred acc: 0.3532004654407501
*** stop loss:  11.261303901672363 stop acc: 0.8414695262908936
*** template loss:  8.489717483520508 template acc: tensor(0.0158, device='cuda:0')
*** label loss:  6.260188579559326 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 46.883218383789064 pred acc: 0.3300637394189835
---> stop loss: 12.012351989746094 stop acc: 0.8560453295707703
---> template loss: 7.250763702392578 tempalte acc: 0.02468515932559967
---> molecule label loss: 5.504203033447266 molecule acc: 0.38298013210296633
---> kl loss: 0.08091247081756592
---> reconstruction loss: 71.65053284168243
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-72-with.npy
loss:  72.02678680419922 0.07790134102106094
loss:  72.14872741699219 0.0853085070848465
loss:  71.41070556640625 0.07612740248441696
loss:  71.3982162475586 0.08430582284927368
loss:  70.8206558227539 0.08740750700235367
loss:  70.94157409667969 0.07907809317111969
loss:  71.50067138671875 0.08216941356658936
loss:  72.07872772216797 0.07691800594329834
loss:  72.02254486083984 0.08123890310525894
loss:  70.82476043701172 0.08180160820484161
loss:  70.56599426269531 0.08045656979084015
loss:  72.25972747802734 0.07875004410743713
loss:  71.91154479980469 0.08318949490785599
loss:  70.43415069580078 0.07531073689460754
loss:  71.61856842041016 0.07623647898435593
loss:  71.33099365234375 0.07760664075613022
loss:  72.19896697998047 0.07753075659275055
loss:  71.20130920410156 0.08000095188617706
loss:  72.33279418945312 0.0784495398402214
loss:  73.0260009765625 0.06442371010780334
*******************Epoch 72 ****************** 1460 1.0
Validation Loss
*** pred loss:  42.10694122314453 pred acc: 0.35392510890960693
*** stop loss:  11.198254585266113 stop acc: 0.8429016470909119
*** template loss:  8.490211486816406 template acc: tensor(0.0155, device='cuda:0')
*** label loss:  6.260192394256592 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 46.83442687988281 pred acc: 0.33043417036533357
---> stop loss: 11.93950958251953 stop acc: 0.8572874218225479
---> template loss: 7.244412231445312 tempalte acc: 0.025786173343658448
---> molecule label loss: 5.505111312866211 molecule acc: 0.3822795867919922
---> kl loss: 0.0792105734348297
---> reconstruction loss: 71.52345055937766
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-73-with.npy
loss:  71.42908477783203 0.07921663671731949
loss:  71.27526092529297 0.08099975436925888
loss:  71.28952026367188 0.08538278937339783
loss:  71.24970245361328 0.08036360144615173
loss:  70.43212127685547 0.08164601027965546
loss:  70.88139343261719 0.0800648182630539
loss:  71.68531799316406 0.07955911755561829
loss:  70.9246826171875 0.08031584322452545
loss:  71.68341064453125 0.07655460387468338
loss:  71.36949920654297 0.07798175513744354
loss:  71.4277114868164 0.08009885251522064
loss:  71.13993072509766 0.07633468508720398
loss:  71.54666900634766 0.08077891170978546
loss:  70.47254180908203 0.07133570313453674
loss:  71.08824157714844 0.07105134427547455
loss:  72.44424438476562 0.08011801540851593
loss:  70.7725601196289 0.07493358850479126
loss:  71.924072265625 0.08216522634029388
loss:  71.50050354003906 0.0755799412727356
loss:  72.15276336669922 0.09042448550462723
*******************Epoch 73 ****************** 1480 1.0
Validation Loss
*** pred loss:  41.95783615112305 pred acc: 0.35404589772224426
*** stop loss:  11.162776947021484 stop acc: 0.8434309363365173
*** template loss:  8.4949951171875 template acc: tensor(0.0148, device='cuda:0')
*** label loss:  6.2616071701049805 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 46.60484313964844 pred acc: 0.3306493699550629
---> stop loss: 11.895091247558593 stop acc: 0.8577682644128799
---> template loss: 7.247799682617187 tempalte acc: 0.025665786862373353
---> molecule label loss: 5.5074810028076175 molecule acc: 0.38240976333618165
---> kl loss: 0.07924529314041137
---> reconstruction loss: 71.25521515607834
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-74-with.npy
loss:  70.98165893554688 0.07942018657922745
loss:  71.07964324951172 0.07605960965156555
loss:  70.12142944335938 0.07546354085206985
loss:  70.4897689819336 0.07972483336925507
loss:  72.1381607055664 0.07724612951278687
loss:  71.5674057006836 0.0772763043642044
loss:  71.39228820800781 0.07808437943458557
loss:  71.5567626953125 0.07553540170192719
loss:  70.99723815917969 0.07777203619480133
loss:  71.35846710205078 0.07588239759206772
loss:  69.935791015625 0.08083821088075638
loss:  72.43305969238281 0.07479195296764374
loss:  71.34125518798828 0.07547570019960403
loss:  70.36341857910156 0.08047565072774887
loss:  70.77594757080078 0.07891742140054703
loss:  71.1089096069336 0.07616275548934937
loss:  71.76890563964844 0.08044180274009705
loss:  70.34400939941406 0.07560855150222778
loss:  70.40386962890625 0.0778471976518631
loss:  70.12103271484375 0.07632477581501007
*******************Epoch 74 ****************** 1500 1.0
Validation Loss
*** pred loss:  41.81569290161133 pred acc: 0.35446858406066895
*** stop loss:  11.107894897460938 stop acc: 0.8441469669342041
*** template loss:  8.49304485321045 template acc: tensor(0.0151, device='cuda:0')
*** label loss:  6.262716293334961 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 46.358392333984376 pred acc: 0.3303793281316757
---> stop loss: 11.822395324707031 stop acc: 0.8586840212345124
---> template loss: 7.241075134277343 tempalte acc: 0.025142356753349304
---> molecule label loss: 5.514621734619141 molecule acc: 0.38130738735198977
---> kl loss: 0.07746744751930237
---> reconstruction loss: 70.93648518919946
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-75-with.npy
loss:  70.1898193359375 0.07416824996471405
loss:  70.43451690673828 0.07743898034095764
loss:  70.45623779296875 0.07439103722572327
loss:  72.04264831542969 0.07311122119426727
loss:  70.59091186523438 0.07509670406579971
loss:  70.84759521484375 0.07519147545099258
loss:  69.95529174804688 0.07418458163738251
loss:  71.54408264160156 0.08125172555446625
loss:  70.39252471923828 0.07573243230581284
loss:  72.34209442138672 0.07651537656784058
loss:  71.25871276855469 0.07448005676269531
loss:  70.25923919677734 0.07636933028697968
loss:  69.9041976928711 0.07609866559505463
loss:  71.76795196533203 0.08168265223503113
loss:  69.92343139648438 0.07449132204055786
loss:  71.3102798461914 0.07157400250434875
loss:  71.1553955078125 0.07793328911066055
loss:  71.25833892822266 0.08012975007295609
loss:  70.093505859375 0.07995709776878357
loss:  70.59782409667969 0.07415047287940979
*******************Epoch 75 ****************** 1520 1.0
Validation Loss
*** pred loss:  41.694366455078125 pred acc: 0.35410627722740173
*** stop loss:  11.071314811706543 stop acc: 0.8447696566581726
*** template loss:  8.500245094299316 template acc: tensor(0.0155, device='cuda:0')
*** label loss:  6.264628887176514 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 46.25046997070312 pred acc: 0.3319330468773842
---> stop loss: 11.766606903076172 stop acc: 0.8590768903493882
---> template loss: 7.223723602294922 tempalte acc: 0.025772523880004884
---> molecule label loss: 5.4992328643798825 molecule acc: 0.3824561595916748
---> kl loss: 0.07619741559028625
---> reconstruction loss: 70.74002572894096
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-76-with.npy
loss:  70.95556640625 0.07739464193582535
loss:  70.19938659667969 0.07020756602287292
loss:  70.659423828125 0.07836766541004181
loss:  71.58219146728516 0.07675564289093018
loss:  69.9277114868164 0.07619320601224899
loss:  70.61294555664062 0.07348775863647461
loss:  71.32939910888672 0.07384613156318665
loss:  70.86183166503906 0.07161644101142883
loss:  70.64672088623047 0.07821283489465714
loss:  69.53591918945312 0.07607702910900116
loss:  70.58712005615234 0.07748864591121674
loss:  70.79720306396484 0.07226508110761642
loss:  69.59041595458984 0.07282255589962006
loss:  71.07569885253906 0.07635146379470825
loss:  70.6347427368164 0.07293848693370819
loss:  69.89056396484375 0.079649418592453
loss:  70.97203063964844 0.0758022889494896
loss:  70.75157928466797 0.07499164342880249
loss:  70.78007507324219 0.07477762550115585
loss:  68.37693786621094 0.07364466786384583
*******************Epoch 76 ****************** 1540 1.0
Validation Loss
*** pred loss:  41.536014556884766 pred acc: 0.35555553436279297
*** stop loss:  11.008557319641113 stop acc: 0.8460460901260376
*** template loss:  8.496969223022461 template acc: tensor(0.0155, device='cuda:0')
*** label loss:  6.264640808105469 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 45.99687194824219 pred acc: 0.3312846481800079
---> stop loss: 11.697386932373046 stop acc: 0.8596053212881088
---> template loss: 7.221984100341797 tempalte acc: 0.025029888749122618
---> molecule label loss: 5.496982574462891 molecule acc: 0.3825854778289795
---> kl loss: 0.07514454126358032
---> reconstruction loss: 70.41322215795516
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-77-with.npy
loss:  71.1090316772461 0.07302834093570709
loss:  70.54478454589844 0.07645950466394424
loss:  70.73430633544922 0.06981483101844788
loss:  69.79609680175781 0.07850970327854156
loss:  70.55045318603516 0.07738615572452545
loss:  69.78741455078125 0.07234888523817062
loss:  69.67411041259766 0.07139714062213898
loss:  71.76424407958984 0.07333233952522278
loss:  69.64759063720703 0.07736547291278839
loss:  70.26387786865234 0.07117418944835663
loss:  69.86542510986328 0.07308320701122284
loss:  70.31017303466797 0.07698999345302582
loss:  70.06232452392578 0.07475541532039642
loss:  71.13667297363281 0.07351548224687576
loss:  71.12059783935547 0.07306909561157227
loss:  70.50721740722656 0.0687243863940239
loss:  70.63705444335938 0.07472041249275208
loss:  69.99960327148438 0.07499772310256958
loss:  69.53726959228516 0.07512663304805756
loss:  67.71757507324219 0.08424443006515503
*******************Epoch 77 ****************** 1560 1.0
Validation Loss
*** pred loss:  41.40163040161133 pred acc: 0.3558574914932251
*** stop loss:  10.966174125671387 stop acc: 0.8464196920394897
*** template loss:  8.499491691589355 template acc: tensor(0.0162, device='cuda:0')
*** label loss:  6.265679359436035 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 45.82352294921875 pred acc: 0.33238434195518496
---> stop loss: 11.618770599365234 stop acc: 0.8610151141881943
---> template loss: 7.2266845703125 tempalte acc: 0.025207024812698365
---> molecule label loss: 5.494812774658203 molecule acc: 0.3828268051147461
---> kl loss: 0.07450217008590698
---> reconstruction loss: 70.1637790799141
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-78-with.npy
loss:  70.84117889404297 0.07293065637350082
loss:  70.07673645019531 0.07189546525478363
loss:  70.5108642578125 0.07422487437725067
loss:  69.63507080078125 0.07461246848106384
loss:  69.89031982421875 0.07435150444507599
loss:  69.4285888671875 0.07202161848545074
loss:  70.17784881591797 0.07343972474336624
loss:  70.89509582519531 0.0753224790096283
loss:  69.90563201904297 0.07650161534547806
loss:  70.77696990966797 0.07018456608057022
loss:  69.94598388671875 0.07069414108991623
loss:  70.22088623046875 0.07410097867250443
loss:  70.2236557006836 0.0763256773352623
loss:  69.52513885498047 0.07231705635786057
loss:  70.0984115600586 0.0697212815284729
loss:  69.94251251220703 0.07114052772521973
loss:  69.37623596191406 0.07267433404922485
loss:  70.03761291503906 0.07361408323049545
loss:  70.9341812133789 0.07106129825115204
loss:  71.56005096435547 0.07549017667770386
*******************Epoch 78 ****************** 1580 1.0
Validation Loss
*** pred loss:  41.26155090332031 pred acc: 0.35712558031082153
*** stop loss:  10.93790340423584 stop acc: 0.8464196920394897
*** template loss:  8.50343132019043 template acc: tensor(0.0151, device='cuda:0')
*** label loss:  6.266709804534912 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 45.78511352539063 pred acc: 0.33400833904743193
---> stop loss: 11.632077026367188 stop acc: 0.8612264782190323
---> template loss: 7.215762329101563 tempalte acc: 0.025175806879997254
---> molecule label loss: 5.49406852722168 molecule acc: 0.38229894638061523
---> kl loss: 0.07313121557235717
---> reconstruction loss: 70.12701526880264
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-79-with.npy
loss:  70.02532196044922 0.07676820456981659
loss:  70.29358673095703 0.07518812268972397
loss:  69.90693664550781 0.07558465003967285
loss:  70.1987075805664 0.07153056561946869
loss:  70.66976928710938 0.07093749940395355
loss:  69.1695785522461 0.07096363604068756
loss:  69.74559783935547 0.07259068638086319
loss:  70.15982818603516 0.07135114073753357
loss:  69.59628295898438 0.06992168724536896
loss:  70.78180694580078 0.07228358089923859
loss:  69.71038818359375 0.06793905049562454
loss:  70.27446746826172 0.07000371813774109
loss:  70.15387725830078 0.06998761743307114
loss:  69.2048110961914 0.0736350417137146
loss:  70.07585906982422 0.07069626450538635
loss:  69.22798919677734 0.07483644783496857
loss:  70.28276062011719 0.07106073945760727
loss:  69.66680908203125 0.07134297490119934
loss:  69.0699234008789 0.07222665101289749
loss:  69.33540344238281 0.08088315278291702
*******************Epoch 79 ****************** 1600 1.0
Validation Loss
*** pred loss:  41.12405014038086 pred acc: 0.35748791694641113
*** stop loss:  10.8788480758667 stop acc: 0.847665011882782
*** template loss:  8.505485534667969 template acc: tensor(0.0148, device='cuda:0')
*** label loss:  6.266261577606201 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 45.57802124023438 pred acc: 0.33379544615745543
---> stop loss: 11.53264923095703 stop acc: 0.8620850205421448
---> template loss: 7.206950378417969 tempalte acc: 0.0252105176448822
---> molecule label loss: 5.4873817443847654 molecule acc: 0.38293144702911375
---> kl loss: 0.07248657345771789
---> reconstruction loss: 69.80499755740165
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-80-with.npy
loss:  69.88626861572266 0.069989413022995
loss:  70.35920715332031 0.07599657773971558
loss:  69.2978744506836 0.0716964527964592
loss:  69.35692596435547 0.07341217249631882
loss:  69.66118621826172 0.06981275975704193
loss:  69.44609069824219 0.07506974041461945
loss:  70.50374603271484 0.07054849714040756
loss:  69.92581176757812 0.07270391285419464
loss:  70.32279205322266 0.06766487658023834
loss:  69.17426300048828 0.0700448602437973
loss:  69.99742889404297 0.06995183974504471
loss:  69.36964416503906 0.06706318259239197
loss:  69.12320709228516 0.06937924027442932
loss:  69.59901428222656 0.07123979926109314
loss:  69.04662322998047 0.06689891219139099
loss:  69.44115447998047 0.06994622945785522
loss:  69.27704620361328 0.07179437577724457
loss:  70.14344787597656 0.07789917290210724
loss:  70.02010345458984 0.06939785927534103
loss:  69.33194732666016 0.06988014280796051
*******************Epoch 80 ****************** 1620 1.0
Validation Loss
*** pred loss:  41.001399993896484 pred acc: 0.36068838834762573
*** stop loss:  10.840553283691406 stop acc: 0.8488481044769287
*** template loss:  8.504332542419434 template acc: tensor(0.0155, device='cuda:0')
*** label loss:  6.2698259353637695 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 45.39494323730469 pred acc: 0.33707122355699537
---> stop loss: 11.523432159423828 stop acc: 0.8623145073652267
---> template loss: 7.195970153808593 tempalte acc: 0.025266918540000915
---> molecule label loss: 5.478824234008789 molecule acc: 0.38337948322296145
---> kl loss: 0.0710195004940033
---> reconstruction loss: 69.59317117333413
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-81-with.npy
loss:  68.60602569580078 0.06826798617839813
loss:  69.57072448730469 0.07468102872371674
loss:  69.63365936279297 0.06851767003536224
loss:  70.0975112915039 0.06893299520015717
loss:  69.16227722167969 0.06951664388179779
loss:  69.65096282958984 0.07280628383159637
loss:  69.24699401855469 0.06550034135580063
loss:  69.25569915771484 0.07148396968841553
loss:  68.9690170288086 0.07224995642900467
loss:  69.7803726196289 0.07106395810842514
loss:  69.54070281982422 0.0714941918849945
loss:  68.89429473876953 0.06633195281028748
loss:  70.65132141113281 0.07276055216789246
loss:  69.4351806640625 0.06376959383487701
loss:  69.85401916503906 0.06822258234024048
loss:  69.67860412597656 0.06959237158298492
loss:  69.56753540039062 0.0738518089056015
loss:  68.90457916259766 0.0725938081741333
loss:  69.10979461669922 0.07041392475366592
loss:  70.51046752929688 0.06485864520072937
*******************Epoch 81 ****************** 1640 1.0
Validation Loss
*** pred loss:  40.867340087890625 pred acc: 0.3607487976551056
*** stop loss:  10.809676170349121 stop acc: 0.8487235903739929
*** template loss:  8.506220817565918 template acc: tensor(0.0158, device='cuda:0')
*** label loss:  6.26993989944458 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 45.312493896484376 pred acc: 0.3367630377411842
---> stop loss: 11.45022201538086 stop acc: 0.8635617256164551
---> template loss: 7.188733673095703 tempalte acc: 0.02578188180923462
---> molecule label loss: 5.484689331054687 molecule acc: 0.3829127073287964
---> kl loss: 0.06984551548957825
---> reconstruction loss: 69.43613592982292
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-82-with.npy
loss:  68.77027130126953 0.07103395462036133
loss:  69.09496307373047 0.0707479864358902
loss:  69.14704895019531 0.07298137992620468
loss:  70.18529510498047 0.06817251443862915
loss:  68.8030014038086 0.06548985838890076
loss:  69.31153106689453 0.07040546834468842
loss:  69.49848937988281 0.06679190695285797
loss:  68.78234100341797 0.07190463691949844
loss:  68.73706817626953 0.06762868911027908
loss:  69.04300689697266 0.06781262159347534
loss:  69.27290344238281 0.07087352871894836
loss:  68.86710357666016 0.06716984510421753
loss:  69.3660659790039 0.07318148016929626
loss:  69.46229553222656 0.07242771238088608
loss:  70.24032592773438 0.06690172851085663
loss:  69.56851959228516 0.06634725630283356
loss:  69.33697509765625 0.07142888009548187
loss:  68.4520034790039 0.06475115567445755
loss:  69.38893127441406 0.0672745555639267
loss:  71.80003356933594 0.06060001254081726
*******************Epoch 82 ****************** 1660 1.0
Validation Loss
*** pred loss:  40.73533630371094 pred acc: 0.3620772957801819
*** stop loss:  10.770816802978516 stop acc: 0.8503113389015198
*** template loss:  8.511128425598145 template acc: tensor(0.0148, device='cuda:0')
*** label loss:  6.269900798797607 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 45.22235107421875 pred acc: 0.33927841335535047
---> stop loss: 11.413428497314452 stop acc: 0.8646425753831863
---> template loss: 7.17816162109375 tempalte acc: 0.025264060497283934
---> molecule label loss: 5.473777008056641 molecule acc: 0.38387398719787597
---> kl loss: 0.06869626045227051
---> reconstruction loss: 69.2877185344696
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-83-with.npy
loss:  68.81401824951172 0.06711816787719727
loss:  69.08570098876953 0.06504492461681366
loss:  68.84165954589844 0.06837358325719833
loss:  68.75204467773438 0.0699133351445198
loss:  69.9033203125 0.06665205955505371
loss:  68.90839385986328 0.07041537761688232
loss:  69.2519302368164 0.07446777075529099
loss:  69.43550109863281 0.07445025444030762
loss:  69.42066192626953 0.06696581095457077
loss:  68.15167999267578 0.06524015963077545
loss:  69.5279769897461 0.0667787492275238
loss:  69.4497299194336 0.0682254284620285
loss:  68.69538879394531 0.06899657845497131
loss:  68.72265625 0.06996248662471771
loss:  68.3017578125 0.06572026759386063
loss:  69.11885833740234 0.06812316179275513
loss:  68.92851257324219 0.07027056813240051
loss:  69.37545776367188 0.0678701102733612
loss:  68.57188415527344 0.06224128603935242
loss:  69.2506103515625 0.07664661854505539
*******************Epoch 83 ****************** 1680 1.0
Validation Loss
*** pred loss:  40.594905853271484 pred acc: 0.36346617341041565
*** stop loss:  10.710724830627441 stop acc: 0.8506227135658264
*** template loss:  8.507465362548828 template acc: tensor(0.0162, device='cuda:0')
*** label loss:  6.271893501281738 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 44.95748596191406 pred acc: 0.3403222993016243
---> stop loss: 11.333541870117188 stop acc: 0.8650081396102905
---> template loss: 7.192076110839844 tempalte acc: 0.025384476780891417
---> molecule label loss: 5.473610305786133 molecule acc: 0.38341188430786133
---> kl loss: 0.06867383718490601
---> reconstruction loss: 68.95671068429947
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-84-with.npy
loss:  69.19530487060547 0.069098100066185
loss:  67.42147064208984 0.06669016927480698
loss:  68.7201156616211 0.06542240083217621
loss:  68.65723419189453 0.0681387409567833
loss:  68.71642303466797 0.06909176707267761
loss:  69.32501983642578 0.06902527064085007
loss:  69.24459838867188 0.0675688162446022
loss:  68.92918395996094 0.06910440325737
loss:  68.7293701171875 0.07250931859016418
loss:  69.14161682128906 0.06059425324201584
loss:  69.19274139404297 0.06535866111516953
loss:  69.13861083984375 0.06816114485263824
loss:  69.65778350830078 0.06550478935241699
loss:  68.23190307617188 0.06581474840641022
loss:  68.8709945678711 0.06686074286699295
loss:  67.94747161865234 0.06913851201534271
loss:  68.69329071044922 0.06720948219299316
loss:  68.84600830078125 0.06739374995231628
loss:  68.5667724609375 0.06869497895240784
loss:  68.0393295288086 0.058732300996780396
*******************Epoch 84 ****************** 1700 1.0
Validation Loss
*** pred loss:  40.474876403808594 pred acc: 0.3650362193584442
*** stop loss:  10.675955772399902 stop acc: 0.8514010310173035
*** template loss:  8.51224422454834 template acc: tensor(0.0158, device='cuda:0')
*** label loss:  6.271530628204346 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 44.77206726074219 pred acc: 0.3415838584303856
---> stop loss: 11.277973175048828 stop acc: 0.8651486337184906
---> template loss: 7.178982543945312 tempalte acc: 0.025417992472648622
---> molecule label loss: 5.467231750488281 molecule acc: 0.3840354919433594
---> kl loss: 0.06700561046600342
---> reconstruction loss: 68.69625732898713
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-85-with.npy
loss:  68.63386535644531 0.06617171317338943
loss:  68.30926513671875 0.06441907584667206
loss:  67.8652114868164 0.06486022472381592
loss:  67.99720764160156 0.07021759450435638
loss:  68.91687774658203 0.06332795321941376
loss:  68.78121185302734 0.0648677796125412
loss:  68.27757263183594 0.06685322523117065
loss:  69.01787567138672 0.06844989210367203
loss:  68.44022369384766 0.0646839514374733
loss:  69.3020248413086 0.06625990569591522
loss:  68.54340362548828 0.06794184446334839
loss:  67.8536605834961 0.06682081520557404
loss:  68.47502899169922 0.0703570693731308
loss:  68.50053405761719 0.06875172257423401
loss:  69.57339477539062 0.06514564901590347
loss:  68.92713928222656 0.06689102947711945
loss:  68.52754211425781 0.06448961049318314
loss:  69.23441314697266 0.06611736118793488
loss:  67.84809875488281 0.06510896980762482
loss:  69.48343658447266 0.07111257314682007
*******************Epoch 85 ****************** 1720 1.0
Validation Loss
*** pred loss:  40.3350944519043 pred acc: 0.3675120770931244
*** stop loss:  10.656209945678711 stop acc: 0.850280225276947
*** template loss:  8.515331268310547 template acc: tensor(0.0158, device='cuda:0')
*** label loss:  6.275008678436279 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 44.701953125 pred acc: 0.342049640417099
---> stop loss: 11.235983276367188 stop acc: 0.866660988330841
---> template loss: 7.15538330078125 tempalte acc: 0.026237213611602785
---> molecule label loss: 5.465435409545899 molecule acc: 0.3839470863342285
---> kl loss: 0.0666424036026001
---> reconstruction loss: 68.55875432491302
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-86-with.npy
loss:  68.60163116455078 0.060709960758686066
loss:  68.72888946533203 0.06622793525457382
loss:  68.49375915527344 0.06778028607368469
loss:  66.98955535888672 0.06609300523996353
loss:  68.73245239257812 0.06640350073575974
loss:  67.60950469970703 0.06794910877943039
loss:  67.8441162109375 0.0666598305106163
loss:  68.92800903320312 0.06332140415906906
loss:  68.55885314941406 0.06904543936252594
loss:  68.41294860839844 0.06402134150266647
loss:  68.58676147460938 0.06214529275894165
loss:  67.93814849853516 0.06545118242502213
loss:  68.9215087890625 0.06839907169342041
loss:  67.8848876953125 0.06515182554721832
loss:  68.53318786621094 0.0620986744761467
loss:  68.88160705566406 0.06846463680267334
loss:  68.48615264892578 0.061827436089515686
loss:  68.39873504638672 0.06776364147663116
loss:  68.28684997558594 0.06760978698730469
loss:  70.31869506835938 0.06264787167310715
*******************Epoch 86 ****************** 1740 1.0
Validation Loss
*** pred loss:  40.229576110839844 pred acc: 0.3689613342285156
*** stop loss:  10.610651016235352 stop acc: 0.8518057465553284
*** template loss:  8.516494750976562 template acc: tensor(0.0155, device='cuda:0')
*** label loss:  6.274256229400635 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 44.55226135253906 pred acc: 0.34550417959690094
---> stop loss: 11.194427490234375 stop acc: 0.8673914194107055
---> template loss: 7.159023284912109 tempalte acc: 0.025345978140830994
---> molecule label loss: 5.485612106323242 molecule acc: 0.3819726467132568
---> kl loss: 0.06548855900764465
---> reconstruction loss: 68.39132296442985
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-87-with.npy
loss:  68.31641387939453 0.06529586017131805
loss:  68.07292938232422 0.06399964541196823
loss:  68.49698638916016 0.06842109560966492
loss:  69.16165161132812 0.06530685722827911
loss:  67.56864929199219 0.06559226661920547
loss:  67.63763427734375 0.06416408717632294
loss:  68.7972183227539 0.06390070915222168
loss:  67.43572998046875 0.06475134193897247
loss:  68.97274017333984 0.06390977650880814
loss:  66.94114685058594 0.06411892175674438
loss:  67.56644439697266 0.06795098632574081
loss:  68.4563980102539 0.06331940740346909
loss:  67.95860290527344 0.0629238411784172
loss:  68.75296020507812 0.06564806401729584
loss:  68.4380874633789 0.06801147013902664
loss:  68.2843246459961 0.0635203942656517
loss:  68.17302703857422 0.06203598901629448
loss:  68.80103302001953 0.06935223937034607
loss:  66.9853286743164 0.060522809624671936
loss:  69.05049133300781 0.0661335438489914
*******************Epoch 87 ****************** 1760 1.0
Validation Loss
*** pred loss:  40.07878875732422 pred acc: 0.37155795097351074
*** stop loss:  10.568495750427246 stop acc: 0.8532378673553467
*** template loss:  8.516214370727539 template acc: tensor(0.0141, device='cuda:0')
*** label loss:  6.275731086730957 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 44.369390869140624 pred acc: 0.3480648919939995
---> stop loss: 11.141024780273437 stop acc: 0.8677420526742935
---> template loss: 7.1512908935546875 tempalte acc: 0.02635921537876129
---> molecule label loss: 5.466741561889648 molecule acc: 0.38353378772735597
---> kl loss: 0.06494396328926086
---> reconstruction loss: 68.12844592928886
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-88-with.npy
loss:  67.92420959472656 0.06726275384426117
loss:  68.55494689941406 0.06391415745019913
loss:  68.12113189697266 0.060630276799201965
loss:  68.75254821777344 0.06540609151124954
loss:  67.29691314697266 0.064638651907444
loss:  67.0342788696289 0.06262828409671783
loss:  68.03291320800781 0.06597132235765457
loss:  68.30358123779297 0.0636652484536171
loss:  67.79559326171875 0.06338725984096527
loss:  66.88933563232422 0.06727613508701324
loss:  67.9837875366211 0.06571013480424881
loss:  67.88035583496094 0.06439067423343658
loss:  68.53231811523438 0.06092970818281174
loss:  67.92082977294922 0.06313153356313705
loss:  67.16730499267578 0.06118141859769821
loss:  67.46830749511719 0.06370319426059723
loss:  67.6696548461914 0.06483446806669235
loss:  69.0905532836914 0.0627632811665535
loss:  68.3237075805664 0.06743840128183365
loss:  68.15274810791016 0.0671301931142807
*******************Epoch 88 ****************** 1780 1.0
Validation Loss
*** pred loss:  39.95541763305664 pred acc: 0.37493959069252014
*** stop loss:  10.524730682373047 stop acc: 0.853486955165863
*** template loss:  8.517502784729004 template acc: tensor(0.0176, device='cuda:0')
*** label loss:  6.275217533111572 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 44.16036682128906 pred acc: 0.35166801512241364
---> stop loss: 11.10934829711914 stop acc: 0.8674660205841065
---> template loss: 7.1459503173828125 tempalte acc: 0.026899257302284242
---> molecule label loss: 5.464787292480469 molecule acc: 0.38261396884918214
---> kl loss: 0.0642996609210968
---> reconstruction loss: 67.88045131564141
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-89-with.npy
loss:  68.01256561279297 0.06348353624343872
loss:  67.05147552490234 0.05967479199171066
loss:  67.19950103759766 0.062134720385074615
loss:  67.48631286621094 0.062374524772167206
loss:  67.49874877929688 0.061833690851926804
loss:  67.47046661376953 0.06143549084663391
loss:  67.55660247802734 0.06197280436754227
loss:  68.0594482421875 0.06501460075378418
loss:  69.15180969238281 0.06526655703783035
loss:  67.21141052246094 0.06354089081287384
loss:  68.10335540771484 0.06238432228565216
loss:  68.62413024902344 0.06448910385370255
loss:  68.0240249633789 0.06402202695608139
loss:  67.79386901855469 0.06407956033945084
loss:  67.21868133544922 0.06493034958839417
loss:  68.21050262451172 0.06439687311649323
loss:  67.2417984008789 0.06455983966588974
loss:  67.17169189453125 0.06512103974819183
loss:  67.11825561523438 0.06483794748783112
loss:  73.51466369628906 0.06082653999328613
*******************Epoch 89 ****************** 1800 1.0
Validation Loss
*** pred loss:  39.82200622558594 pred acc: 0.3772946894168854
*** stop loss:  10.495859146118164 stop acc: 0.8537048697471619
*** template loss:  8.51983642578125 template acc: tensor(0.0158, device='cuda:0')
*** label loss:  6.276748180389404 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 44.17911071777344 pred acc: 0.35366335660219195
---> stop loss: 11.127983093261719 stop acc: 0.8684224545955658
---> template loss: 7.142861938476562 tempalte acc: 0.026759859919548035
---> molecule label loss: 5.472687530517578 molecule acc: 0.38273556232452394
---> kl loss: 0.06331895589828491
---> reconstruction loss: 67.92264906167985
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-90-with.npy
loss:  67.5888671875 0.06376717239618301
loss:  67.43439483642578 0.06139806658029556
loss:  67.03520202636719 0.0637582316994667
loss:  68.04729461669922 0.062340959906578064
loss:  67.63846588134766 0.06023109704256058
loss:  66.9372329711914 0.062031812965869904
loss:  67.74652862548828 0.06251196563243866
loss:  67.83792114257812 0.06502711027860641
loss:  68.23250579833984 0.06786532700061798
loss:  67.84657287597656 0.06335645169019699
loss:  67.69705963134766 0.06287654489278793
loss:  67.65286254882812 0.06487765908241272
loss:  67.21318817138672 0.06029297411441803
loss:  68.44725799560547 0.06740598380565643
loss:  67.00213623046875 0.06343105435371399
loss:  66.17205810546875 0.06082398444414139
loss:  67.94973754882812 0.0622323676943779
loss:  67.08341217041016 0.060312747955322266
loss:  67.02237701416016 0.0587192177772522
loss:  67.69131469726562 0.05263279378414154
*******************Epoch 90 ****************** 1820 1.0
Validation Loss
*** pred loss:  39.690704345703125 pred acc: 0.37922704219818115
*** stop loss:  10.460628509521484 stop acc: 0.8543898463249207
*** template loss:  8.520033836364746 template acc: tensor(0.0176, device='cuda:0')
*** label loss:  6.276069164276123 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 43.83167724609375 pred acc: 0.3549055546522141
---> stop loss: 11.014485931396484 stop acc: 0.8691432863473892
---> template loss: 7.138517761230469 tempalte acc: 0.02735874950885773
---> molecule label loss: 5.466845321655273 molecule acc: 0.3828107833862305
---> kl loss: 0.06229468584060669
---> reconstruction loss: 67.45151757001877
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-91-with.npy
loss:  67.50550842285156 0.06253205239772797
loss:  67.3740234375 0.06578870862722397
loss:  66.93354034423828 0.0651206374168396
loss:  67.36711883544922 0.06293225288391113
loss:  67.33577728271484 0.05922998860478401
loss:  66.83399200439453 0.06491824984550476
loss:  66.51223754882812 0.06368683278560638
loss:  67.75260162353516 0.06558218598365784
loss:  67.36285400390625 0.059482455253601074
loss:  67.81970977783203 0.05949476361274719
loss:  66.95304107666016 0.06154496967792511
loss:  65.91910552978516 0.057569194585084915
loss:  67.62374877929688 0.06400518864393234
loss:  67.6024169921875 0.06354675441980362
loss:  68.20633697509766 0.06063047796487808
loss:  67.53604125976562 0.06398719549179077
loss:  67.79071044921875 0.05867665261030197
loss:  66.89563751220703 0.0608334094285965
loss:  67.24639129638672 0.060651734471321106
loss:  67.591796875 0.04922795295715332
*******************Epoch 91 ****************** 1840 1.0
Validation Loss
*** pred loss:  39.56956100463867 pred acc: 0.3811594247817993
*** stop loss:  10.429230690002441 stop acc: 0.8539228439331055
*** template loss:  8.519601821899414 template acc: tensor(0.0158, device='cuda:0')
*** label loss:  6.278456211090088 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 43.6937255859375 pred acc: 0.3595479100942612
---> stop loss: 10.970351409912109 stop acc: 0.8695825904607772
---> template loss: 7.127704620361328 tempalte acc: 0.027640163898468018
---> molecule label loss: 5.4548789978027346 molecule acc: 0.38414323329925537
---> kl loss: 0.061472088098526
---> reconstruction loss: 67.2466638982296
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-92-with.npy
loss:  66.23028564453125 0.058209240436553955
loss:  67.27503204345703 0.06343986093997955
loss:  67.21336364746094 0.06358300149440765
loss:  67.09571838378906 0.057039014995098114
loss:  67.90824890136719 0.06707178801298141
loss:  68.05093383789062 0.06006917357444763
loss:  66.46337127685547 0.05886460095643997
loss:  66.52537536621094 0.062115639448165894
loss:  67.44960021972656 0.062362514436244965
loss:  67.15766143798828 0.06248834356665611
loss:  67.02560424804688 0.061494000256061554
loss:  67.21843719482422 0.06255350261926651
loss:  67.06336975097656 0.06134006381034851
loss:  66.99011993408203 0.058847952634096146
loss:  66.67292022705078 0.05948648974299431
loss:  67.3857192993164 0.06478214263916016
loss:  66.93222045898438 0.06297094374895096
loss:  66.85916900634766 0.0573975071310997
loss:  67.0601806640625 0.06199467554688454
loss:  68.321044921875 0.06308348476886749
*******************Epoch 92 ****************** 1860 1.0
Validation Loss
*** pred loss:  39.455291748046875 pred acc: 0.3827294707298279
*** stop loss:  10.36368179321289 stop acc: 0.856008768081665
*** template loss:  8.519286155700684 template acc: tensor(0.0144, device='cuda:0')
*** label loss:  6.277942180633545 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 43.59183044433594 pred acc: 0.3595645785331726
---> stop loss: 10.90200424194336 stop acc: 0.8703214854001999
---> template loss: 7.119697570800781 tempalte acc: 0.027880021929740907
---> molecule label loss: 5.469928741455078 molecule acc: 0.3816784143447876
---> kl loss: 0.061459696292877196
---> reconstruction loss: 67.0834560751915
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-93-with.npy
loss:  67.3791732788086 0.05932796001434326
loss:  67.11988067626953 0.06444916129112244
loss:  66.6817398071289 0.059195928275585175
loss:  66.89788818359375 0.06617648154497147
loss:  67.27376556396484 0.061611223965883255
loss:  66.57047271728516 0.06231072545051575
loss:  67.9268569946289 0.060175590217113495
loss:  66.9728775024414 0.06350106000900269
loss:  65.53870391845703 0.06145154684782028
loss:  66.57096099853516 0.05954110622406006
loss:  67.37584686279297 0.06178436055779457
loss:  66.14372253417969 0.05997344106435776
loss:  67.23645782470703 0.058718565851449966
loss:  66.06719207763672 0.06358999758958817
loss:  67.2061538696289 0.057899102568626404
loss:  66.61067962646484 0.056298401206731796
loss:  66.2929916381836 0.058958135545253754
loss:  66.84251403808594 0.05688384547829628
loss:  68.2815933227539 0.060327447950839996
loss:  64.0638656616211 0.059285398572683334
*******************Epoch 93 ****************** 1880 1.0
Validation Loss
*** pred loss:  39.31769561767578 pred acc: 0.3836956322193146
*** stop loss:  10.346885681152344 stop acc: 0.8557285666465759
*** template loss:  8.523855209350586 template acc: tensor(0.0169, device='cuda:0')
*** label loss:  6.2796406745910645 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 43.27348937988281 pred acc: 0.3614345997571945
---> stop loss: 10.845589447021485 stop acc: 0.8714047610759735
---> template loss: 7.110175323486328 tempalte acc: 0.028015193343162537
---> molecule label loss: 5.462841415405274 molecule acc: 0.38253352642059324
---> kl loss: 0.06057296991348267
---> reconstruction loss: 66.69209426641464
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-94-with.npy
loss:  66.21524047851562 0.06176276504993439
loss:  67.02191925048828 0.06410984694957733
loss:  66.51276397705078 0.06052635610103607
loss:  66.43140411376953 0.05760776996612549
loss:  66.25741577148438 0.06014012545347214
loss:  66.82682037353516 0.05606585741043091
loss:  67.07546997070312 0.059285566210746765
loss:  66.5008773803711 0.060585275292396545
loss:  66.1037826538086 0.06171393394470215
loss:  66.65120697021484 0.05682311952114105
loss:  67.04421997070312 0.058607086539268494
loss:  66.93363189697266 0.062441885471343994
loss:  66.7405014038086 0.05863698944449425
loss:  67.35157775878906 0.05966021493077278
loss:  66.77184295654297 0.05967175215482712
loss:  66.09317779541016 0.06392844021320343
loss:  67.59227752685547 0.06057339906692505
loss:  66.05579376220703 0.05842436105012894
loss:  66.65943908691406 0.06027308478951454
loss:  68.26837158203125 0.056876201182603836
*******************Epoch 94 ****************** 1900 1.0
Validation Loss
*** pred loss:  39.20118713378906 pred acc: 0.3843598961830139
*** stop loss:  10.323189735412598 stop acc: 0.855915367603302
*** template loss:  8.521862030029297 template acc: tensor(0.0155, device='cuda:0')
*** label loss:  6.281303405761719 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 43.33450012207031 pred acc: 0.3622679695487022
---> stop loss: 10.810655212402343 stop acc: 0.8717963069677352
---> template loss: 7.103231811523438 tempalte acc: 0.028388860821723937
---> molecule label loss: 5.447113037109375 molecule acc: 0.3835234880447388
---> kl loss: 0.059885692596435544
---> reconstruction loss: 66.69549760818481
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-95-with.npy
loss:  67.27153778076172 0.06037198752164841
loss:  65.74227142333984 0.05868903547525406
loss:  65.7779541015625 0.06136716157197952
loss:  66.67198181152344 0.05734984576702118
loss:  66.01041412353516 0.06415392458438873
loss:  67.02490997314453 0.058084502816200256
loss:  67.30842590332031 0.05812130123376846
loss:  65.90103149414062 0.06304232776165009
loss:  66.04574584960938 0.06101822853088379
loss:  67.10106658935547 0.0580255389213562
loss:  65.95526885986328 0.057697415351867676
loss:  67.59745788574219 0.06167139112949371
loss:  66.32844543457031 0.05548981949687004
loss:  66.39722442626953 0.05897907167673111
loss:  66.249755859375 0.06148465722799301
loss:  65.51605987548828 0.05975523591041565
loss:  67.12303161621094 0.05816703662276268
loss:  65.73304748535156 0.05554118752479553
loss:  67.34400177001953 0.060646556317806244
loss:  66.6705551147461 0.06235194206237793
*******************Epoch 95 ****************** 1920 1.0
Validation Loss
*** pred loss:  39.08131408691406 pred acc: 0.3857487738132477
*** stop loss:  10.277740478515625 stop acc: 0.8572540879249573
*** template loss:  8.523462295532227 template acc: tensor(0.0162, device='cuda:0')
*** label loss:  6.281917572021484 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 43.12367553710938 pred acc: 0.36280461251735685
---> stop loss: 10.757431030273438 stop acc: 0.871782985329628
---> template loss: 7.100285339355469 tempalte acc: 0.028188100457191466
---> molecule label loss: 5.447516632080078 molecule acc: 0.3840248823165894
---> kl loss: 0.05960040092468262
---> reconstruction loss: 66.42890667915344
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-96-with.npy
loss:  66.80834197998047 0.062280505895614624
loss:  66.54573822021484 0.05760804936289787
loss:  66.0414810180664 0.06040365993976593
loss:  66.77531433105469 0.05882322043180466
loss:  66.65552520751953 0.057702481746673584
loss:  66.92758178710938 0.05741395801305771
loss:  65.96150970458984 0.05507534742355347
loss:  66.6678466796875 0.05462775379419327
loss:  66.45520782470703 0.05840352922677994
loss:  66.84977722167969 0.06256319582462311
loss:  65.77970123291016 0.05857282876968384
loss:  65.56175994873047 0.058096498250961304
loss:  66.25199890136719 0.05992088094353676
loss:  66.18439483642578 0.05976004898548126
loss:  66.10192108154297 0.05787494406104088
loss:  66.24617767333984 0.06129644811153412
loss:  65.86954498291016 0.05843633413314819
loss:  66.08389282226562 0.05949418991804123
loss:  65.58052062988281 0.06065388768911362
loss:  66.28253936767578 0.05350956320762634
*******************Epoch 96 ****************** 1940 1.0
Validation Loss
*** pred loss:  38.97523880004883 pred acc: 0.3871980607509613
*** stop loss:  10.228090286254883 stop acc: 0.8573163747787476
*** template loss:  8.530742645263672 template acc: tensor(0.0169, device='cuda:0')
*** label loss:  6.281477451324463 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 42.962118530273436 pred acc: 0.3637785539031029
---> stop loss: 10.715322875976563 stop acc: 0.8730852723121643
---> template loss: 7.091492462158203 tempalte acc: 0.02968928813934326
---> molecule label loss: 5.4539794921875 molecule acc: 0.3829393148422241
---> kl loss: 0.05862586498260498
---> reconstruction loss: 66.2229171037674
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-97-with.npy
loss:  65.90924835205078 0.05829603970050812
loss:  66.3271484375 0.06046680361032486
loss:  66.23109436035156 0.054794397205114365
loss:  65.2483901977539 0.057373758405447006
loss:  64.70664978027344 0.05669911205768585
loss:  65.41716766357422 0.05863457918167114
loss:  65.50184631347656 0.058206409215927124
loss:  66.27198791503906 0.056210801005363464
loss:  65.53995513916016 0.06364921480417252
loss:  66.5063247680664 0.05890689790248871
loss:  66.63146209716797 0.05841450393199921
loss:  67.5962142944336 0.06200288236141205
loss:  66.10037231445312 0.0583350732922554
loss:  66.29125213623047 0.05749886482954025
loss:  65.7376937866211 0.058465857058763504
loss:  66.46095275878906 0.056829784065485
loss:  66.15642547607422 0.05825326591730118
loss:  67.37779235839844 0.05715112388134003
loss:  65.37586212158203 0.05762265622615814
loss:  69.18647766113281 0.05693208426237106
*******************Epoch 97 ****************** 1960 1.0
Validation Loss
*** pred loss:  38.8381462097168 pred acc: 0.3871980607509613
*** stop loss:  10.217755317687988 stop acc: 0.8577210903167725
*** template loss:  8.529741287231445 template acc: tensor(0.0169, device='cuda:0')
*** label loss:  6.285220623016357 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 42.905233764648436 pred acc: 0.3646515250205994
---> stop loss: 10.733030700683594 stop acc: 0.872893625497818
---> template loss: 7.085076904296875 tempalte acc: 0.02994767129421234
---> molecule label loss: 5.447136688232422 molecule acc: 0.38331894874572753
---> kl loss: 0.05823721289634705
---> reconstruction loss: 66.17047982811928
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-98-with.npy
loss:  65.74999237060547 0.05801820755004883
loss:  66.33468627929688 0.05624473839998245
loss:  65.69683837890625 0.06087859719991684
loss:  65.47225189208984 0.05528514087200165
loss:  66.80162811279297 0.05674196034669876
loss:  66.31996154785156 0.0582292303442955
loss:  66.03057861328125 0.05569250509142876
loss:  66.14411163330078 0.054893024265766144
loss:  65.30709838867188 0.05897325277328491
loss:  66.19674682617188 0.05689728260040283
loss:  65.25743103027344 0.0582001768052578
loss:  65.79705047607422 0.057178057730197906
loss:  65.77570343017578 0.05908694863319397
loss:  65.93611145019531 0.0582861453294754
loss:  65.76847076416016 0.058182694017887115
loss:  65.3164291381836 0.05824713408946991
loss:  65.78832244873047 0.06049612909555435
loss:  65.36105346679688 0.05765634775161743
loss:  66.73333740234375 0.058285780251026154
loss:  67.31436157226562 0.0549100786447525
*******************Epoch 98 ****************** 1980 1.0
Validation Loss
*** pred loss:  38.71815872192383 pred acc: 0.3874396085739136
*** stop loss:  10.172289848327637 stop acc: 0.8581880927085876
*** template loss:  8.529104232788086 template acc: tensor(0.0176, device='cuda:0')
*** label loss:  6.284202575683594 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 42.708837890625 pred acc: 0.36577540040016177
---> stop loss: 10.667340087890626 stop acc: 0.8737249433994293
---> template loss: 7.076976013183594 tempalte acc: 0.03032357394695282
---> molecule label loss: 5.44433822631836 molecule acc: 0.383658766746521
---> kl loss: 0.0576191782951355
---> reconstruction loss: 65.89748946428298
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-99-with.npy
loss:  67.25239562988281 0.05502023547887802
loss:  65.6558609008789 0.05440163239836693
loss:  65.30318450927734 0.05743371695280075
loss:  65.1915283203125 0.05785461142659187
loss:  65.98336791992188 0.057461291551589966
loss:  65.60895538330078 0.05739970505237579
loss:  66.057373046875 0.05863263085484505
loss:  65.29483032226562 0.0558224692940712
loss:  66.27918243408203 0.057458676397800446
loss:  65.16133117675781 0.0562494620680809
loss:  66.15286254882812 0.05895024910569191
loss:  65.57234191894531 0.05470142886042595
loss:  65.8941650390625 0.05505606532096863
loss:  65.45178985595703 0.05783369392156601
loss:  65.55941009521484 0.05855055898427963
loss:  66.20564270019531 0.060391105711460114
loss:  65.53771209716797 0.058398112654685974
loss:  65.37171936035156 0.06013142317533493
loss:  64.89035034179688 0.05628066509962082
loss:  63.16215133666992 0.04589409381151199
*******************Epoch 99 ****************** 2000 1.0
Validation Loss
*** pred loss:  38.59682846069336 pred acc: 0.38955312967300415
*** stop loss:  10.123953819274902 stop acc: 0.8598381280899048
*** template loss:  8.532824516296387 template acc: tensor(0.0176, device='cuda:0')
*** label loss:  6.282205104827881 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 42.4697265625 pred acc: 0.3661152869462967
---> stop loss: 10.54064483642578 stop acc: 0.8746497392654419
---> template loss: 7.062996673583984 tempalte acc: 0.030534455180168153
---> molecule label loss: 5.449242401123047 molecule acc: 0.3823108196258545
---> kl loss: 0.05669609308242798
---> reconstruction loss: 65.52261298894882
saving file:weights/hidden_size_200_latent_size_100_depth_2_beta_1.0_lr_0.00001/bvae_iter-100-with.npy
