cuda is  True
loading data.....
size of reactant dic: 9766
size of template dic: 5567
size of fgm_trees: 20080
size of rxn_trees: 20080
size of fragment dic: 273
hidden size: 200 latent_size: 100 batch size: 1000 depth: 5
beta: 1.0 lr: 0.001
size of data pairs: 20080
trainng size: 19079
valid size: 1000
loss:  144.95899963378906 1.387755036354065
loss:  140.39617919921875 1.7198150157928467
loss:  136.56243896484375 2.9583582878112793
loss:  129.03834533691406 5.33403205871582
loss:  121.77356719970703 9.206092834472656
loss:  113.966064453125 15.683111190795898
loss:  105.1082992553711 24.584915161132812
loss:  102.59468841552734 30.584453582763672
loss:  98.93380737304688 32.33418273925781
loss:  92.21336364746094 31.98270034790039
loss:  87.8755874633789 31.38201904296875
loss:  84.08049774169922 31.221435546875
loss:  80.53598022460938 30.76016616821289
loss:  80.05187225341797 30.72200584411621
loss:  79.63509368896484 30.902971267700195
loss:  77.79730224609375 30.286022186279297
loss:  78.41942596435547 30.148298263549805
loss:  76.33048248291016 29.9970760345459
loss:  75.65594482421875 29.804162979125977
loss:  77.72815704345703 29.681447982788086
*******************Epoch 0 ****************** 20 0.00095
Validation Loss
*** pred loss:  42.40284729003906 pred acc: 0.3293478190898895
*** stop loss:  11.688924789428711 stop acc: 0.8349003791809082
*** template loss:  8.678426742553711 template acc: tensor(0.0239, device='cuda:0')
*** label loss:  6.432246208190918 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 67.6429443359375 pred acc: 0.254961165424902
---> stop loss: 16.93463897705078 stop acc: 0.764189726114273
---> template loss: 7.867608642578125 tempalte acc: 0.015689572691917418
---> molecule label loss: 6.72398681640625 molecule acc: 0.36196293830871584
---> kl loss: 23.03404998779297
---> reconstruction loss: 99.16091184196472
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-1-with.npy
loss:  72.1171646118164 29.31236457824707
loss:  72.00198364257812 29.188735961914062
loss:  72.59182739257812 29.37472915649414
loss:  71.01458740234375 29.292922973632812
loss:  70.6261978149414 28.614627838134766
loss:  70.70378112792969 28.490463256835938
loss:  70.36651611328125 28.188617706298828
loss:  68.99030303955078 28.389144897460938
loss:  68.49605560302734 28.093704223632812
loss:  66.80105590820312 28.747543334960938
loss:  67.44552612304688 28.307334899902344
loss:  66.69692993164062 28.313934326171875
loss:  67.00611877441406 28.3830509185791
loss:  64.8285140991211 28.357372283935547
loss:  65.55791473388672 28.65761947631836
loss:  65.03545379638672 28.842208862304688
loss:  64.45333862304688 29.079635620117188
loss:  63.7495231628418 29.40645408630371
loss:  63.48286437988281 29.502492904663086
loss:  62.9969596862793 29.456422805786133
*******************Epoch 1 ****************** 40 0.0019500000000000001
Validation Loss
*** pred loss:  37.09099578857422 pred acc: 0.38713768124580383
*** stop loss:  9.5839204788208 stop acc: 0.8672478795051575
*** template loss:  8.493683815002441 template acc: tensor(0.0433, device='cuda:0')
*** label loss:  6.333920001983643 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 43.76254577636719 pred acc: 0.3409497693181038
---> stop loss: 11.017501831054688 stop acc: 0.8657833576202393
---> template loss: 7.3002685546875 tempalte acc: 0.03518373966217041
---> molecule label loss: 5.625322723388672 molecule acc: 0.3822804927825928
---> kl loss: 28.799969482421876
---> reconstruction loss: 67.69196628021241
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-2-with.npy
loss:  63.177494049072266 29.2385311126709
loss:  62.43706130981445 29.748167037963867
loss:  62.675140380859375 29.329761505126953
loss:  60.573482513427734 29.099884033203125
loss:  60.40689468383789 29.644498825073242
loss:  60.61526870727539 29.431081771850586
loss:  61.839900970458984 29.603609085083008
loss:  60.694679260253906 29.910533905029297
loss:  58.83559036254883 30.4240665435791
loss:  59.9444580078125 30.573230743408203
loss:  58.26870346069336 31.050748825073242
loss:  58.65861511230469 31.4331111907959
loss:  58.605567932128906 31.79570960998535
loss:  58.365234375 32.349342346191406
loss:  57.933006286621094 32.798526763916016
loss:  57.734806060791016 34.16943359375
loss:  56.511199951171875 34.468265533447266
loss:  56.48548126220703 34.37192916870117
loss:  56.6967658996582 34.473026275634766
loss:  56.282203674316406 34.74794006347656
*******************Epoch 2 ****************** 60 0.00295
Validation Loss
*** pred loss:  33.11167526245117 pred acc: 0.4611714780330658
*** stop loss:  8.355724334716797 stop acc: 0.8803238272666931
*** template loss:  8.401751518249512 template acc: tensor(0.0598, device='cuda:0')
*** label loss:  6.281957149505615 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 38.231103515625 pred acc: 0.40116515159606936
---> stop loss: 8.792453002929687 stop acc: 0.8946744412183761
---> template loss: 6.733763122558594 tempalte acc: 0.06408565044403076
---> molecule label loss: 5.501407241821289 molecule acc: 0.3826561689376831
---> kl loss: 31.43306884765625
---> reconstruction loss: 59.244351304321285
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-3-with.npy
loss:  55.298583984375 34.844215393066406
loss:  55.16975784301758 35.332828521728516
loss:  54.562713623046875 35.27460479736328
loss:  54.63942337036133 34.91667556762695
loss:  54.53535461425781 35.37069320678711
loss:  54.02069854736328 35.828086853027344
loss:  54.38119125366211 35.76011657714844
loss:  53.37948989868164 35.5815315246582
loss:  53.402931213378906 36.0938835144043
loss:  53.01789474487305 36.42064666748047
loss:  52.66563415527344 36.38847351074219
loss:  52.40678405761719 36.423606872558594
loss:  52.26704025268555 37.0815544128418
loss:  51.97284698486328 37.196922302246094
loss:  51.842857360839844 37.301509857177734
loss:  52.018924713134766 37.918243408203125
loss:  51.25648498535156 38.22349548339844
loss:  52.004756927490234 37.390846252441406
loss:  50.61720275878906 37.966896057128906
loss:  52.01975631713867 37.32115936279297
*******************Epoch 3 ****************** 80 0.00395
Validation Loss
*** pred loss:  30.318275451660156 pred acc: 0.5141907930374146
*** stop loss:  7.484596252441406 stop acc: 0.8947073817253113
*** template loss:  8.267749786376953 template acc: tensor(0.0770, device='cuda:0')
*** label loss:  6.128328800201416 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 33.96485595703125 pred acc: 0.47530099749565125
---> stop loss: 7.592597198486328 stop acc: 0.9086045622825623
---> template loss: 6.055542755126953 tempalte acc: 0.11045633554458618
---> molecule label loss: 5.334137725830078 molecule acc: 0.3825840950012207
---> kl loss: 36.43180541992187
---> reconstruction loss: 52.930105599060056
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-4-with.npy
loss:  50.762969970703125 37.48865509033203
loss:  50.22254943847656 36.99856948852539
loss:  49.478187561035156 37.24872589111328
loss:  49.914764404296875 36.84125518798828
loss:  48.96782684326172 36.380828857421875
loss:  48.785423278808594 37.45075988769531
loss:  49.432865142822266 37.67921447753906
loss:  48.741729736328125 37.363250732421875
loss:  49.336849212646484 36.74834442138672
loss:  48.50333786010742 36.610557556152344
loss:  48.0046501159668 36.979225158691406
loss:  48.039649963378906 36.77059555053711
loss:  47.462955474853516 37.18932342529297
loss:  47.680362701416016 36.71044158935547
loss:  47.06949234008789 37.004783630371094
loss:  46.63762283325195 37.21144104003906
loss:  47.1931037902832 37.17976379394531
loss:  47.13004684448242 37.69591522216797
loss:  46.43473815917969 36.77391052246094
loss:  47.253658294677734 38.365089416503906
*******************Epoch 4 ****************** 100 0.0049499999999999995
Validation Loss
*** pred loss:  28.496694564819336 pred acc: 0.5457125306129456
*** stop loss:  7.058255672454834 stop acc: 0.9007161259651184
*** template loss:  8.065857887268066 template acc: tensor(0.0918, device='cuda:0')
*** label loss:  6.082371711730957 label acc: tensor(0.3479, device='cuda:0')
Train Loss
---> pred loss: 30.92021484375 pred acc: 0.5292969852685928
---> stop loss: 6.809281921386718 stop acc: 0.9191194385290146
---> template loss: 5.400570297241211 tempalte acc: 0.16242904663085939
---> molecule label loss: 5.056365585327148 molecule acc: 0.3835209846496582
---> kl loss: 37.13453369140625
---> reconstruction loss: 48.16882993225098
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-5-with.npy
loss:  46.76482391357422 37.343910217285156
loss:  46.047115325927734 37.04767608642578
loss:  45.628326416015625 37.431365966796875
loss:  45.63454055786133 37.59185028076172
loss:  45.38508987426758 36.972564697265625
loss:  45.57845687866211 37.050018310546875
loss:  45.4274787902832 37.23371887207031
loss:  44.72848129272461 36.54058837890625
loss:  44.99390411376953 37.04492950439453
loss:  44.910736083984375 37.44894790649414
loss:  45.29951858520508 37.474815368652344
loss:  45.252201080322266 37.38720703125
loss:  44.282310485839844 37.21282958984375
loss:  44.079044342041016 37.27704620361328
loss:  44.27756118774414 37.578460693359375
loss:  44.67388916015625 37.28190231323242
loss:  44.067474365234375 37.03248977661133
loss:  43.986934661865234 36.81704330444336
loss:  43.848663330078125 37.280479431152344
loss:  43.690895080566406 36.639190673828125
*******************Epoch 5 ****************** 120 0.0059499999999999996
Validation Loss
*** pred loss:  27.107145309448242 pred acc: 0.5602656602859497
*** stop loss:  6.896427154541016 stop acc: 0.9025218486785889
*** template loss:  7.870178699493408 template acc: tensor(0.1041, device='cuda:0')
*** label loss:  6.048675537109375 label acc: tensor(0.3504, device='cuda:0')
Train Loss
---> pred loss: 28.755770874023437 pred acc: 0.5595994234085083
---> stop loss: 6.353128051757812 stop acc: 0.9246283859014511
---> template loss: 4.822613143920899 tempalte acc: 0.2126136302947998
---> molecule label loss: 4.79278793334961 molecule acc: 0.38524470329284666
---> kl loss: 37.18434448242188
---> reconstruction loss: 44.70662790618897
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-6-with.npy
loss:  43.267059326171875 38.77379608154297
loss:  43.24831771850586 38.05317687988281
loss:  43.45952224731445 38.035438537597656
loss:  43.285221099853516 38.374664306640625
loss:  42.88918685913086 38.27020263671875
loss:  42.366241455078125 37.72205352783203
loss:  42.06626510620117 38.817481994628906
loss:  42.49483108520508 38.42742919921875
loss:  42.25810623168945 38.238258361816406
loss:  42.02718734741211 38.20311737060547
loss:  42.04625701904297 38.92277526855469
loss:  41.589393615722656 39.165550231933594
loss:  41.65785217285156 38.91252899169922
loss:  41.823219299316406 38.814361572265625
loss:  41.28409194946289 38.1948356628418
loss:  42.2338981628418 39.13701629638672
loss:  41.16289138793945 38.694786071777344
loss:  41.27991485595703 39.25524139404297
loss:  41.343780517578125 39.16078186035156
loss:  40.41742706298828 40.646217346191406
*******************Epoch 6 ****************** 140 0.00695
Validation Loss
*** pred loss:  26.084861755371094 pred acc: 0.577838122844696
*** stop loss:  6.238555908203125 stop acc: 0.9161893129348755
*** template loss:  7.7294921875 template acc: tensor(0.1154, device='cuda:0')
*** label loss:  6.079919815063477 label acc: tensor(0.3492, device='cuda:0')
Train Loss
---> pred loss: 27.180923461914062 pred acc: 0.5809131860733032
---> stop loss: 5.984780120849609 stop acc: 0.9296822428703309
---> template loss: 4.222655868530273 tempalte acc: 0.2837101221084595
---> molecule label loss: 4.471030807495117 molecule acc: 0.39011154174804685
---> kl loss: 38.690985107421874
---> reconstruction loss: 41.84113488494873
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-7-with.npy
loss:  40.273963928222656 39.137840270996094
loss:  40.665401458740234 39.92882537841797
loss:  40.647029876708984 39.824649810791016
loss:  40.912784576416016 39.93253707885742
loss:  40.94581985473633 39.641849517822266
loss:  40.767906188964844 39.66194152832031
loss:  40.70763397216797 39.39898681640625
loss:  40.46337127685547 39.70600891113281
loss:  40.506839752197266 39.9359245300293
loss:  39.24128341674805 39.179962158203125
loss:  40.117427825927734 40.061378479003906
loss:  40.173274993896484 39.86998748779297
loss:  39.869258880615234 39.615169525146484
loss:  39.65980529785156 39.990169525146484
loss:  39.42724609375 40.283416748046875
loss:  39.444644927978516 40.02695846557617
loss:  38.98630142211914 40.7503776550293
loss:  39.2634162902832 40.477195739746094
loss:  39.35982894897461 40.62207794189453
loss:  39.99880599975586 41.419097900390625
*******************Epoch 7 ****************** 160 0.00795
Validation Loss
*** pred loss:  25.28534698486328 pred acc: 0.5919082164764404
*** stop loss:  6.357678413391113 stop acc: 0.9113636612892151
*** template loss:  7.533856391906738 template acc: tensor(0.1203, device='cuda:0')
*** label loss:  6.008904933929443 label acc: tensor(0.3505, device='cuda:0')
Train Loss
---> pred loss: 26.040716552734374 pred acc: 0.5997807949781417
---> stop loss: 5.7834114074707035 stop acc: 0.9319745600223541
---> template loss: 3.7390323638916017 tempalte acc: 0.3389988660812378
---> molecule label loss: 4.209529113769531 molecule acc: 0.39758973121643065
---> kl loss: 39.973211669921874
---> reconstruction loss: 39.753813309021
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-8-with.npy
loss:  38.82038497924805 41.13628387451172
loss:  38.38513946533203 40.473419189453125
loss:  38.608882904052734 41.20941925048828
loss:  38.620731353759766 41.153594970703125
loss:  39.0031852722168 41.31676483154297
loss:  38.183616638183594 40.85566711425781
loss:  38.55659866333008 41.163673400878906
loss:  38.41834259033203 40.626548767089844
loss:  38.6019172668457 40.66324234008789
loss:  37.90187072753906 40.68582534790039
loss:  37.77302932739258 40.749290466308594
loss:  37.507049560546875 40.83388900756836
loss:  38.15220260620117 40.77345657348633
loss:  37.89461135864258 41.09423828125
loss:  37.973628997802734 40.89781188964844
loss:  37.69615936279297 41.29534912109375
loss:  37.419376373291016 41.395843505859375
loss:  37.39014434814453 41.458133697509766
loss:  37.550010681152344 41.439613342285156
loss:  39.06278991699219 41.29667282104492
*******************Epoch 8 ****************** 180 0.00895
Validation Loss
*** pred loss:  24.481210708618164 pred acc: 0.6037439703941345
*** stop loss:  6.119044303894043 stop acc: 0.9162515997886658
*** template loss:  7.463539123535156 template acc: tensor(0.1231, device='cuda:0')
*** label loss:  6.033408164978027 label acc: tensor(0.3507, device='cuda:0')
Train Loss
---> pred loss: 25.02099609375 pred acc: 0.6168382048606873
---> stop loss: 5.465018844604492 stop acc: 0.9367208808660508
---> template loss: 3.3866958618164062 tempalte acc: 0.38629727363586425
---> molecule label loss: 3.955545425415039 molecule acc: 0.40787835121154786
---> kl loss: 41.02593994140625
---> reconstruction loss: 37.80880355529785
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-9-with.npy
loss:  37.10420227050781 41.19249725341797
loss:  37.495975494384766 41.04730224609375
loss:  37.29423522949219 41.545928955078125
loss:  36.70166015625 41.55876159667969
loss:  36.719398498535156 41.45998764038086
loss:  36.76303482055664 41.62860107421875
loss:  36.716148376464844 41.282894134521484
loss:  36.5657958984375 41.26426696777344
loss:  36.234615325927734 42.1970329284668
loss:  36.55403518676758 42.06135559082031
loss:  36.42609786987305 42.236968994140625
loss:  36.62338638305664 42.326019287109375
loss:  36.54894256591797 42.38323211669922
loss:  36.472023010253906 41.83369445800781
loss:  36.374244689941406 41.93907928466797
loss:  36.25407409667969 42.21824645996094
loss:  36.089454650878906 42.32807922363281
loss:  36.484256744384766 42.364097595214844
loss:  36.546321868896484 42.86653137207031
loss:  36.122718811035156 42.95720672607422
*******************Epoch 9 ****************** 200 0.00995
Validation Loss
*** pred loss:  23.781482696533203 pred acc: 0.6207125186920166
*** stop loss:  5.766099452972412 stop acc: 0.921201765537262
*** template loss:  7.33186149597168 template acc: tensor(0.1375, device='cuda:0')
*** label loss:  5.998558044433594 label acc: tensor(0.3517, device='cuda:0')
Train Loss
---> pred loss: 24.060882568359375 pred acc: 0.6296342372894287
---> stop loss: 5.333205795288086 stop acc: 0.9379729062318802
---> template loss: 3.080981636047363 tempalte acc: 0.42789769172668457
---> molecule label loss: 3.7319931030273437 molecule acc: 0.4223292827606201
---> kl loss: 41.93458557128906
---> reconstruction loss: 36.187285785675044
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-10-with.npy
loss:  35.81086730957031 42.70954132080078
loss:  35.15598678588867 42.16477966308594
loss:  35.644020080566406 42.92441177368164
loss:  35.63405990600586 43.337974548339844
loss:  35.461978912353516 43.27257537841797
loss:  35.14847946166992 42.50471496582031
loss:  35.36875534057617 43.21465301513672
loss:  34.91641616821289 42.88671875
loss:  35.556121826171875 42.951995849609375
loss:  34.95976638793945 42.92018127441406
loss:  35.16433334350586 42.75543975830078
loss:  35.226505279541016 42.7337760925293
loss:  34.287200927734375 42.89659118652344
loss:  35.048744201660156 42.89168167114258
loss:  34.82448959350586 43.013912200927734
loss:  34.77413558959961 42.881980895996094
loss:  35.2372932434082 43.39530944824219
loss:  34.324913024902344 42.81502914428711
loss:  34.24725341796875 42.51274871826172
loss:  34.65739822387695 42.8053092956543
*******************Epoch 10 ****************** 220 0.01095
Validation Loss
*** pred loss:  23.17611312866211 pred acc: 0.6298912763595581
*** stop loss:  5.798822402954102 stop acc: 0.9219178557395935
*** template loss:  7.257562637329102 template acc: tensor(0.1558, device='cuda:0')
*** label loss:  6.0185980796813965 label acc: tensor(0.3507, device='cuda:0')
Train Loss
---> pred loss: 23.19505920410156 pred acc: 0.6427261680364609
---> stop loss: 5.080157089233398 stop acc: 0.9416151434183121
---> template loss: 2.8164987564086914 tempalte acc: 0.4679145812988281
---> molecule label loss: 3.53155403137207 molecule acc: 0.43174090385437014
---> kl loss: 42.87946472167969
---> reconstruction loss: 34.60290333297729
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-11-with.npy
loss:  35.0667610168457 43.336761474609375
loss:  34.66627502441406 43.00624465942383
loss:  34.26536560058594 42.863521575927734
loss:  33.68872833251953 43.1455078125
loss:  33.918758392333984 43.05712127685547
loss:  34.34374237060547 42.966102600097656
loss:  34.117286682128906 43.601356506347656
loss:  33.55495071411133 42.8137321472168
loss:  34.24143600463867 43.30141067504883
loss:  33.93567657470703 43.30435562133789
loss:  33.796749114990234 43.32267761230469
loss:  33.7008056640625 43.25148391723633
loss:  33.864925384521484 43.20060348510742
loss:  33.72169494628906 43.33681869506836
loss:  33.39728927612305 43.86861038208008
loss:  33.09742736816406 43.4364128112793
loss:  32.906776428222656 43.46539306640625
loss:  33.42235565185547 43.44554901123047
loss:  33.13410186767578 43.517478942871094
loss:  33.494041442871094 44.0137825012207
*******************Epoch 11 ****************** 240 0.01195
Validation Loss
*** pred loss:  22.729352951049805 pred acc: 0.6326086521148682
*** stop loss:  5.677772521972656 stop acc: 0.9256227016448975
*** template loss:  7.1462273597717285 template acc: tensor(0.1632, device='cuda:0')
*** label loss:  6.003093719482422 label acc: tensor(0.3517, device='cuda:0')
Train Loss
---> pred loss: 22.47357940673828 pred acc: 0.6519343227148056
---> stop loss: 4.921762466430664 stop acc: 0.9432489514350891
---> template loss: 2.585586738586426 tempalte acc: 0.5045699596405029
---> molecule label loss: 3.3387577056884767 molecule acc: 0.446986722946167
---> kl loss: 43.312741088867185
---> reconstruction loss: 33.29916994613647
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-12-with.npy
loss:  32.46951675415039 43.20817184448242
loss:  32.84503936767578 43.23161315917969
loss:  32.976104736328125 43.5551643371582
loss:  32.9647216796875 43.459083557128906
loss:  33.364845275878906 43.56812286376953
loss:  33.09540557861328 43.43696594238281
loss:  33.18926239013672 43.7175178527832
loss:  32.836509704589844 43.69432067871094
loss:  33.15812301635742 43.797935485839844
loss:  32.398990631103516 43.428802490234375
loss:  32.40580749511719 43.84513854980469
loss:  32.822975158691406 43.87822723388672
loss:  32.334651947021484 44.23831558227539
loss:  32.35746383666992 44.01869201660156
loss:  32.43095397949219 43.68473815917969
loss:  32.068050384521484 43.93575668334961
loss:  32.6059455871582 44.00060272216797
loss:  32.217472076416016 43.71971893310547
loss:  32.14149475097656 43.66729736328125
loss:  31.736173629760742 42.93321228027344
*******************Epoch 12 ****************** 260 0.01295
Validation Loss
*** pred loss:  22.342844009399414 pred acc: 0.6403985619544983
*** stop loss:  5.55242919921875 stop acc: 0.9261208176612854
*** template loss:  7.132052898406982 template acc: tensor(0.1720, device='cuda:0')
*** label loss:  5.976261615753174 label acc: tensor(0.3554, device='cuda:0')
Train Loss
---> pred loss: 21.732489013671874 pred acc: 0.6622287482023239
---> stop loss: 4.775248718261719 stop acc: 0.9451711297035217
---> template loss: 2.3890804290771483 tempalte acc: 0.5356425762176513
---> molecule label loss: 3.179585075378418 molecule acc: 0.4589091300964355
---> kl loss: 43.65097351074219
---> reconstruction loss: 32.055694624481205
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-13-with.npy
loss:  32.08498764038086 43.814605712890625
loss:  31.56008529663086 43.880775451660156
loss:  32.30500793457031 43.67698287963867
loss:  32.08210372924805 43.926124572753906
loss:  31.740554809570312 43.37284851074219
loss:  31.734241485595703 43.86262893676758
loss:  31.963359832763672 43.90420150756836
loss:  31.722652435302734 43.862674713134766
loss:  31.9412899017334 43.90997314453125
loss:  31.783845901489258 44.30815124511719
loss:  31.171009063720703 44.254539489746094
loss:  31.588409423828125 44.157562255859375
loss:  31.595745086669922 44.0010986328125
loss:  31.57455062866211 43.85448455810547
loss:  31.202638626098633 44.23580551147461
loss:  31.671268463134766 43.53417205810547
loss:  30.763816833496094 44.056732177734375
loss:  30.93846321105957 43.88798904418945
loss:  31.35330581665039 44.122596740722656
loss:  31.341032028198242 44.218570709228516
*******************Epoch 13 ****************** 280 0.01395
Validation Loss
*** pred loss:  21.86608123779297 pred acc: 0.6477656960487366
*** stop loss:  5.387979984283447 stop acc: 0.9301681518554688
*** template loss:  7.088869094848633 template acc: tensor(0.1706, device='cuda:0')
*** label loss:  5.969010829925537 label acc: tensor(0.3537, device='cuda:0')
Train Loss
---> pred loss: 21.137281799316405 pred acc: 0.6701162695884705
---> stop loss: 4.639811325073242 stop acc: 0.9469764232635498
---> template loss: 2.2046344757080076 tempalte acc: 0.563496208190918
---> molecule label loss: 3.0320430755615235 molecule acc: 0.475958251953125
---> kl loss: 43.94212951660156
---> reconstruction loss: 30.992924651641843
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-14-with.npy
loss:  30.556442260742188 44.27965545654297
loss:  31.18689727783203 44.54676055908203
loss:  31.2354793548584 44.51869201660156
loss:  31.418054580688477 44.6385498046875
loss:  31.696504592895508 44.4723014831543
loss:  31.11067771911621 44.681182861328125
loss:  31.256919860839844 44.0401496887207
loss:  31.186004638671875 44.66456604003906
loss:  31.158161163330078 43.880401611328125
loss:  30.884815216064453 43.882652282714844
loss:  31.030895233154297 43.60088348388672
loss:  31.030298233032227 43.601402282714844
loss:  30.69415283203125 43.52399826049805
loss:  30.559131622314453 43.68449401855469
loss:  30.491849899291992 43.70859146118164
loss:  30.935277938842773 43.96855545043945
loss:  30.716251373291016 43.48785400390625
loss:  30.5024471282959 43.490264892578125
loss:  30.548368453979492 43.33989715576172
loss:  29.51946449279785 43.89813232421875
*******************Epoch 14 ****************** 300 0.014950000000000001
Validation Loss
*** pred loss:  21.45346450805664 pred acc: 0.6577898263931274
*** stop loss:  5.404928207397461 stop acc: 0.9289539456367493
*** template loss:  7.088554859161377 template acc: tensor(0.1741, device='cuda:0')
*** label loss:  5.9913129806518555 label acc: tensor(0.3569, device='cuda:0')
Train Loss
---> pred loss: 20.539280700683594 pred acc: 0.6771738827228546
---> stop loss: 4.560870742797851 stop acc: 0.947439330816269
---> template loss: 2.2147430419921874 tempalte acc: 0.5599325180053711
---> molecule label loss: 2.9342763900756834 molecule acc: 0.4838706970214844
---> kl loss: 43.995452880859375
---> reconstruction loss: 30.228171910095217
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-15-with.npy
loss:  30.256269454956055 44.090431213378906
loss:  30.166688919067383 43.4747314453125
loss:  30.507978439331055 44.168617248535156
loss:  30.27816390991211 44.06742477416992
loss:  30.07240104675293 43.663795471191406
loss:  30.35505485534668 43.62263870239258
loss:  29.80466079711914 44.39856719970703
loss:  29.637287139892578 44.137718200683594
loss:  29.79195213317871 44.09583282470703
loss:  29.88688087463379 44.335853576660156
loss:  30.141695022583008 44.259735107421875
loss:  29.846511840820312 44.1345100402832
loss:  30.096704483032227 44.177772521972656
loss:  29.811002731323242 44.331329345703125
loss:  29.996381759643555 44.37058639526367
loss:  29.439640045166016 44.14322280883789
loss:  29.391277313232422 44.06840515136719
loss:  29.310760498046875 44.37420654296875
loss:  29.65149688720703 44.22604751586914
loss:  30.68222999572754 43.98468017578125
*******************Epoch 15 ****************** 320 0.01595
Validation Loss
*** pred loss:  21.16063690185547 pred acc: 0.6569444537162781
*** stop loss:  5.664818286895752 stop acc: 0.9259029030799866
*** template loss:  6.9658331871032715 template acc: tensor(0.1889, device='cuda:0')
*** label loss:  5.998231887817383 label acc: tensor(0.3547, device='cuda:0')
Train Loss
---> pred loss: 20.039033508300783 pred acc: 0.6858248710632324
---> stop loss: 4.426064300537109 stop acc: 0.9493620008230209
---> template loss: 2.0099437713623045 tempalte acc: 0.5971422672271729
---> molecule label loss: 2.7986351013183595 molecule acc: 0.49729013442993164
---> kl loss: 44.10631103515625
---> reconstruction loss: 29.25275433898926
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-16-with.npy
loss:  29.56524658203125 44.297393798828125
loss:  29.84423065185547 44.485984802246094
loss:  29.093326568603516 44.39099884033203
loss:  29.44701385498047 44.12049865722656
loss:  29.537269592285156 44.35010528564453
loss:  29.827606201171875 44.378414154052734
loss:  28.7873477935791 44.14597702026367
loss:  28.928714752197266 44.07835388183594
loss:  29.276599884033203 43.96018981933594
loss:  28.893997192382812 44.4029426574707
loss:  28.929506301879883 44.38114547729492
loss:  29.138952255249023 44.09343719482422
loss:  29.216997146606445 44.20695495605469
loss:  28.904254913330078 44.07429504394531
loss:  29.62294578552246 44.143768310546875
loss:  29.17291831970215 44.25836181640625
loss:  29.071849822998047 44.08404541015625
loss:  29.350290298461914 44.15039825439453
loss:  28.82349967956543 44.26667022705078
loss:  28.502927780151367 44.91047286987305
*******************Epoch 16 ****************** 340 0.01695
Validation Loss
*** pred loss:  20.9012508392334 pred acc: 0.6618961095809937
*** stop loss:  5.140328884124756 stop acc: 0.9325653910636902
*** template loss:  6.893399715423584 template acc: tensor(0.1829, device='cuda:0')
*** label loss:  5.995283603668213 label acc: tensor(0.3592, device='cuda:0')
Train Loss
---> pred loss: 19.518771362304687 pred acc: 0.6918419539928437
---> stop loss: 4.461656951904297 stop acc: 0.9485302597284317
---> template loss: 1.831201171875 tempalte acc: 0.625924015045166
---> molecule label loss: 2.6559776306152343 molecule acc: 0.5151194572448731
---> kl loss: 44.25902099609375
---> reconstruction loss: 28.4465838861084
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-17-with.npy
loss:  28.37396240234375 43.65473175048828
loss:  28.26109504699707 44.02100372314453
loss:  29.287839889526367 44.10578918457031
loss:  28.679298400878906 44.02385711669922
loss:  28.611099243164062 44.02894973754883
loss:  28.36612319946289 43.88720703125
loss:  28.808927536010742 44.171043395996094
loss:  27.99938201904297 43.636138916015625
loss:  28.143932342529297 43.75633239746094
loss:  28.50969696044922 44.42286682128906
loss:  28.261646270751953 43.86334991455078
loss:  28.387184143066406 44.033348083496094
loss:  28.009965896606445 44.0405158996582
loss:  27.946979522705078 44.35729217529297
loss:  28.06138801574707 44.31547164916992
loss:  28.270238876342773 44.31224822998047
loss:  27.95008087158203 44.033042907714844
loss:  28.47188949584961 43.77525329589844
loss:  28.260772705078125 44.34858703613281
loss:  26.966514587402344 43.52581787109375
*******************Epoch 17 ****************** 360 0.01795
Validation Loss
*** pred loss:  20.762413024902344 pred acc: 0.6620168685913086
*** stop loss:  5.078800201416016 stop acc: 0.933935284614563
*** template loss:  6.845093250274658 template acc: tensor(0.2026, device='cuda:0')
*** label loss:  6.01291036605835 label acc: tensor(0.3594, device='cuda:0')
Train Loss
---> pred loss: 19.01512451171875 pred acc: 0.6972361385822297
---> stop loss: 4.218088531494141 stop acc: 0.9517475813627243
---> template loss: 1.722039031982422 tempalte acc: 0.6475457191467285
---> molecule label loss: 2.556966018676758 molecule acc: 0.5282664775848389
---> kl loss: 44.01564331054688
---> reconstruction loss: 27.491318738708497
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-18-with.npy
loss:  27.786928176879883 44.289100646972656
loss:  27.927364349365234 44.05882263183594
loss:  28.065113067626953 43.989845275878906
loss:  27.87729263305664 44.159584045410156
loss:  27.87458038330078 44.70502471923828
loss:  28.025991439819336 44.43122100830078
loss:  27.8189754486084 43.94599151611328
loss:  27.934078216552734 44.155364990234375
loss:  27.63967514038086 44.24827575683594
loss:  27.490549087524414 44.149810791015625
loss:  27.781932830810547 44.00422668457031
loss:  27.820568084716797 43.830177307128906
loss:  28.05927848815918 44.0057373046875
loss:  27.367351531982422 43.76860046386719
loss:  27.07343864440918 44.02007293701172
loss:  27.391389846801758 44.37736511230469
loss:  27.08643341064453 44.34022521972656
loss:  27.224735260009766 44.160987854003906
loss:  27.595558166503906 43.91318130493164
loss:  27.76675796508789 44.032257080078125
*******************Epoch 18 ****************** 380 0.01895
Validation Loss
*** pred loss:  20.33279037475586 pred acc: 0.6679951548576355
*** stop loss:  5.286377429962158 stop acc: 0.9327210783958435
*** template loss:  6.848834037780762 template acc: tensor(0.1966, device='cuda:0')
*** label loss:  6.017971992492676 label acc: tensor(0.3626, device='cuda:0')
Train Loss
---> pred loss: 18.60638427734375 pred acc: 0.7055692642927169
---> stop loss: 4.1267555236816404 stop acc: 0.9532603055238724
---> template loss: 1.660698127746582 tempalte acc: 0.6539188385009765
---> molecule label loss: 2.471287727355957 molecule acc: 0.5390225887298584
---> kl loss: 44.129296875
---> reconstruction loss: 26.844148383789065
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-19-with.npy
loss:  27.248394012451172 43.65155029296875
loss:  27.49641990661621 43.989044189453125
loss:  27.786945343017578 43.678688049316406
loss:  27.585594177246094 44.06489562988281
loss:  27.417570114135742 43.710975646972656
loss:  26.92494773864746 43.89454650878906
loss:  27.523569107055664 43.75727844238281
loss:  27.57649803161621 44.002952575683594
loss:  27.181001663208008 44.044960021972656
loss:  26.846128463745117 44.04436492919922
loss:  27.231525421142578 43.80989074707031
loss:  26.950870513916016 43.81849670410156
loss:  26.9224910736084 43.89837646484375
loss:  26.736801147460938 43.81645965576172
loss:  27.154903411865234 43.60838317871094
loss:  26.942256927490234 43.81256866455078
loss:  26.769588470458984 43.52685546875
loss:  26.758590698242188 44.286346435546875
loss:  27.472728729248047 43.934993743896484
loss:  26.161165237426758 43.72930908203125
*******************Epoch 19 ****************** 400 0.019950000000000002
Validation Loss
*** pred loss:  20.29468536376953 pred acc: 0.667391300201416
*** stop loss:  5.046017646789551 stop acc: 0.9361146092414856
*** template loss:  6.777563571929932 template acc: tensor(0.2033, device='cuda:0')
*** label loss:  5.993323802947998 label acc: tensor(0.3624, device='cuda:0')
Train Loss
---> pred loss: 18.16755065917969 pred acc: 0.7110724180936814
---> stop loss: 4.150115966796875 stop acc: 0.9526813119649887
---> template loss: 1.5697656631469727 tempalte acc: 0.6721214771270752
---> molecule label loss: 2.392910385131836 molecule acc: 0.5487085342407226
---> kl loss: 43.85404663085937
---> reconstruction loss: 26.259511183776855
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-20-with.npy
loss:  69.64108276367188 43.83330535888672
loss:  67.74504852294922 41.89484405517578
loss:  65.83470916748047 39.008331298828125
loss:  62.31488800048828 35.978755950927734
loss:  60.0085563659668 32.714073181152344
loss:  57.66347122192383 30.0880126953125
loss:  55.65867614746094 28.12420082092285
loss:  54.12733459472656 26.304080963134766
loss:  52.55298614501953 24.391948699951172
loss:  51.30012130737305 22.882904052734375
loss:  50.441497802734375 21.47690773010254
loss:  49.296348571777344 19.835351943969727
loss:  47.93098449707031 18.03054428100586
loss:  46.90427017211914 16.458633422851562
loss:  46.691001892089844 14.852653503417969
loss:  46.826358795166016 13.239710807800293
loss:  45.35221481323242 11.650437355041504
loss:  42.752296447753906 10.320392608642578
loss:  41.82994079589844 8.92033863067627
loss:  41.27495193481445 7.43645715713501
*******************Epoch 20 ****************** 420 1.0
Validation Loss
*** pred loss:  24.08316993713379 pred acc: 0.59794682264328
*** stop loss:  7.092617034912109 stop acc: 0.9083749055862427
*** template loss:  7.593254089355469 template acc: tensor(0.0528, device='cuda:0')
*** label loss:  5.871249675750732 label acc: tensor(0.3470, device='cuda:0')
Train Loss
---> pred loss: 19.186724853515624 pred acc: 0.6902701646089554
---> stop loss: 4.512519836425781 stop acc: 0.9471461921930313
---> template loss: 2.809137535095215 tempalte acc: 0.4586517810821533
---> molecule label loss: 2.926859474182129 molecule acc: 0.46622576713562014
---> kl loss: 23.372097778320313
---> reconstruction loss: 29.435238647460938
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-21-with.npy
loss:  42.0538444519043 7.102881908416748
loss:  39.93938446044922 6.038543224334717
loss:  39.95716857910156 5.238130569458008
loss:  39.45663070678711 4.85189962387085
loss:  38.89910125732422 4.540658950805664
loss:  38.94879913330078 4.216913223266602
loss:  38.78404235839844 4.0333147048950195
loss:  38.14470291137695 3.6900928020477295
loss:  38.357784271240234 3.676748752593994
loss:  38.13664245605469 3.4525082111358643
loss:  37.829986572265625 3.4239895343780518
loss:  38.21412658691406 3.356837749481201
loss:  37.31825256347656 3.231844425201416
loss:  36.87739944458008 3.162505626678467
loss:  37.575077056884766 3.0764925479888916
loss:  36.52183151245117 3.012141227722168
loss:  37.00041961669922 2.9758048057556152
loss:  36.15473175048828 2.8358702659606934
loss:  36.829280853271484 2.9376673698425293
loss:  35.375213623046875 2.6901941299438477
*******************Epoch 21 ****************** 440 1.0
Validation Loss
*** pred loss:  24.4997501373291 pred acc: 0.5942632555961609
*** stop loss:  5.92101526260376 stop acc: 0.921980082988739
*** template loss:  7.473413467407227 template acc: tensor(0.0760, device='cuda:0')
*** label loss:  5.888873100280762 label acc: tensor(0.3489, device='cuda:0')
Train Loss
---> pred loss: 22.50737762451172 pred acc: 0.635152155160904
---> stop loss: 4.963640975952148 stop acc: 0.9409211248159408
---> template loss: 3.654301071166992 tempalte acc: 0.32828502655029296
---> molecule label loss: 3.1161500930786135 molecule acc: 0.457387638092041
---> kl loss: 3.877252197265625
---> reconstruction loss: 34.24146728515625
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-22-with.npy
loss:  35.8988037109375 2.8962321281433105
loss:  36.18926239013672 2.8947834968566895
loss:  35.614559173583984 2.840416669845581
loss:  35.384666442871094 2.8400979042053223
loss:  36.067691802978516 2.7622718811035156
loss:  35.971214294433594 2.786860704421997
loss:  35.43632125854492 2.773864507675171
loss:  35.907894134521484 2.7889506816864014
loss:  35.359954833984375 2.812946319580078
loss:  35.46162414550781 2.820284366607666
loss:  35.327396392822266 2.7824490070343018
loss:  35.24664306640625 2.825936794281006
loss:  34.96931457519531 2.632774591445923
loss:  35.082496643066406 2.6249637603759766
loss:  35.0229377746582 2.6168789863586426
loss:  34.42482376098633 2.5361101627349854
loss:  35.28839874267578 2.600586175918579
loss:  35.20313262939453 2.5777454376220703
loss:  34.86655807495117 2.4718241691589355
loss:  34.49989318847656 2.425746202468872
*******************Epoch 22 ****************** 460 1.0
Validation Loss
*** pred loss:  24.31982421875 pred acc: 0.5925724506378174
*** stop loss:  5.821528911590576 stop acc: 0.9232565760612488
*** template loss:  7.438104629516602 template acc: tensor(0.0883, device='cuda:0')
*** label loss:  5.989006519317627 label acc: tensor(0.3502, device='cuda:0')
Train Loss
---> pred loss: 22.074478149414062 pred acc: 0.6460086166858673
---> stop loss: 4.697012710571289 stop acc: 0.9446997523307801
---> template loss: 3.1068992614746094 tempalte acc: 0.4040958404541016
---> molecule label loss: 2.7672050476074217 molecule acc: 0.48819875717163086
---> kl loss: 2.715586280822754
---> reconstruction loss: 32.64558925628662
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-23-with.npy
loss:  34.745384216308594 2.546828031539917
loss:  33.92612838745117 2.445307970046997
loss:  34.64206314086914 2.5225419998168945
loss:  34.16238784790039 2.457512855529785
loss:  34.431575775146484 2.567195415496826
loss:  34.73466491699219 2.5083394050598145
loss:  34.10786056518555 2.457892656326294
loss:  35.0561637878418 2.5113227367401123
loss:  33.967201232910156 2.4826438426971436
loss:  34.802490234375 2.455960273742676
loss:  34.25248336791992 2.3193130493164062
loss:  34.013389587402344 2.389554738998413
loss:  34.56703186035156 2.3762638568878174
loss:  33.83256530761719 2.381959915161133
loss:  34.16401672363281 2.349405288696289
loss:  33.896514892578125 2.352935314178467
loss:  33.95565414428711 2.328903913497925
loss:  33.93628692626953 2.3131351470947266
loss:  34.005653381347656 2.3195598125457764
loss:  33.711483001708984 2.321233034133911
*******************Epoch 23 ****************** 480 1.0
Validation Loss
*** pred loss:  24.34198570251465 pred acc: 0.5942632555961609
*** stop loss:  6.044491767883301 stop acc: 0.9211083650588989
*** template loss:  7.345362663269043 template acc: tensor(0.0978, device='cuda:0')
*** label loss:  5.936951160430908 label acc: tensor(0.3475, device='cuda:0')
Train Loss
---> pred loss: 21.807742309570312 pred acc: 0.6484136372804642
---> stop loss: 4.618202590942383 stop acc: 0.9457572817802429
---> template loss: 2.8274864196777343 tempalte acc: 0.4474283218383789
---> molecule label loss: 2.5717304229736326 molecule acc: 0.513443899154663
---> kl loss: 2.420390319824219
---> reconstruction loss: 31.825157165527347
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-24-with.npy
loss:  33.856380462646484 2.273676633834839
loss:  34.161705017089844 2.264688730239868
loss:  33.75387954711914 2.2922070026397705
loss:  33.4948616027832 2.235821008682251
loss:  33.823692321777344 2.246748924255371
loss:  33.135223388671875 2.2196056842803955
loss:  33.66438293457031 2.289827585220337
loss:  33.19270706176758 2.234602928161621
loss:  33.83592987060547 2.2206923961639404
loss:  33.43208694458008 2.2304587364196777
loss:  33.65790557861328 2.2078988552093506
loss:  33.62545394897461 2.210846185684204
loss:  33.38370132446289 2.176112174987793
loss:  33.567970275878906 2.1901395320892334
loss:  33.161075592041016 2.0675361156463623
loss:  33.69084167480469 2.0810272693634033
loss:  33.04222869873047 2.1401143074035645
loss:  32.64000701904297 2.1017184257507324
loss:  33.56313705444336 2.1748692989349365
loss:  33.41819763183594 2.2707161903381348
*******************Epoch 24 ****************** 500 1.0
Validation Loss
*** pred loss:  24.281681060791016 pred acc: 0.5966787338256836
*** stop loss:  5.992472171783447 stop acc: 0.9228206872940063
*** template loss:  7.3909831047058105 template acc: tensor(0.0992, device='cuda:0')
*** label loss:  6.056447505950928 label acc: tensor(0.3447, device='cuda:0')
Train Loss
---> pred loss: 21.66814727783203 pred acc: 0.6500351309776307
---> stop loss: 4.573486709594727 stop acc: 0.9463684499263764
---> template loss: 2.614933395385742 tempalte acc: 0.47679691314697265
---> molecule label loss: 2.4420339584350588 molecule acc: 0.5309236526489258
---> kl loss: 2.2064655303955076
---> reconstruction loss: 31.298603439331057
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-25-with.npy
loss:  32.57428741455078 2.06414794921875
loss:  32.93199920654297 2.062908172607422
loss:  32.66856384277344 2.088305711746216
loss:  33.071319580078125 2.1118178367614746
loss:  33.090518951416016 2.120504856109619
loss:  32.716590881347656 2.100104570388794
loss:  33.11250305175781 2.061614751815796
loss:  32.54342269897461 2.0050766468048096
loss:  33.27104568481445 2.04044246673584
loss:  32.90376663208008 1.960249662399292
loss:  32.81473922729492 1.9141613245010376
loss:  32.88066864013672 1.9593271017074585
loss:  32.58578109741211 1.9553664922714233
loss:  33.137794494628906 2.0200047492980957
loss:  32.97047424316406 2.0221714973449707
loss:  33.071414947509766 1.9618825912475586
loss:  33.28186798095703 1.9329180717468262
loss:  32.537906646728516 2.0004115104675293
loss:  32.8593635559082 1.983933925628662
loss:  31.690053939819336 2.0130372047424316
*******************Epoch 25 ****************** 520 1.0
Validation Loss
*** pred loss:  24.456525802612305 pred acc: 0.5966787338256836
*** stop loss:  5.798550128936768 stop acc: 0.9234122633934021
*** template loss:  7.365090847015381 template acc: tensor(0.1006, device='cuda:0')
*** label loss:  6.080604076385498 label acc: tensor(0.3511, device='cuda:0')
Train Loss
---> pred loss: 21.523675537109376 pred acc: 0.6514610826969147
---> stop loss: 4.50073471069336 stop acc: 0.9475373595952987
---> template loss: 2.4721439361572264 tempalte acc: 0.5050214290618896
---> molecule label loss: 2.320232391357422 molecule acc: 0.547602653503418
---> kl loss: 2.0189193725585937
---> reconstruction loss: 30.816786193847655
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-26-with.npy
loss:  32.634212493896484 1.9887452125549316
loss:  32.71183776855469 2.022340774536133
loss:  32.39579391479492 2.0032331943511963
loss:  32.3336067199707 2.010413646697998
loss:  32.17495346069336 1.9832499027252197
loss:  32.0235481262207 1.9333136081695557
loss:  32.90190887451172 1.925321340560913
loss:  32.01385498046875 1.9226667881011963
loss:  32.911373138427734 2.0008022785186768
loss:  31.874248504638672 1.896881103515625
loss:  32.47643280029297 1.9839122295379639
loss:  32.37538146972656 1.924890160560608
loss:  32.34785842895508 1.8945246934890747
loss:  32.45691680908203 1.839202880859375
loss:  32.379661560058594 1.891947865486145
loss:  32.4808235168457 1.8516266345977783
loss:  32.528663635253906 1.886980414390564
loss:  32.38710021972656 1.86296808719635
loss:  32.30156707763672 1.9020451307296753
loss:  32.1673583984375 2.0749099254608154
*******************Epoch 26 ****************** 540 1.0
Validation Loss
*** pred loss:  24.44584083557129 pred acc: 0.5952898263931274
*** stop loss:  5.902822971343994 stop acc: 0.9239726662635803
*** template loss:  7.395506858825684 template acc: tensor(0.1055, device='cuda:0')
*** label loss:  6.045351982116699 label acc: tensor(0.3505, device='cuda:0')
Train Loss
---> pred loss: 21.40595703125 pred acc: 0.6552306741476059
---> stop loss: 4.438992309570312 stop acc: 0.9480540513992309
---> template loss: 2.371914863586426 tempalte acc: 0.5207368850708007
---> molecule label loss: 2.2369932174682616 molecule acc: 0.5613186836242676
---> kl loss: 1.9399990081787108
---> reconstruction loss: 30.453857803344725
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-27-with.npy
loss:  32.160457611083984 1.8773760795593262
loss:  32.035579681396484 1.8847606182098389
loss:  32.638973236083984 1.8949720859527588
loss:  31.631349563598633 1.8164258003234863
loss:  32.04290008544922 1.8268545866012573
loss:  31.95047950744629 1.7781431674957275
loss:  31.57722282409668 1.71957266330719
loss:  32.18134689331055 1.7748113870620728
loss:  31.712602615356445 1.811252236366272
loss:  32.06700897216797 1.7851684093475342
loss:  31.935344696044922 1.730177879333496
loss:  32.13069152832031 1.7825086116790771
loss:  31.732255935668945 1.745086431503296
loss:  31.99643325805664 1.7073400020599365
loss:  32.04734420776367 1.7328068017959595
loss:  32.35099411010742 1.7999778985977173
loss:  31.84908103942871 1.790571928024292
loss:  32.563011169433594 1.7723326683044434
loss:  31.58416748046875 1.7604405879974365
loss:  33.083221435546875 1.8868322372436523
*******************Epoch 27 ****************** 560 1.0
Validation Loss
*** pred loss:  24.532690048217773 pred acc: 0.5910024046897888
*** stop loss:  6.027736663818359 stop acc: 0.9220112562179565
*** template loss:  7.382064342498779 template acc: tensor(0.1009, device='cuda:0')
*** label loss:  6.1268839836120605 label acc: tensor(0.3543, device='cuda:0')
Train Loss
---> pred loss: 21.385060119628907 pred acc: 0.6549157828092576
---> stop loss: 4.458699417114258 stop acc: 0.9480339258909225
---> template loss: 2.2736587524414062 tempalte acc: 0.5412513732910156
---> molecule label loss: 2.1522329330444334 molecule acc: 0.5760199546813964
---> kl loss: 1.7938705444335938
---> reconstruction loss: 30.269648742675777
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-28-with.npy
loss:  32.06740951538086 1.7862107753753662
loss:  31.057950973510742 1.7219974994659424
loss:  31.8735294342041 1.7869752645492554
loss:  31.696382522583008 1.7747598886489868
loss:  31.056373596191406 1.8091802597045898
loss:  31.71332359313965 1.7517753839492798
loss:  31.406906127929688 1.7538881301879883
loss:  31.96871566772461 1.7532668113708496
loss:  31.440696716308594 1.760164499282837
loss:  31.522972106933594 1.694229245185852
loss:  31.470733642578125 1.6661263704299927
loss:  31.63311195373535 1.6995480060577393
loss:  31.448352813720703 1.7082533836364746
loss:  31.37442970275879 1.6492037773132324
loss:  31.735336303710938 1.6379011869430542
loss:  31.384521484375 1.6555094718933105
loss:  32.19533920288086 1.6723231077194214
loss:  31.399614334106445 1.6398149728775024
loss:  30.66963005065918 1.6471256017684937
loss:  30.381465911865234 1.6140369176864624
*******************Epoch 28 ****************** 580 1.0
Validation Loss
*** pred loss:  24.47654151916504 pred acc: 0.5906400680541992
*** stop loss:  5.855588912963867 stop acc: 0.9257472157478333
*** template loss:  7.330210208892822 template acc: tensor(0.1133, device='cuda:0')
*** label loss:  6.049629211425781 label acc: tensor(0.3507, device='cuda:0')
Train Loss
---> pred loss: 21.161294555664064 pred acc: 0.6569455146789551
---> stop loss: 4.363496017456055 stop acc: 0.9490054756402969
---> template loss: 2.1769746780395507 tempalte acc: 0.5540589332580567
---> molecule label loss: 2.0639616012573243 molecule acc: 0.5881919860839844
---> kl loss: 1.7091146469116212
---> reconstruction loss: 29.765723609924315
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-29-with.npy
loss:  31.27613067626953 1.6682480573654175
loss:  31.422313690185547 1.6917797327041626
loss:  31.263978958129883 1.6707615852355957
loss:  30.697004318237305 1.6420937776565552
loss:  31.173622131347656 1.7139198780059814
loss:  31.042957305908203 1.6953939199447632
loss:  31.24509620666504 1.6595860719680786
loss:  30.94327163696289 1.621490716934204
loss:  31.19062614440918 1.598775863647461
loss:  31.005701065063477 1.5891680717468262
loss:  31.028715133666992 1.6259677410125732
loss:  31.02472686767578 1.6240061521530151
loss:  31.01876449584961 1.5988110303878784
loss:  31.356632232666016 1.647609829902649
loss:  31.112451553344727 1.638458013534546
loss:  31.435514450073242 1.643629789352417
loss:  30.709814071655273 1.5971742868423462
loss:  30.952346801757812 1.6414144039154053
loss:  31.154842376708984 1.606179118156433
loss:  30.704269409179688 1.6873003244400024
*******************Epoch 29 ****************** 600 1.0
Validation Loss
*** pred loss:  24.81995964050293 pred acc: 0.5824878811836243
*** stop loss:  6.088706016540527 stop acc: 0.9222291707992554
*** template loss:  7.339995861053467 template acc: tensor(0.1115, device='cuda:0')
*** label loss:  6.090021133422852 label acc: tensor(0.3573, device='cuda:0')
Train Loss
---> pred loss: 21.03397979736328 pred acc: 0.6603654146194458
---> stop loss: 4.345263290405273 stop acc: 0.9496013462543488
---> template loss: 2.08446044921875 tempalte acc: 0.5690232753753662
---> molecule label loss: 1.981147575378418 molecule acc: 0.6045044422149658
---> kl loss: 1.643088150024414
---> reconstruction loss: 29.444851303100585
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-30-with.npy
loss:  30.853675842285156 1.5622870922088623
loss:  30.702972412109375 1.5849663019180298
loss:  31.218717575073242 1.5908457040786743
loss:  31.106563568115234 1.5671870708465576
loss:  31.509033203125 1.577061653137207
loss:  31.492233276367188 1.514708399772644
loss:  30.46636390686035 1.5055903196334839
loss:  30.972793579101562 1.5417866706848145
loss:  31.065717697143555 1.5312398672103882
loss:  30.616439819335938 1.5428881645202637
loss:  30.92572593688965 1.5322105884552002
loss:  30.12194061279297 1.552983283996582
loss:  30.798816680908203 1.5399596691131592
loss:  30.451995849609375 1.5445984601974487
loss:  30.79335594177246 1.5936106443405151
loss:  30.157413482666016 1.5775777101516724
loss:  30.610092163085938 1.5757982730865479
loss:  30.51321792602539 1.5166823863983154
loss:  30.966686248779297 1.5388520956039429
loss:  30.94257926940918 1.458824872970581
*******************Epoch 30 ****************** 620 1.0
Validation Loss
*** pred loss:  24.744112014770508 pred acc: 0.5845410227775574
*** stop loss:  6.131134986877441 stop acc: 0.9225716590881348
*** template loss:  7.321937561035156 template acc: tensor(0.1143, device='cuda:0')
*** label loss:  6.0723981857299805 label acc: tensor(0.3374, device='cuda:0')
Train Loss
---> pred loss: 20.980389404296876 pred acc: 0.6617357283830643
---> stop loss: 4.336029815673828 stop acc: 0.9494421809911728
---> template loss: 2.0264286041259765 tempalte acc: 0.5826157569885254
---> molecule label loss: 1.9239843368530274 molecule acc: 0.6136355876922608
---> kl loss: 1.5474828720092773
---> reconstruction loss: 29.266835975646973
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-31-with.npy
loss:  30.48147964477539 1.5513479709625244
loss:  30.436723709106445 1.5498484373092651
loss:  30.738208770751953 1.555107831954956
loss:  30.29428482055664 1.5821421146392822
loss:  30.351078033447266 1.4981085062026978
loss:  30.561763763427734 1.581457495689392
loss:  30.121652603149414 1.4993451833724976
loss:  30.579448699951172 1.506980299949646
loss:  30.633533477783203 1.5263540744781494
loss:  30.578794479370117 1.4804129600524902
loss:  30.37265396118164 1.478603720664978
loss:  30.18720054626465 1.483026385307312
loss:  30.268163681030273 1.453070044517517
loss:  30.20624351501465 1.4608830213546753
loss:  30.622875213623047 1.4748620986938477
loss:  30.415685653686523 1.4865268468856812
loss:  30.036842346191406 1.4481154680252075
loss:  29.85445785522461 1.4690574407577515
loss:  30.46661376953125 1.5086997747421265
loss:  30.82804298400879 1.4677056074142456
*******************Epoch 31 ****************** 640 1.0
Validation Loss
*** pred loss:  24.55060386657715 pred acc: 0.5919082164764404
*** stop loss:  6.008134841918945 stop acc: 0.9225093722343445
*** template loss:  7.314334869384766 template acc: tensor(0.1171, device='cuda:0')
*** label loss:  6.082619667053223 label acc: tensor(0.3489, device='cuda:0')
Train Loss
---> pred loss: 20.7810302734375 pred acc: 0.6645286321640015
---> stop loss: 4.289391326904297 stop acc: 0.9507725149393081
---> template loss: 1.9737672805786133 tempalte acc: 0.5882432460784912
---> molecule label loss: 1.854515266418457 molecule acc: 0.6235145092010498
---> kl loss: 1.5030826568603515
---> reconstruction loss: 28.89870262145996
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-32-with.npy
loss:  29.601871490478516 1.490804672241211
loss:  30.205379486083984 1.4752291440963745
loss:  30.025379180908203 1.4906654357910156
loss:  30.46701431274414 1.4759645462036133
loss:  30.110942840576172 1.4695483446121216
loss:  30.518428802490234 1.4891245365142822
loss:  30.208362579345703 1.4785696268081665
loss:  30.22115707397461 1.4877793788909912
loss:  30.255691528320312 1.4662809371948242
loss:  29.96116828918457 1.4340659379959106
loss:  30.465213775634766 1.4278630018234253
loss:  30.35984992980957 1.4111626148223877
loss:  30.211158752441406 1.4454305171966553
loss:  29.71328353881836 1.488393783569336
loss:  29.903337478637695 1.4755123853683472
loss:  30.17380142211914 1.4667789936065674
loss:  29.90575408935547 1.4680739641189575
loss:  29.998746871948242 1.4716616868972778
loss:  29.947959899902344 1.4390548467636108
loss:  31.485952377319336 1.4387191534042358
*******************Epoch 32 ****************** 660 1.0
Validation Loss
*** pred loss:  24.813289642333984 pred acc: 0.5844806432723999
*** stop loss:  6.195342540740967 stop acc: 0.9206413626670837
*** template loss:  7.313385486602783 template acc: tensor(0.1189, device='cuda:0')
*** label loss:  6.1065754890441895 label acc: tensor(0.3397, device='cuda:0')
Train Loss
---> pred loss: 20.711917114257812 pred acc: 0.6648325830698013
---> stop loss: 4.277586364746094 stop acc: 0.9505064100027084
---> template loss: 1.9341585159301757 tempalte acc: 0.5960272312164306
---> molecule label loss: 1.7988269805908204 molecule acc: 0.635572862625122
---> kl loss: 1.4645342826843262
---> reconstruction loss: 28.722486591339113
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-33-with.npy
loss:  29.557031631469727 1.4316983222961426
loss:  29.743282318115234 1.4499565362930298
loss:  29.78036880493164 1.4552621841430664
loss:  29.860576629638672 1.4444845914840698
loss:  30.05417251586914 1.3853849172592163
loss:  29.994606018066406 1.4387365579605103
loss:  29.610595703125 1.4210058450698853
loss:  30.213682174682617 1.4400471448898315
loss:  29.841039657592773 1.4283398389816284
loss:  29.931140899658203 1.4638640880584717
loss:  29.7740478515625 1.411275029182434
loss:  29.426448822021484 1.4087189435958862
loss:  29.289888381958008 1.4236778020858765
loss:  29.597261428833008 1.4169398546218872
loss:  29.742395401000977 1.3876396417617798
loss:  29.910438537597656 1.4027374982833862
loss:  29.725353240966797 1.4092552661895752
loss:  29.499961853027344 1.4282313585281372
loss:  29.537363052368164 1.4069379568099976
loss:  28.385162353515625 1.261292815208435
*******************Epoch 33 ****************** 680 1.0
Validation Loss
*** pred loss:  24.719816207885742 pred acc: 0.5883454084396362
*** stop loss:  5.979548931121826 stop acc: 0.9247509837150574
*** template loss:  7.304722785949707 template acc: tensor(0.1206, device='cuda:0')
*** label loss:  6.073572635650635 label acc: tensor(0.3436, device='cuda:0')
Train Loss
---> pred loss: 20.470614624023437 pred acc: 0.667919808626175
---> stop loss: 4.1823570251464846 stop acc: 0.9516524165868759
---> template loss: 1.8606693267822265 tempalte acc: 0.6102500915527344
---> molecule label loss: 1.7443256378173828 molecule acc: 0.6438238143920898
---> kl loss: 1.415774440765381
---> reconstruction loss: 28.257968235015866
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-34-with.npy
loss:  29.29357147216797 1.3904286623001099
loss:  29.35224151611328 1.3904435634613037
loss:  29.467987060546875 1.4105838537216187
loss:  29.96201515197754 1.4339462518692017
loss:  29.385238647460938 1.3911170959472656
loss:  29.757545471191406 1.4045679569244385
loss:  30.06557273864746 1.392371654510498
loss:  29.35883140563965 1.3592349290847778
loss:  28.882675170898438 1.3788487911224365
loss:  29.5135555267334 1.3331133127212524
loss:  29.510128021240234 1.3486402034759521
loss:  29.703670501708984 1.354225754737854
loss:  29.426956176757812 1.346665859222412
loss:  30.004648208618164 1.3524929285049438
loss:  29.14254379272461 1.336688756942749
loss:  29.219682693481445 1.3483890295028687
loss:  28.828651428222656 1.296444058418274
loss:  29.01777458190918 1.329282283782959
loss:  29.163166046142578 1.3578487634658813
loss:  29.838821411132812 1.4393234252929688
*******************Epoch 34 ****************** 700 1.0
Validation Loss
*** pred loss:  24.752765655517578 pred acc: 0.5928744077682495
*** stop loss:  6.19350528717041 stop acc: 0.9213574528694153
*** template loss:  7.306854248046875 template acc: tensor(0.1192, device='cuda:0')
*** label loss:  6.121472358703613 label acc: tensor(0.3633, device='cuda:0')
Train Loss
---> pred loss: 20.419952392578125 pred acc: 0.6698849350214005
---> stop loss: 4.210645294189453 stop acc: 0.951106384396553
---> template loss: 1.7849601745605468 tempalte acc: 0.6233482837677002
---> molecule label loss: 1.6594732284545899 molecule acc: 0.6590534210205078
---> kl loss: 1.36973295211792
---> reconstruction loss: 28.07503023147583
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-35-with.npy
loss:  29.167591094970703 1.3455173969268799
loss:  29.03343963623047 1.3331377506256104
loss:  29.058338165283203 1.3341515064239502
loss:  28.799861907958984 1.3213661909103394
loss:  29.567129135131836 1.347954273223877
loss:  29.22903823852539 1.3193409442901611
loss:  29.051427841186523 1.3239045143127441
loss:  29.224945068359375 1.3557660579681396
loss:  29.012107849121094 1.3319485187530518
loss:  29.138526916503906 1.3185206651687622
loss:  29.28834342956543 1.3215080499649048
loss:  29.1055965423584 1.3212547302246094
loss:  28.779848098754883 1.3494739532470703
loss:  28.933897018432617 1.3196858167648315
loss:  29.24321746826172 1.3324463367462158
loss:  29.079076766967773 1.3093407154083252
loss:  28.976165771484375 1.320359230041504
loss:  28.703746795654297 1.2990753650665283
loss:  29.082429885864258 1.3140943050384521
loss:  28.082693099975586 1.3476001024246216
*******************Epoch 35 ****************** 720 1.0
Validation Loss
*** pred loss:  24.983566284179688 pred acc: 0.582608699798584
*** stop loss:  6.13759708404541 stop acc: 0.9231942892074585
*** template loss:  7.316624164581299 template acc: tensor(0.1252, device='cuda:0')
*** label loss:  6.1213483810424805 label acc: tensor(0.3624, device='cuda:0')
Train Loss
---> pred loss: 20.264993286132814 pred acc: 0.6727616757154464
---> stop loss: 4.128559494018555 stop acc: 0.9523828744888305
---> template loss: 1.717095947265625 tempalte acc: 0.6353956699371338
---> molecule label loss: 1.5888985633850097 molecule acc: 0.6737737655639648
---> kl loss: 1.3283225059509278
---> reconstruction loss: 27.699549198150635
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-36-with.npy
loss:  28.655563354492188 1.240373969078064
loss:  28.2650146484375 1.249444603919983
loss:  29.212444305419922 1.282418966293335
loss:  28.7519588470459 1.2618403434753418
loss:  29.27354621887207 1.306082010269165
loss:  29.0651912689209 1.292734146118164
loss:  28.632122039794922 1.2838959693908691
loss:  28.880292892456055 1.310595154762268
loss:  28.6615047454834 1.2976406812667847
loss:  28.3094482421875 1.3315390348434448
loss:  29.01144790649414 1.3125572204589844
loss:  29.340145111083984 1.333206295967102
loss:  28.75228500366211 1.2696869373321533
loss:  28.309324264526367 1.2749481201171875
loss:  29.055795669555664 1.2906224727630615
loss:  28.31982421875 1.270176649093628
loss:  28.547340393066406 1.2641676664352417
loss:  28.814054489135742 1.2875813245773315
loss:  28.89969825744629 1.2788350582122803
loss:  30.54248809814453 1.2847031354904175
*******************Epoch 36 ****************** 740 1.0
Validation Loss
*** pred loss:  24.75322723388672 pred acc: 0.5896738767623901
*** stop loss:  6.018770217895508 stop acc: 0.9227584600448608
*** template loss:  7.306735038757324 template acc: tensor(0.1242, device='cuda:0')
*** label loss:  6.090428829193115 label acc: tensor(0.3520, device='cuda:0')
Train Loss
---> pred loss: 20.275558471679688 pred acc: 0.6731168180704117
---> stop loss: 4.066796493530274 stop acc: 0.9531392633914948
---> template loss: 1.6788040161132813 tempalte acc: 0.6429932117462158
---> molecule label loss: 1.557662010192871 molecule acc: 0.6767176151275635
---> kl loss: 1.286152458190918
---> reconstruction loss: 27.578822517395018
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-37-with.npy
loss:  28.475238800048828 1.2596813440322876
loss:  28.074371337890625 1.2452495098114014
loss:  28.36893081665039 1.2585698366165161
loss:  28.73615837097168 1.2807332277297974
loss:  28.568056106567383 1.2601183652877808
loss:  28.435344696044922 1.2586241960525513
loss:  28.562969207763672 1.2536085844039917
loss:  28.560911178588867 1.2484676837921143
loss:  28.45878028869629 1.249383807182312
loss:  28.48135757446289 1.2459042072296143
loss:  28.218246459960938 1.2488133907318115
loss:  28.904705047607422 1.228380799293518
loss:  28.478500366210938 1.3029671907424927
loss:  28.759017944335938 1.2641210556030273
loss:  28.545164108276367 1.208720088005066
loss:  28.707921981811523 1.196327805519104
loss:  28.766204833984375 1.2459899187088013
loss:  28.51214599609375 1.2364884614944458
loss:  28.883150100708008 1.2639533281326294
loss:  28.942007064819336 1.3268171548843384
*******************Epoch 37 ****************** 760 1.0
Validation Loss
*** pred loss:  24.6795711517334 pred acc: 0.5916062593460083
*** stop loss:  6.523499965667725 stop acc: 0.9183375239372253
*** template loss:  7.3471479415893555 template acc: tensor(0.1203, device='cuda:0')
*** label loss:  6.17521333694458 label acc: tensor(0.3641, device='cuda:0')
Train Loss
---> pred loss: 20.1350341796875 pred acc: 0.6750199377536774
---> stop loss: 4.041334915161133 stop acc: 0.9535951912403107
---> template loss: 1.6406000137329102 tempalte acc: 0.6494014739990235
---> molecule label loss: 1.5008441925048828 molecule acc: 0.6865199089050293
---> kl loss: 1.254145908355713
---> reconstruction loss: 27.317814540863036
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-38-with.npy
loss:  28.82512855529785 1.2952383756637573
loss:  28.619915008544922 1.237266182899475
loss:  28.336013793945312 1.2427988052368164
loss:  28.508987426757812 1.2648922204971313
loss:  28.676870346069336 1.251873254776001
loss:  28.032472610473633 1.219321370124817
loss:  28.703584671020508 1.2339595556259155
loss:  28.22989273071289 1.2337793111801147
loss:  28.10901641845703 1.201347827911377
loss:  28.247068405151367 1.2165123224258423
loss:  28.663251876831055 1.232340693473816
loss:  28.55477523803711 1.2373698949813843
loss:  28.30693244934082 1.2111254930496216
loss:  28.22477149963379 1.2444989681243896
loss:  28.255842208862305 1.199747085571289
loss:  28.34534454345703 1.222010612487793
loss:  27.952178955078125 1.1921749114990234
loss:  28.193252563476562 1.1947277784347534
loss:  28.28080940246582 1.1953905820846558
loss:  27.515235900878906 1.285042643547058
*******************Epoch 38 ****************** 780 1.0
Validation Loss
*** pred loss:  24.909961700439453 pred acc: 0.5842995047569275
*** stop loss:  6.205260753631592 stop acc: 0.922073483467102
*** template loss:  7.344390869140625 template acc: tensor(0.1238, device='cuda:0')
*** label loss:  6.110164642333984 label acc: tensor(0.3661, device='cuda:0')
Train Loss
---> pred loss: 19.933432006835936 pred acc: 0.6784122109413147
---> stop loss: 4.1075702667236325 stop acc: 0.9526591002941132
---> template loss: 1.592247200012207 tempalte acc: 0.6589282989501953
---> molecule label loss: 1.4652466773986816 molecule acc: 0.6925562858581543
---> kl loss: 1.2305706977844237
---> reconstruction loss: 27.09849729537964
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-39-with.npy
loss:  28.356828689575195 1.2324249744415283
loss:  27.959684371948242 1.2093039751052856
loss:  28.23792839050293 1.2093344926834106
loss:  28.087993621826172 1.1964569091796875
loss:  28.2701416015625 1.1891083717346191
loss:  28.385784149169922 1.2092372179031372
loss:  27.864168167114258 1.1891121864318848
loss:  28.17580223083496 1.1687675714492798
loss:  28.124399185180664 1.1684014797210693
loss:  28.03767204284668 1.181229829788208
loss:  28.1157169342041 1.157977819442749
loss:  27.816543579101562 1.1922078132629395
loss:  28.309844970703125 1.1970200538635254
loss:  28.226741790771484 1.1940008401870728
loss:  27.98983383178711 1.2234647274017334
loss:  27.602012634277344 1.1769627332687378
loss:  27.945507049560547 1.1863223314285278
loss:  28.24998664855957 1.1906272172927856
loss:  28.11438751220703 1.2000839710235596
loss:  27.824207305908203 1.1491700410842896
*******************Epoch 39 ****************** 800 1.0
Validation Loss
*** pred loss:  25.02312469482422 pred acc: 0.5811594128608704
*** stop loss:  6.2408294677734375 stop acc: 0.9221668839454651
*** template loss:  7.31532096862793 template acc: tensor(0.1266, device='cuda:0')
*** label loss:  6.106902122497559 label acc: tensor(0.3547, device='cuda:0')
Train Loss
---> pred loss: 19.886376953125 pred acc: 0.6781012773513794
---> stop loss: 4.067338943481445 stop acc: 0.9531494468450546
---> template loss: 1.5397603988647461 tempalte acc: 0.6701448917388916
---> molecule label loss: 1.400224208831787 molecule acc: 0.7034923553466796
---> kl loss: 1.1910608291625977
---> reconstruction loss: 26.89370174407959
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-40-with.npy
loss:  27.404003143310547 1.1951110363006592
loss:  27.986122131347656 1.2094650268554688
loss:  28.10139274597168 1.2117336988449097
loss:  27.862886428833008 1.2173930406570435
loss:  27.540130615234375 1.2044693231582642
loss:  27.649673461914062 1.1827619075775146
loss:  27.867895126342773 1.16336989402771
loss:  28.004636764526367 1.175362467765808
loss:  27.826568603515625 1.1527351140975952
loss:  27.829853057861328 1.1717607975006104
loss:  27.978242874145508 1.1364903450012207
loss:  27.926639556884766 1.1432384252548218
loss:  27.54526710510254 1.1400035619735718
loss:  27.949249267578125 1.1526086330413818
loss:  27.854970932006836 1.1419119834899902
loss:  27.782867431640625 1.146697998046875
loss:  27.364736557006836 1.1105619668960571
loss:  27.365163803100586 1.155210256576538
loss:  27.833744049072266 1.1270898580551147
loss:  27.74234390258789 1.2180562019348145
*******************Epoch 40 ****************** 820 1.0
Validation Loss
*** pred loss:  24.998991012573242 pred acc: 0.5902173519134521
*** stop loss:  6.255370616912842 stop acc: 0.9210149645805359
*** template loss:  7.3015947341918945 template acc: tensor(0.1235, device='cuda:0')
*** label loss:  6.112252712249756 label acc: tensor(0.3582, device='cuda:0')
Train Loss
---> pred loss: 19.760842895507814 pred acc: 0.6804644346237183
---> stop loss: 4.01148567199707 stop acc: 0.9534953832626343
---> template loss: 1.4847414016723632 tempalte acc: 0.6778934478759766
---> molecule label loss: 1.3459486007690429 molecule acc: 0.7152509689331055
---> kl loss: 1.167801570892334
---> reconstruction loss: 26.603020572662356
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-41-with.npy
loss:  27.403076171875 1.1305018663406372
loss:  27.31557846069336 1.142712116241455
loss:  27.69354820251465 1.172415018081665
loss:  27.583175659179688 1.1602355241775513
loss:  27.86210060119629 1.1713496446609497
loss:  27.623046875 1.1432374715805054
loss:  27.730459213256836 1.1599806547164917
loss:  27.565053939819336 1.1662840843200684
loss:  27.792531967163086 1.1790034770965576
loss:  27.501087188720703 1.1379058361053467
loss:  27.565113067626953 1.166090726852417
loss:  27.708839416503906 1.1341441869735718
loss:  27.296571731567383 1.1265569925308228
loss:  27.803356170654297 1.1245390176773071
loss:  27.335554122924805 1.1629084348678589
loss:  27.225656509399414 1.1088727712631226
loss:  27.223859786987305 1.1233065128326416
loss:  27.88321304321289 1.1427830457687378
loss:  27.592378616333008 1.1353317499160767
loss:  28.377635955810547 1.1989330053329468
*******************Epoch 41 ****************** 840 1.0
Validation Loss
*** pred loss:  25.119230270385742 pred acc: 0.5873188376426697
*** stop loss:  6.3642964363098145 stop acc: 0.921886682510376
*** template loss:  7.330733776092529 template acc: tensor(0.1337, device='cuda:0')
*** label loss:  6.130136489868164 label acc: tensor(0.3584, device='cuda:0')
Train Loss
---> pred loss: 19.74140319824219 pred acc: 0.6797598361968994
---> stop loss: 3.9659976959228516 stop acc: 0.9547634780406952
---> template loss: 1.449863338470459 tempalte acc: 0.6868247985839844
---> molecule label loss: 1.297475242614746 molecule acc: 0.7223854541778565
---> kl loss: 1.1493545532226563
---> reconstruction loss: 26.454734802246094
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-42-with.npy
loss:  27.21830940246582 1.1447314023971558
loss:  27.432106018066406 1.1121793985366821
loss:  27.531389236450195 1.128440022468567
loss:  27.48134422302246 1.150962471961975
loss:  27.2286434173584 1.1374610662460327
loss:  27.03837013244629 1.126297116279602
loss:  27.435638427734375 1.151133418083191
loss:  27.740489959716797 1.1793444156646729
loss:  27.800384521484375 1.1603344678878784
loss:  27.149152755737305 1.1742624044418335
loss:  27.236284255981445 1.1434550285339355
loss:  27.309431076049805 1.135298490524292
loss:  27.07671356201172 1.0969294309616089
loss:  28.062206268310547 1.1337023973464966
loss:  27.009689331054688 1.095794677734375
loss:  26.990713119506836 1.1069319248199463
loss:  27.459129333496094 1.1503537893295288
loss:  26.98790168762207 1.0770026445388794
loss:  27.2437801361084 1.1005229949951172
loss:  28.964656829833984 1.162623643875122
*******************Epoch 42 ****************** 860 1.0
Validation Loss
*** pred loss:  24.841032028198242 pred acc: 0.5891907811164856
*** stop loss:  6.932640075683594 stop acc: 0.9149439930915833
*** template loss:  7.332973957061768 template acc: tensor(0.1280, device='cuda:0')
*** label loss:  6.129493236541748 label acc: tensor(0.3590, device='cuda:0')
Train Loss
---> pred loss: 19.65422668457031 pred acc: 0.6822406202554703
---> stop loss: 3.9539474487304687 stop acc: 0.9547540873289109
---> template loss: 1.4274491310119628 tempalte acc: 0.6910603523254395
---> molecule label loss: 1.2508041381835937 molecule acc: 0.7323140144348145
---> kl loss: 1.133388137817383
---> reconstruction loss: 26.28642997741699
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-43-with.npy
loss:  27.537355422973633 1.0573559999465942
loss:  27.436172485351562 1.0806721448898315
loss:  27.173717498779297 1.0973119735717773
loss:  27.903162002563477 1.109977126121521
loss:  27.287220001220703 1.102510690689087
loss:  27.0554256439209 1.0898959636688232
loss:  27.062564849853516 1.0821787118911743
loss:  27.004486083984375 1.0467346906661987
loss:  26.94066619873047 1.0722460746765137
loss:  27.21713638305664 1.0772017240524292
loss:  27.23348617553711 1.069663405418396
loss:  27.199687957763672 1.0763318538665771
loss:  26.85274887084961 1.0650763511657715
loss:  27.261627197265625 1.104232668876648
loss:  26.933441162109375 1.082729697227478
loss:  27.002826690673828 1.085147500038147
loss:  27.132320404052734 1.0711935758590698
loss:  26.772235870361328 1.1092753410339355
loss:  27.008380889892578 1.0946362018585205
loss:  26.790279388427734 1.146764874458313
*******************Epoch 43 ****************** 880 1.0
Validation Loss
*** pred loss:  25.339481353759766 pred acc: 0.5757849812507629
*** stop loss:  6.402490615844727 stop acc: 0.9217621684074402
*** template loss:  7.311134338378906 template acc: tensor(0.1330, device='cuda:0')
*** label loss:  6.16631555557251 label acc: tensor(0.3599, device='cuda:0')
Train Loss
---> pred loss: 19.525921630859376 pred acc: 0.6839849054813385
---> stop loss: 3.9449878692626954 stop acc: 0.9548566907644271
---> template loss: 1.3727402687072754 tempalte acc: 0.7005992412567139
---> molecule label loss: 1.2105384826660157 molecule acc: 0.7384544372558594
---> kl loss: 1.086056900024414
---> reconstruction loss: 26.054189682006836
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-44-with.npy
loss:  27.23244857788086 1.1225193738937378
loss:  26.73613739013672 1.106239676475525
loss:  27.084932327270508 1.121872067451477
loss:  27.440391540527344 1.1486926078796387
loss:  27.065431594848633 1.1331536769866943
loss:  26.787050247192383 1.1184076070785522
loss:  26.306278228759766 1.073952078819275
loss:  27.060134887695312 1.0957320928573608
loss:  26.962886810302734 1.0769280195236206
loss:  27.06525421142578 1.0846041440963745
loss:  26.900772094726562 1.0530873537063599
loss:  27.01181411743164 1.0558688640594482
loss:  26.702991485595703 1.0354803800582886
loss:  27.220565795898438 1.0860707759857178
loss:  26.74754524230957 1.0735303163528442
loss:  26.591341018676758 1.0688034296035767
loss:  27.044172286987305 1.0754356384277344
loss:  26.812158584594727 1.0926460027694702
loss:  26.541349411010742 1.0782145261764526
loss:  26.201677322387695 1.0258963108062744
*******************Epoch 44 ****************** 900 1.0
Validation Loss
*** pred loss:  24.84707260131836 pred acc: 0.5894927382469177
*** stop loss:  6.346189975738525 stop acc: 0.9218555688858032
*** template loss:  7.28116512298584 template acc: tensor(0.1400, device='cuda:0')
*** label loss:  6.145205020904541 label acc: tensor(0.3532, device='cuda:0')
Train Loss
---> pred loss: 19.441436767578125 pred acc: 0.6857993751764297
---> stop loss: 3.8200435638427734 stop acc: 0.9563861101865768
---> template loss: 1.342690658569336 tempalte acc: 0.7069948196411133
---> molecule label loss: 1.185238742828369 molecule acc: 0.7405821323394776
---> kl loss: 1.0863568305969238
---> reconstruction loss: 25.789409160614014
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-45-with.npy
loss:  26.51132583618164 1.08721923828125
loss:  26.37653350830078 1.0802183151245117
loss:  26.697525024414062 1.0654070377349854
loss:  26.73114585876465 1.0644981861114502
loss:  26.749465942382812 1.0605418682098389
loss:  26.60605239868164 1.029646396636963
loss:  26.66901969909668 1.028635859489441
loss:  26.895675659179688 1.0570404529571533
loss:  26.717191696166992 1.0622100830078125
loss:  26.84414291381836 1.040183424949646
loss:  26.808364868164062 1.063067078590393
loss:  26.369766235351562 1.0487496852874756
loss:  26.65810775756836 1.063962459564209
loss:  26.160364151000977 1.0675222873687744
loss:  26.58867645263672 1.0598945617675781
loss:  26.65983009338379 1.0753653049468994
loss:  26.49005699157715 1.0534958839416504
loss:  26.120386123657227 1.06834876537323
loss:  26.65171241760254 1.0371880531311035
loss:  26.489459991455078 1.0205134153366089
*******************Epoch 45 ****************** 920 1.0
Validation Loss
*** pred loss:  25.132455825805664 pred acc: 0.5847222208976746
*** stop loss:  6.392315864562988 stop acc: 0.9220112562179565
*** template loss:  7.343581199645996 template acc: tensor(0.1375, device='cuda:0')
*** label loss:  6.1640777587890625 label acc: tensor(0.3669, device='cuda:0')
Train Loss
---> pred loss: 19.275349426269532 pred acc: 0.6879494845867157
---> stop loss: 3.81240234375 stop acc: 0.9565300703048706
---> template loss: 1.3027316093444825 tempalte acc: 0.714617395401001
---> molecule label loss: 1.1425732612609862 molecule acc: 0.7495242595672608
---> kl loss: 1.0566853523254394
---> reconstruction loss: 25.533054637908936
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-46-with.npy
loss:  26.744117736816406 1.0460788011550903
loss:  26.703699111938477 1.054830551147461
loss:  26.543989181518555 1.0544929504394531
loss:  26.374971389770508 1.0516597032546997
loss:  26.612815856933594 1.0447087287902832
loss:  26.285781860351562 1.0736421346664429
loss:  26.5466365814209 1.0444118976593018
loss:  26.573820114135742 0.9949887990951538
loss:  26.512001037597656 1.032505989074707
loss:  26.454654693603516 1.0457686185836792
loss:  26.77322006225586 0.9979419708251953
loss:  26.158491134643555 1.0336718559265137
loss:  26.356706619262695 1.0713778734207153
loss:  26.11949920654297 1.0546575784683228
loss:  26.489791870117188 1.0528491735458374
loss:  26.251832962036133 1.0189604759216309
loss:  26.436166763305664 1.051639199256897
loss:  26.600627899169922 1.0333781242370605
loss:  26.117942810058594 1.0274438858032227
loss:  25.57098388671875 0.974980890750885
*******************Epoch 46 ****************** 940 1.0
Validation Loss
*** pred loss:  24.980199813842773 pred acc: 0.5870168805122375
*** stop loss:  6.4603352546691895 stop acc: 0.9205791354179382
*** template loss:  7.334254264831543 template acc: tensor(0.1294, device='cuda:0')
*** label loss:  6.161625385284424 label acc: tensor(0.3622, device='cuda:0')
Train Loss
---> pred loss: 19.195741271972658 pred acc: 0.6886442035436631
---> stop loss: 3.7989715576171874 stop acc: 0.9568001419305802
---> template loss: 1.2772273063659667 tempalte acc: 0.719727897644043
---> molecule label loss: 1.101448154449463 molecule acc: 0.7591806411743164
---> kl loss: 1.037999439239502
---> reconstruction loss: 25.373386669158936
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-47-with.npy
loss:  26.40919303894043 1.0176149606704712
loss:  26.357059478759766 1.0239253044128418
loss:  25.90401840209961 1.0109871625900269
loss:  26.6652774810791 1.0282840728759766
loss:  26.278308868408203 0.9979477524757385
loss:  26.65170669555664 1.016689658164978
loss:  26.53294563293457 1.038397192955017
loss:  25.96672821044922 1.0442557334899902
loss:  26.31871223449707 1.0041686296463013
loss:  25.934093475341797 1.0165520906448364
loss:  26.046180725097656 1.0083122253417969
loss:  26.31562042236328 1.0609078407287598
loss:  26.117008209228516 1.0371235609054565
loss:  26.254302978515625 1.0318907499313354
loss:  26.302623748779297 1.0094423294067383
loss:  26.280969619750977 1.0033921003341675
loss:  25.798816680908203 1.013168454170227
loss:  25.9830322265625 0.9782708287239075
loss:  26.39018440246582 1.0035604238510132
loss:  26.319894790649414 0.9230245351791382
*******************Epoch 47 ****************** 960 1.0
Validation Loss
*** pred loss:  25.129196166992188 pred acc: 0.5867753624916077
*** stop loss:  6.228294372558594 stop acc: 0.9251245856285095
*** template loss:  7.337264060974121 template acc: tensor(0.1396, device='cuda:0')
*** label loss:  6.141855239868164 label acc: tensor(0.3609, device='cuda:0')
Train Loss
---> pred loss: 19.077569580078126 pred acc: 0.6912591099739075
---> stop loss: 3.813008117675781 stop acc: 0.9563608914613724
---> template loss: 1.2562221527099608 tempalte acc: 0.7254142761230469
---> molecule label loss: 1.0811392784118652 molecule acc: 0.7607054710388184
---> kl loss: 1.0133958816528321
---> reconstruction loss: 25.227937126159667
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-48-with.npy
loss:  26.192747116088867 0.9818242788314819
loss:  25.76370620727539 0.9923222064971924
loss:  26.101884841918945 1.0050029754638672
loss:  26.064062118530273 0.9735528230667114
loss:  26.22804832458496 0.9720608592033386
loss:  26.333534240722656 0.9642109274864197
loss:  26.102909088134766 0.9902504086494446
loss:  25.81736183166504 0.977274477481842
loss:  26.071134567260742 0.9998190999031067
loss:  25.933008193969727 1.0058543682098389
loss:  25.716983795166016 1.0139739513397217
loss:  26.18105125427246 1.0011239051818848
loss:  26.015378952026367 1.014053225517273
loss:  26.15016746520996 0.9821465611457825
loss:  26.101408004760742 0.9946819543838501
loss:  26.167869567871094 1.0215201377868652
loss:  25.65786361694336 1.0173373222351074
loss:  25.983413696289062 0.996934175491333
loss:  26.0640926361084 0.9778192639350891
loss:  25.821510314941406 0.9762008190155029
*******************Epoch 48 ****************** 980 1.0
Validation Loss
*** pred loss:  25.24517822265625 pred acc: 0.582608699798584
*** stop loss:  6.588085651397705 stop acc: 0.9205479621887207
*** template loss:  7.315317630767822 template acc: tensor(0.1382, device='cuda:0')
*** label loss:  6.146383285522461 label acc: tensor(0.3689, device='cuda:0')
Train Loss
---> pred loss: 19.036537170410156 pred acc: 0.6922754615545272
---> stop loss: 3.7118606567382812 stop acc: 0.9578560799360275
---> template loss: 1.2346482276916504 tempalte acc: 0.727642297744751
---> molecule label loss: 1.0474634170532227 molecule acc: 0.7663341522216797
---> kl loss: 0.9928981781005859
---> reconstruction loss: 25.0305118560791
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-49-with.npy
loss:  25.887474060058594 0.9734811186790466
loss:  25.583242416381836 0.9467996954917908
loss:  25.804241180419922 0.9773950576782227
loss:  26.06241226196289 0.9764834642410278
loss:  25.72509765625 0.959330677986145
loss:  26.637020111083984 0.9763848185539246
loss:  26.018871307373047 0.9578635692596436
loss:  25.828943252563477 0.97471022605896
loss:  25.77618980407715 0.9774607419967651
loss:  25.645801544189453 0.9785149097442627
loss:  25.694107055664062 0.9832873344421387
loss:  26.02648162841797 1.0228530168533325
loss:  25.714075088500977 1.00116765499115
loss:  26.11663818359375 0.9964978098869324
loss:  26.16900634765625 1.0010405778884888
loss:  25.783466339111328 0.9915680885314941
loss:  25.755605697631836 0.969308078289032
loss:  26.65633201599121 0.9863911271095276
loss:  25.79091453552246 0.9683132171630859
loss:  24.712926864624023 0.9133414626121521
*******************Epoch 49 ****************** 1000 1.0
Validation Loss
*** pred loss:  25.318145751953125 pred acc: 0.5851449370384216
*** stop loss:  6.4844183921813965 stop acc: 0.9220112562179565
*** template loss:  7.347989082336426 template acc: tensor(0.1396, device='cuda:0')
*** label loss:  6.20952844619751 label acc: tensor(0.3659, device='cuda:0')
Train Loss
---> pred loss: 18.988438415527344 pred acc: 0.6928100138902664
---> stop loss: 3.687637710571289 stop acc: 0.9580493122339249
---> template loss: 1.1972292900085448 tempalte acc: 0.7352104187011719
---> molecule label loss: 1.0195273399353026 molecule acc: 0.774815034866333
---> kl loss: 0.9766096115112305
---> reconstruction loss: 24.89283618927002
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-50-with.npy
loss:  25.83171844482422 0.9944548010826111
loss:  25.539403915405273 0.9662718772888184
loss:  25.667438507080078 0.9600222110748291
loss:  25.650344848632812 0.959683895111084
loss:  26.097640991210938 0.9782152771949768
loss:  25.872236251831055 0.9647718071937561
loss:  25.90180778503418 0.9772993922233582
loss:  25.371782302856445 0.9831210970878601
loss:  25.92176628112793 0.9899434447288513
loss:  25.377676010131836 0.9946250915527344
loss:  25.703397750854492 0.9627799391746521
loss:  25.700647354125977 0.9486954212188721
loss:  25.78554344177246 0.9716448187828064
loss:  25.909366607666016 0.9510712027549744
loss:  26.026622772216797 0.9551894664764404
loss:  25.41389274597168 0.9434677362442017
loss:  26.117555618286133 0.9900946021080017
loss:  25.571247100830078 0.9474665522575378
loss:  25.65316390991211 0.9574037194252014
loss:  24.330547332763672 1.0672616958618164
*******************Epoch 50 ****************** 1020 1.0
Validation Loss
*** pred loss:  25.13645362854004 pred acc: 0.5872584581375122
*** stop loss:  6.210156440734863 stop acc: 0.9256849884986877
*** template loss:  7.374470233917236 template acc: tensor(0.1337, device='cuda:0')
*** label loss:  6.186470031738281 label acc: tensor(0.3667, device='cuda:0')
Train Loss
---> pred loss: 18.80747833251953 pred acc: 0.6958159774541854
---> stop loss: 3.656980514526367 stop acc: 0.9586626440286636
---> template loss: 1.220625114440918 tempalte acc: 0.7318865776062011
---> molecule label loss: 1.0139328956604003 molecule acc: 0.7722009658813477
---> kl loss: 0.9731740951538086
---> reconstruction loss: 24.69901523590088
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-51-with.npy
loss:  25.500831604003906 0.9650187492370605
loss:  25.264507293701172 0.9830605387687683
loss:  25.647192001342773 0.9741232991218567
loss:  25.664546966552734 0.9734191298484802
loss:  25.324018478393555 0.9877869486808777
loss:  25.616165161132812 0.9880585670471191
loss:  25.636659622192383 0.99428391456604
loss:  25.191940307617188 0.9446447491645813
loss:  25.627761840820312 0.9493247270584106
loss:  25.51755142211914 0.9726882576942444
loss:  25.4143123626709 0.9655020236968994
loss:  26.020057678222656 0.9689114093780518
loss:  26.096681594848633 0.9816299080848694
loss:  25.47987937927246 0.9631019234657288
loss:  25.499832153320312 0.9299913644790649
loss:  25.5594482421875 0.943930983543396
loss:  25.644752502441406 0.929030179977417
loss:  25.260875701904297 0.9698188900947571
loss:  25.4143009185791 0.9453480839729309
loss:  24.896909713745117 0.9116581082344055
*******************Epoch 51 ****************** 1040 1.0
Validation Loss
*** pred loss:  25.055946350097656 pred acc: 0.5867149829864502
*** stop loss:  6.287365436553955 stop acc: 0.9241594076156616
*** template loss:  7.341087341308594 template acc: tensor(0.1368, device='cuda:0')
*** label loss:  6.336881637573242 label acc: tensor(0.3866, device='cuda:0')
Train Loss
---> pred loss: 18.745713806152345 pred acc: 0.6952408194541931
---> stop loss: 3.664943313598633 stop acc: 0.9581419974565506
---> template loss: 1.1650266647338867 tempalte acc: 0.7425468444824219
---> molecule label loss: 0.976158618927002 molecule acc: 0.7792516231536866
---> kl loss: 0.9620665550231934
---> reconstruction loss: 24.55184488296509
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-52-with.npy
loss:  25.073162078857422 0.9505049586296082
loss:  25.110408782958984 0.9397370219230652
loss:  25.334989547729492 0.9454103708267212
loss:  25.212663650512695 0.9368661046028137
loss:  25.66157341003418 0.9171179533004761
loss:  25.609394073486328 0.9244749546051025
loss:  25.09910011291504 0.9257712960243225
loss:  25.538475036621094 0.9326596856117249
loss:  25.535541534423828 0.9464742541313171
loss:  25.187185287475586 0.956078052520752
loss:  25.06642723083496 0.9463551640510559
loss:  25.4338321685791 0.9685552716255188
loss:  24.828210830688477 0.9297919869422913
loss:  25.593910217285156 0.9460124373435974
loss:  25.6666202545166 0.940345823764801
loss:  25.199848175048828 0.9040626883506775
loss:  24.80644989013672 0.9462478160858154
loss:  25.433250427246094 0.9301161170005798
loss:  25.398447036743164 0.9416670799255371
loss:  25.884939193725586 0.95272296667099
*******************Epoch 52 ****************** 1060 1.0
Validation Loss
*** pred loss:  25.249670028686523 pred acc: 0.582065224647522
*** stop loss:  6.4934515953063965 stop acc: 0.9240660071372986
*** template loss:  7.324271202087402 template acc: tensor(0.1414, device='cuda:0')
*** label loss:  6.222811698913574 label acc: tensor(0.3759, device='cuda:0')
Train Loss
---> pred loss: 18.689080810546876 pred acc: 0.6982917159795761
---> stop loss: 3.642538070678711 stop acc: 0.9589056551456452
---> template loss: 1.1294490814208984 tempalte acc: 0.7492492198944092
---> molecule label loss: 0.9336045265197754 molecule acc: 0.786665964126587
---> kl loss: 0.9390485763549805
---> reconstruction loss: 24.39467487335205
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-53-with.npy
loss:  25.450916290283203 0.933071494102478
loss:  25.582448959350586 0.9318497776985168
loss:  24.931766510009766 0.9518679976463318
loss:  24.95212745666504 0.9521626234054565
loss:  25.157636642456055 0.902050793170929
loss:  25.087636947631836 0.9198417663574219
loss:  25.407102584838867 0.9370843768119812
loss:  25.552478790283203 0.9240944385528564
loss:  25.50885772705078 0.929623544216156
loss:  25.195716857910156 0.940487265586853
loss:  25.272537231445312 0.9435815811157227
loss:  25.08966636657715 0.9179179668426514
loss:  25.226341247558594 0.9296658635139465
loss:  25.133634567260742 0.9234833717346191
loss:  25.335824966430664 0.9653574824333191
loss:  24.6180419921875 0.93793785572052
loss:  25.32123565673828 0.9639924764633179
loss:  24.872610092163086 0.9275491237640381
loss:  25.096750259399414 0.9347955584526062
loss:  24.840927124023438 0.9683206081390381
*******************Epoch 53 ****************** 1080 1.0
Validation Loss
*** pred loss:  25.350095748901367 pred acc: 0.5878623127937317
*** stop loss:  6.337813377380371 stop acc: 0.9238480925559998
*** template loss:  7.321839809417725 template acc: tensor(0.1474, device='cuda:0')
*** label loss:  6.306369304656982 label acc: tensor(0.3781, device='cuda:0')
Train Loss
---> pred loss: 18.583395385742186 pred acc: 0.6980126827955246
---> stop loss: 3.646988296508789 stop acc: 0.9586271554231643
---> template loss: 1.1092377662658692 tempalte acc: 0.7536479949951171
---> molecule label loss: 0.9053538322448731 molecule acc: 0.7921549320220947
---> kl loss: 0.93673677444458
---> reconstruction loss: 24.24497709274292
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-54-with.npy
loss:  24.84429359436035 0.9296255707740784
loss:  25.288795471191406 0.9323826432228088
loss:  25.0628604888916 0.9086605310440063
loss:  24.903369903564453 0.9374842643737793
loss:  25.281238555908203 0.9146867990493774
loss:  24.65273094177246 0.941731870174408
loss:  24.804088592529297 0.9293769001960754
loss:  24.927383422851562 0.9205310940742493
loss:  25.08256721496582 0.9269853830337524
loss:  24.822345733642578 0.881681501865387
loss:  24.84029769897461 0.9026947021484375
loss:  24.809804916381836 0.9142130017280579
loss:  24.607160568237305 0.9124912023544312
loss:  25.31028175354004 0.9293108582496643
loss:  24.79118537902832 0.9173061847686768
loss:  25.497379302978516 0.9082030653953552
loss:  25.017711639404297 0.9093453288078308
loss:  25.004220962524414 0.9028255343437195
loss:  25.01893424987793 0.907619059085846
loss:  25.28398323059082 0.9397140741348267
*******************Epoch 54 ****************** 1100 1.0
Validation Loss
*** pred loss:  25.331525802612305 pred acc: 0.5850241184234619
*** stop loss:  6.36005973815918 stop acc: 0.9271482229232788
*** template loss:  7.345584392547607 template acc: tensor(0.1344, device='cuda:0')
*** label loss:  6.271557807922363 label acc: tensor(0.3783, device='cuda:0')
Train Loss
---> pred loss: 18.53918914794922 pred acc: 0.7012883096933364
---> stop loss: 3.5920742034912108 stop acc: 0.959414753317833
---> template loss: 1.0702488899230957 tempalte acc: 0.7625462055206299
---> molecule label loss: 0.8726757049560547 molecule acc: 0.8005482673645019
---> kl loss: 0.9183435440063477
---> reconstruction loss: 24.07418575286865
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-55-with.npy
loss:  24.57442855834961 0.9387204647064209
loss:  25.132606506347656 0.8994458913803101
loss:  25.11977767944336 0.8999089002609253
loss:  24.996158599853516 0.9065581560134888
loss:  24.847135543823242 0.9129346609115601
loss:  24.647029876708984 0.8733835220336914
loss:  24.520122528076172 0.897712230682373
loss:  24.812843322753906 0.9033898711204529
loss:  24.88802146911621 0.9019010663032532
loss:  25.126916885375977 0.9043046832084656
loss:  24.69615936279297 0.9103597402572632
loss:  24.627300262451172 0.9133116006851196
loss:  25.076448440551758 0.895183801651001
loss:  24.84252166748047 0.8984811902046204
loss:  24.473907470703125 0.8746975064277649
loss:  25.16908836364746 0.8850860595703125
loss:  24.7542724609375 0.8821056485176086
loss:  24.710289001464844 0.8701221942901611
loss:  24.476585388183594 0.8920636177062988
loss:  23.60420036315918 0.8770314455032349
*******************Epoch 55 ****************** 1120 1.0
Validation Loss
*** pred loss:  25.396896362304688 pred acc: 0.5869565010070801
*** stop loss:  6.477305889129639 stop acc: 0.9231631755828857
*** template loss:  7.320067882537842 template acc: tensor(0.1421, device='cuda:0')
*** label loss:  6.23403263092041 label acc: tensor(0.3776, device='cuda:0')
Train Loss
---> pred loss: 18.402894592285158 pred acc: 0.7014596045017243
---> stop loss: 3.556048583984375 stop acc: 0.9598702371120453
---> template loss: 1.052957248687744 tempalte acc: 0.767128324508667
---> molecule label loss: 0.8460549354553223 molecule acc: 0.8062543869018555
---> kl loss: 0.8968351364135743
---> reconstruction loss: 23.85795612335205
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-56-with.npy
loss:  24.613115310668945 0.8819790482521057
loss:  24.463897705078125 0.877678632736206
loss:  24.769502639770508 0.8952174782752991
loss:  25.0963134765625 0.8823741674423218
loss:  25.124784469604492 0.9015191793441772
loss:  24.771949768066406 0.8870084881782532
loss:  24.433799743652344 0.8805703520774841
loss:  24.837196350097656 0.9146908521652222
loss:  24.532258987426758 0.9381241202354431
loss:  24.823238372802734 0.8843965530395508
loss:  24.479421615600586 0.8896920680999756
loss:  24.507686614990234 0.8872180581092834
loss:  24.994125366210938 0.9094148874282837
loss:  24.709510803222656 0.8959557414054871
loss:  25.010774612426758 0.9004887938499451
loss:  24.605701446533203 0.8888351321220398
loss:  24.566898345947266 0.8719973564147949
loss:  24.645713806152344 0.8832498788833618
loss:  24.632421493530273 0.8867585062980652
loss:  25.555479049682617 0.9086664319038391
*******************Epoch 56 ****************** 1140 1.0
Validation Loss
*** pred loss:  25.23021697998047 pred acc: 0.5830313563346863
*** stop loss:  6.774325847625732 stop acc: 0.9187734127044678
*** template loss:  7.331233978271484 template acc: tensor(0.1505, device='cuda:0')
*** label loss:  6.289868354797363 label acc: tensor(0.3748, device='cuda:0')
Train Loss
---> pred loss: 18.39984893798828 pred acc: 0.7015633344650268
---> stop loss: 3.5636829376220702 stop acc: 0.9596100807189941
---> template loss: 1.0638175010681152 tempalte acc: 0.7632457733154296
---> molecule label loss: 0.8380487442016602 molecule acc: 0.8066112518310546
---> kl loss: 0.8932918548583985
---> reconstruction loss: 23.865399551391604
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-57-with.npy
loss:  24.70326042175293 0.873893678188324
loss:  25.136629104614258 0.884022057056427
loss:  24.7616024017334 0.8422905802726746
loss:  24.85995864868164 0.8525055050849915
loss:  25.060928344726562 0.8736474514007568
loss:  24.87621307373047 0.8369264006614685
loss:  24.7372989654541 0.8752906918525696
loss:  24.37514877319336 0.8809258341789246
loss:  24.53406524658203 0.8778985142707825
loss:  25.0362606048584 0.8794729709625244
loss:  24.58957862854004 0.868104100227356
loss:  24.766345977783203 0.8812692761421204
loss:  24.776790618896484 0.8911558389663696
loss:  24.62627601623535 0.9255021214485168
loss:  24.454246520996094 0.9005403518676758
loss:  24.31157112121582 0.8658120036125183
loss:  24.515613555908203 0.8824988603591919
loss:  24.64687728881836 0.8621958494186401
loss:  24.473115921020508 0.8820035457611084
loss:  23.078847885131836 0.853675365447998
*******************Epoch 57 ****************** 1160 1.0
Validation Loss
*** pred loss:  25.18282699584961 pred acc: 0.5868961215019226
*** stop loss:  6.299278259277344 stop acc: 0.927615225315094
*** template loss:  7.364350318908691 template acc: tensor(0.1442, device='cuda:0')
*** label loss:  6.2338995933532715 label acc: tensor(0.3650, device='cuda:0')
Train Loss
---> pred loss: 18.273957824707033 pred acc: 0.7025364905595779
---> stop loss: 3.589228057861328 stop acc: 0.9588493287563324
---> template loss: 1.0395828247070313 tempalte acc: 0.7680646419525147
---> molecule label loss: 0.8387808799743652 molecule acc: 0.8048202514648437
---> kl loss: 0.8744815826416016
---> reconstruction loss: 23.741552352905273
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-58-with.npy
loss:  24.5967960357666 0.8660871982574463
loss:  24.16682243347168 0.8824909329414368
loss:  24.287334442138672 0.8759154081344604
loss:  24.3061466217041 0.8554608821868896
loss:  24.81942367553711 0.8502694368362427
loss:  24.470205307006836 0.8535582423210144
loss:  24.12053108215332 0.8500694036483765
loss:  25.080995559692383 0.8927776217460632
loss:  25.170167922973633 0.896712064743042
loss:  24.382400512695312 0.8714606761932373
loss:  24.438230514526367 0.8981443643569946
loss:  24.171175003051758 0.87428879737854
loss:  24.850875854492188 0.8792264461517334
loss:  24.312257766723633 0.8642908334732056
loss:  24.80339813232422 0.8609635233879089
loss:  24.543317794799805 0.858771800994873
loss:  24.353334426879883 0.8536418676376343
loss:  24.09718132019043 0.899163544178009
loss:  24.027528762817383 0.9067119359970093
loss:  24.628332138061523 0.83478182554245
*******************Epoch 58 ****************** 1180 1.0
Validation Loss
*** pred loss:  25.344619750976562 pred acc: 0.5868357419967651
*** stop loss:  6.321720600128174 stop acc: 0.9267123341560364
*** template loss:  7.388880729675293 template acc: tensor(0.1393, device='cuda:0')
*** label loss:  6.276372909545898 label acc: tensor(0.3832, device='cuda:0')
Train Loss
---> pred loss: 18.265699768066405 pred acc: 0.7039915561676026
---> stop loss: 3.5371463775634764 stop acc: 0.9596661388874054
---> template loss: 1.0060099601745605 tempalte acc: 0.7761474132537842
---> molecule label loss: 0.801226806640625 molecule acc: 0.8124505996704101
---> kl loss: 0.8712393760681152
---> reconstruction loss: 23.610080814361574
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-59-with.npy
loss:  24.787841796875 0.848046064376831
loss:  24.538423538208008 0.8745819926261902
loss:  24.169151306152344 0.8500438928604126
loss:  24.006759643554688 0.8653497099876404
loss:  23.978633880615234 0.854911744594574
loss:  24.010759353637695 0.8753224015235901
loss:  23.998321533203125 0.8921465873718262
loss:  24.263822555541992 0.8773382306098938
loss:  24.353057861328125 0.86728835105896
loss:  24.136953353881836 0.8467199206352234
loss:  24.20183753967285 0.8501980304718018
loss:  24.09969711303711 0.8426076769828796
loss:  24.223175048828125 0.8813301920890808
loss:  23.972923278808594 0.8528121113777161
loss:  24.066837310791016 0.8868680596351624
loss:  23.976659774780273 0.8426244258880615
loss:  24.452024459838867 0.8440053462982178
loss:  24.68680191040039 0.852361798286438
loss:  24.4816837310791 0.840512752532959
loss:  24.605968475341797 0.9224538207054138
*******************Epoch 59 ****************** 1200 1.0
Validation Loss
*** pred loss:  25.399311065673828 pred acc: 0.5867753624916077
*** stop loss:  6.477676868438721 stop acc: 0.9239414930343628
*** template loss:  7.339639186859131 template acc: tensor(0.1410, device='cuda:0')
*** label loss:  6.3559980392456055 label acc: tensor(0.3887, device='cuda:0')
Train Loss
---> pred loss: 18.134906005859374 pred acc: 0.7055031448602677
---> stop loss: 3.4585426330566404 stop acc: 0.9607996463775634
---> template loss: 1.0013435363769532 tempalte acc: 0.7771445274353027
---> molecule label loss: 0.7923993110656739 molecule acc: 0.8124711036682128
---> kl loss: 0.8633761405944824
---> reconstruction loss: 23.387189960479738
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-60-with.npy
loss:  24.863264083862305 0.866561770439148
loss:  24.059118270874023 0.8764767646789551
loss:  24.133655548095703 0.8626192212104797
loss:  24.247039794921875 0.8768614530563354
loss:  24.024913787841797 0.8730865120887756
loss:  24.308395385742188 0.8732107877731323
loss:  23.788137435913086 0.8612521290779114
loss:  23.963722229003906 0.8313485383987427
loss:  24.23314094543457 0.8576792478561401
loss:  24.229524612426758 0.8413237929344177
loss:  23.535112380981445 0.8413953185081482
loss:  24.382389068603516 0.8153510093688965
loss:  23.86575698852539 0.8046600222587585
loss:  23.64525604248047 0.8203983306884766
loss:  24.31989288330078 0.8183457255363464
loss:  23.742385864257812 0.8214967846870422
loss:  24.049942016601562 0.8179721236228943
loss:  24.38376808166504 0.8224511742591858
loss:  24.198326110839844 0.8216408491134644
loss:  23.926612854003906 0.8246275782585144
*******************Epoch 60 ****************** 1220 1.0
Validation Loss
*** pred loss:  25.34269905090332 pred acc: 0.5906400680541992
*** stop loss:  6.579492568969727 stop acc: 0.9205479621887207
*** template loss:  7.438887119293213 template acc: tensor(0.1379, device='cuda:0')
*** label loss:  6.222118854522705 label acc: tensor(0.3776, device='cuda:0')
Train Loss
---> pred loss: 18.047282409667968 pred acc: 0.7076927691698074
---> stop loss: 3.4285205841064452 stop acc: 0.9615411430597305
---> template loss: 0.9919875144958497 tempalte acc: 0.7764272212982177
---> molecule label loss: 0.7857903957366943 molecule acc: 0.8121743202209473
---> kl loss: 0.8414379119873047
---> reconstruction loss: 23.253577041625974
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-61-with.npy
loss:  23.891780853271484 0.8426328897476196
loss:  23.68667984008789 0.8498607873916626
loss:  24.346446990966797 0.8685699701309204
loss:  24.3618221282959 0.8905993700027466
loss:  24.040969848632812 0.8908869624137878
loss:  24.306074142456055 0.8695014119148254
loss:  24.067296981811523 0.8447242975234985
loss:  24.170856475830078 0.8387048244476318
loss:  24.13080596923828 0.8607088327407837
loss:  24.141931533813477 0.8500635027885437
loss:  24.358333587646484 0.8441635370254517
loss:  24.169334411621094 0.8492412567138672
loss:  23.781396865844727 0.8412052392959595
loss:  23.779808044433594 0.8074046969413757
loss:  23.771333694458008 0.8287981152534485
loss:  23.66388702392578 0.8408722281455994
loss:  24.118160247802734 0.8394719362258911
loss:  24.419410705566406 0.863981306552887
loss:  23.991483688354492 0.8522641658782959
loss:  24.83445167541504 0.9577712416648865
*******************Epoch 61 ****************** 1240 1.0
Validation Loss
*** pred loss:  25.65704917907715 pred acc: 0.584903359413147
*** stop loss:  6.398630142211914 stop acc: 0.9274595379829407
*** template loss:  7.4184489250183105 template acc: tensor(0.1439, device='cuda:0')
*** label loss:  6.283602237701416 label acc: tensor(0.3770, device='cuda:0')
Train Loss
---> pred loss: 18.047825622558594 pred acc: 0.7074462443590164
---> stop loss: 3.4523040771484377 stop acc: 0.9611835151910781
---> template loss: 0.9829989433288574 tempalte acc: 0.7788044929504394
---> molecule label loss: 0.7619131088256836 molecule acc: 0.817777442932129
---> kl loss: 0.8565712928771972
---> reconstruction loss: 23.24504156112671
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-62-with.npy
loss:  23.802827835083008 0.8558027744293213
loss:  23.409927368164062 0.8361625075340271
loss:  23.745534896850586 0.8264674544334412
loss:  23.79499053955078 0.8248499035835266
loss:  24.14767074584961 0.8317755460739136
loss:  23.880084991455078 0.8315210938453674
loss:  24.451181411743164 0.8225648999214172
loss:  24.20878791809082 0.8487588763237
loss:  24.090728759765625 0.8163525462150574
loss:  23.66409683227539 0.8182119727134705
loss:  24.090343475341797 0.8343058228492737
loss:  23.802207946777344 0.8344793319702148
loss:  23.596904754638672 0.8353878259658813
loss:  23.621891021728516 0.8146300911903381
loss:  23.471437454223633 0.8170138597488403
loss:  23.85839080810547 0.8105158805847168
loss:  23.87300682067871 0.8292052149772644
loss:  23.709537506103516 0.8143563270568848
loss:  23.940807342529297 0.8018471002578735
loss:  24.46788787841797 0.85359126329422
*******************Epoch 62 ****************** 1260 1.0
Validation Loss
*** pred loss:  25.414508819580078 pred acc: 0.5874999761581421
*** stop loss:  6.682065963745117 stop acc: 0.9229763746261597
*** template loss:  7.414925575256348 template acc: tensor(0.1400, device='cuda:0')
*** label loss:  6.2622199058532715 label acc: tensor(0.3813, device='cuda:0')
Train Loss
---> pred loss: 18.029190063476562 pred acc: 0.7065711677074432
---> stop loss: 3.3752468109130858 stop acc: 0.9621239185333252
---> template loss: 0.9327262878417969 tempalte acc: 0.7919663906097412
---> molecule label loss: 0.7163593292236328 molecule acc: 0.8295416831970215
---> kl loss: 0.8278901100158691
---> reconstruction loss: 23.053521633148193
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-63-with.npy
loss:  23.536468505859375 0.7988351583480835
loss:  23.89365577697754 0.8234978914260864
loss:  23.648967742919922 0.7931008338928223
loss:  23.223834991455078 0.8122324347496033
loss:  23.603498458862305 0.817168116569519
loss:  23.76807975769043 0.8126446008682251
loss:  23.834753036499023 0.8405053615570068
loss:  23.86985206604004 0.8252912163734436
loss:  23.919042587280273 0.8347976207733154
loss:  23.560317993164062 0.7900559306144714
loss:  24.03249168395996 0.8420885801315308
loss:  23.196460723876953 0.8189465403556824
loss:  23.51339340209961 0.8408967852592468
loss:  23.781274795532227 0.8464730381965637
loss:  23.37356185913086 0.8526529669761658
loss:  23.933670043945312 0.8187568187713623
loss:  24.03677749633789 0.8381974101066589
loss:  23.52104949951172 0.8162013292312622
loss:  23.403474807739258 0.7954525947570801
loss:  22.7535457611084 0.7717403173446655
*******************Epoch 63 ****************** 1280 1.0
Validation Loss
*** pred loss:  25.456361770629883 pred acc: 0.5833333134651184
*** stop loss:  6.569155693054199 stop acc: 0.9243462085723877
*** template loss:  7.390016555786133 template acc: tensor(0.1421, device='cuda:0')
*** label loss:  6.278382778167725 label acc: tensor(0.3785, device='cuda:0')
Train Loss
---> pred loss: 17.848774719238282 pred acc: 0.7095607906579972
---> stop loss: 3.370252990722656 stop acc: 0.9621094048023224
---> template loss: 0.9016201019287109 tempalte acc: 0.7988238334655762
---> molecule label loss: 0.6800853729248046 molecule acc: 0.83834867477417
---> kl loss: 0.8194767951965332
---> reconstruction loss: 22.800731945037843
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-64-with.npy
loss:  23.262588500976562 0.8037020564079285
loss:  23.52432632446289 0.7930231094360352
loss:  23.707557678222656 0.8088283538818359
loss:  23.270151138305664 0.8026787042617798
loss:  23.312423706054688 0.7935200929641724
loss:  23.472787857055664 0.796805202960968
loss:  23.643735885620117 0.8025477528572083
loss:  23.274009704589844 0.7893089652061462
loss:  23.846296310424805 0.7769712209701538
loss:  23.822233200073242 0.7999687790870667
loss:  23.882034301757812 0.8021888136863708
loss:  23.53713607788086 0.8163991570472717
loss:  23.564844131469727 0.8079348802566528
loss:  23.523635864257812 0.7891923785209656
loss:  24.100830078125 0.8084526658058167
loss:  23.944643020629883 0.7962266802787781
loss:  23.82571029663086 0.7874342799186707
loss:  23.80934715270996 0.7917386293411255
loss:  23.667709350585938 0.7964869141578674
loss:  23.639278411865234 0.7925212383270264
*******************Epoch 64 ****************** 1300 1.0
Validation Loss
*** pred loss:  25.503185272216797 pred acc: 0.587077260017395
*** stop loss:  6.858715057373047 stop acc: 0.9208593368530273
*** template loss:  7.424265384674072 template acc: tensor(0.1393, device='cuda:0')
*** label loss:  6.2665696144104 label acc: tensor(0.3676, device='cuda:0')
Train Loss
---> pred loss: 17.797579956054687 pred acc: 0.7117840379476548
---> stop loss: 3.348558044433594 stop acc: 0.9623627960681915
---> template loss: 0.9520119667053223 tempalte acc: 0.7876615524291992
---> molecule label loss: 0.7356179714202881 molecule acc: 0.8231122970581055
---> kl loss: 0.7977965354919434
---> reconstruction loss: 22.833770847320555
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-65-with.npy
loss:  23.60420036315918 0.7860589623451233
loss:  23.441465377807617 0.7956832647323608
loss:  24.075668334960938 0.8129721879959106
loss:  23.58494758605957 0.7792285084724426
loss:  23.460721969604492 0.7848569750785828
loss:  23.78940773010254 0.8034753203392029
loss:  23.399675369262695 0.7891247272491455
loss:  23.440155029296875 0.7772267460823059
loss:  24.170915603637695 0.7992156147956848
loss:  23.56985855102539 0.7939407229423523
loss:  23.620080947875977 0.7692456245422363
loss:  23.2086181640625 0.7771143317222595
loss:  23.756244659423828 0.7909945845603943
loss:  23.540546417236328 0.7822684049606323
loss:  23.56267738342285 0.8071326017379761
loss:  23.107131958007812 0.8058858513832092
loss:  22.984098434448242 0.8180885314941406
loss:  23.561368942260742 0.8391925096511841
loss:  23.54204750061035 0.8082015514373779
loss:  22.893705368041992 0.8624594807624817
*******************Epoch 65 ****************** 1320 1.0
Validation Loss
*** pred loss:  25.91314697265625 pred acc: 0.584782600402832
*** stop loss:  6.48256778717041 stop acc: 0.9254670143127441
*** template loss:  7.394948959350586 template acc: tensor(0.1379, device='cuda:0')
*** label loss:  6.313209056854248 label acc: tensor(0.3896, device='cuda:0')
Train Loss
---> pred loss: 17.722796630859374 pred acc: 0.7113998413085938
---> stop loss: 3.340795135498047 stop acc: 0.9622310340404511
---> template loss: 0.9369856834411621 tempalte acc: 0.7916513919830322
---> molecule label loss: 0.7159818649291992 molecule acc: 0.8243009567260742
---> kl loss: 0.7991183280944825
---> reconstruction loss: 22.716560077667236
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-66-with.npy
loss:  22.97893524169922 0.7963868975639343
loss:  23.26409339904785 0.7974170446395874
loss:  23.518028259277344 0.7790248394012451
loss:  23.317895889282227 0.793477475643158
loss:  23.150327682495117 0.8094894289970398
loss:  23.572790145874023 0.806978166103363
loss:  23.47242546081543 0.8040527105331421
loss:  23.827238082885742 0.7856475114822388
loss:  22.999494552612305 0.7812454700469971
loss:  23.14208984375 0.7665621042251587
loss:  23.385313034057617 0.7660219669342041
loss:  23.449508666992188 0.7818586230278015
loss:  23.51878547668457 0.7707515358924866
loss:  23.531463623046875 0.768886387348175
loss:  23.371986389160156 0.7481517195701599
loss:  23.29939079284668 0.7644278407096863
loss:  23.454484939575195 0.7638530135154724
loss:  23.80149269104004 0.7602065801620483
loss:  23.830121994018555 0.7756698727607727
loss:  24.242300033569336 0.8331642150878906
*******************Epoch 66 ****************** 1340 1.0
Validation Loss
*** pred loss:  25.710512161254883 pred acc: 0.5791062712669373
*** stop loss:  6.715923309326172 stop acc: 0.9232565760612488
*** template loss:  7.419463634490967 template acc: tensor(0.1414, device='cuda:0')
*** label loss:  6.392632961273193 label acc: tensor(0.3823, device='cuda:0')
Train Loss
---> pred loss: 17.731773376464844 pred acc: 0.7116148740053176
---> stop loss: 3.3247486114501954 stop acc: 0.9627884000539779
---> template loss: 0.9389764785766601 tempalte acc: 0.7853812217712403
---> molecule label loss: 0.6782480716705322 molecule acc: 0.8353689193725586
---> kl loss: 0.7826637268066406
---> reconstruction loss: 22.673743438720706
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-67-with.npy
loss:  23.44999122619629 0.7809602618217468
loss:  23.070890426635742 0.7924143671989441
loss:  23.039026260375977 0.801235556602478
loss:  23.394588470458984 0.7963929772377014
loss:  23.401887893676758 0.8092759847640991
loss:  23.452587127685547 0.7881379723548889
loss:  23.729124069213867 0.785582423210144
loss:  22.868574142456055 0.75653475522995
loss:  23.478866577148438 0.7861207723617554
loss:  23.588008880615234 0.7935793399810791
loss:  23.053150177001953 0.7852432131767273
loss:  23.14384651184082 0.7977755069732666
loss:  22.7927303314209 0.7710188627243042
loss:  22.918575286865234 0.8063557744026184
loss:  23.300439834594727 0.7897958159446716
loss:  23.171571731567383 0.782576322555542
loss:  23.013835906982422 0.8137404918670654
loss:  23.601192474365234 0.8234401345252991
loss:  23.126758575439453 0.80818110704422
loss:  24.396526336669922 0.797028124332428
*******************Epoch 67 ****************** 1360 1.0
Validation Loss
*** pred loss:  25.67277717590332 pred acc: 0.5816425085067749
*** stop loss:  6.474886894226074 stop acc: 0.9268991351127625
*** template loss:  7.3983235359191895 template acc: tensor(0.1467, device='cuda:0')
*** label loss:  6.368709564208984 label acc: tensor(0.3902, device='cuda:0')
Train Loss
---> pred loss: 17.676141357421876 pred acc: 0.713255450129509
---> stop loss: 3.2859630584716797 stop acc: 0.963408687710762
---> template loss: 0.8947891235351563 tempalte acc: 0.798435640335083
---> molecule label loss: 0.6494454860687255 molecule acc: 0.8407663345336914
---> kl loss: 0.7932694911956787
---> reconstruction loss: 22.50633988380432
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-68-with.npy
loss:  23.029848098754883 0.7919173240661621
loss:  23.237674713134766 0.7928810119628906
loss:  23.27602195739746 0.7859510183334351
loss:  22.914592742919922 0.7714859247207642
loss:  23.118595123291016 0.7653699517250061
loss:  23.286026000976562 0.7818837761878967
loss:  23.190664291381836 0.7665830850601196
loss:  23.534791946411133 0.7739965915679932
loss:  22.749099731445312 0.7619488835334778
loss:  22.980600357055664 0.7706962823867798
loss:  23.06124496459961 0.8035092949867249
loss:  23.24927520751953 0.7673184275627136
loss:  23.149234771728516 0.7823917269706726
loss:  23.06068992614746 0.8029885292053223
loss:  23.126113891601562 0.7823149561882019
loss:  23.09403419494629 0.7766355276107788
loss:  22.86261749267578 0.7882577180862427
loss:  22.81008529663086 0.7888898253440857
loss:  23.274646759033203 0.7922776341438293
loss:  21.854467391967773 0.7426725625991821
*******************Epoch 68 ****************** 1380 1.0
Validation Loss
*** pred loss:  25.515167236328125 pred acc: 0.5868357419967651
*** stop loss:  6.626135349273682 stop acc: 0.9249066114425659
*** template loss:  7.326021671295166 template acc: tensor(0.1527, device='cuda:0')
*** label loss:  6.304850101470947 label acc: tensor(0.3853, device='cuda:0')
Train Loss
---> pred loss: 17.515476989746094 pred acc: 0.7168849170207977
---> stop loss: 3.2780303955078125 stop acc: 0.9636125296354294
---> template loss: 0.8527003288269043 tempalte acc: 0.8092408180236816
---> molecule label loss: 0.6173107147216796 molecule acc: 0.8499261856079101
---> kl loss: 0.7794985294342041
---> reconstruction loss: 22.263517522811892
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-69-with.npy
loss:  22.73040008544922 0.789868950843811
loss:  22.963916778564453 0.7904005646705627
loss:  22.549541473388672 0.7713457942008972
loss:  22.83142852783203 0.7872434854507446
loss:  22.86726188659668 0.7821295261383057
loss:  23.168787002563477 0.7758141756057739
loss:  22.753381729125977 0.7448480129241943
loss:  22.66554069519043 0.7799122333526611
loss:  23.39866828918457 0.7570918202400208
loss:  22.55569076538086 0.7521785497665405
loss:  22.656803131103516 0.7727933526039124
loss:  22.887828826904297 0.7758035659790039
loss:  22.9072322845459 0.7581786513328552
loss:  22.598020553588867 0.7514519095420837
loss:  22.425626754760742 0.7371049523353577
loss:  22.96013832092285 0.7651292681694031
loss:  23.014625549316406 0.7617627382278442
loss:  23.204471588134766 0.7748776078224182
loss:  23.287424087524414 0.7737237215042114
loss:  22.751705169677734 0.7524101138114929
*******************Epoch 69 ****************** 1400 1.0
Validation Loss
*** pred loss:  25.683277130126953 pred acc: 0.5893115997314453
*** stop loss:  6.5522541999816895 stop acc: 0.9259651899337769
*** template loss:  7.372684478759766 template acc: tensor(0.1410, device='cuda:0')
*** label loss:  6.306864261627197 label acc: tensor(0.3896, device='cuda:0')
Train Loss
---> pred loss: 17.448614501953124 pred acc: 0.7165092259645462
---> stop loss: 3.2391246795654296 stop acc: 0.9638411730527878
---> template loss: 0.8167430877685546 tempalte acc: 0.8190882682800293
---> molecule label loss: 0.5867405414581299 molecule acc: 0.8584222793579102
---> kl loss: 0.7677034378051758
---> reconstruction loss: 22.091221427917482
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-70-with.npy
loss:  22.68734359741211 0.7525120973587036
loss:  22.56304359436035 0.7532501220703125
loss:  23.16005516052246 0.7926138043403625
loss:  23.000408172607422 0.8025907278060913
loss:  23.06502914428711 0.7822116613388062
loss:  22.823471069335938 0.7509751319885254
loss:  22.766477584838867 0.7549166083335876
loss:  23.067001342773438 0.7859898805618286
loss:  22.333587646484375 0.7631311416625977
loss:  22.730443954467773 0.7769531011581421
loss:  22.77444839477539 0.7918931841850281
loss:  22.97408676147461 0.7824887037277222
loss:  22.56632423400879 0.7832521796226501
loss:  22.44167709350586 0.7668394446372986
loss:  22.655927658081055 0.7556708455085754
loss:  22.753400802612305 0.7707593441009521
loss:  22.756305694580078 0.7696018218994141
loss:  23.145509719848633 0.7664855718612671
loss:  22.713098526000977 0.756339967250824
loss:  22.686683654785156 0.7776725888252258
*******************Epoch 70 ****************** 1420 1.0
Validation Loss
*** pred loss:  25.77019691467285 pred acc: 0.5884057879447937
*** stop loss:  6.533311367034912 stop acc: 0.9255604147911072
*** template loss:  7.398203372955322 template acc: tensor(0.1393, device='cuda:0')
*** label loss:  6.32628059387207 label acc: tensor(0.3828, device='cuda:0')
Train Loss
---> pred loss: 17.431480407714844 pred acc: 0.7179751724004746
---> stop loss: 3.2177730560302735 stop acc: 0.9644618064165116
---> template loss: 0.789033031463623 tempalte acc: 0.8258040428161622
---> molecule label loss: 0.5731229305267334 molecule acc: 0.8590450286865234
---> kl loss: 0.7718073844909668
---> reconstruction loss: 22.011407947540285
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-71-with.npy
loss:  22.594003677368164 0.7356590032577515
loss:  22.435312271118164 0.7557958364486694
loss:  22.99118423461914 0.7701687216758728
loss:  22.762372970581055 0.7595688700675964
loss:  22.681034088134766 0.769921064376831
loss:  22.344585418701172 0.7598990201950073
loss:  22.45829963684082 0.7770097255706787
loss:  22.676225662231445 0.7563322186470032
loss:  22.407939910888672 0.7699117660522461
loss:  22.41864585876465 0.7455239295959473
loss:  22.50780487060547 0.7693555951118469
loss:  22.71562957763672 0.7697237730026245
loss:  22.463048934936523 0.7613247036933899
loss:  22.438997268676758 0.7523243427276611
loss:  22.412193298339844 0.7447904944419861
loss:  22.557497024536133 0.7354480624198914
loss:  22.690420150756836 0.7539582252502441
loss:  22.92117691040039 0.7492957711219788
loss:  22.926843643188477 0.7379060983657837
loss:  23.673938751220703 0.7206637263298035
*******************Epoch 71 ****************** 1440 1.0
Validation Loss
*** pred loss:  26.049589157104492 pred acc: 0.5765096545219421
*** stop loss:  7.351487636566162 stop acc: 0.9161893129348755
*** template loss:  7.383076190948486 template acc: tensor(0.1474, device='cuda:0')
*** label loss:  6.444523334503174 label acc: tensor(0.3956, device='cuda:0')
Train Loss
---> pred loss: 17.37159423828125 pred acc: 0.718890517950058
---> stop loss: 3.2338977813720704 stop acc: 0.9641502559185028
---> template loss: 0.7591273784637451 tempalte acc: 0.832391357421875
---> molecule label loss: 0.5345080375671387 molecule acc: 0.8690519332885742
---> kl loss: 0.7547290802001954
---> reconstruction loss: 21.89912986755371
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-72-with.npy
loss:  23.0357608795166 0.7576248049736023
loss:  22.915494918823242 0.7503295540809631
loss:  22.608936309814453 0.7509105801582336
loss:  23.43477439880371 0.7440932989120483
loss:  23.2824649810791 0.7572919726371765
loss:  22.649202346801758 0.7609010338783264
loss:  23.089933395385742 0.7464407086372375
loss:  22.631757736206055 0.7292238473892212
loss:  22.434589385986328 0.7625404000282288
loss:  22.940793991088867 0.7442727088928223
loss:  22.50421905517578 0.7978603839874268
loss:  22.680809020996094 0.7778863906860352
loss:  22.66410255432129 0.783716082572937
loss:  22.819467544555664 0.7340602278709412
loss:  22.628482818603516 0.7735347151756287
loss:  23.104148864746094 0.7719895839691162
loss:  23.125690460205078 0.7954668998718262
loss:  22.614625930786133 0.7777279615402222
loss:  22.402711868286133 0.755189836025238
loss:  22.1074275970459 0.7092785239219666
*******************Epoch 72 ****************** 1460 1.0
Validation Loss
*** pred loss:  25.98771095275879 pred acc: 0.5818840265274048
*** stop loss:  6.69658899307251 stop acc: 0.9234122633934021
*** template loss:  7.385777473449707 template acc: tensor(0.1474, device='cuda:0')
*** label loss:  6.404205799102783 label acc: tensor(0.3911, device='cuda:0')
Train Loss
---> pred loss: 17.37509765625 pred acc: 0.7163189888000489
---> stop loss: 3.3760753631591798 stop acc: 0.9614749073982238
---> template loss: 0.7484659671783447 tempalte acc: 0.8355198860168457
---> molecule label loss: 0.5251138210296631 molecule acc: 0.8703203201293945
---> kl loss: 0.759017038345337
---> reconstruction loss: 22.024752187728883
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-73-with.npy
loss:  22.7816219329834 0.7384123206138611
loss:  22.050796508789062 0.7313021421432495
loss:  22.204856872558594 0.7275896668434143
loss:  21.979984283447266 0.7574924230575562
loss:  22.26628303527832 0.7544237971305847
loss:  22.348962783813477 0.7494924068450928
loss:  22.604856491088867 0.7323445081710815
loss:  22.185277938842773 0.7606146335601807
loss:  22.61872673034668 0.7271193861961365
loss:  22.550779342651367 0.730224609375
loss:  22.27192497253418 0.7299593687057495
loss:  22.353687286376953 0.7558188438415527
loss:  22.660242080688477 0.751535177230835
loss:  23.113826751708984 0.7181673049926758
loss:  22.59662628173828 0.7200167179107666
loss:  22.626970291137695 0.7307295799255371
loss:  22.096336364746094 0.7302153706550598
loss:  22.631237030029297 0.7448508739471436
loss:  22.646360397338867 0.7370550036430359
loss:  21.065113067626953 0.7501620054244995
*******************Epoch 73 ****************** 1480 1.0
Validation Loss
*** pred loss:  25.9362735748291 pred acc: 0.587620735168457
*** stop loss:  6.774229049682617 stop acc: 0.9227272868156433
*** template loss:  7.434080123901367 template acc: tensor(0.1442, device='cuda:0')
*** label loss:  6.477847576141357 label acc: tensor(0.3845, device='cuda:0')
Train Loss
---> pred loss: 17.204072570800783 pred acc: 0.720844641327858
---> stop loss: 3.180763816833496 stop acc: 0.9644765704870224
---> template loss: 0.7413627147674561 tempalte acc: 0.8351591110229493
---> molecule label loss: 0.5176490306854248 molecule acc: 0.8714313507080078
---> kl loss: 0.7388762950897216
---> reconstruction loss: 21.643849229812623
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-74-with.npy
loss:  22.330787658691406 0.7811508178710938
loss:  22.113187789916992 0.7470881938934326
loss:  22.15511131286621 0.7441967725753784
loss:  22.680381774902344 0.7696298956871033
loss:  22.407739639282227 0.7485348582267761
loss:  22.109020233154297 0.7686250805854797
loss:  22.71703338623047 0.7686865925788879
loss:  22.09496307373047 0.7541959881782532
loss:  22.70612335205078 0.7506264448165894
loss:  22.601802825927734 0.735154390335083
loss:  22.106918334960938 0.7232780456542969
loss:  22.65168571472168 0.7368149757385254
loss:  22.673025131225586 0.7586353421211243
loss:  22.268856048583984 0.7323649525642395
loss:  22.29121208190918 0.7397983074188232
loss:  22.066328048706055 0.7485178709030151
loss:  22.336551666259766 0.7473821043968201
loss:  22.625200271606445 0.7659878730773926
loss:  22.49930763244629 0.747766375541687
loss:  21.908105850219727 0.6459250450134277
*******************Epoch 74 ****************** 1500 1.0
Validation Loss
*** pred loss:  25.884492874145508 pred acc: 0.5862318873405457
*** stop loss:  6.653975009918213 stop acc: 0.924408495426178
*** template loss:  7.452486038208008 template acc: tensor(0.1481, device='cuda:0')
*** label loss:  6.3640570640563965 label acc: tensor(0.3815, device='cuda:0')
Train Loss
---> pred loss: 17.172764587402344 pred acc: 0.7207811951637269
---> stop loss: 3.2047142028808593 stop acc: 0.9642310470342637
---> template loss: 0.732401180267334 tempalte acc: 0.837013053894043
---> molecule label loss: 0.5115700244903565 molecule acc: 0.8739469528198243
---> kl loss: 0.7457180976867676
---> reconstruction loss: 21.62144956588745
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-75-with.npy
loss:  21.869037628173828 0.7457413077354431
loss:  22.365880966186523 0.7726643085479736
loss:  22.31145477294922 0.756928026676178
loss:  22.57048797607422 0.7501149773597717
loss:  22.25065803527832 0.7226717472076416
loss:  22.354473114013672 0.7549293041229248
loss:  22.396718978881836 0.7490986585617065
loss:  21.966793060302734 0.7638712525367737
loss:  22.653141021728516 0.7385866641998291
loss:  22.034059524536133 0.7371950745582581
loss:  22.113008499145508 0.7711243629455566
loss:  21.74818229675293 0.7342391014099121
loss:  22.130334854125977 0.7413848638534546
loss:  21.990625381469727 0.7372232675552368
loss:  22.22427749633789 0.7294988036155701
loss:  22.045562744140625 0.7232507467269897
loss:  21.896020889282227 0.714074432849884
loss:  22.340959548950195 0.7524667978286743
loss:  22.205028533935547 0.7451980113983154
loss:  21.241540908813477 0.7065733671188354
*******************Epoch 75 ****************** 1520 1.0
Validation Loss
*** pred loss:  26.186588287353516 pred acc: 0.5807970762252808
*** stop loss:  6.817843914031982 stop acc: 0.9223848581314087
*** template loss:  7.4295220375061035 template acc: tensor(0.1439, device='cuda:0')
*** label loss:  6.346169471740723 label acc: tensor(0.3821, device='cuda:0')
Train Loss
---> pred loss: 17.07139892578125 pred acc: 0.7214723587036133
---> stop loss: 3.1097951889038087 stop acc: 0.9651386737823486
---> template loss: 0.7154981613159179 tempalte acc: 0.843568229675293
---> molecule label loss: 0.496378755569458 molecule acc: 0.8753536224365235
---> kl loss: 0.7423418045043946
---> reconstruction loss: 21.393070793151853
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-76-with.npy
loss:  22.09297752380371 0.7460501194000244
loss:  21.971601486206055 0.7434298992156982
loss:  21.93743324279785 0.7464277148246765
loss:  22.290557861328125 0.7316737174987793
loss:  21.846755981445312 0.7250780463218689
loss:  21.989980697631836 0.727569043636322
loss:  22.240249633789062 0.730973482131958
loss:  22.045433044433594 0.7148016691207886
loss:  21.844751358032227 0.7077221274375916
loss:  22.63508415222168 0.7102922797203064
loss:  22.47822380065918 0.7049679756164551
loss:  21.9006404876709 0.7145611047744751
loss:  21.90291404724121 0.7151833772659302
loss:  22.304765701293945 0.7109965682029724
loss:  21.738927841186523 0.712236225605011
loss:  22.175962448120117 0.7355592846870422
loss:  22.242414474487305 0.724976658821106
loss:  22.104883193969727 0.7340350151062012
loss:  22.535478591918945 0.7319529056549072
loss:  22.157445907592773 0.7264050245285034
*******************Epoch 76 ****************** 1540 1.0
Validation Loss
*** pred loss:  25.892026901245117 pred acc: 0.5898550748825073
*** stop loss:  6.937338352203369 stop acc: 0.9223848581314087
*** template loss:  7.449708461761475 template acc: tensor(0.1453, device='cuda:0')
*** label loss:  6.385887622833252 label acc: tensor(0.3704, device='cuda:0')
Train Loss
---> pred loss: 17.037687683105467 pred acc: 0.7238174676895142
---> stop loss: 3.1276952743530275 stop acc: 0.9651610821485519
---> template loss: 0.7214458465576172 tempalte acc: 0.8408596992492676
---> molecule label loss: 0.5102504253387451 molecule acc: 0.8719290733337403
---> kl loss: 0.7247446537017822
---> reconstruction loss: 21.39707999229431
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-77-with.npy
loss:  22.05829620361328 0.7522336840629578
loss:  22.327632904052734 0.7219627499580383
loss:  21.912649154663086 0.7112261056900024
loss:  22.34686851501465 0.7133944034576416
loss:  21.92764663696289 0.7112651467323303
loss:  22.082237243652344 0.7115570306777954
loss:  21.991214752197266 0.7129918932914734
loss:  22.471406936645508 0.7211939096450806
loss:  22.129899978637695 0.7172137498855591
loss:  22.229631423950195 0.7267636060714722
loss:  22.04146385192871 0.7207525968551636
loss:  21.64589500427246 0.7238927483558655
loss:  21.80801010131836 0.7146368026733398
loss:  22.094404220581055 0.7389869689941406
loss:  22.130064010620117 0.7133187651634216
loss:  22.12677764892578 0.6924030780792236
loss:  22.072519302368164 0.7192880511283875
loss:  21.775657653808594 0.7212812304496765
loss:  21.649770736694336 0.7019333839416504
loss:  20.733173370361328 0.6699122786521912
*******************Epoch 77 ****************** 1560 1.0
Validation Loss
*** pred loss:  26.272703170776367 pred acc: 0.5765700340270996
*** stop loss:  6.791220188140869 stop acc: 0.9229452610015869
*** template loss:  7.430334568023682 template acc: tensor(0.1453, device='cuda:0')
*** label loss:  6.511938571929932 label acc: tensor(0.3954, device='cuda:0')
Train Loss
---> pred loss: 16.9704833984375 pred acc: 0.7239117801189423
---> stop loss: 3.1148162841796876 stop acc: 0.9650578916072845
---> template loss: 0.6882472038269043 tempalte acc: 0.8483853340148926
---> molecule label loss: 0.4884041309356689 molecule acc: 0.8759074211120605
---> kl loss: 0.7158103942871094
---> reconstruction loss: 21.261949920654295
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-78-with.npy
loss:  21.77239990234375 0.6927015781402588
loss:  21.78093910217285 0.7044576406478882
loss:  21.745498657226562 0.7014046311378479
loss:  22.172454833984375 0.6994361281394958
loss:  21.732248306274414 0.7120445370674133
loss:  22.185466766357422 0.6901923418045044
loss:  21.961986541748047 0.7039220333099365
loss:  22.058509826660156 0.6980240345001221
loss:  21.759586334228516 0.7004426121711731
loss:  22.080638885498047 0.6998615264892578
loss:  22.006765365600586 0.7046583294868469
loss:  21.797082901000977 0.6933990120887756
loss:  21.899900436401367 0.7071566581726074
loss:  22.173965454101562 0.7171261310577393
loss:  21.779464721679688 0.7306628227233887
loss:  21.94704818725586 0.7179142236709595
loss:  21.972715377807617 0.7272619605064392
loss:  22.15460968017578 0.7215189933776855
loss:  21.57394790649414 0.7039856910705566
loss:  21.375879287719727 0.724328339099884
*******************Epoch 78 ****************** 1580 1.0
Validation Loss
*** pred loss:  26.115076065063477 pred acc: 0.5861715078353882
*** stop loss:  6.915119647979736 stop acc: 0.9224470853805542
*** template loss:  7.463209629058838 template acc: tensor(0.1449, device='cuda:0')
*** label loss:  6.453378200531006 label acc: tensor(0.3900, device='cuda:0')
Train Loss
---> pred loss: 16.968067932128907 pred acc: 0.7239319413900376
---> stop loss: 3.092154884338379 stop acc: 0.9653580397367477
---> template loss: 0.6699295043945312 tempalte acc: 0.8530896186828614
---> molecule label loss: 0.4588765144348145 molecule acc: 0.8835129737854004
---> kl loss: 0.7075248241424561
---> reconstruction loss: 21.189031267166136
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-79-with.npy
loss:  21.77126693725586 0.7270644307136536
loss:  21.777122497558594 0.7266217470169067
loss:  21.982540130615234 0.7415027022361755
loss:  21.943706512451172 0.6944354176521301
loss:  21.849760055541992 0.7240355610847473
loss:  22.13153648376465 0.7088529467582703
loss:  22.144006729125977 0.7318739891052246
loss:  21.932167053222656 0.7180212736129761
loss:  21.819721221923828 0.7306674718856812
loss:  22.05931854248047 0.7238638997077942
loss:  22.09050941467285 0.7092655301094055
loss:  22.006906509399414 0.7384217381477356
loss:  21.950397491455078 0.7022398710250854
loss:  22.082868576049805 0.740845799446106
loss:  21.906993865966797 0.7234323620796204
loss:  22.00899887084961 0.7164217233657837
loss:  21.671297073364258 0.7235430479049683
loss:  21.88078498840332 0.712398111820221
loss:  22.139881134033203 0.7185379266738892
loss:  22.33196449279785 0.6946321129798889
*******************Epoch 79 ****************** 1600 1.0
Validation Loss
*** pred loss:  26.310855865478516 pred acc: 0.5792874097824097
*** stop loss:  6.997377395629883 stop acc: 0.9216376543045044
*** template loss:  7.539721965789795 template acc: tensor(0.1407, device='cuda:0')
*** label loss:  6.432814598083496 label acc: tensor(0.3594, device='cuda:0')
Train Loss
---> pred loss: 16.878602600097658 pred acc: 0.7256014108657837
---> stop loss: 3.0856067657470705 stop acc: 0.9656844347715378
---> template loss: 0.7702188491821289 tempalte acc: 0.8293263435363769
---> molecule label loss: 0.5193242073059082 molecule acc: 0.8665648460388183
---> kl loss: 0.7203340053558349
---> reconstruction loss: 21.25375351905823
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-80-with.npy
loss:  21.98674201965332 0.7071663737297058
loss:  22.293533325195312 0.7328681945800781
loss:  22.141197204589844 0.7110834717750549
loss:  21.914037704467773 0.7236422300338745
loss:  21.803638458251953 0.7294266819953918
loss:  22.091537475585938 0.713383138179779
loss:  22.29562759399414 0.6787835955619812
loss:  22.116619110107422 0.6947625279426575
loss:  21.988767623901367 0.7254631519317627
loss:  21.9747314453125 0.6856285333633423
loss:  21.910011291503906 0.6951080560684204
loss:  21.971576690673828 0.7057960033416748
loss:  21.810070037841797 0.6944847106933594
loss:  21.663814544677734 0.7043889760971069
loss:  21.620851516723633 0.6916264891624451
loss:  22.190345764160156 0.6932304501533508
loss:  21.772106170654297 0.6784251928329468
loss:  21.729211807250977 0.7003713250160217
loss:  21.80268669128418 0.6932865977287292
loss:  22.015731811523438 0.6704890131950378
*******************Epoch 80 ****************** 1620 1.0
Validation Loss
*** pred loss:  26.199481964111328 pred acc: 0.5855675935745239
*** stop loss:  6.889123916625977 stop acc: 0.9233188629150391
*** template loss:  7.467827320098877 template acc: tensor(0.1572, device='cuda:0')
*** label loss:  6.50337028503418 label acc: tensor(0.3887, device='cuda:0')
Train Loss
---> pred loss: 16.870201110839844 pred acc: 0.7249629974365235
---> stop loss: 3.046734619140625 stop acc: 0.9661664068698883
---> template loss: 0.7812695026397705 tempalte acc: 0.8226757049560547
---> molecule label loss: 0.554964828491211 molecule acc: 0.8568463325500488
---> kl loss: 0.7014707565307617
---> reconstruction loss: 21.25317096710205
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-81-with.npy
loss:  21.662065505981445 0.7108966708183289
loss:  22.003774642944336 0.7055291533470154
loss:  21.706541061401367 0.706562876701355
loss:  21.339181900024414 0.7038869261741638
loss:  21.648473739624023 0.7181454300880432
loss:  22.056747436523438 0.7236961722373962
loss:  22.264585494995117 0.7320531606674194
loss:  21.488370895385742 0.7092059850692749
loss:  21.856481552124023 0.7167722582817078
loss:  21.798725128173828 0.6920057535171509
loss:  21.55050277709961 0.6965677738189697
loss:  21.3142147064209 0.6797888278961182
loss:  21.551738739013672 0.6872277855873108
loss:  21.36730194091797 0.6813380718231201
loss:  21.290210723876953 0.6628291606903076
loss:  21.287315368652344 0.6761898398399353
loss:  21.233346939086914 0.6833372712135315
loss:  21.83963394165039 0.6495056748390198
loss:  22.171586990356445 0.6907676458358765
loss:  22.438247680664062 0.7067638039588928
*******************Epoch 81 ****************** 1640 1.0
Validation Loss
*** pred loss:  26.084367752075195 pred acc: 0.5791666507720947
*** stop loss:  6.906797409057617 stop acc: 0.9232565760612488
*** template loss:  7.475388050079346 template acc: tensor(0.1512, device='cuda:0')
*** label loss:  6.467219352722168 label acc: tensor(0.3919, device='cuda:0')
Train Loss
---> pred loss: 16.80085144042969 pred acc: 0.7272242069244385
---> stop loss: 3.036669158935547 stop acc: 0.9665268570184707
---> template loss: 0.6915518760681152 tempalte acc: 0.8450624465942382
---> molecule label loss: 0.4677261829376221 molecule acc: 0.8798614501953125
---> kl loss: 0.6966535091400147
---> reconstruction loss: 20.996800470352174
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-82-with.npy
loss:  21.541475296020508 0.7140222191810608
loss:  21.669252395629883 0.7225572466850281
loss:  22.128332138061523 0.7083578705787659
loss:  21.81810188293457 0.7091912031173706
loss:  21.76327896118164 0.7195267677307129
loss:  21.491262435913086 0.69476318359375
loss:  21.654788970947266 0.7191341519355774
loss:  21.889225006103516 0.703109085559845
loss:  21.891386032104492 0.7003909349441528
loss:  21.803560256958008 0.7004587054252625
loss:  21.60002326965332 0.6690619587898254
loss:  21.268068313598633 0.6644128561019897
loss:  21.403242111206055 0.6824464201927185
loss:  21.721511840820312 0.6839235424995422
loss:  21.478822708129883 0.6833098530769348
loss:  21.484928131103516 0.6932846307754517
loss:  21.5357723236084 0.6797779202461243
loss:  21.265459060668945 0.6871313452720642
loss:  21.421180725097656 0.6789193749427795
loss:  21.198850631713867 0.6989632248878479
*******************Epoch 82 ****************** 1660 1.0
Validation Loss
*** pred loss:  26.11853790283203 pred acc: 0.58423912525177
*** stop loss:  6.9215521812438965 stop acc: 0.9222914576530457
*** template loss:  7.475373268127441 template acc: tensor(0.1555, device='cuda:0')
*** label loss:  6.5449910163879395 label acc: tensor(0.4018, device='cuda:0')
Train Loss
---> pred loss: 16.722914123535155 pred acc: 0.7271844804286957
---> stop loss: 3.041585922241211 stop acc: 0.9659340232610703
---> template loss: 0.679008960723877 tempalte acc: 0.8485240936279297
---> molecule label loss: 0.4622805118560791 molecule acc: 0.8809062957763671
---> kl loss: 0.6956371307373047
---> reconstruction loss: 20.905788040161134
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-83-with.npy
loss:  21.426671981811523 0.7108102440834045
loss:  21.711313247680664 0.7306808829307556
loss:  21.646831512451172 0.7266436219215393
loss:  21.60854148864746 0.731245756149292
loss:  21.539438247680664 0.726603627204895
loss:  21.82868766784668 0.7303637266159058
loss:  21.80876922607422 0.6979024410247803
loss:  21.55320930480957 0.6886186003684998
loss:  21.41642189025879 0.6889778971672058
loss:  21.265575408935547 0.6964622735977173
loss:  21.13282585144043 0.6910174489021301
loss:  21.98716163635254 0.6651003956794739
loss:  21.383806228637695 0.6779417991638184
loss:  21.700305938720703 0.6705226302146912
loss:  21.862308502197266 0.6701267957687378
loss:  21.210643768310547 0.679365873336792
loss:  21.627817153930664 0.6775156855583191
loss:  21.557809829711914 0.6942014098167419
loss:  21.663394927978516 0.6999101638793945
loss:  20.91907501220703 0.7245227098464966
*******************Epoch 83 ****************** 1680 1.0
Validation Loss
*** pred loss:  26.281604766845703 pred acc: 0.5867753624916077
*** stop loss:  6.937538146972656 stop acc: 0.9256849884986877
*** template loss:  7.4751296043396 template acc: tensor(0.1488, device='cuda:0')
*** label loss:  6.523049354553223 label acc: tensor(0.3958, device='cuda:0')
Train Loss
---> pred loss: 16.668533325195312 pred acc: 0.729071706533432
---> stop loss: 2.9706184387207033 stop acc: 0.9672150909900665
---> template loss: 0.7221420288085938 tempalte acc: 0.8372814178466796
---> molecule label loss: 0.48230953216552735 molecule acc: 0.8740992546081543
---> kl loss: 0.6989267349243165
---> reconstruction loss: 20.843602561950682
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-84-with.npy
loss:  20.935749053955078 0.6853631734848022
loss:  21.290767669677734 0.6885939240455627
loss:  21.434131622314453 0.6663272976875305
loss:  21.70481300354004 0.6786316633224487
loss:  20.866544723510742 0.6607373952865601
loss:  21.264989852905273 0.6575413346290588
loss:  21.355953216552734 0.6543700695037842
loss:  21.586061477661133 0.6663814783096313
loss:  21.677539825439453 0.660439670085907
loss:  21.050886154174805 0.6659219861030579
loss:  21.78286361694336 0.6866099834442139
loss:  21.07036590576172 0.6611896753311157
loss:  21.316614151000977 0.675839900970459
loss:  21.223392486572266 0.6977116465568542
loss:  21.660886764526367 0.6783027648925781
loss:  20.957611083984375 0.6901030540466309
loss:  21.419008255004883 0.6997462511062622
loss:  21.942243576049805 0.7116702198982239
loss:  21.112796783447266 0.6794655323028564
loss:  22.77713394165039 0.6760941743850708
*******************Epoch 84 ****************** 1700 1.0
Validation Loss
*** pred loss:  26.29608154296875 pred acc: 0.5889492630958557
*** stop loss:  7.100693702697754 stop acc: 0.9220423698425293
*** template loss:  7.522374153137207 template acc: tensor(0.1463, device='cuda:0')
*** label loss:  6.778131484985352 label acc: tensor(0.4046, device='cuda:0')
Train Loss
---> pred loss: 16.63035430908203 pred acc: 0.7298723191022873
---> stop loss: 2.9951557159423827 stop acc: 0.9670803815126419
---> template loss: 0.6784079551696778 tempalte acc: 0.8491110801696777
---> molecule label loss: 0.4405481815338135 molecule acc: 0.8858153343200683
---> kl loss: 0.6770520210266113
---> reconstruction loss: 20.74446439743042
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-85-with.npy
loss:  21.62875747680664 0.6747369170188904
loss:  21.31990623474121 0.6894848346710205
loss:  21.408824920654297 0.6970748901367188
loss:  21.685279846191406 0.6781206130981445
loss:  21.235294342041016 0.6762815117835999
loss:  21.545822143554688 0.6687530279159546
loss:  21.37061309814453 0.6726973652839661
loss:  21.465227127075195 0.6692021489143372
loss:  21.405261993408203 0.6751181483268738
loss:  21.404071807861328 0.6657111644744873
loss:  21.68271255493164 0.6747080087661743
loss:  21.333452224731445 0.6656422019004822
loss:  21.549114227294922 0.6545500755310059
loss:  21.42610740661621 0.6758860349655151
loss:  21.69831085205078 0.672055721282959
loss:  21.020292282104492 0.6954096555709839
loss:  21.233694076538086 0.6967886686325073
loss:  21.504920959472656 0.6885200142860413
loss:  21.15089225769043 0.699024498462677
loss:  21.401142120361328 0.6961597204208374
*******************Epoch 85 ****************** 1720 1.0
Validation Loss
*** pred loss:  26.186195373535156 pred acc: 0.5862318873405457
*** stop loss:  6.937005996704102 stop acc: 0.9228829741477966
*** template loss:  7.4647908210754395 template acc: tensor(0.1541, device='cuda:0')
*** label loss:  6.384440898895264 label acc: tensor(0.3796, device='cuda:0')
Train Loss
---> pred loss: 16.59486083984375 pred acc: 0.7299150049686431
---> stop loss: 3.0478649139404297 stop acc: 0.9660331964492798
---> template loss: 0.6615214824676514 tempalte acc: 0.8535199165344238
---> molecule label loss: 0.4399415969848633 molecule acc: 0.8864557266235351
---> kl loss: 0.6792963027954102
---> reconstruction loss: 20.744186973571775
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-86-with.npy
loss:  21.099075317382812 0.6952027678489685
loss:  21.352638244628906 0.7010231614112854
loss:  21.38362693786621 0.7104983329772949
loss:  20.92947006225586 0.6760785579681396
loss:  21.084447860717773 0.6767168641090393
loss:  21.190166473388672 0.6933420300483704
loss:  21.485374450683594 0.6938335299491882
loss:  21.681943893432617 0.6987354159355164
loss:  21.267593383789062 0.6724623441696167
loss:  21.118284225463867 0.6882303357124329
loss:  21.06862449645996 0.6759925484657288
loss:  20.939537048339844 0.6882526278495789
loss:  21.252859115600586 0.7035496234893799
loss:  20.83353614807129 0.6655001640319824
loss:  21.584383010864258 0.6828669309616089
loss:  20.98267364501953 0.6617578268051147
loss:  21.561767578125 0.6849836111068726
loss:  21.070514678955078 0.6817196011543274
loss:  21.01187515258789 0.6805697679519653
loss:  20.6325626373291 0.6842251420021057
*******************Epoch 86 ****************** 1740 1.0
Validation Loss
*** pred loss:  26.33057403564453 pred acc: 0.5833333134651184
*** stop loss:  7.121366024017334 stop acc: 0.9221357703208923
*** template loss:  7.4688029289245605 template acc: tensor(0.1484, device='cuda:0')
*** label loss:  6.452909469604492 label acc: tensor(0.3793, device='cuda:0')
Train Loss
---> pred loss: 16.54023132324219 pred acc: 0.7308089792728424
---> stop loss: 2.9382862091064452 stop acc: 0.9674095839262009
---> template loss: 0.6144876956939698 tempalte acc: 0.864511775970459
---> molecule label loss: 0.3977663993835449 molecule acc: 0.8970762252807617
---> kl loss: 0.6857769966125489
---> reconstruction loss: 20.490771770477295
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-87-with.npy
loss:  20.990598678588867 0.6967530250549316
loss:  21.021841049194336 0.6943385004997253
loss:  21.00859260559082 0.6927756071090698
loss:  20.938871383666992 0.6915912628173828
loss:  21.47642707824707 0.7033389806747437
loss:  21.29192352294922 0.6757659316062927
loss:  21.4202938079834 0.683478832244873
loss:  20.87668800354004 0.6993669867515564
loss:  21.024513244628906 0.6998566389083862
loss:  20.955217361450195 0.680082380771637
loss:  20.94537353515625 0.6884824633598328
loss:  21.36931610107422 0.6853327751159668
loss:  21.155933380126953 0.6739418506622314
loss:  20.78961181640625 0.6664876937866211
loss:  21.07830810546875 0.6842674612998962
loss:  20.92780876159668 0.6754087805747986
loss:  21.03331756591797 0.6877762675285339
loss:  20.480548858642578 0.6721259951591492
loss:  21.16854476928711 0.6684979200363159
loss:  22.03546714782715 0.7151505947113037
*******************Epoch 87 ****************** 1760 1.0
Validation Loss
*** pred loss:  26.488208770751953 pred acc: 0.5829105973243713
*** stop loss:  7.061326503753662 stop acc: 0.9235990643501282
*** template loss:  7.515805244445801 template acc: tensor(0.1460, device='cuda:0')
*** label loss:  6.516664981842041 label acc: tensor(0.3945, device='cuda:0')
Train Loss
---> pred loss: 16.4723876953125 pred acc: 0.7322589933872223
---> stop loss: 2.9612857818603517 stop acc: 0.96715327501297
---> template loss: 0.5934455394744873 tempalte acc: 0.8690353393554687
---> molecule label loss: 0.3855982542037964 molecule acc: 0.899541187286377
---> kl loss: 0.6867409706115722
---> reconstruction loss: 20.412718868255613
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-88-with.npy
loss:  20.62367820739746 0.6546919941902161
loss:  20.92224884033203 0.65693199634552
loss:  20.848674774169922 0.6688275933265686
loss:  20.888139724731445 0.6709399223327637
loss:  20.853044509887695 0.6616361737251282
loss:  21.070632934570312 0.6748560070991516
loss:  20.950092315673828 0.6428701281547546
loss:  21.180784225463867 0.6543970704078674
loss:  20.75229835510254 0.6504638195037842
loss:  21.215131759643555 0.6503327488899231
loss:  21.203125 0.6608978509902954
loss:  20.920406341552734 0.6641132235527039
loss:  21.12874412536621 0.6444268226623535
loss:  20.788503646850586 0.652828574180603
loss:  21.114381790161133 0.6521562933921814
loss:  21.21128273010254 0.6534884572029114
loss:  21.056434631347656 0.6646654605865479
loss:  20.98140525817871 0.6539685726165771
loss:  21.376163482666016 0.6762787699699402
loss:  21.628820419311523 0.7345153093338013
*******************Epoch 88 ****************** 1780 1.0
Validation Loss
*** pred loss:  26.484970092773438 pred acc: 0.58423912525177
*** stop loss:  7.04738712310791 stop acc: 0.9216064810752869
*** template loss:  7.500919342041016 template acc: tensor(0.1520, device='cuda:0')
*** label loss:  6.408586502075195 label acc: tensor(0.3744, device='cuda:0')
Train Loss
---> pred loss: 16.448527526855468 pred acc: 0.7319979995489121
---> stop loss: 2.9392200469970704 stop acc: 0.9673241198062896
---> template loss: 0.5943464756011962 tempalte acc: 0.8704177856445312
---> molecule label loss: 0.3914416551589966 molecule acc: 0.8986433029174805
---> kl loss: 0.662164306640625
---> reconstruction loss: 20.37353515625
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-89-with.npy
loss:  20.582677841186523 0.6624447703361511
loss:  21.23723030090332 0.6776716709136963
loss:  20.83467674255371 0.6569429636001587
loss:  21.152498245239258 0.6814266443252563
loss:  21.32935905456543 0.6742740869522095
loss:  21.049226760864258 0.6790608763694763
loss:  20.672266006469727 0.6606888175010681
loss:  21.074785232543945 0.644593358039856
loss:  20.826862335205078 0.6319852471351624
loss:  20.923053741455078 0.6464377045631409
loss:  20.633644104003906 0.6514726877212524
loss:  20.63055419921875 0.6532462239265442
loss:  20.716163635253906 0.6586599349975586
loss:  21.239585876464844 0.6525618433952332
loss:  20.909032821655273 0.6573790311813354
loss:  20.87968635559082 0.6648924350738525
loss:  20.760066986083984 0.6835625171661377
loss:  20.91410255432129 0.6748155951499939
loss:  21.061969757080078 0.6775197982788086
loss:  19.569252014160156 0.673140823841095
*******************Epoch 89 ****************** 1800 1.0
Validation Loss
*** pred loss:  26.332252502441406 pred acc: 0.594142496585846
*** stop loss:  7.006428241729736 stop acc: 0.9234744906425476
*** template loss:  7.497064113616943 template acc: tensor(0.1544, device='cuda:0')
*** label loss:  6.535283088684082 label acc: tensor(0.3980, device='cuda:0')
Train Loss
---> pred loss: 16.333714294433594 pred acc: 0.7340385138988494
---> stop loss: 2.9028627395629885 stop acc: 0.9680077791213989
---> template loss: 0.5740089893341065 tempalte acc: 0.8762991905212403
---> molecule label loss: 0.3761084318161011 molecule acc: 0.9013579368591309
---> kl loss: 0.6631388187408447
---> reconstruction loss: 20.18669638633728
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-90-with.npy
loss:  20.937461853027344 0.672785758972168
loss:  20.657102584838867 0.6816760897636414
loss:  20.654115676879883 0.6749694347381592
loss:  20.448463439941406 0.6583458185195923
loss:  20.498775482177734 0.6555877923965454
loss:  20.641841888427734 0.6429083347320557
loss:  20.757919311523438 0.6428822875022888
loss:  21.097326278686523 0.6579157114028931
loss:  21.198497772216797 0.6620992422103882
loss:  20.83592987060547 0.6613161563873291
loss:  20.65065574645996 0.6642787456512451
loss:  20.90375518798828 0.6438177824020386
loss:  20.602357864379883 0.6439324617385864
loss:  20.642200469970703 0.642336905002594
loss:  20.6397705078125 0.6492695808410645
loss:  21.02729034423828 0.6529540419578552
loss:  20.76877784729004 0.6649982929229736
loss:  20.829423904418945 0.6477367281913757
loss:  20.873332977294922 0.6518964767456055
loss:  19.951457977294922 0.6457200050354004
*******************Epoch 90 ****************** 1820 1.0
Validation Loss
*** pred loss:  26.577016830444336 pred acc: 0.5899758338928223
*** stop loss:  7.235461235046387 stop acc: 0.9224470853805542
*** template loss:  7.5084075927734375 template acc: tensor(0.1544, device='cuda:0')
*** label loss:  6.480481147766113 label acc: tensor(0.3842, device='cuda:0')
Train Loss
---> pred loss: 16.274722290039062 pred acc: 0.7344439089298248
---> stop loss: 2.8941287994384766 stop acc: 0.9679511070251465
---> template loss: 0.553499174118042 tempalte acc: 0.8804731369018555
---> molecule label loss: 0.3525991439819336 molecule acc: 0.9107736587524414
---> kl loss: 0.6558713912963867
---> reconstruction loss: 20.074951362609863
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-91-with.npy
loss:  21.07243537902832 0.6406567096710205
loss:  20.6358699798584 0.6616420745849609
loss:  21.018115997314453 0.6727097630500793
loss:  20.820981979370117 0.6581777334213257
loss:  20.832096099853516 0.6621379852294922
loss:  20.806367874145508 0.676852285861969
loss:  20.559589385986328 0.6697683930397034
loss:  20.95210075378418 0.6570780277252197
loss:  20.209373474121094 0.6496309638023376
loss:  20.92212677001953 0.6689503192901611
loss:  21.19402313232422 0.6517857313156128
loss:  20.67620086669922 0.6559224128723145
loss:  21.06511878967285 0.6600795388221741
loss:  20.808820724487305 0.6556878685951233
loss:  20.943439483642578 0.6492986083030701
loss:  20.777706146240234 0.6541167497634888
loss:  20.951292037963867 0.653300404548645
loss:  21.257278442382812 0.662424623966217
loss:  20.588550567626953 0.6615106463432312
loss:  21.630002975463867 0.6803032755851746
*******************Epoch 91 ****************** 1840 1.0
Validation Loss
*** pred loss:  26.757564544677734 pred acc: 0.5820048451423645
*** stop loss:  7.892009258270264 stop acc: 0.9165629148483276
*** template loss:  7.5518798828125 template acc: tensor(0.1442, device='cuda:0')
*** label loss:  6.683675765991211 label acc: tensor(0.3930, device='cuda:0')
Train Loss
---> pred loss: 16.368022155761718 pred acc: 0.7331428945064544
---> stop loss: 2.9569238662719726 stop acc: 0.9669367700815201
---> template loss: 0.5522699356079102 tempalte acc: 0.8808189392089844
---> molecule label loss: 0.3487551689147949 molecule acc: 0.9109591484069824
---> kl loss: 0.6601017475128174
---> reconstruction loss: 20.225973081588744
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-92-with.npy
loss:  21.028104782104492 0.6545122861862183
loss:  20.736587524414062 0.6954309940338135
loss:  20.937654495239258 0.6691856980323792
loss:  21.26310920715332 0.6646106243133545
loss:  20.41773796081543 0.6734076142311096
loss:  21.000171661376953 0.6782624125480652
loss:  20.902605056762695 0.6784399747848511
loss:  20.89446258544922 0.6920230984687805
loss:  21.536943435668945 0.6736018061637878
loss:  20.63417625427246 0.6700990796089172
loss:  20.901201248168945 0.6775820851325989
loss:  20.96084213256836 0.6544081568717957
loss:  20.83710479736328 0.6494360566139221
loss:  21.0883846282959 0.6441346406936646
loss:  20.751575469970703 0.656792402267456
loss:  20.712018966674805 0.6461430788040161
loss:  20.883319854736328 0.6632741689682007
loss:  20.688737869262695 0.6355232000350952
loss:  20.6026611328125 0.636884868144989
loss:  21.613000869750977 0.616949737071991
*******************Epoch 92 ****************** 1860 1.0
Validation Loss
*** pred loss:  26.63372230529785 pred acc: 0.5809178352355957
*** stop loss:  7.091836452484131 stop acc: 0.9225093722343445
*** template loss:  7.502333641052246 template acc: tensor(0.1488, device='cuda:0')
*** label loss:  6.566549777984619 label acc: tensor(0.3988, device='cuda:0')
Train Loss
---> pred loss: 16.304959106445313 pred acc: 0.734110751748085
---> stop loss: 3.0896623611450194 stop acc: 0.9652433186769486
---> template loss: 0.5296664237976074 tempalte acc: 0.8884230613708496
---> molecule label loss: 0.3336952209472656 molecule acc: 0.9139056205749512
---> kl loss: 0.6615350723266602
---> reconstruction loss: 20.257985496520995
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-93-with.npy
loss:  20.42665672302246 0.6476156115531921
loss:  20.89470863342285 0.6734756827354431
loss:  20.59227180480957 0.6745175123214722
loss:  20.687461853027344 0.6650727987289429
loss:  20.53948211669922 0.6684147715568542
loss:  20.43324851989746 0.6614840626716614
loss:  20.146024703979492 0.6750333309173584
loss:  20.506454467773438 0.6644375920295715
loss:  20.89908790588379 0.666008472442627
loss:  20.425966262817383 0.6568633913993835
loss:  20.830793380737305 0.6769642233848572
loss:  20.16213607788086 0.6540101766586304
loss:  20.156375885009766 0.6562498211860657
loss:  20.30523109436035 0.666607141494751
loss:  20.88023567199707 0.642983615398407
loss:  20.562210083007812 0.6321334838867188
loss:  20.948095321655273 0.6360177397727966
loss:  21.07117462158203 0.6463860869407654
loss:  20.63425064086914 0.6426723599433899
loss:  20.036705017089844 0.6607418656349182
*******************Epoch 93 ****************** 1880 1.0
Validation Loss
*** pred loss:  26.651697158813477 pred acc: 0.5815821290016174
*** stop loss:  7.136667251586914 stop acc: 0.9230697751045227
*** template loss:  7.532596111297607 template acc: tensor(0.1516, device='cuda:0')
*** label loss:  6.560403347015381 label acc: tensor(0.3800, device='cuda:0')
Train Loss
---> pred loss: 16.17680206298828 pred acc: 0.736814621090889
---> stop loss: 2.8934913635253907 stop acc: 0.9681635975837708
---> template loss: 0.5135186672210693 tempalte acc: 0.8910823822021484
---> molecule label loss: 0.3147311210632324 molecule acc: 0.9190966606140136
---> kl loss: 0.6583845138549804
---> reconstruction loss: 19.8985445022583
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-94-with.npy
loss:  20.439178466796875 0.6393045783042908
loss:  20.206928253173828 0.6462448835372925
loss:  20.7240047454834 0.6350826025009155
loss:  20.372045516967773 0.626130223274231
loss:  20.8798770904541 0.6508274078369141
loss:  20.955429077148438 0.6281269788742065
loss:  20.50177001953125 0.6380584239959717
loss:  20.60912322998047 0.6253517270088196
loss:  20.266063690185547 0.6453233361244202
loss:  20.64078712463379 0.6401855945587158
loss:  20.547616958618164 0.6447119116783142
loss:  20.849817276000977 0.6409553289413452
loss:  20.580345153808594 0.6554261445999146
loss:  20.25580596923828 0.6367220282554626
loss:  20.92058753967285 0.6706362962722778
loss:  20.48845100402832 0.6503964066505432
loss:  20.7171630859375 0.658166229724884
loss:  20.51011848449707 0.6540454030036926
loss:  20.104074478149414 0.6564818620681763
loss:  20.90127182006836 0.7195518612861633
*******************Epoch 94 ****************** 1900 1.0
Validation Loss
*** pred loss:  26.775733947753906 pred acc: 0.5850844979286194
*** stop loss:  7.010879993438721 stop acc: 0.9231631755828857
*** template loss:  7.522534370422363 template acc: tensor(0.1523, device='cuda:0')
*** label loss:  6.679648399353027 label acc: tensor(0.4027, device='cuda:0')
Train Loss
---> pred loss: 16.207987976074218 pred acc: 0.7354421883821487
---> stop loss: 2.877651405334473 stop acc: 0.967972207069397
---> template loss: 0.5173465251922608 tempalte acc: 0.891388988494873
---> molecule label loss: 0.3224494457244873 molecule acc: 0.9170190811157226
---> kl loss: 0.648086404800415
---> reconstruction loss: 19.92543807029724
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-95-with.npy
loss:  19.988590240478516 0.6384227275848389
loss:  20.2745304107666 0.658374547958374
loss:  20.27634048461914 0.661292314529419
loss:  20.618885040283203 0.6546330451965332
loss:  20.28565788269043 0.6533682942390442
loss:  20.497692108154297 0.6258766651153564
loss:  20.169605255126953 0.6430639028549194
loss:  20.637962341308594 0.6218949556350708
loss:  20.774660110473633 0.6352750658988953
loss:  20.566781997680664 0.648764967918396
loss:  20.307104110717773 0.6455065011978149
loss:  20.25455665588379 0.6477642059326172
loss:  20.419485092163086 0.6395254731178284
loss:  20.455209732055664 0.6576550602912903
loss:  20.605756759643555 0.6405971646308899
loss:  20.533781051635742 0.6779347658157349
loss:  20.4400634765625 0.6556161642074585
loss:  20.529478073120117 0.6748161315917969
loss:  20.509113311767578 0.6408465504646301
loss:  21.237091064453125 0.6919175982475281
*******************Epoch 95 ****************** 1920 1.0
Validation Loss
*** pred loss:  26.53653907775879 pred acc: 0.5902173519134521
*** stop loss:  6.984814643859863 stop acc: 0.9252490997314453
*** template loss:  7.550220966339111 template acc: tensor(0.1446, device='cuda:0')
*** label loss:  6.6859636306762695 label acc: tensor(0.3917, device='cuda:0')
Train Loss
---> pred loss: 16.150900268554686 pred acc: 0.7368928372859955
---> stop loss: 2.8038656234741213 stop acc: 0.9690169095993042
---> template loss: 0.5264359474182129 tempalte acc: 0.886229419708252
---> molecule label loss: 0.3372577905654907 molecule acc: 0.9114625930786133
---> kl loss: 0.6506572246551514
---> reconstruction loss: 19.818460512161256
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-96-with.npy
loss:  20.336971282958984 0.6442400217056274
loss:  20.862232208251953 0.6356919407844543
loss:  20.795398712158203 0.6286611557006836
loss:  20.869691848754883 0.6435806155204773
loss:  20.762155532836914 0.6265096068382263
loss:  20.560131072998047 0.6165910959243774
loss:  20.56570816040039 0.6234796047210693
loss:  20.718721389770508 0.6196852326393127
loss:  20.73077392578125 0.6307674646377563
loss:  20.927030563354492 0.6345727443695068
loss:  20.525144577026367 0.6459510922431946
loss:  20.49129867553711 0.637726902961731
loss:  20.34751319885254 0.6489304304122925
loss:  20.73703956604004 0.6579047441482544
loss:  20.51480484008789 0.6490494608879089
loss:  20.76831817626953 0.6633619070053101
loss:  20.492403030395508 0.642952024936676
loss:  20.190885543823242 0.6340609788894653
loss:  20.630352020263672 0.6491258144378662
loss:  19.780029296875 0.6620201468467712
*******************Epoch 96 ****************** 1940 1.0
Validation Loss
*** pred loss:  26.696977615356445 pred acc: 0.5888285040855408
*** stop loss:  7.345200061798096 stop acc: 0.9184620380401611
*** template loss:  7.574357509613037 template acc: tensor(0.1488, device='cuda:0')
*** label loss:  6.556959629058838 label acc: tensor(0.3926, device='cuda:0')
Train Loss
---> pred loss: 16.07355194091797 pred acc: 0.7372442185878754
---> stop loss: 2.797068977355957 stop acc: 0.9692138880491257
---> template loss: 0.6309532642364502 tempalte acc: 0.8592137336730957
---> molecule label loss: 0.4390125751495361 molecule acc: 0.8809179306030274
---> kl loss: 0.6397431373596192
---> reconstruction loss: 19.940585231781004
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-97-with.npy
loss:  20.67715072631836 0.6587855815887451
loss:  20.896526336669922 0.6262481808662415
loss:  20.207239151000977 0.6392828822135925
loss:  20.55567741394043 0.6594932079315186
loss:  20.554922103881836 0.6225696206092834
loss:  20.916292190551758 0.6343740820884705
loss:  20.650535583496094 0.6283994913101196
loss:  20.736942291259766 0.632267415523529
loss:  20.348281860351562 0.6410486698150635
loss:  20.648908615112305 0.6258015632629395
loss:  20.38920021057129 0.6337905526161194
loss:  20.192873001098633 0.645426869392395
loss:  20.484487533569336 0.6381093263626099
loss:  20.274391174316406 0.6609280109405518
loss:  20.435453414916992 0.6411671042442322
loss:  20.11965560913086 0.6257374882698059
loss:  20.651525497436523 0.6621230244636536
loss:  20.198802947998047 0.6389522552490234
loss:  20.230823516845703 0.6401985287666321
loss:  19.541316986083984 0.6149638295173645
*******************Epoch 97 ****************** 1960 1.0
Validation Loss
*** pred loss:  27.163328170776367 pred acc: 0.5748188495635986
*** stop loss:  7.134973049163818 stop acc: 0.9219489693641663
*** template loss:  7.589310646057129 template acc: tensor(0.1498, device='cuda:0')
*** label loss:  6.503663539886475 label acc: tensor(0.3840, device='cuda:0')
Train Loss
---> pred loss: 15.997578430175782 pred acc: 0.7390730142593384
---> stop loss: 2.842426300048828 stop acc: 0.9687183529138566
---> template loss: 0.5792664051055908 tempalte acc: 0.8736131668090821
---> molecule label loss: 0.3777980089187622 molecule acc: 0.8995149612426758
---> kl loss: 0.6384832859039307
---> reconstruction loss: 19.79706664085388
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-98-with.npy
loss:  20.50084686279297 0.6294971704483032
loss:  20.465198516845703 0.6512494087219238
loss:  20.560321807861328 0.6251065135002136
loss:  20.318988800048828 0.6312149167060852
loss:  20.314001083374023 0.6514971256256104
loss:  20.19554328918457 0.6789507269859314
loss:  20.386798858642578 0.6538457870483398
loss:  20.58193016052246 0.6564922332763672
loss:  20.062631607055664 0.6551597714424133
loss:  20.383460998535156 0.6670819520950317
loss:  20.073284149169922 0.6604442000389099
loss:  20.383651733398438 0.6606048941612244
loss:  20.253934860229492 0.6533030271530151
loss:  20.546478271484375 0.6512256264686584
loss:  20.340316772460938 0.6373075246810913
loss:  20.324125289916992 0.6352986097335815
loss:  20.046476364135742 0.647495448589325
loss:  20.74458885192871 0.6322004199028015
loss:  20.23691749572754 0.6446098685264587
loss:  19.637550354003906 0.6443369388580322
*******************Epoch 98 ****************** 1980 1.0
Validation Loss
*** pred loss:  26.6923885345459 pred acc: 0.5874395966529846
*** stop loss:  6.968480110168457 stop acc: 0.9250311851501465
*** template loss:  7.578073024749756 template acc: tensor(0.1597, device='cuda:0')
*** label loss:  6.533915042877197 label acc: tensor(0.3843, device='cuda:0')
Train Loss
---> pred loss: 16.009983825683594 pred acc: 0.7371841251850129
---> stop loss: 2.7763242721557617 stop acc: 0.969351801276207
---> template loss: 0.5355906963348389 tempalte acc: 0.8843902587890625
---> molecule label loss: 0.3476089000701904 molecule acc: 0.9065628051757812
---> kl loss: 0.6483460426330566
---> reconstruction loss: 19.66950521469116
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-99-with.npy
loss:  19.948713302612305 0.6414705514907837
loss:  19.900590896606445 0.6332377195358276
loss:  20.02935028076172 0.642833411693573
loss:  19.982938766479492 0.6250540018081665
loss:  20.003829956054688 0.6257407069206238
loss:  20.4925479888916 0.6497043371200562
loss:  20.139591217041016 0.6507517099380493
loss:  19.712749481201172 0.6272591352462769
loss:  20.529035568237305 0.634346067905426
loss:  20.663259506225586 0.6311454176902771
loss:  20.41031837463379 0.6343408823013306
loss:  20.447872161865234 0.6514604687690735
loss:  20.422924041748047 0.6442437767982483
loss:  20.334089279174805 0.6487407088279724
loss:  20.68081283569336 0.6443790197372437
loss:  20.70804214477539 0.6430726051330566
loss:  20.716136932373047 0.6419616341590881
loss:  20.524551391601562 0.6586133241653442
loss:  20.491838455200195 0.6553484201431274
loss:  19.17579460144043 0.6453375816345215
*******************Epoch 99 ****************** 2000 1.0
Validation Loss
*** pred loss:  26.81096649169922 pred acc: 0.5861715078353882
*** stop loss:  7.220032691955566 stop acc: 0.9217932820320129
*** template loss:  7.623473644256592 template acc: tensor(0.1488, device='cuda:0')
*** label loss:  6.532649993896484 label acc: tensor(0.3719, device='cuda:0')
Train Loss
---> pred loss: 15.8808837890625 pred acc: 0.7396013468503952
---> stop loss: 2.755712127685547 stop acc: 0.9697137117385864
---> template loss: 0.5750245094299317 tempalte acc: 0.8726063728332519
---> molecule label loss: 0.4126755237579346 molecule acc: 0.8879310607910156
---> kl loss: 0.6414521217346192
---> reconstruction loss: 19.624296474456788
saving file:weights/hidden_size_200_latent_size_100_depth_5_beta_1.0_lr_0.001/bvae_iter-100-with.npy
