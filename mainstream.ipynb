{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed98a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python import\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import logging\n",
    "import random\n",
    "from optparse import OptionParser\n",
    "import yaml\n",
    "\n",
    "# rxnft_vae imports\n",
    "from rxnft_vae.reaction import ReactionTree, extract_starting_reactants, StartingReactants, Templates, extract_templates\n",
    "from rxnft_vae.fragment import FragmentVocab, FragmentTree\n",
    "from rxnft_vae.vae import bFTRXNVAE\n",
    "from rxnft_vae.mpn import MPN\n",
    "from rxnft_vae.reaction_utils import read_multistep_rxns, get_qed_score\n",
    "# torch\n",
    "import torch\n",
    "# my binary vae utils\n",
    "import binary_vae_utils\n",
    "\n",
    "def main(X_train, y_train, X_test, y_test, smiles, targets, model, parameters, configs, metric, seed):\n",
    "    X_train = torch.Tensor(X_train)\n",
    "    y_train = torch.Tensor(y_train)\n",
    "    X_test = torch.Tensor(X_test)\n",
    "    y_test = torch.Tensor(y_test)\n",
    "\n",
    "    optimizer = binary_vae_utils.bVAE_IM(smiles=smiles, targets=targets, bvae_model=model, seed=seed)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    optimizer.optimize(X_train, y_train, X_test, y_test, configs)\n",
    "\n",
    "    logging.info(\"Running Time: %f\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "def seed_all(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    \n",
    "\n",
    "hidden_size = 300\n",
    "latent_size = 100\n",
    "depth = 2\n",
    "data_filename = \"/home/gzou/fitcheck/newnnn/brxngenerator-master/data/data.txt\"\n",
    "w_save_path = \"/home/gzou/fitcheck/newnnn/brxngenerator-master/weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-30-with.npy\"\n",
    "metric = \"qed\"\n",
    "seed = 4\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"hidden size:\", hidden_size, \"latent_size:\", latent_size, \"depth:\", depth)\n",
    "print(\"loading data.....\")\n",
    "routes, scores = read_multistep_rxns(data_filename)\n",
    "rxn_trees = [ReactionTree(route) for route in routes]\n",
    "molecules = [rxn_tree.molecule_nodes[0].smiles for rxn_tree in rxn_trees]\n",
    "reactants = extract_starting_reactants(rxn_trees)\n",
    "templates, n_reacts = extract_templates(rxn_trees)\n",
    "reactantDic = StartingReactants(reactants)\n",
    "templateDic = Templates(templates, n_reacts)\n",
    "\n",
    "print(\"size of reactant dic:\", reactantDic.size())\n",
    "print(\"size of template dic:\", templateDic.size())\n",
    "\n",
    "n_pairs = len(routes)\n",
    "ind_list = [i for i in range(n_pairs)]\n",
    "\n",
    "fgm_trees = []\n",
    "valid_id = []\n",
    "for i in ind_list:\n",
    "    try:\n",
    "        fgm_trees.append(FragmentTree(rxn_trees[i].molecule_nodes[0].smiles))\n",
    "        valid_id.append(i)\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        continue\n",
    "rxn_trees = [rxn_trees[i] for i in valid_id]\n",
    "\n",
    "print(\"size of fgm_trees:\", len(fgm_trees))\n",
    "print(\"size of rxn_trees:\", len(rxn_trees))\n",
    "data_pairs = []\n",
    "for fgm_tree, rxn_tree in zip(fgm_trees, rxn_trees):\n",
    "    data_pairs.append((fgm_tree, rxn_tree))\n",
    "cset = set()\n",
    "for fgm_tree in fgm_trees:\n",
    "    for node in fgm_tree.nodes:\n",
    "        cset.add(node.smiles)\n",
    "cset = list(cset)\n",
    "fragmentDic = FragmentVocab(cset)\n",
    "\n",
    "print(\"size of fragment dic:\", fragmentDic.size())\n",
    "\n",
    "\n",
    "mpn = MPN(hidden_size, depth)\n",
    "model = bFTRXNVAE(fragmentDic, reactantDic, templateDic, hidden_size, latent_size, depth, device,\n",
    "                    fragment_embedding=None, reactant_embedding=None, template_embedding=None).to(device)\n",
    "checkpoint = torch.load(w_save_path, map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "print(\"finished loading model...\")\n",
    "\n",
    "print(\"number of samples:\", len(data_pairs))\n",
    "data_pairs = data_pairs\n",
    "latent_list = []\n",
    "score_list = []\n",
    "print(\"num of samples:\", len(rxn_trees))\n",
    "latent_list = []\n",
    "score_list = []\n",
    "print('========start to compute all scores')\n",
    "if metric == \"qed\":\n",
    "    # tqdm\n",
    "    for i, data_pair in tqdm(enumerate(data_pairs)):\n",
    "        latent = model.encode([data_pair])\n",
    "        latent_list.append(latent[0])\n",
    "        rxn_tree = data_pair[1]\n",
    "        smiles = rxn_tree.molecule_nodes[0].smiles\n",
    "        score_list.append(get_qed_score(smiles))\n",
    "if metric == \"logp\":\n",
    "    logP_values = np.loadtxt('./data/logP_values.txt')\n",
    "    SA_scores = np.loadtxt('./data/SA_scores.txt')\n",
    "    cycle_scores = np.loadtxt('./data/cycle_scores.txt')\n",
    "\n",
    "    logp_m = np.mean(logP_values)\n",
    "    logp_s = np.std(logP_values)\n",
    "\n",
    "    sascore_m = np.mean(SA_scores)\n",
    "    sascore_s = np.std(SA_scores)\n",
    "\n",
    "    cycle_m = np.mean(cycle_scores)\n",
    "    cycle_s = np.std(cycle_scores)\n",
    "    for i, data_pair in tqdm(enumerate(data_pairs)):\n",
    "        # only need the previous half of the latent vector\n",
    "        latent = model.encode([data_pair])\n",
    "        latent_list.append(latent[0])\n",
    "        print(\"ForTraining, latent shape:\", latent_list[-1].shape)\n",
    "        rxn_tree = data_pair[1]\n",
    "        smiles = rxn_tree.molecule_nodes[0].smiles\n",
    "        score_list.append(get_clogp_score(smiles, logp_m, logp_s, sascore_m, sascore_s, cycle_m, cycle_s))\n",
    "latents = torch.stack(latent_list, dim=0)\n",
    "scores = np.array(score_list)\n",
    "scores = scores.reshape((-1, 1))\n",
    "# move to cpu first\n",
    "latents = latents.detach().cpu().numpy()\n",
    "n = latents.shape[0]\n",
    "print('===================latent shape', latents.shape)\n",
    "latents = latents[:, : latent_size // 2]\n",
    "print('===================latent shape', latents.shape)\n",
    "permutation = np.random.choice(n, n, replace=False)\n",
    "X_train = latents[permutation, :][0: int(np.round(0.9 * n)), :]\n",
    "X_test = latents[permutation, :][int(np.round(0.9 * n)):, :]\n",
    "y_train = -scores[permutation][0: int(np.round(0.9 * n))]\n",
    "y_test = -scores[permutation][int(np.round(0.9 * n)):]\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "if metric == \"logp\":\n",
    "    parameters = [logp_m, logp_s, sascore_m, sascore_s, cycle_m, cycle_s]\n",
    "else:\n",
    "    parameters = []\n",
    "\n",
    "with open('config/config.yaml', 'r') as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "\n",
    "# main(X_train, y_train, X_test, y_test, molecules, -scores, model, parameters, configs, metric, seed)\n",
    "from optparse import OptionParser\n",
    "parser = OptionParser()\n",
    "parser.add_option(\"--seed-start\", dest=\"seed_start\", type=\"int\", default=seed,\n",
    "                  help=\"起始 seed（包含）\")\n",
    "parser.add_option(\"--seed-end\",   dest=\"seed_end\",   type=\"int\", default=seed,\n",
    "                  help=\"结束   seed（包含）\")\n",
    "(options, args) = parser.parse_args()\n",
    "\n",
    "# 3. 对指定范围内的每个 seed 依次调用 main()\n",
    "for sd in tqdm(range(options.seed_start, options.seed_end + 1), desc=\"Seeds\"):\n",
    "    print(f\"\\n=== Running optimization with seed = {sd} ===\")\n",
    "    seed_all(sd)   # 重设随机种子\n",
    "    main(\n",
    "        X_train, y_train,\n",
    "        X_test,  y_test,\n",
    "        molecules, -scores,\n",
    "        model, parameters,\n",
    "        configs, metric,\n",
    "        sd\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brxngenerator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
