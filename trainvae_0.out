cuda is  True
loading data.....
size of reactant dic: 9766
size of template dic: 5567
size of fgm_trees: 20080
size of rxn_trees: 20080
size of fragment dic: 273
hidden size: 100 latent_size: 100 batch size: 1000 depth: 2
beta: 1.0 lr: 0.001
size of data pairs: 20080
trainng size: 19079
valid size: 1000
loss:  146.72010803222656 1.9154119491577148
loss:  143.15478515625 2.1074674129486084
loss:  141.2462615966797 2.5518360137939453
loss:  139.4715576171875 3.2940189838409424
loss:  133.1298828125 4.33588981628418
loss:  130.01443481445312 5.874269008636475
loss:  126.68244934082031 7.8760666847229
loss:  120.13018035888672 10.524162292480469
loss:  116.8714370727539 14.314837455749512
loss:  112.0398941040039 18.89635467529297
loss:  107.08180236816406 24.966794967651367
loss:  100.25594329833984 31.372310638427734
loss:  97.1927261352539 37.224674224853516
loss:  94.46808624267578 40.854156494140625
loss:  89.1446533203125 42.873329162597656
loss:  87.0748062133789 43.90382385253906
loss:  86.38766479492188 43.82787322998047
loss:  86.3010025024414 44.26122283935547
loss:  84.6495590209961 44.30491638183594
loss:  88.11222076416016 43.971763610839844
*******************Epoch 0 ****************** 20 0.00095
Validation Loss
*** pred loss:  46.93999099731445 pred acc: 0.2998792231082916
*** stop loss:  14.846142768859863 stop acc: 0.7889477014541626
*** template loss:  8.703967094421387 template acc: tensor(0.0056, device='cuda:0')
*** label loss:  6.536480903625488 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 76.0929443359375 pred acc: 0.22348378906026484
---> stop loss: 20.061749267578126 stop acc: 0.6984723657369614
---> template loss: 7.995252227783203 tempalte acc: 0.010938763618469238
---> molecule label loss: 7.340555572509766 molecule acc: 0.3299699068069458
---> kl loss: 23.462559509277344
---> reconstruction loss: 111.48420470909119
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-1-with.npy
loss:  82.76116180419922 42.993858337402344
loss:  81.94934844970703 41.969993591308594
loss:  79.8001708984375 41.33009338378906
loss:  79.65345001220703 40.54008102416992
loss:  79.2685546875 40.18453598022461
loss:  79.47760772705078 39.717689514160156
loss:  79.91246795654297 39.1947021484375
loss:  77.02766418457031 37.89543914794922
loss:  76.86660766601562 38.12578582763672
loss:  77.42794036865234 37.49303436279297
loss:  75.54888916015625 36.744842529296875
loss:  74.86515808105469 35.90556335449219
loss:  76.14044952392578 35.2618408203125
loss:  75.50704956054688 34.184505462646484
loss:  74.41644287109375 33.33973693847656
loss:  74.10907745361328 32.37236022949219
loss:  73.99890899658203 31.922164916992188
loss:  73.1513442993164 30.610647201538086
loss:  73.3219223022461 30.483165740966797
loss:  72.41371154785156 30.083919525146484
*******************Epoch 1 ****************** 40 0.0019500000000000001
Validation Loss
*** pred loss:  42.852901458740234 pred acc: 0.3247584402561188
*** stop loss:  11.570637702941895 stop acc: 0.8330946564674377
*** template loss:  8.639327049255371 template acc: tensor(0.0292, device='cuda:0')
*** label loss:  6.385331153869629 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 49.739385986328124 pred acc: 0.2881531849503517
---> stop loss: 13.85986785888672 stop acc: 0.8271912187337875
---> template loss: 7.457477569580078 tempalte acc: 0.019452524185180665
---> molecule label loss: 5.771438217163086 molecule acc: 0.3830259323120117
---> kl loss: 36.5177001953125
---> reconstruction loss: 76.80969258422851
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-2-with.npy
loss:  72.03013610839844 29.242177963256836
loss:  73.43598175048828 29.092546463012695
loss:  71.55559539794922 29.65013313293457
loss:  72.14098358154297 29.531719207763672
loss:  71.17510223388672 28.980388641357422
loss:  71.28092193603516 29.18101692199707
loss:  71.0803451538086 28.98935890197754
loss:  70.19430541992188 28.74837303161621
loss:  69.1917724609375 28.55454444885254
loss:  70.67308044433594 28.66431427001953
loss:  69.32788848876953 28.395824432373047
loss:  69.0928726196289 28.089691162109375
loss:  69.50069427490234 27.991193771362305
loss:  68.36228942871094 27.896411895751953
loss:  68.37598419189453 28.086708068847656
loss:  67.38066101074219 28.004711151123047
loss:  68.7215805053711 27.72556495666504
loss:  68.65939331054688 27.972673416137695
loss:  67.84418487548828 27.6871337890625
loss:  67.38186645507812 28.389747619628906
*******************Epoch 2 ****************** 60 0.00295
Validation Loss
*** pred loss:  39.69379806518555 pred acc: 0.37173911929130554
*** stop loss:  10.284488677978516 stop acc: 0.8603674173355103
*** template loss:  8.621881484985352 template acc: tensor(0.0302, device='cuda:0')
*** label loss:  6.365904808044434 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 45.51351623535156 pred acc: 0.3225416034460068
---> stop loss: 11.511408233642578 stop acc: 0.8614877492189408
---> template loss: 7.186750030517578 tempalte acc: 0.03367990553379059
---> molecule label loss: 5.588111114501953 molecule acc: 0.38364434242248535
---> kl loss: 28.54371032714844
---> reconstruction loss: 69.78608414047241
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-3-with.npy
loss:  67.7855453491211 27.64485740661621
loss:  66.14930725097656 27.199583053588867
loss:  66.58045196533203 26.977447509765625
loss:  66.8655014038086 27.073932647705078
loss:  65.75560760498047 26.968135833740234
loss:  65.48268127441406 27.00102996826172
loss:  65.85597229003906 27.137937545776367
loss:  64.2679443359375 26.741117477416992
loss:  64.65390014648438 26.418834686279297
loss:  64.9949951171875 26.544891357421875
loss:  63.96055221557617 26.277090072631836
loss:  64.03419494628906 26.572280883789062
loss:  63.56523895263672 26.329626083374023
loss:  63.158145904541016 26.402374267578125
loss:  62.86690902709961 26.26766586303711
loss:  63.18430709838867 26.634254455566406
loss:  63.0870246887207 25.91042709350586
loss:  62.958213806152344 26.327579498291016
loss:  62.792816162109375 26.445850372314453
loss:  61.35325241088867 27.067367553710938
*******************Epoch 3 ****************** 80 0.00395
Validation Loss
*** pred loss:  36.85023880004883 pred acc: 0.4053743779659271
*** stop loss:  9.274367332458496 stop acc: 0.8753736019134521
*** template loss:  8.495442390441895 template acc: tensor(0.0443, device='cuda:0')
*** label loss:  6.290375232696533 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 42.01222229003906 pred acc: 0.3645475938916206
---> stop loss: 9.963864135742188 stop acc: 0.8846392393112182
---> template loss: 6.8563720703125 tempalte acc: 0.05163697600364685
---> molecule label loss: 5.5424762725830075 molecule acc: 0.38270273208618166
---> kl loss: 26.697113037109375
---> reconstruction loss: 64.36217335662842
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-4-with.npy
loss:  61.78010940551758 26.858657836914062
loss:  61.046974182128906 26.96000862121582
loss:  61.9789924621582 27.15207290649414
loss:  61.1139030456543 27.408935546875
loss:  60.76976776123047 27.878644943237305
loss:  60.531105041503906 28.126483917236328
loss:  60.654964447021484 27.807479858398438
loss:  60.376529693603516 28.078975677490234
loss:  59.057064056396484 28.6583251953125
loss:  59.84624481201172 28.307842254638672
loss:  59.8480339050293 28.24894142150879
loss:  59.72896194458008 28.863584518432617
loss:  58.434410095214844 29.11248016357422
loss:  59.0604362487793 29.154754638671875
loss:  58.4925651550293 29.08766746520996
loss:  58.902618408203125 29.522052764892578
loss:  57.94105529785156 30.137920379638672
loss:  57.250526428222656 29.747962951660156
loss:  57.772518157958984 30.269420623779297
loss:  61.124202728271484 29.853530883789062
*******************Epoch 4 ****************** 100 0.0049499999999999995
Validation Loss
*** pred loss:  34.15797424316406 pred acc: 0.4352053105831146
*** stop loss:  8.479765892028809 stop acc: 0.8855541944503784
*** template loss:  8.426861763000488 template acc: tensor(0.0559, device='cuda:0')
*** label loss:  6.217280387878418 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 38.890811157226565 pred acc: 0.4052394211292267
---> stop loss: 8.847457122802734 stop acc: 0.8980569303035736
---> template loss: 6.4500892639160154 tempalte acc: 0.07921631336212158
---> molecule label loss: 5.4690910339355465 molecule acc: 0.3826282501220703
---> kl loss: 28.561785888671874
---> reconstruction loss: 59.64415382781982
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-5-with.npy
loss:  56.71807861328125 30.51880645751953
loss:  57.05754852294922 30.794527053833008
loss:  57.61273193359375 31.370256423950195
loss:  56.125972747802734 30.47073745727539
loss:  56.36833190917969 30.943607330322266
loss:  56.37425994873047 30.429296493530273
loss:  56.45646667480469 30.45691680908203
loss:  56.023345947265625 30.98754119873047
loss:  55.97504806518555 31.369125366210938
loss:  55.36925506591797 30.660037994384766
loss:  56.066253662109375 31.3110408782959
loss:  55.7094612121582 31.611934661865234
loss:  55.104713439941406 31.58422088623047
loss:  55.2076301574707 31.18858528137207
loss:  54.34817123413086 31.841821670532227
loss:  54.6514778137207 32.358070373535156
loss:  54.308753967285156 31.215015411376953
loss:  54.05705642700195 31.283538818359375
loss:  53.619773864746094 31.635711669921875
loss:  52.64583206176758 30.58084487915039
*******************Epoch 5 ****************** 120 0.0059499999999999996
Validation Loss
*** pred loss:  32.09539031982422 pred acc: 0.4791666567325592
*** stop loss:  7.897744655609131 stop acc: 0.8937110900878906
*** template loss:  8.296611785888672 template acc: tensor(0.0623, device='cuda:0')
*** label loss:  6.15189790725708 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 35.89290771484375 pred acc: 0.44343937039375303
---> stop loss: 8.056068420410156 stop acc: 0.9063471972942352
---> template loss: 6.015689468383789 tempalte acc: 0.10363651514053344
---> molecule label loss: 5.35482177734375 molecule acc: 0.38252935409545896
---> kl loss: 31.130587768554687
---> reconstruction loss: 55.3047876512146
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-6-with.npy
loss:  53.45735549926758 30.956661224365234
loss:  53.32044219970703 31.334274291992188
loss:  53.66498565673828 32.75238037109375
loss:  52.85566329956055 32.375667572021484
loss:  53.520660400390625 32.04317092895508
loss:  52.82938766479492 32.646080017089844
loss:  52.807281494140625 33.04145050048828
loss:  53.116485595703125 33.00025177001953
loss:  52.93242645263672 32.087059020996094
loss:  52.37786102294922 31.836626052856445
loss:  52.27259063720703 32.91339111328125
loss:  51.971126556396484 32.267005920410156
loss:  51.92673110961914 31.68252944946289
loss:  51.56126403808594 31.516674041748047
loss:  51.16908645629883 32.01142501831055
loss:  51.47040939331055 32.307594299316406
loss:  51.52680969238281 32.14146041870117
loss:  51.2949333190918 32.502967834472656
loss:  51.87132263183594 33.227630615234375
loss:  50.20973205566406 31.83085060119629
*******************Epoch 6 ****************** 140 0.00695
Validation Loss
*** pred loss:  30.60761260986328 pred acc: 0.5073671340942383
*** stop loss:  7.421575546264648 stop acc: 0.8991594314575195
*** template loss:  8.178775787353516 template acc: tensor(0.0686, device='cuda:0')
*** label loss:  6.1095147132873535 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 33.748171997070315 pred acc: 0.4803564965724945
---> stop loss: 7.515631103515625 stop acc: 0.9126515984535217
---> template loss: 5.600103378295898 tempalte acc: 0.13104976415634156
---> molecule label loss: 5.235241317749024 molecule acc: 0.38329718112945554
---> kl loss: 32.223757934570315
---> reconstruction loss: 52.08386958938599
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-7-with.npy
loss:  50.909358978271484 32.554351806640625
loss:  50.024845123291016 32.11809158325195
loss:  49.9615478515625 32.70010757446289
loss:  50.830318450927734 32.85856246948242
loss:  50.38924026489258 32.522926330566406
loss:  50.38931655883789 32.48493194580078
loss:  49.89963912963867 32.32233810424805
loss:  49.60419464111328 32.178443908691406
loss:  49.2346076965332 32.295936584472656
loss:  49.246334075927734 32.703399658203125
loss:  49.68456268310547 32.2318000793457
loss:  49.64784240722656 32.417606353759766
loss:  49.325477600097656 32.80558395385742
loss:  48.97956848144531 32.52958679199219
loss:  48.84078598022461 33.009239196777344
loss:  48.81198501586914 32.87552261352539
loss:  48.86512756347656 32.44391632080078
loss:  48.8399658203125 33.414894104003906
loss:  48.194740295410156 33.542274475097656
loss:  47.99396896362305 34.25356674194336
*******************Epoch 7 ****************** 160 0.00795
Validation Loss
*** pred loss:  29.2893123626709 pred acc: 0.5330917835235596
*** stop loss:  6.99522066116333 stop acc: 0.9044209718704224
*** template loss:  8.10757064819336 template acc: tensor(0.0763, device='cuda:0')
*** label loss:  6.077388763427734 label acc: tensor(0.3464, device='cuda:0')
Train Loss
---> pred loss: 31.91285400390625 pred acc: 0.510245430469513
---> stop loss: 7.053992462158203 stop acc: 0.91811982691288
---> template loss: 5.198506927490234 tempalte acc: 0.16292325258255005
---> molecule label loss: 5.07369384765625 molecule acc: 0.38384644985198973
---> kl loss: 32.71315307617188
---> reconstruction loss: 49.223600476989745
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-8-with.npy
loss:  47.78752517700195 32.7225341796875
loss:  47.95635223388672 33.113216400146484
loss:  48.139854431152344 32.9631233215332
loss:  48.0671272277832 33.19800567626953
loss:  48.16949462890625 32.98697280883789
loss:  47.17868423461914 33.53377914428711
loss:  46.86838912963867 32.79413604736328
loss:  47.33954620361328 33.06794357299805
loss:  47.56621551513672 33.22126007080078
loss:  47.55537414550781 34.241302490234375
loss:  46.817291259765625 34.100730895996094
loss:  46.46195983886719 33.69883346557617
loss:  46.99789047241211 34.22607421875
loss:  46.3646125793457 33.84601593017578
loss:  46.73530197143555 33.95391082763672
loss:  46.11756134033203 34.035648345947266
loss:  46.50690841674805 34.423912048339844
loss:  45.88865661621094 34.21725082397461
loss:  45.9513053894043 34.62229919433594
loss:  45.94769287109375 34.814735412597656
*******************Epoch 8 ****************** 180 0.00895
Validation Loss
*** pred loss:  28.2603702545166 pred acc: 0.544021725654602
*** stop loss:  6.695255279541016 stop acc: 0.9079079031944275
*** template loss:  8.031264305114746 template acc: tensor(0.0886, device='cuda:0')
*** label loss:  6.063309192657471 label acc: tensor(0.3475, device='cuda:0')
Train Loss
---> pred loss: 30.323245239257812 pred acc: 0.537481302022934
---> stop loss: 6.640634155273437 stop acc: 0.9226378053426743
---> template loss: 4.869767379760742 tempalte acc: 0.19403055906295777
---> molecule label loss: 4.9015625 molecule acc: 0.38433523178100587
---> kl loss: 33.689083862304685
---> reconstruction loss: 46.719365878143314
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-9-with.npy
loss:  45.63105010986328 34.659324645996094
loss:  45.515953063964844 34.79798889160156
loss:  45.43095779418945 34.788917541503906
loss:  45.680633544921875 35.00611114501953
loss:  45.606746673583984 35.46475601196289
loss:  45.6341438293457 35.632232666015625
loss:  45.30960464477539 35.61238479614258
loss:  45.27134323120117 35.42243194580078
loss:  45.06992721557617 35.264259338378906
loss:  45.20176696777344 35.177764892578125
loss:  44.77591323852539 35.29230499267578
loss:  44.48809814453125 35.687278747558594
loss:  44.74473190307617 35.53596115112305
loss:  44.84458541870117 35.41053771972656
loss:  44.97702407836914 35.52573776245117
loss:  44.13896560668945 35.419464111328125
loss:  44.35441589355469 35.716575622558594
loss:  44.13920593261719 35.8260498046875
loss:  44.47533416748047 36.025691986083984
loss:  44.15422821044922 37.116432189941406
*******************Epoch 9 ****************** 200 0.00995
Validation Loss
*** pred loss:  27.468069076538086 pred acc: 0.5575482845306396
*** stop loss:  6.416788578033447 stop acc: 0.9132939577102661
*** template loss:  7.956849098205566 template acc: tensor(0.0971, device='cuda:0')
*** label loss:  6.02420711517334 label acc: tensor(0.3481, device='cuda:0')
Train Loss
---> pred loss: 29.123492431640624 pred acc: 0.5560234695672989
---> stop loss: 6.310281753540039 stop acc: 0.9266094148159028
---> template loss: 4.531411743164062 tempalte acc: 0.23241164684295654
---> molecule label loss: 4.6708637237548825 molecule acc: 0.3871975660324097
---> kl loss: 35.469113159179685
---> reconstruction loss: 44.619317431488035
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-10-with.npy
loss:  43.42088317871094 36.032936096191406
loss:  43.9579963684082 36.023834228515625
loss:  44.20228576660156 35.584007263183594
loss:  44.309486389160156 35.97611999511719
loss:  42.999298095703125 35.957332611083984
loss:  43.750701904296875 36.179786682128906
loss:  43.81925582885742 36.662864685058594
loss:  43.23111343383789 36.30788803100586
loss:  43.63951873779297 36.94901657104492
loss:  43.28766632080078 36.990753173828125
loss:  43.43161392211914 37.12506103515625
loss:  42.820350646972656 36.25044631958008
loss:  43.319000244140625 37.03772735595703
loss:  42.93125534057617 36.9215087890625
loss:  42.981536865234375 36.87504196166992
loss:  43.70249557495117 37.43608856201172
loss:  42.64305877685547 36.984073638916016
loss:  42.87598419189453 37.05624771118164
loss:  42.68935012817383 37.16144561767578
loss:  42.47697067260742 38.34435272216797
*******************Epoch 10 ****************** 220 0.01095
Validation Loss
*** pred loss:  26.75569725036621 pred acc: 0.5676932334899902
*** stop loss:  6.344717502593994 stop acc: 0.9131382703781128
*** template loss:  7.898858070373535 template acc: tensor(0.1017, device='cuda:0')
*** label loss:  6.067421913146973 label acc: tensor(0.3475, device='cuda:0')
Train Loss
---> pred loss: 28.12999267578125 pred acc: 0.5717226237058639
---> stop loss: 6.0904685974121096 stop acc: 0.9287954926490783
---> template loss: 4.255699157714844 tempalte acc: 0.25737025737762453
---> molecule label loss: 4.463816070556641 molecule acc: 0.39035079479217527
---> kl loss: 36.69282836914063
---> reconstruction loss: 42.922709989318854
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-11-with.npy
loss:  42.67134094238281 37.00731658935547
loss:  42.347679138183594 36.940372467041016
loss:  42.474220275878906 37.61274337768555
loss:  42.56908416748047 37.65934753417969
loss:  41.93546676635742 36.899261474609375
loss:  42.48622131347656 37.29118347167969
loss:  41.565128326416016 37.72370147705078
loss:  41.66236877441406 37.55706787109375
loss:  42.19131851196289 37.71552276611328
loss:  41.87704086303711 37.63090515136719
loss:  41.827476501464844 37.377994537353516
loss:  42.16719436645508 37.427391052246094
loss:  41.56058120727539 37.455894470214844
loss:  41.58488845825195 38.69288635253906
loss:  41.76719284057617 38.136985778808594
loss:  41.533660888671875 38.5011100769043
loss:  41.683837890625 38.250274658203125
loss:  41.3764762878418 38.492897033691406
loss:  40.75910949707031 38.11553955078125
loss:  42.04214859008789 39.01580047607422
*******************Epoch 11 ****************** 240 0.01195
Validation Loss
*** pred loss:  26.15538215637207 pred acc: 0.580978274345398
*** stop loss:  6.2646942138671875 stop acc: 0.91310715675354
*** template loss:  7.806591510772705 template acc: tensor(0.1143, device='cuda:0')
*** label loss:  6.012295722961426 label acc: tensor(0.3483, device='cuda:0')
Train Loss
---> pred loss: 27.309423828125 pred acc: 0.5824848681688308
---> stop loss: 5.860496902465821 stop acc: 0.9318954914808273
---> template loss: 4.007569122314453 tempalte acc: 0.2910187244415283
---> molecule label loss: 4.2930248260498045 molecule acc: 0.3930487155914307
---> kl loss: 37.77520751953125
---> reconstruction loss: 41.452712246704095
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-12-with.npy
loss:  40.93730545043945 38.163970947265625
loss:  40.787322998046875 38.36172866821289
loss:  40.87657165527344 38.79832458496094
loss:  40.9611930847168 39.03056335449219
loss:  40.92060852050781 38.74978256225586
loss:  40.327816009521484 38.213409423828125
loss:  40.52198028564453 38.82483673095703
loss:  41.136104583740234 38.811920166015625
loss:  40.73615646362305 38.6876220703125
loss:  40.51868438720703 38.838035583496094
loss:  41.31087875366211 38.89925003051758
loss:  40.65416717529297 38.98089599609375
loss:  40.25407028198242 38.94932556152344
loss:  40.16001510620117 38.61115264892578
loss:  40.76755142211914 38.52134704589844
loss:  40.39314651489258 38.85034942626953
loss:  40.16530227661133 39.27190399169922
loss:  39.74782943725586 38.9151611328125
loss:  40.05329895019531 38.658836364746094
loss:  40.33864974975586 38.31051254272461
*******************Epoch 12 ****************** 260 0.01295
Validation Loss
*** pred loss:  25.629411697387695 pred acc: 0.5877415537834167
*** stop loss:  5.982037544250488 stop acc: 0.9184620380401611
*** template loss:  7.684757709503174 template acc: tensor(0.1185, device='cuda:0')
*** label loss:  6.03364372253418 label acc: tensor(0.3507, device='cuda:0')
Train Loss
---> pred loss: 26.575332641601562 pred acc: 0.5926552295684815
---> stop loss: 5.635747909545898 stop acc: 0.9344874799251557
---> template loss: 3.764494705200195 tempalte acc: 0.32207660675048827
---> molecule label loss: 4.119772338867188 molecule acc: 0.3989308595657349
---> kl loss: 38.72244567871094
---> reconstruction loss: 40.076974504241946
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-13-with.npy
loss:  39.61479187011719 39.001930236816406
loss:  39.400062561035156 39.0888671875
loss:  39.4025993347168 38.79662322998047
loss:  39.40749740600586 38.40996551513672
loss:  39.930973052978516 39.390289306640625
loss:  39.85491943359375 39.29430389404297
loss:  39.47441482543945 39.34845733642578
loss:  39.930633544921875 39.79048156738281
loss:  39.92007827758789 39.38092041015625
loss:  39.13936233520508 39.79027557373047
loss:  39.69091796875 39.83457565307617
loss:  40.02265167236328 39.57908630371094
loss:  38.91825866699219 39.81962966918945
loss:  39.48386001586914 39.688011169433594
loss:  38.91144943237305 39.38419723510742
loss:  38.94625473022461 39.681365966796875
loss:  39.06423568725586 39.91462707519531
loss:  39.06792068481445 39.76729965209961
loss:  39.014869689941406 39.530975341796875
loss:  39.23808288574219 39.929962158203125
*******************Epoch 13 ****************** 280 0.01395
Validation Loss
*** pred loss:  25.232213973999023 pred acc: 0.5932970643043518
*** stop loss:  5.825287818908691 stop acc: 0.9220423698425293
*** template loss:  7.607860088348389 template acc: tensor(0.1252, device='cuda:0')
*** label loss:  6.029804229736328 label acc: tensor(0.3492, device='cuda:0')
Train Loss
---> pred loss: 25.875714111328126 pred acc: 0.6029132157564163
---> stop loss: 5.455284500122071 stop acc: 0.936823433637619
---> template loss: 3.568464660644531 tempalte acc: 0.34951860904693605
---> molecule label loss: 3.9902729034423827 molecule acc: 0.4047374248504639
---> kl loss: 39.47108764648438
---> reconstruction loss: 38.871070221862794
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-14-with.npy
loss:  38.75807571411133 39.96133804321289
loss:  39.065956115722656 39.97848129272461
loss:  38.385643005371094 40.18214416503906
loss:  38.86394500732422 40.158050537109375
loss:  39.487361907958984 40.12393569946289
loss:  39.24507141113281 39.99640655517578
loss:  38.324981689453125 40.03484344482422
loss:  38.78923034667969 39.983619689941406
loss:  38.538238525390625 39.976768493652344
loss:  38.39750671386719 40.388633728027344
loss:  38.277828216552734 40.062461853027344
loss:  37.91753387451172 40.31641387939453
loss:  38.201534271240234 40.4952392578125
loss:  37.90495681762695 40.379478454589844
loss:  37.77766036987305 40.32689666748047
loss:  38.076114654541016 40.337432861328125
loss:  38.31842803955078 40.48314666748047
loss:  37.923831939697266 40.34458923339844
loss:  38.13596725463867 40.16222381591797
loss:  38.63563919067383 40.621917724609375
*******************Epoch 14 ****************** 300 0.014950000000000001
Validation Loss
*** pred loss:  24.676376342773438 pred acc: 0.602717399597168
*** stop loss:  5.791537284851074 stop acc: 0.92303866147995
*** template loss:  7.639322757720947 template acc: tensor(0.1277, device='cuda:0')
*** label loss:  6.044766902923584 label acc: tensor(0.3526, device='cuda:0')
Train Loss
---> pred loss: 25.255712890625 pred acc: 0.6091393202543258
---> stop loss: 5.361508178710937 stop acc: 0.9376884639263153
---> template loss: 3.3893356323242188 tempalte acc: 0.372879695892334
---> molecule label loss: 3.8625587463378905 molecule acc: 0.4108879089355469
---> kl loss: 40.215704345703124
---> reconstruction loss: 37.85005085479736
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-15-with.npy
loss:  37.33907699584961 40.13050842285156
loss:  38.02144241333008 40.53684997558594
loss:  38.11917495727539 40.588287353515625
loss:  37.19318771362305 40.10968780517578
loss:  37.882442474365234 40.70105743408203
loss:  37.472957611083984 40.62885284423828
loss:  37.55631637573242 40.6790771484375
loss:  37.75436782836914 40.52130126953125
loss:  37.830421447753906 40.8828125
loss:  37.9924201965332 40.867530822753906
loss:  37.498661041259766 40.361366271972656
loss:  37.70555877685547 40.69984436035156
loss:  37.97193145751953 40.35521697998047
loss:  37.15255355834961 40.412940979003906
loss:  37.04207229614258 40.73956298828125
loss:  36.770729064941406 40.4225959777832
loss:  36.996273040771484 40.62272644042969
loss:  36.77118682861328 40.563758850097656
loss:  36.890960693359375 40.211517333984375
loss:  37.418426513671875 40.81044006347656
*******************Epoch 15 ****************** 320 0.01595
Validation Loss
*** pred loss:  24.254610061645508 pred acc: 0.6099033951759338
*** stop loss:  5.687838077545166 stop acc: 0.9229140877723694
*** template loss:  7.524598598480225 template acc: tensor(0.1428, device='cuda:0')
*** label loss:  6.045197486877441 label acc: tensor(0.3534, device='cuda:0')
Train Loss
---> pred loss: 24.686582946777342 pred acc: 0.6190776467323303
---> stop loss: 5.215348815917968 stop acc: 0.939596876502037
---> template loss: 3.208928680419922 tempalte acc: 0.398970365524292
---> molecule label loss: 3.730745315551758 molecule acc: 0.41724467277526855
---> kl loss: 40.54229736328125
---> reconstruction loss: 36.822356704711915
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-16-with.npy
loss:  36.741943359375 40.92831039428711
loss:  36.92268371582031 40.907318115234375
loss:  36.44203186035156 41.24960708618164
loss:  36.726112365722656 41.11540985107422
loss:  37.0405158996582 40.75816345214844
loss:  37.022708892822266 41.17021179199219
loss:  36.2740478515625 41.329246520996094
loss:  36.2675666809082 40.813079833984375
loss:  35.84201431274414 40.95564270019531
loss:  37.06129837036133 41.23155212402344
loss:  36.94065475463867 41.104820251464844
loss:  36.505428314208984 40.94673156738281
loss:  36.21030807495117 41.11308288574219
loss:  36.735107421875 41.42461395263672
loss:  36.71583938598633 40.75859832763672
loss:  35.98377990722656 41.39007568359375
loss:  36.33273696899414 41.137725830078125
loss:  35.72230911254883 41.24190139770508
loss:  37.047706604003906 41.151329040527344
loss:  36.27705001831055 40.565399169921875
*******************Epoch 16 ****************** 340 0.01695
Validation Loss
*** pred loss:  23.993473052978516 pred acc: 0.6169081926345825
*** stop loss:  5.599194526672363 stop acc: 0.9249377846717834
*** template loss:  7.450207233428955 template acc: tensor(0.1449, device='cuda:0')
*** label loss:  6.046971321105957 label acc: tensor(0.3519, device='cuda:0')
Train Loss
---> pred loss: 24.094876098632813 pred acc: 0.6277860552072525
---> stop loss: 5.101706314086914 stop acc: 0.9404700428247452
---> template loss: 3.0514673233032226 tempalte acc: 0.42097949981689453
---> molecule label loss: 3.615998458862305 molecule acc: 0.4236534595489502
---> kl loss: 41.064642333984374
---> reconstruction loss: 35.84454574310303
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-17-with.npy
loss:  35.91276550292969 40.917724609375
loss:  35.77340316772461 41.508087158203125
loss:  36.29001235961914 41.094696044921875
loss:  35.99280548095703 41.16698455810547
loss:  36.14446258544922 41.397064208984375
loss:  35.9665412902832 41.900753021240234
loss:  35.910118103027344 41.609893798828125
loss:  35.70553970336914 41.150123596191406
loss:  36.18919372558594 41.6301155090332
loss:  35.936622619628906 41.48756408691406
loss:  35.91824722290039 41.31071090698242
loss:  35.22795104980469 41.73387908935547
loss:  34.78019714355469 41.49543762207031
loss:  34.988529205322266 41.54597091674805
loss:  35.69223403930664 41.8089599609375
loss:  35.607295989990234 41.56929016113281
loss:  35.986541748046875 41.86652374267578
loss:  35.86613082885742 41.89982223510742
loss:  35.43145751953125 41.52234649658203
loss:  35.5986442565918 41.39002227783203
*******************Epoch 17 ****************** 360 0.01795
Validation Loss
*** pred loss:  23.526174545288086 pred acc: 0.6270531415939331
*** stop loss:  5.6104817390441895 stop acc: 0.9240348935127258
*** template loss:  7.427392482757568 template acc: tensor(0.1439, device='cuda:0')
*** label loss:  6.0737481117248535 label acc: tensor(0.3517, device='cuda:0')
Train Loss
---> pred loss: 23.601014709472658 pred acc: 0.6357078939676285
---> stop loss: 4.995687103271484 stop acc: 0.9418556839227676
---> template loss: 2.9192874908447264 tempalte acc: 0.43878374099731443
---> molecule label loss: 3.504688262939453 molecule acc: 0.43112525939941404
---> kl loss: 41.500299072265626
---> reconstruction loss: 35.00100469024658
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-18-with.npy
loss:  34.99440383911133 41.62052917480469
loss:  35.51239013671875 41.761199951171875
loss:  35.58806610107422 41.83354187011719
loss:  35.30476379394531 41.45465087890625
loss:  34.707183837890625 41.444007873535156
loss:  35.58452606201172 42.3880615234375
loss:  35.53938674926758 41.42586898803711
loss:  34.83784866333008 41.628074645996094
loss:  34.391544342041016 41.594688415527344
loss:  35.040687561035156 41.60041046142578
loss:  35.31167221069336 41.60899353027344
loss:  35.3483772277832 41.59510040283203
loss:  35.326194763183594 41.43714904785156
loss:  35.141300201416016 42.38633728027344
loss:  34.8695182800293 41.45942687988281
loss:  34.66177749633789 41.49812316894531
loss:  34.57011413574219 41.64886474609375
loss:  34.416900634765625 41.516021728515625
loss:  33.99028015136719 41.24897003173828
loss:  36.5780143737793 41.45442581176758
*******************Epoch 18 ****************** 380 0.01895
Validation Loss
*** pred loss:  23.18476104736328 pred acc: 0.6320047974586487
*** stop loss:  5.4002180099487305 stop acc: 0.928393542766571
*** template loss:  7.396829128265381 template acc: tensor(0.1481, device='cuda:0')
*** label loss:  6.052391052246094 label acc: tensor(0.3492, device='cuda:0')
Train Loss
---> pred loss: 23.17427978515625 pred acc: 0.6427336484193802
---> stop loss: 4.925399398803711 stop acc: 0.9431511729955673
---> template loss: 2.794211769104004 tempalte acc: 0.4598803997039795
---> molecule label loss: 3.422759246826172 molecule acc: 0.4342212677001953
---> kl loss: 41.630218505859375
---> reconstruction loss: 34.2968587020874
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-19-with.npy
loss:  34.44440841674805 41.52059555053711
loss:  34.353309631347656 41.570648193359375
loss:  34.46961975097656 42.03236389160156
loss:  34.47697830200195 41.739990234375
loss:  34.775333404541016 41.653587341308594
loss:  34.510498046875 41.89274978637695
loss:  34.8795280456543 42.08087158203125
loss:  34.4317626953125 41.92442321777344
loss:  34.200889587402344 41.6652946472168
loss:  33.888694763183594 41.62163162231445
loss:  33.81064987182617 41.980613708496094
loss:  34.13852310180664 42.2062873840332
loss:  34.10361862182617 41.773048400878906
loss:  34.15046310424805 42.11725616455078
loss:  34.105865478515625 42.175655364990234
loss:  34.316585540771484 42.22847366333008
loss:  34.576759338378906 41.99237823486328
loss:  34.286949157714844 41.98762512207031
loss:  33.86787033081055 42.38739013671875
loss:  34.34229278564453 42.03461837768555
*******************Epoch 19 ****************** 400 0.019950000000000002
Validation Loss
*** pred loss:  22.83721923828125 pred acc: 0.6389492750167847
*** stop loss:  5.581769943237305 stop acc: 0.9245641827583313
*** template loss:  7.361145496368408 template acc: tensor(0.1544, device='cuda:0')
*** label loss:  6.037916660308838 label acc: tensor(0.3466, device='cuda:0')
Train Loss
---> pred loss: 22.685772705078126 pred acc: 0.6486606955528259
---> stop loss: 4.808595275878906 stop acc: 0.9446995168924331
---> template loss: 2.6780508041381834 tempalte acc: 0.4794668674468994
---> molecule label loss: 3.3174930572509767 molecule acc: 0.442842960357666
---> kl loss: 41.9292724609375
---> reconstruction loss: 33.47003872436524
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-20-with.npy
loss:  75.43890380859375 41.913124084472656
loss:  74.05068969726562 40.781158447265625
loss:  72.042236328125 38.95284652709961
loss:  69.63899230957031 36.22791290283203
loss:  67.36294555664062 33.743896484375
loss:  65.00486755371094 30.47825813293457
loss:  62.08293151855469 27.887741088867188
loss:  60.541221618652344 25.55040740966797
loss:  58.409400939941406 23.096630096435547
loss:  57.0557861328125 21.146257400512695
loss:  55.4175910949707 19.093944549560547
loss:  54.02250671386719 17.202856063842773
loss:  53.881771087646484 15.94260025024414
loss:  51.72384262084961 14.417323112487793
loss:  50.2679328918457 12.972569465637207
loss:  49.88229751586914 11.537943840026855
loss:  49.73313903808594 10.552423477172852
loss:  48.23072052001953 9.321986198425293
loss:  47.41022872924805 8.307209014892578
loss:  46.62710189819336 7.6977338790893555
*******************Epoch 20 ****************** 420 1.0
Validation Loss
*** pred loss:  25.509992599487305 pred acc: 0.5812197923660278
*** stop loss:  5.964046955108643 stop acc: 0.918088436126709
*** template loss:  8.116805076599121 template acc: tensor(0.0292, device='cuda:0')
*** label loss:  6.0964508056640625 label acc: tensor(0.3449, device='cuda:0')
Train Loss
---> pred loss: 23.32280731201172 pred acc: 0.6364784002304077
---> stop loss: 5.077473068237305 stop acc: 0.940199676156044
---> template loss: 3.8495098114013673 tempalte acc: 0.30216326713562014
---> molecule label loss: 3.8502243041992186 molecule acc: 0.3986156702041626
---> kl loss: 22.34123992919922
---> reconstruction loss: 36.10001983642578
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-21-with.npy
loss:  46.26927947998047 6.810956954956055
loss:  46.55224609375 6.269410133361816
loss:  45.002532958984375 5.618005275726318
loss:  44.84486770629883 5.167065143585205
loss:  44.45165252685547 4.592935085296631
loss:  44.006752014160156 4.327678203582764
loss:  44.27984619140625 4.068976879119873
loss:  43.265140533447266 3.7639946937561035
loss:  44.452632904052734 3.547253131866455
loss:  43.25450897216797 3.40229868888855
loss:  43.9801025390625 3.24418306350708
loss:  44.009735107421875 3.2513201236724854
loss:  43.38679885864258 3.0625970363616943
loss:  43.2657356262207 2.921238660812378
loss:  42.71324920654297 2.806062698364258
loss:  43.30426788330078 2.8589627742767334
loss:  43.042640686035156 2.65850830078125
loss:  43.10001754760742 2.698672294616699
loss:  42.0242919921875 2.698190689086914
loss:  44.02361297607422 2.668630361557007
*******************Epoch 21 ****************** 440 1.0
Validation Loss
*** pred loss:  26.054481506347656 pred acc: 0.5719202756881714
*** stop loss:  6.3224077224731445 stop acc: 0.9112080335617065
*** template loss:  8.093334197998047 template acc: tensor(0.0327, device='cuda:0')
*** label loss:  6.037549018859863 label acc: tensor(0.3457, device='cuda:0')
Train Loss
---> pred loss: 25.585935974121092 pred acc: 0.5964173346757888
---> stop loss: 5.50622329711914 stop acc: 0.9339504301548004
---> template loss: 4.968133926391602 tempalte acc: 0.14925923347473144
---> molecule label loss: 4.079357147216797 molecule acc: 0.3900602340698242
---> kl loss: 3.821846771240234
---> reconstruction loss: 40.13964920043946
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-22-with.npy
loss:  42.472652435302734 2.5976710319519043
loss:  42.26802444458008 2.532836675643921
loss:  41.64621353149414 2.4909262657165527
loss:  42.066749572753906 2.539923906326294
loss:  41.51976776123047 2.421940803527832
loss:  42.082271575927734 2.401977062225342
loss:  41.57256317138672 2.383249282836914
loss:  41.574954986572266 2.3004937171936035
loss:  41.770606994628906 2.326554298400879
loss:  41.88982391357422 2.3404910564422607
loss:  41.835960388183594 2.2559447288513184
loss:  40.747039794921875 2.226317882537842
loss:  41.50135040283203 2.3385047912597656
loss:  41.402923583984375 2.280242919921875
loss:  41.377384185791016 2.297799587249756
loss:  40.99245834350586 2.2802388668060303
loss:  41.019927978515625 2.213106155395508
loss:  40.92751693725586 2.1591036319732666
loss:  41.33464813232422 2.21809720993042
loss:  40.49138259887695 2.239882230758667
*******************Epoch 22 ****************** 460 1.0
Validation Loss
*** pred loss:  25.777597427368164 pred acc: 0.5768719911575317
*** stop loss:  6.129712104797363 stop acc: 0.9145081043243408
*** template loss:  7.996774673461914 template acc: tensor(0.0478, device='cuda:0')
*** label loss:  6.0742058753967285 label acc: tensor(0.3457, device='cuda:0')
Train Loss
---> pred loss: 25.308192443847656 pred acc: 0.6003428131341935
---> stop loss: 5.423204803466797 stop acc: 0.9350400984287262
---> template loss: 4.605439758300781 tempalte acc: 0.1914908170700073
---> molecule label loss: 3.8456077575683594 molecule acc: 0.3965437889099121
---> kl loss: 2.3422651290893555
---> reconstruction loss: 39.18244800567627
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-23-with.npy
loss:  40.84714889526367 2.1801748275756836
loss:  40.89902114868164 2.1714327335357666
loss:  41.196109771728516 2.0997703075408936
loss:  41.01054763793945 2.170342445373535
loss:  40.920692443847656 2.146749258041382
loss:  40.95481872558594 2.154280424118042
loss:  40.34225845336914 2.1047260761260986
loss:  40.078495025634766 2.087012529373169
loss:  40.295753479003906 2.0451488494873047
loss:  40.62066650390625 2.1323657035827637
loss:  40.10383605957031 2.107585906982422
loss:  40.960723876953125 2.073716402053833
loss:  40.1911506652832 2.0406382083892822
loss:  40.46849060058594 1.962342381477356
loss:  40.27516174316406 1.9736943244934082
loss:  40.19883346557617 2.0009660720825195
loss:  40.62397384643555 2.1056642532348633
loss:  40.759952545166016 2.0600903034210205
loss:  40.414894104003906 1.9942866563796997
loss:  41.632118225097656 1.9586341381072998
*******************Epoch 23 ****************** 480 1.0
Validation Loss
*** pred loss:  25.663597106933594 pred acc: 0.5778985619544983
*** stop loss:  6.149878025054932 stop acc: 0.9151619076728821
*** template loss:  7.995091438293457 template acc: tensor(0.0492, device='cuda:0')
*** label loss:  6.112254619598389 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 25.14000549316406 pred acc: 0.6037767797708511
---> stop loss: 5.372195816040039 stop acc: 0.9356156557798385
---> template loss: 4.359140014648437 tempalte acc: 0.2210549831390381
---> molecule label loss: 3.689911651611328 molecule acc: 0.40052971839904783
---> kl loss: 2.078480911254883
---> reconstruction loss: 38.561252975463866
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-24-with.npy
loss:  39.919620513916016 1.9701639413833618
loss:  40.44005584716797 1.9451349973678589
loss:  39.42839050292969 1.92900550365448
loss:  40.555789947509766 1.9349255561828613
loss:  39.63380432128906 1.9655675888061523
loss:  39.84986114501953 1.9430042505264282
loss:  40.06912612915039 1.9072020053863525
loss:  39.745628356933594 1.9551070928573608
loss:  39.726318359375 1.9635759592056274
loss:  39.79480743408203 1.9158055782318115
loss:  40.296199798583984 2.0043439865112305
loss:  39.68037033081055 1.8827813863754272
loss:  39.881256103515625 1.9309695959091187
loss:  40.14492416381836 1.9136420488357544
loss:  39.68035125732422 1.9274959564208984
loss:  39.39460754394531 1.896448016166687
loss:  39.83677673339844 1.9003617763519287
loss:  39.72847366333008 1.8380622863769531
loss:  39.831268310546875 1.8299450874328613
loss:  38.45145797729492 1.7923616170883179
*******************Epoch 24 ****************** 500 1.0
Validation Loss
*** pred loss:  25.705760955810547 pred acc: 0.5777173638343811
*** stop loss:  5.995202541351318 stop acc: 0.9188356399536133
*** template loss:  7.9464216232299805 template acc: tensor(0.0535, device='cuda:0')
*** label loss:  6.12185525894165 label acc: tensor(0.3451, device='cuda:0')
Train Loss
---> pred loss: 24.943278503417968 pred acc: 0.6048463553190231
---> stop loss: 5.264412689208984 stop acc: 0.9370489239692688
---> template loss: 4.126877975463867 tempalte acc: 0.2518810510635376
---> molecule label loss: 3.5525897979736327 molecule acc: 0.40963091850280764
---> kl loss: 1.917295265197754
---> reconstruction loss: 37.88715724945069
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-25-with.npy
loss:  39.479061126708984 1.8777365684509277
loss:  39.39747619628906 1.843259334564209
loss:  39.33781051635742 1.824567198753357
loss:  39.3817138671875 1.818528652191162
loss:  39.47734832763672 1.8097530603408813
loss:  39.51039123535156 1.8407714366912842
loss:  39.382568359375 1.8034439086914062
loss:  39.584232330322266 1.8062005043029785
loss:  39.02073287963867 1.7897827625274658
loss:  39.547054290771484 1.7573180198669434
loss:  39.62752914428711 1.7591850757598877
loss:  38.78171157836914 1.7083790302276611
loss:  39.22199249267578 1.7711224555969238
loss:  38.96588134765625 1.722739577293396
loss:  38.7371711730957 1.6828218698501587
loss:  39.20178985595703 1.740086317062378
loss:  39.086669921875 1.7349082231521606
loss:  39.096256256103516 1.7736085653305054
loss:  39.28877639770508 1.7270019054412842
loss:  38.500152587890625 1.6647945642471313
*******************Epoch 25 ****************** 520 1.0
Validation Loss
*** pred loss:  25.789051055908203 pred acc: 0.5765700340270996
*** stop loss:  5.991272926330566 stop acc: 0.916313886642456
*** template loss:  7.9933624267578125 template acc: tensor(0.0524, device='cuda:0')
*** label loss:  6.133939743041992 label acc: tensor(0.3430, device='cuda:0')
Train Loss
---> pred loss: 24.858491516113283 pred acc: 0.6080556005239487
---> stop loss: 5.220859146118164 stop acc: 0.9378866195678711
---> template loss: 3.951982879638672 tempalte acc: 0.274362850189209
---> molecule label loss: 3.4271835327148437 molecule acc: 0.4154642581939697
---> kl loss: 1.7728006362915039
---> reconstruction loss: 37.458510398864746
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-26-with.npy
loss:  38.76435089111328 1.6688241958618164
loss:  38.533607482910156 1.6641217470169067
loss:  39.218849182128906 1.7285311222076416
loss:  39.165504455566406 1.7612518072128296
loss:  38.87830352783203 1.756988525390625
loss:  38.96112823486328 1.6975038051605225
loss:  38.708656311035156 1.678249478340149
loss:  39.022281646728516 1.682795763015747
loss:  39.02009201049805 1.658096194267273
loss:  38.5772705078125 1.7500901222229004
loss:  38.622398376464844 1.6825759410858154
loss:  38.7374153137207 1.6265264749526978
loss:  38.883182525634766 1.682888150215149
loss:  38.67686462402344 1.6369819641113281
loss:  38.4622688293457 1.6630127429962158
loss:  38.64710235595703 1.6599665880203247
loss:  39.29941940307617 1.6275593042373657
loss:  38.53871536254883 1.5915324687957764
loss:  38.50983810424805 1.5946208238601685
loss:  38.82498550415039 1.5695416927337646
*******************Epoch 26 ****************** 540 1.0
Validation Loss
*** pred loss:  25.67238998413086 pred acc: 0.5751811265945435
*** stop loss:  6.116058826446533 stop acc: 0.9154421091079712
*** template loss:  7.950674057006836 template acc: tensor(0.0616, device='cuda:0')
*** label loss:  6.1550493240356445 label acc: tensor(0.3466, device='cuda:0')
Train Loss
---> pred loss: 24.743954467773438 pred acc: 0.6085399180650711
---> stop loss: 5.223747634887696 stop acc: 0.9379177272319794
---> template loss: 3.8240543365478517 tempalte acc: 0.2935669422149658
---> molecule label loss: 3.341771697998047 molecule acc: 0.4219672679901123
---> kl loss: 1.669083023071289
---> reconstruction loss: 37.13352928161621
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-27-with.npy
loss:  38.02317428588867 1.6673541069030762
loss:  38.51409149169922 1.609143853187561
loss:  38.49769973754883 1.587188482284546
loss:  37.9297981262207 1.660419225692749
loss:  38.25044631958008 1.6030409336090088
loss:  38.80229568481445 1.620501160621643
loss:  38.51788330078125 1.610007405281067
loss:  38.2805290222168 1.5825902223587036
loss:  38.51314163208008 1.6256846189498901
loss:  38.90816879272461 1.5644569396972656
loss:  38.740806579589844 1.6289777755737305
loss:  38.61210250854492 1.6187390089035034
loss:  38.171939849853516 1.5654393434524536
loss:  38.504188537597656 1.593828558921814
loss:  38.53730010986328 1.6301108598709106
loss:  37.972171783447266 1.5615742206573486
loss:  37.409847259521484 1.5297670364379883
loss:  38.02245330810547 1.5710688829421997
loss:  38.47506332397461 1.5750423669815063
loss:  35.8557014465332 1.5743404626846313
*******************Epoch 27 ****************** 560 1.0
Validation Loss
*** pred loss:  25.575145721435547 pred acc: 0.5785627961158752
*** stop loss:  6.0355753898620605 stop acc: 0.9165006279945374
*** template loss:  7.907405853271484 template acc: tensor(0.0644, device='cuda:0')
*** label loss:  6.215236186981201 label acc: tensor(0.3445, device='cuda:0')
Train Loss
---> pred loss: 24.536480712890626 pred acc: 0.609792810678482
---> stop loss: 5.133833694458008 stop acc: 0.9386039614677429
---> template loss: 3.701018524169922 tempalte acc: 0.30998969078063965
---> molecule label loss: 3.256643295288086 molecule acc: 0.42944746017456054
---> kl loss: 1.5989638328552247
---> reconstruction loss: 36.62797403335571
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-28-with.npy
loss:  38.295372009277344 1.5562565326690674
loss:  38.30977249145508 1.6408889293670654
loss:  38.07927703857422 1.5736570358276367
loss:  37.97796630859375 1.5565072298049927
loss:  37.955379486083984 1.6400763988494873
loss:  38.16101837158203 1.5849782228469849
loss:  37.77324295043945 1.5396605730056763
loss:  38.467803955078125 1.5195196866989136
loss:  38.1423225402832 1.5848637819290161
loss:  37.95640182495117 1.5461199283599854
loss:  38.29528045654297 1.5376721620559692
loss:  37.969913482666016 1.528751254081726
loss:  37.68297576904297 1.5017093420028687
loss:  37.919986724853516 1.4786876440048218
loss:  37.89265060424805 1.5275397300720215
loss:  38.175533294677734 1.5125645399093628
loss:  37.81285095214844 1.474227786064148
loss:  37.757240295410156 1.47502863407135
loss:  38.08588409423828 1.4691083431243896
loss:  36.24651336669922 1.460088849067688
*******************Epoch 28 ****************** 580 1.0
Validation Loss
*** pred loss:  25.60418701171875 pred acc: 0.5792270302772522
*** stop loss:  6.008748531341553 stop acc: 0.9184932112693787
*** template loss:  7.92740535736084 template acc: tensor(0.0637, device='cuda:0')
*** label loss:  6.179607391357422 label acc: tensor(0.3412, device='cuda:0')
Train Loss
---> pred loss: 24.431927490234376 pred acc: 0.6119117200374603
---> stop loss: 5.162868881225586 stop acc: 0.9381285846233368
---> template loss: 3.6284008026123047 tempalte acc: 0.3174772262573242
---> molecule label loss: 3.1892763137817384 molecule acc: 0.43590245246887205
---> kl loss: 1.535395336151123
---> reconstruction loss: 36.41247758865356
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-29-with.npy
loss:  37.5018310546875 1.4950716495513916
loss:  37.495361328125 1.4574635028839111
loss:  37.46548080444336 1.5239225625991821
loss:  37.334800720214844 1.494386076927185
loss:  37.208946228027344 1.4723596572875977
loss:  37.70841979980469 1.5133559703826904
loss:  37.58704376220703 1.5138604640960693
loss:  37.62187194824219 1.5158987045288086
loss:  37.72612762451172 1.4452848434448242
loss:  37.637454986572266 1.4630695581436157
loss:  37.244964599609375 1.4120573997497559
loss:  37.21308135986328 1.4681402444839478
loss:  37.809226989746094 1.4665707349777222
loss:  37.72346878051758 1.4441722631454468
loss:  37.56660079956055 1.4429048299789429
loss:  37.1181526184082 1.4616907835006714
loss:  37.685543060302734 1.4024674892425537
loss:  37.41234588623047 1.4644945859909058
loss:  37.50292205810547 1.4457920789718628
loss:  36.474632263183594 1.4159873723983765
*******************Epoch 29 ****************** 600 1.0
Validation Loss
*** pred loss:  25.53651237487793 pred acc: 0.5815821290016174
*** stop loss:  5.972250461578369 stop acc: 0.9182752370834351
*** template loss:  7.94012975692749 template acc: tensor(0.0689, device='cuda:0')
*** label loss:  6.208693027496338 label acc: tensor(0.3447, device='cuda:0')
Train Loss
---> pred loss: 24.299195861816408 pred acc: 0.6140130370855331
---> stop loss: 5.100014114379883 stop acc: 0.9393823146820068
---> template loss: 3.50328369140625 tempalte acc: 0.33863468170166017
---> molecule label loss: 3.0834724426269533 molecule acc: 0.44742584228515625
---> kl loss: 1.465947437286377
---> reconstruction loss: 35.985966014862065
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-30-with.npy
loss:  37.286659240722656 1.4314191341400146
loss:  36.531681060791016 1.462313175201416
loss:  37.279197692871094 1.495291829109192
loss:  37.315452575683594 1.4635875225067139
loss:  37.39540100097656 1.4452015161514282
loss:  37.477928161621094 1.4839107990264893
loss:  37.297672271728516 1.4152735471725464
loss:  37.27809143066406 1.444977879524231
loss:  37.303653717041016 1.5022684335708618
loss:  37.00825119018555 1.4123382568359375
loss:  37.745235443115234 1.39897620677948
loss:  37.85434341430664 1.4203476905822754
loss:  37.289188385009766 1.4690041542053223
loss:  37.01470947265625 1.4306700229644775
loss:  36.8739013671875 1.4359077215194702
loss:  37.29802322387695 1.4419972896575928
loss:  36.84086608886719 1.364688754081726
loss:  37.29793930053711 1.406491994857788
loss:  37.236148834228516 1.4220266342163086
loss:  36.05003356933594 1.3869593143463135
*******************Epoch 30 ****************** 620 1.0
Validation Loss
*** pred loss:  25.526405334472656 pred acc: 0.5793477892875671
*** stop loss:  6.0599446296691895 stop acc: 0.9160647988319397
*** template loss:  7.988380432128906 template acc: tensor(0.0661, device='cuda:0')
*** label loss:  6.197610855102539 label acc: tensor(0.3415, device='cuda:0')
Train Loss
---> pred loss: 24.196937561035156 pred acc: 0.6150834858417511
---> stop loss: 5.1298828125 stop acc: 0.9388276278972626
---> template loss: 3.40740852355957 tempalte acc: 0.3526270627975464
---> molecule label loss: 3.012810707092285 molecule acc: 0.4557539939880371
---> kl loss: 1.4366825103759766
---> reconstruction loss: 35.747033309936526
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-31-with.npy
loss:  37.14162826538086 1.3690320253372192
loss:  37.1265869140625 1.4212080240249634
loss:  37.32207107543945 1.4660985469818115
loss:  37.1946907043457 1.4023841619491577
loss:  36.93355941772461 1.4776698350906372
loss:  37.52922439575195 1.4830955266952515
loss:  36.52129364013672 1.4528980255126953
loss:  37.41914749145508 1.4102824926376343
loss:  36.5222282409668 1.3509644269943237
loss:  36.92927932739258 1.4469507932662964
loss:  36.843753814697266 1.3844568729400635
loss:  36.6845703125 1.387701153755188
loss:  36.52685546875 1.3889068365097046
loss:  36.83894729614258 1.4154958724975586
loss:  36.740909576416016 1.3187741041183472
loss:  37.06795120239258 1.3435273170471191
loss:  36.58246994018555 1.3685728311538696
loss:  36.99759292602539 1.370602011680603
loss:  36.61129379272461 1.344236969947815
loss:  39.323333740234375 1.5478514432907104
*******************Epoch 31 ****************** 640 1.0
Validation Loss
*** pred loss:  25.46856689453125 pred acc: 0.5774154663085938
*** stop loss:  6.371634006500244 stop acc: 0.9123599529266357
*** template loss:  7.927276134490967 template acc: tensor(0.0696, device='cuda:0')
*** label loss:  6.2329206466674805 label acc: tensor(0.3413, device='cuda:0')
Train Loss
---> pred loss: 24.195309448242188 pred acc: 0.6178362190723419
---> stop loss: 5.148760604858398 stop acc: 0.9388002693653107
---> template loss: 3.3429393768310547 tempalte acc: 0.3634721994400024
---> molecule label loss: 2.9483287811279295 molecule acc: 0.46268177032470703
---> kl loss: 1.4075352668762207
---> reconstruction loss: 35.635329723358154
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-32-with.npy
loss:  36.6314582824707 1.3720579147338867
loss:  36.620849609375 1.3476768732070923
loss:  36.7420768737793 1.3484030961990356
loss:  37.02043914794922 1.3702161312103271
loss:  36.78241729736328 1.366766333580017
loss:  36.45280075073242 1.3716565370559692
loss:  36.18449020385742 1.337195873260498
loss:  36.404388427734375 1.3001089096069336
loss:  36.13800811767578 1.3285354375839233
loss:  36.28694152832031 1.3102550506591797
loss:  36.4539794921875 1.3738187551498413
loss:  36.33201599121094 1.3419984579086304
loss:  36.71543502807617 1.3091868162155151
loss:  36.470314025878906 1.3198742866516113
loss:  36.414432525634766 1.2742449045181274
loss:  36.62586212158203 1.3239251375198364
loss:  36.57930374145508 1.3148244619369507
loss:  36.692928314208984 1.3257652521133423
loss:  36.639747619628906 1.2730720043182373
loss:  35.38158416748047 1.2437000274658203
*******************Epoch 32 ****************** 660 1.0
Validation Loss
*** pred loss:  25.52290153503418 pred acc: 0.5765700340270996
*** stop loss:  5.934443950653076 stop acc: 0.9176526069641113
*** template loss:  7.944799423217773 template acc: tensor(0.0668, device='cuda:0')
*** label loss:  6.210356712341309 label acc: tensor(0.3382, device='cuda:0')
Train Loss
---> pred loss: 24.009318542480468 pred acc: 0.6171007663011551
---> stop loss: 5.000395965576172 stop acc: 0.940581527352333
---> template loss: 3.258321762084961 tempalte acc: 0.37741522789001464
---> molecule label loss: 2.8827739715576173 molecule acc: 0.4699573516845703
---> kl loss: 1.3276640892028808
---> reconstruction loss: 35.150808811187744
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-33-with.npy
loss:  36.647705078125 1.2994295358657837
loss:  36.238460540771484 1.3995208740234375
loss:  36.105525970458984 1.3772757053375244
loss:  35.843238830566406 1.3492158651351929
loss:  35.895362854003906 1.28954017162323
loss:  36.393367767333984 1.3679323196411133
loss:  36.5716667175293 1.3756279945373535
loss:  35.98019027709961 1.2915825843811035
loss:  36.59954833984375 1.2625130414962769
loss:  36.902488708496094 1.3135334253311157
loss:  35.942203521728516 1.2751948833465576
loss:  36.025856018066406 1.2519241571426392
loss:  36.05136489868164 1.3069242238998413
loss:  36.589847564697266 1.304374098777771
loss:  36.09641647338867 1.2743343114852905
loss:  36.655757904052734 1.2625302076339722
loss:  36.422122955322266 1.3264985084533691
loss:  35.9600830078125 1.2873445749282837
loss:  36.14208984375 1.2988072633743286
loss:  35.66630935668945 1.291993498802185
*******************Epoch 33 ****************** 680 1.0
Validation Loss
*** pred loss:  25.41643524169922 pred acc: 0.5792270302772522
*** stop loss:  6.377744674682617 stop acc: 0.9133250713348389
*** template loss:  7.9311604499816895 template acc: tensor(0.0756, device='cuda:0')
*** label loss:  6.204934597015381 label acc: tensor(0.3400, device='cuda:0')
Train Loss
---> pred loss: 23.914862060546874 pred acc: 0.6206256926059723
---> stop loss: 5.007243347167969 stop acc: 0.9404295265674592
---> template loss: 3.1840627670288084 tempalte acc: 0.3862579584121704
---> molecule label loss: 2.8200056076049806 molecule acc: 0.4785158157348633
---> kl loss: 1.310304832458496
---> reconstruction loss: 34.926175880432126
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-34-with.npy
loss:  35.68997573852539 1.2878955602645874
loss:  35.76421356201172 1.2890533208847046
loss:  35.759849548339844 1.2869035005569458
loss:  36.19304275512695 1.3078426122665405
loss:  36.12193298339844 1.3167439699172974
loss:  36.53342819213867 1.3172281980514526
loss:  35.86060333251953 1.2646074295043945
loss:  36.04042434692383 1.2547622919082642
loss:  35.92512512207031 1.273545742034912
loss:  36.201698303222656 1.2377042770385742
loss:  35.802608489990234 1.2831504344940186
loss:  35.65408706665039 1.2697938680648804
loss:  36.1981086730957 1.2565243244171143
loss:  36.054630279541016 1.272139310836792
loss:  35.86784362792969 1.2607568502426147
loss:  35.70767593383789 1.2506457567214966
loss:  36.346099853515625 1.2319468259811401
loss:  35.748634338378906 1.2681621313095093
loss:  35.923309326171875 1.2266669273376465
loss:  34.63626480102539 1.2462328672409058
*******************Epoch 34 ****************** 700 1.0
Validation Loss
*** pred loss:  25.33124351501465 pred acc: 0.5801932215690613
*** stop loss:  5.875918865203857 stop acc: 0.9197696447372437
*** template loss:  7.915003776550293 template acc: tensor(0.0767, device='cuda:0')
*** label loss:  6.218271255493164 label acc: tensor(0.3445, device='cuda:0')
Train Loss
---> pred loss: 23.799224853515625 pred acc: 0.6196191430091857
---> stop loss: 4.961104965209961 stop acc: 0.9412115693092347
---> template loss: 3.1218999862670898 tempalte acc: 0.3988102197647095
---> molecule label loss: 2.7491302490234375 molecule acc: 0.4869829177856445
---> kl loss: 1.2701153755187988
---> reconstruction loss: 34.631370830535886
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-35-with.npy
loss:  35.2924919128418 1.2016147375106812
loss:  35.60945510864258 1.2474929094314575
loss:  35.52484130859375 1.2260246276855469
loss:  35.08441162109375 1.2365856170654297
loss:  35.77799606323242 1.2518876791000366
loss:  35.532161712646484 1.2404571771621704
loss:  35.99371337890625 1.2564655542373657
loss:  36.19318389892578 1.2255027294158936
loss:  35.27546310424805 1.233359456062317
loss:  35.884307861328125 1.22672700881958
loss:  35.67277908325195 1.2199046611785889
loss:  35.669036865234375 1.2105783224105835
loss:  35.75515365600586 1.2450052499771118
loss:  35.42793655395508 1.2037476301193237
loss:  35.573516845703125 1.224547266960144
loss:  35.718711853027344 1.2148199081420898
loss:  35.53892517089844 1.2012847661972046
loss:  35.962860107421875 1.24075186252594
loss:  35.015296936035156 1.2160978317260742
loss:  35.98221969604492 1.1645320653915405
*******************Epoch 35 ****************** 720 1.0
Validation Loss
*** pred loss:  25.282573699951172 pred acc: 0.5827294588088989
*** stop loss:  5.96361780166626 stop acc: 0.9186177253723145
*** template loss:  7.9272356033325195 template acc: tensor(0.0770, device='cuda:0')
*** label loss:  6.21232271194458 label acc: tensor(0.3372, device='cuda:0')
Train Loss
---> pred loss: 23.73481140136719 pred acc: 0.620721286535263
---> stop loss: 4.924845504760742 stop acc: 0.9414538830518723
---> template loss: 3.049326515197754 tempalte acc: 0.409576940536499
---> molecule label loss: 2.690868377685547 molecule acc: 0.49440388679504393
---> kl loss: 1.2243692398071289
---> reconstruction loss: 34.399855613708496
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-36-with.npy
loss:  34.95634841918945 1.2065500020980835
loss:  35.588077545166016 1.2356507778167725
loss:  35.17706298828125 1.2343369722366333
loss:  35.43655014038086 1.2005106210708618
loss:  34.98442840576172 1.1971944570541382
loss:  35.424278259277344 1.296569585800171
loss:  34.874969482421875 1.2675254344940186
loss:  35.3736572265625 1.2120743989944458
loss:  35.690914154052734 1.2491111755371094
loss:  36.02894973754883 1.2286508083343506
loss:  35.489601135253906 1.2274587154388428
loss:  35.817867279052734 1.2296562194824219
loss:  35.29645919799805 1.2349880933761597
loss:  35.20398712158203 1.2345305681228638
loss:  35.34203338623047 1.2260875701904297
loss:  35.57572937011719 1.213577151298523
loss:  35.02862548828125 1.2261631488800049
loss:  34.99107360839844 1.2538747787475586
loss:  35.327030181884766 1.2398375272750854
loss:  35.57960891723633 1.1955009698867798
*******************Epoch 36 ****************** 740 1.0
Validation Loss
*** pred loss:  25.400957107543945 pred acc: 0.5818236470222473
*** stop loss:  6.359344959259033 stop acc: 0.913605272769928
*** template loss:  7.938199996948242 template acc: tensor(0.0809, device='cuda:0')
*** label loss:  6.239345550537109 label acc: tensor(0.3284, device='cuda:0')
Train Loss
---> pred loss: 23.62061767578125 pred acc: 0.625171086192131
---> stop loss: 4.899435424804688 stop acc: 0.9425308674573898
---> template loss: 2.9829193115234376 tempalte acc: 0.4221635818481445
---> molecule label loss: 2.6258977890014648 molecule acc: 0.504306697845459
---> kl loss: 1.2304924964904784
---> reconstruction loss: 34.128870296478276
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-37-with.npy
loss:  34.81929397583008 1.173175573348999
loss:  35.42777633666992 1.238134503364563
loss:  34.9952507019043 1.2086514234542847
loss:  35.2557258605957 1.2237213850021362
loss:  35.06316375732422 1.1994255781173706
loss:  35.426788330078125 1.1534125804901123
loss:  35.38377380371094 1.1884832382202148
loss:  34.50341796875 1.2050633430480957
loss:  35.1092529296875 1.1975399255752563
loss:  35.08124542236328 1.2015405893325806
loss:  34.619056701660156 1.1748720407485962
loss:  35.189849853515625 1.2013769149780273
loss:  35.02077102661133 1.1756058931350708
loss:  34.86350631713867 1.1429539918899536
loss:  35.67335510253906 1.1818492412567139
loss:  35.22116470336914 1.1813154220581055
loss:  34.992305755615234 1.131823182106018
loss:  35.576175689697266 1.1743658781051636
loss:  34.92766571044922 1.167312502861023
loss:  34.90876007080078 1.147833228111267
*******************Epoch 37 ****************** 760 1.0
Validation Loss
*** pred loss:  25.34259605407715 pred acc: 0.5795893669128418
*** stop loss:  5.862051963806152 stop acc: 0.9192403554916382
*** template loss:  7.95803689956665 template acc: tensor(0.0805, device='cuda:0')
*** label loss:  6.284252643585205 label acc: tensor(0.3443, device='cuda:0')
Train Loss
---> pred loss: 23.541395568847655 pred acc: 0.6242318093776703
---> stop loss: 4.880497741699219 stop acc: 0.9420007944107056
---> template loss: 2.921141242980957 tempalte acc: 0.4296726226806641
---> molecule label loss: 2.576457977294922 molecule acc: 0.5111316680908203
---> kl loss: 1.1834228515625
---> reconstruction loss: 33.91949157714844
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-38-with.npy
loss:  34.98710632324219 1.151259422302246
loss:  35.003761291503906 1.2257769107818604
loss:  34.765159606933594 1.2342588901519775
loss:  35.12337875366211 1.2379052639007568
loss:  35.17613220214844 1.2135933637619019
loss:  34.806068420410156 1.3154191970825195
loss:  35.318321228027344 1.2376136779785156
loss:  35.39204788208008 1.174742579460144
loss:  35.38273620605469 1.218261480331421
loss:  35.4018440246582 1.2309238910675049
loss:  34.60990905761719 1.1700127124786377
loss:  34.61451721191406 1.1875532865524292
loss:  34.600189208984375 1.1613109111785889
loss:  34.725616455078125 1.1649909019470215
loss:  35.222625732421875 1.1625757217407227
loss:  34.84918975830078 1.1733909845352173
loss:  34.40377426147461 1.1691343784332275
loss:  34.57365417480469 1.1437057256698608
loss:  35.30980682373047 1.1888457536697388
loss:  34.7952995300293 1.1818052530288696
*******************Epoch 38 ****************** 780 1.0
Validation Loss
*** pred loss:  25.25886344909668 pred acc: 0.5795289874076843
*** stop loss:  5.988607406616211 stop acc: 0.9182752370834351
*** template loss:  7.928422927856445 template acc: tensor(0.0777, device='cuda:0')
*** label loss:  6.262689590454102 label acc: tensor(0.3380, device='cuda:0')
Train Loss
---> pred loss: 23.492955017089844 pred acc: 0.6259219288825989
---> stop loss: 4.895166015625 stop acc: 0.9422221809625626
---> template loss: 2.8661022186279297 tempalte acc: 0.43961567878723146
---> molecule label loss: 2.5016805648803713 molecule acc: 0.5204225063323975
---> kl loss: 1.1971539497375487
---> reconstruction loss: 33.755900859832764
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-39-with.npy
loss:  34.85434341430664 1.1817010641098022
loss:  34.74950408935547 1.1881541013717651
loss:  34.45792770385742 1.1983524560928345
loss:  34.92512512207031 1.1691864728927612
loss:  34.55297088623047 1.1472886800765991
loss:  34.79880905151367 1.1982321739196777
loss:  34.55997848510742 1.1930012702941895
loss:  34.88359069824219 1.1503210067749023
loss:  34.54644012451172 1.1189415454864502
loss:  34.59723663330078 1.1240448951721191
loss:  34.571964263916016 1.1557440757751465
loss:  34.67847442626953 1.1698893308639526
loss:  34.75882339477539 1.1317574977874756
loss:  34.366416931152344 1.111928939819336
loss:  34.28550338745117 1.1576100587844849
loss:  34.45347213745117 1.1525890827178955
loss:  34.76607131958008 1.1203253269195557
loss:  34.39918899536133 1.1422208547592163
loss:  34.25767517089844 1.1475858688354492
loss:  34.88682556152344 1.1669987440109253
*******************Epoch 39 ****************** 800 1.0
Validation Loss
*** pred loss:  25.257190704345703 pred acc: 0.5821859836578369
*** stop loss:  5.938089370727539 stop acc: 0.9191781282424927
*** template loss:  7.938422679901123 template acc: tensor(0.0813, device='cuda:0')
*** label loss:  6.2859063148498535 label acc: tensor(0.3428, device='cuda:0')
Train Loss
---> pred loss: 23.360060119628905 pred acc: 0.6279242515563965
---> stop loss: 4.792735290527344 stop acc: 0.9436191976070404
---> template loss: 2.8418760299682617 tempalte acc: 0.44054713249206545
---> molecule label loss: 2.4665512084960937 molecule acc: 0.5279223442077636
---> kl loss: 1.156293773651123
---> reconstruction loss: 33.46122636795044
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-40-with.npy
loss:  34.629249572753906 1.1574803590774536
loss:  34.58335494995117 1.1160798072814941
loss:  33.5614013671875 1.123105525970459
loss:  34.40753936767578 1.1093329191207886
loss:  34.56834411621094 1.1402379274368286
loss:  34.236083984375 1.1645605564117432
loss:  34.441246032714844 1.144567608833313
loss:  34.222129821777344 1.1355069875717163
loss:  34.679443359375 1.1515508890151978
loss:  34.14856719970703 1.1789289712905884
loss:  34.07473373413086 1.1515141725540161
loss:  34.67353057861328 1.1417696475982666
loss:  34.94685745239258 1.16358482837677
loss:  34.24232482910156 1.1318682432174683
loss:  34.327308654785156 1.1516441106796265
loss:  34.28116989135742 1.1388075351715088
loss:  34.03451919555664 1.1396735906600952
loss:  34.43931579589844 1.107231616973877
loss:  34.82326889038086 1.1314677000045776
loss:  34.28288650512695 1.187217116355896
*******************Epoch 40 ****************** 820 1.0
Validation Loss
*** pred loss:  25.33224105834961 pred acc: 0.5799517035484314
*** stop loss:  6.156857490539551 stop acc: 0.9163761138916016
*** template loss:  7.955052852630615 template acc: tensor(0.0827, device='cuda:0')
*** label loss:  6.316232204437256 label acc: tensor(0.3528, device='cuda:0')
Train Loss
---> pred loss: 23.276780700683595 pred acc: 0.627972349524498
---> stop loss: 4.77831802368164 stop acc: 0.9434837281703949
---> template loss: 2.770890998840332 tempalte acc: 0.45362324714660646
---> molecule label loss: 2.410865592956543 molecule acc: 0.5361194610595703
---> kl loss: 1.1433064460754394
---> reconstruction loss: 33.23686017990112
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-41-with.npy
loss:  34.29343032836914 1.0886887311935425
loss:  34.48917007446289 1.1083604097366333
loss:  34.582942962646484 1.0846562385559082
loss:  34.544761657714844 1.1234065294265747
loss:  34.39806365966797 1.1082016229629517
loss:  34.08674240112305 1.1021770238876343
loss:  34.09721755981445 1.123311161994934
loss:  34.21999740600586 1.1371183395385742
loss:  33.488616943359375 1.130234956741333
loss:  33.708038330078125 1.1437608003616333
loss:  34.08989715576172 1.1421109437942505
loss:  34.13434982299805 1.1548116207122803
loss:  34.28428649902344 1.1755805015563965
loss:  34.17087936401367 1.1324114799499512
loss:  33.758567810058594 1.1416758298873901
loss:  34.56730270385742 1.1178699731826782
loss:  33.89396667480469 1.1525806188583374
loss:  33.794044494628906 1.1327301263809204
loss:  34.28376007080078 1.1206085681915283
loss:  34.08863067626953 1.1351596117019653
*******************Epoch 41 ****************** 840 1.0
Validation Loss
*** pred loss:  25.256031036376953 pred acc: 0.5814613103866577
*** stop loss:  5.953148365020752 stop acc: 0.9193337559700012
*** template loss:  7.9323272705078125 template acc: tensor(0.0851, device='cuda:0')
*** label loss:  6.283044815063477 label acc: tensor(0.3428, device='cuda:0')
Train Loss
---> pred loss: 23.175801086425782 pred acc: 0.6299409031867981
---> stop loss: 4.768759536743164 stop acc: 0.9438124805688858
---> template loss: 2.7180559158325197 tempalte acc: 0.464801025390625
---> molecule label loss: 2.3583438873291014 molecule acc: 0.5426000118255615
---> kl loss: 1.1277728080749512
---> reconstruction loss: 33.020963764190675
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-42-with.npy
loss:  33.61345672607422 1.0893750190734863
loss:  33.990386962890625 1.0899314880371094
loss:  34.685943603515625 1.0909911394119263
loss:  33.009796142578125 1.0593485832214355
loss:  34.17422866821289 1.0850223302841187
loss:  33.95242691040039 1.1280702352523804
loss:  33.68094253540039 1.0900944471359253
loss:  33.85287857055664 1.0654219388961792
loss:  33.88135528564453 1.0859205722808838
loss:  34.45892333984375 1.0646530389785767
loss:  33.280460357666016 1.0669046640396118
loss:  34.508724212646484 1.1301641464233398
loss:  33.887916564941406 1.140410304069519
loss:  33.94124221801758 1.1335333585739136
loss:  33.87700271606445 1.088135838508606
loss:  33.963077545166016 1.06944739818573
loss:  33.946537017822266 1.1017581224441528
loss:  33.79212188720703 1.109891414642334
loss:  33.893375396728516 1.1250262260437012
loss:  32.846702575683594 1.0511935949325562
*******************Epoch 42 ****************** 860 1.0
Validation Loss
*** pred loss:  25.34381675720215 pred acc: 0.582065224647522
*** stop loss:  6.022900581359863 stop acc: 0.9190847277641296
*** template loss:  7.972537994384766 template acc: tensor(0.0813, device='cuda:0')
*** label loss:  6.3057966232299805 label acc: tensor(0.3412, device='cuda:0')
Train Loss
---> pred loss: 23.097557067871094 pred acc: 0.6295267760753631
---> stop loss: 4.700196075439453 stop acc: 0.9446144789457321
---> template loss: 2.66299991607666 tempalte acc: 0.47371997833251955
---> molecule label loss: 2.3078563690185545 molecule acc: 0.5517578601837159
---> kl loss: 1.0932647705078125
---> reconstruction loss: 32.76860961914062
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-43-with.npy
loss:  33.75918960571289 1.0985709428787231
loss:  33.896881103515625 1.1386326551437378
loss:  33.92594909667969 1.1251600980758667
loss:  33.20825958251953 1.0599497556686401
loss:  33.958274841308594 1.060725450515747
loss:  33.549869537353516 1.1131502389907837
loss:  33.620540618896484 1.1243948936462402
loss:  33.59039306640625 1.1046193838119507
loss:  33.636802673339844 1.1161445379257202
loss:  34.227481842041016 1.0909459590911865
loss:  33.3115234375 1.0895469188690186
loss:  33.741432189941406 1.103735089302063
loss:  33.71384811401367 1.1338090896606445
loss:  33.40268325805664 1.118923306465149
loss:  33.80497741699219 1.1077747344970703
loss:  33.57461929321289 1.1150286197662354
loss:  34.05611801147461 1.1105319261550903
loss:  33.51378631591797 1.088542103767395
loss:  34.291622161865234 1.0885803699493408
loss:  32.377586364746094 1.0711699724197388
*******************Epoch 43 ****************** 880 1.0
Validation Loss
*** pred loss:  25.291885375976562 pred acc: 0.5836352705955505
*** stop loss:  5.934329509735107 stop acc: 0.9203611612319946
*** template loss:  7.8988871574401855 template acc: tensor(0.0897, device='cuda:0')
*** label loss:  6.250999450683594 label acc: tensor(0.3451, device='cuda:0')
Train Loss
---> pred loss: 22.948870849609374 pred acc: 0.6329050987958909
---> stop loss: 4.689305114746094 stop acc: 0.9448581576347351
---> template loss: 2.6460411071777346 tempalte acc: 0.47463188171386717
---> molecule label loss: 2.2708770751953127 molecule acc: 0.5561190128326416
---> kl loss: 1.1029969215393067
---> reconstruction loss: 32.55509328842163
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-44-with.npy
loss:  33.11320877075195 1.0790728330612183
loss:  33.84229278564453 1.0646474361419678
loss:  32.88648986816406 1.0865886211395264
loss:  33.9919548034668 1.1004935503005981
loss:  33.72206497192383 1.0995625257492065
loss:  33.143836975097656 1.1033371686935425
loss:  33.51442337036133 1.0716586112976074
loss:  33.26301193237305 1.0883489847183228
loss:  33.388397216796875 1.0547422170639038
loss:  33.561546325683594 1.083078145980835
loss:  33.83307647705078 1.0642313957214355
loss:  33.731361389160156 1.0854488611221313
loss:  33.47725296020508 1.0486770868301392
loss:  33.52329635620117 1.0437694787979126
loss:  33.784027099609375 1.0510365962982178
loss:  33.40409469604492 1.0692999362945557
loss:  33.14127731323242 1.076729655265808
loss:  33.216766357421875 1.0477327108383179
loss:  33.449180603027344 1.0695403814315796
loss:  33.97647476196289 0.9611395597457886
*******************Epoch 44 ****************** 900 1.0
Validation Loss
*** pred loss:  25.209611892700195 pred acc: 0.5825483202934265
*** stop loss:  5.843784332275391 stop acc: 0.9216687679290771
*** template loss:  7.968051433563232 template acc: tensor(0.0911, device='cuda:0')
*** label loss:  6.285836219787598 label acc: tensor(0.3367, device='cuda:0')
Train Loss
---> pred loss: 22.946823120117188 pred acc: 0.6327147841453552
---> stop loss: 4.682823181152344 stop acc: 0.944955763220787
---> template loss: 2.5926368713378904 tempalte acc: 0.4844524383544922
---> molecule label loss: 2.208462142944336 molecule acc: 0.5681440830230713
---> kl loss: 1.0674568176269532
---> reconstruction loss: 32.430748748779294
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-45-with.npy
loss:  33.679141998291016 1.1089918613433838
loss:  33.40766525268555 1.0986307859420776
loss:  33.34235763549805 1.0717339515686035
loss:  33.22264099121094 1.038812279701233
loss:  33.14618682861328 1.0523825883865356
loss:  33.263580322265625 1.085379958152771
loss:  33.24605941772461 1.0738751888275146
loss:  33.32395935058594 1.0606157779693604
loss:  33.60441207885742 1.0705198049545288
loss:  33.23383712768555 1.0741620063781738
loss:  33.41585159301758 1.0879426002502441
loss:  33.11491775512695 1.0714784860610962
loss:  33.149784088134766 1.070783019065857
loss:  33.09849166870117 1.0530747175216675
loss:  33.03370666503906 1.0754504203796387
loss:  33.41436004638672 1.0517607927322388
loss:  33.07124328613281 1.0528982877731323
loss:  33.38547897338867 1.0590044260025024
loss:  33.688846588134766 1.0954067707061768
loss:  35.405574798583984 1.1172544956207275
*******************Epoch 45 ****************** 920 1.0
Validation Loss
*** pred loss:  25.17049789428711 pred acc: 0.58423912525177
*** stop loss:  5.8340301513671875 stop acc: 0.9214508533477783
*** template loss:  7.9341278076171875 template acc: tensor(0.0911, device='cuda:0')
*** label loss:  6.318029880523682 label acc: tensor(0.3534, device='cuda:0')
Train Loss
---> pred loss: 22.918516540527342 pred acc: 0.6330951958894729
---> stop loss: 4.666095733642578 stop acc: 0.9448801904916764
---> template loss: 2.5716209411621094 tempalte acc: 0.48723692893981935
---> molecule label loss: 2.1826637268066404 molecule acc: 0.570280933380127
---> kl loss: 1.0735078811645509
---> reconstruction loss: 32.33889751434326
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-46-with.npy
loss:  33.24677276611328 1.089754581451416
loss:  33.46925735473633 1.1086493730545044
loss:  33.11272430419922 1.1062387228012085
loss:  32.939292907714844 1.065292239189148
loss:  33.24808883666992 1.0819422006607056
loss:  33.209964752197266 1.0807987451553345
loss:  33.4556770324707 1.102809190750122
loss:  32.980220794677734 1.0882786512374878
loss:  32.80241775512695 1.0601369142532349
loss:  32.78608322143555 1.0217913389205933
loss:  32.27620315551758 0.9993634223937988
loss:  33.25059509277344 1.0313940048217773
loss:  33.365623474121094 1.0907295942306519
loss:  33.102848052978516 1.0814011096954346
loss:  33.06491470336914 1.055017352104187
loss:  33.41889953613281 1.07344651222229
loss:  32.893978118896484 1.0491833686828613
loss:  32.890506744384766 1.0405523777008057
loss:  32.92692184448242 1.062946081161499
loss:  33.9385871887207 1.1881619691848755
*******************Epoch 46 ****************** 940 1.0
Validation Loss
*** pred loss:  25.120290756225586 pred acc: 0.5881038308143616
*** stop loss:  5.8625383377075195 stop acc: 0.9211395382881165
*** template loss:  7.953777313232422 template acc: tensor(0.0897, device='cuda:0')
*** label loss:  6.312434673309326 label acc: tensor(0.3462, device='cuda:0')
Train Loss
---> pred loss: 22.802796936035158 pred acc: 0.6346953839063645
---> stop loss: 4.657324981689453 stop acc: 0.9455657750368118
---> template loss: 2.4826122283935548 tempalte acc: 0.5028129577636719
---> molecule label loss: 2.1023513793945314 molecule acc: 0.5829497814178467
---> kl loss: 1.0738943099975586
---> reconstruction loss: 32.04508457183838
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-47-with.npy
loss:  33.01216506958008 1.1041914224624634
loss:  33.33943176269531 1.0718525648117065
loss:  33.016563415527344 1.0543692111968994
loss:  32.98484420776367 1.0623468160629272
loss:  32.761817932128906 1.0599333047866821
loss:  33.07789993286133 1.0220577716827393
loss:  32.850650787353516 1.0771325826644897
loss:  33.007877349853516 1.0677974224090576
loss:  32.70097732543945 1.057357907295227
loss:  32.76398468017578 1.034035086631775
loss:  32.88465881347656 1.0513790845870972
loss:  33.312538146972656 1.0605862140655518
loss:  32.94499588012695 1.090218424797058
loss:  32.89118194580078 1.0382856130599976
loss:  32.55462646484375 1.0631978511810303
loss:  32.34381103515625 1.0360233783721924
loss:  33.016944885253906 1.047525405883789
loss:  32.727569580078125 1.0416667461395264
loss:  32.70762634277344 1.030023217201233
loss:  31.323654174804688 1.0066077709197998
*******************Epoch 47 ****************** 960 1.0
Validation Loss
*** pred loss:  25.190893173217773 pred acc: 0.585326075553894
*** stop loss:  5.88542366027832 stop acc: 0.9198630452156067
*** template loss:  7.964922904968262 template acc: tensor(0.0872, device='cuda:0')
*** label loss:  6.340578079223633 label acc: tensor(0.3442, device='cuda:0')
Train Loss
---> pred loss: 22.662088012695314 pred acc: 0.6360843449831008
---> stop loss: 4.5777122497558596 stop acc: 0.9460941851139069
---> template loss: 2.449139404296875 tempalte acc: 0.5093990325927734
---> molecule label loss: 2.0684194564819336 molecule acc: 0.590511703491211
---> kl loss: 1.053829288482666
---> reconstruction loss: 31.757361507415773
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-48-with.npy
loss:  32.65348815917969 1.042690396308899
loss:  32.52321243286133 1.051570177078247
loss:  32.345367431640625 1.0596946477890015
loss:  33.027732849121094 1.0515798330307007
loss:  32.50224304199219 1.0353204011917114
loss:  32.60216522216797 1.056616187095642
loss:  32.85604476928711 1.054172396659851
loss:  33.382301330566406 1.100576639175415
loss:  32.2845344543457 1.055390477180481
loss:  32.741634368896484 1.035468339920044
loss:  32.75510787963867 1.0603421926498413
loss:  32.47018814086914 1.046931266784668
loss:  32.488853454589844 1.030237078666687
loss:  32.55827713012695 1.0095151662826538
loss:  33.0464973449707 1.0221205949783325
loss:  32.65399932861328 1.0056854486465454
loss:  32.65175247192383 1.0031731128692627
loss:  32.72535705566406 1.0236610174179077
loss:  32.16834259033203 0.9741308093070984
loss:  33.49768829345703 1.017998456954956
*******************Epoch 48 ****************** 980 1.0
Validation Loss
*** pred loss:  25.12760353088379 pred acc: 0.5886473059654236
*** stop loss:  6.0714945793151855 stop acc: 0.9194894433021545
*** template loss:  8.001201629638672 template acc: tensor(0.0939, device='cuda:0')
*** label loss:  6.349573612213135 label acc: tensor(0.3487, device='cuda:0')
Train Loss
---> pred loss: 22.66175994873047 pred acc: 0.6370943516492844
---> stop loss: 4.575957107543945 stop acc: 0.9461610317230225
---> template loss: 2.399484634399414 tempalte acc: 0.516695785522461
---> molecule label loss: 2.0226951599121095 molecule acc: 0.5968419551849365
---> kl loss: 1.0368436813354491
---> reconstruction loss: 31.65989398956299
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-49-with.npy
loss:  32.747047424316406 1.0785622596740723
loss:  32.385738372802734 1.0494109392166138
loss:  32.297576904296875 1.0482940673828125
loss:  32.87540817260742 1.0604420900344849
loss:  33.006473541259766 1.1196691989898682
loss:  32.42790603637695 1.0991919040679932
loss:  32.84405517578125 1.0823783874511719
loss:  32.713863372802734 1.0813803672790527
loss:  32.45934295654297 1.0888906717300415
loss:  32.5594367980957 1.0532110929489136
loss:  31.970703125 1.05971097946167
loss:  32.70294189453125 1.0546696186065674
loss:  32.72757339477539 1.019799828529358
loss:  32.02598190307617 1.0524065494537354
loss:  32.321990966796875 1.0325288772583008
loss:  32.76176071166992 1.0120596885681152
loss:  32.596771240234375 0.9882947206497192
loss:  32.647525787353516 1.0257349014282227
loss:  32.13401412963867 1.0247802734375
loss:  30.839183807373047 0.9744726419448853
*******************Epoch 49 ****************** 1000 1.0
Validation Loss
*** pred loss:  25.207887649536133 pred acc: 0.583695650100708
*** stop loss:  5.916803359985352 stop acc: 0.9190224409103394
*** template loss:  7.95017671585083 template acc: tensor(0.0957, device='cuda:0')
*** label loss:  6.365654468536377 label acc: tensor(0.3485, device='cuda:0')
Train Loss
---> pred loss: 22.494015502929688 pred acc: 0.6378984361886978
---> stop loss: 4.564559555053711 stop acc: 0.946352744102478
---> template loss: 2.364998435974121 tempalte acc: 0.5239773750305176
---> molecule label loss: 1.9783969879150392 molecule acc: 0.6052759647369385
---> kl loss: 1.0502944946289063
---> reconstruction loss: 31.40196990966797
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-50-with.npy
loss:  32.57168197631836 1.0376570224761963
loss:  32.19038009643555 1.0737568140029907
loss:  32.16426467895508 1.0134661197662354
loss:  32.467525482177734 1.0191230773925781
loss:  33.01398849487305 1.0078125
loss:  32.75636672973633 1.0189194679260254
loss:  32.311031341552734 1.0218939781188965
loss:  32.19978713989258 1.0130369663238525
loss:  32.084720611572266 0.9888888001441956
loss:  32.06438064575195 1.0063525438308716
loss:  31.90599250793457 0.969389796257019
loss:  32.260101318359375 1.0490036010742188
loss:  32.56318664550781 1.010658860206604
loss:  32.51487350463867 0.9781854748725891
loss:  32.2803955078125 0.9792255759239197
loss:  32.12803268432617 1.0080020427703857
loss:  32.43600082397461 1.0348533391952515
loss:  32.71923065185547 1.0187017917633057
loss:  32.25452423095703 1.0057299137115479
loss:  31.513891220092773 0.9720587134361267
*******************Epoch 50 ****************** 1020 1.0
Validation Loss
*** pred loss:  25.16927719116211 pred acc: 0.5871980786323547
*** stop loss:  5.89886474609375 stop acc: 0.9214508533477783
*** template loss:  7.996951103210449 template acc: tensor(0.0950, device='cuda:0')
*** label loss:  6.421700477600098 label acc: tensor(0.3498, device='cuda:0')
Train Loss
---> pred loss: 22.476751708984374 pred acc: 0.6383879274129868
---> stop loss: 4.537311172485351 stop acc: 0.9467349827289582
---> template loss: 2.3472288131713865 tempalte acc: 0.5247713565826416
---> molecule label loss: 1.9473899841308593 molecule acc: 0.6091765403747559
---> kl loss: 1.0113357543945312
---> reconstruction loss: 31.308683776855467
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-51-with.npy
loss:  32.21291732788086 0.9914101362228394
loss:  31.75596809387207 0.9853528141975403
loss:  32.442447662353516 1.046789526939392
loss:  32.51008987426758 1.0068398714065552
loss:  32.18914031982422 1.0163211822509766
loss:  31.746171951293945 0.9977400898933411
loss:  32.221595764160156 1.0042669773101807
loss:  32.101097106933594 1.003930926322937
loss:  32.27963638305664 0.9863132238388062
loss:  32.25234603881836 1.0002421140670776
loss:  32.487548828125 1.020782709121704
loss:  32.352474212646484 0.9876986145973206
loss:  32.21228790283203 1.0251784324645996
loss:  32.1542854309082 1.0167741775512695
loss:  32.19472122192383 1.001831293106079
loss:  31.744749069213867 1.0065193176269531
loss:  32.3049430847168 1.0271706581115723
loss:  32.48161697387695 1.0051953792572021
loss:  32.27016830444336 0.9958652257919312
loss:  30.149940490722656 1.0327873229980469
*******************Epoch 51 ****************** 1040 1.0
Validation Loss
*** pred loss:  25.33440589904785 pred acc: 0.5812801718711853
*** stop loss:  5.852562427520752 stop acc: 0.9217932820320129
*** template loss:  8.004843711853027 template acc: tensor(0.0876, device='cuda:0')
*** label loss:  6.330007076263428 label acc: tensor(0.3490, device='cuda:0')
Train Loss
---> pred loss: 22.340855407714844 pred acc: 0.6413968414068222
---> stop loss: 4.514062881469727 stop acc: 0.9471729695796967
---> template loss: 2.3185617446899416 tempalte acc: 0.5286717414855957
---> molecule label loss: 1.9217782974243165 molecule acc: 0.6127330780029296
---> kl loss: 1.007950496673584
---> reconstruction loss: 31.09525690078735
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-52-with.npy
loss:  32.314937591552734 1.0117112398147583
loss:  31.745813369750977 1.001950740814209
loss:  32.11139678955078 1.019982933998108
loss:  32.38847351074219 1.040154218673706
loss:  31.923513412475586 1.0308102369308472
loss:  31.647886276245117 1.0420089960098267
loss:  31.68926429748535 1.02511465549469
loss:  31.908023834228516 1.0207816362380981
loss:  31.706825256347656 0.9861688613891602
loss:  32.638450622558594 1.0240422487258911
loss:  32.49357223510742 1.01478910446167
loss:  32.645267486572266 1.0080569982528687
loss:  32.05425262451172 0.9906246662139893
loss:  31.593534469604492 0.9689406752586365
loss:  31.491640090942383 0.9682825207710266
loss:  32.0172004699707 0.9954957365989685
loss:  32.043296813964844 1.0117177963256836
loss:  32.173885345458984 1.0199532508850098
loss:  31.839570999145508 0.9952223300933838
loss:  30.320039749145508 1.0242483615875244
*******************Epoch 52 ****************** 1060 1.0
Validation Loss
*** pred loss:  25.24202537536621 pred acc: 0.5841183662414551
*** stop loss:  5.895337104797363 stop acc: 0.9214197397232056
*** template loss:  8.043282508850098 template acc: tensor(0.0960, device='cuda:0')
*** label loss:  6.350432872772217 label acc: tensor(0.3391, device='cuda:0')
Train Loss
---> pred loss: 22.275894165039062 pred acc: 0.6402258932590484
---> stop loss: 4.480775451660156 stop acc: 0.947243919968605
---> template loss: 2.2888967514038088 tempalte acc: 0.5338831901550293
---> molecule label loss: 1.8817735671997071 molecule acc: 0.6210525035858154
---> kl loss: 1.0100028038024902
---> reconstruction loss: 30.927341556549074
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-53-with.npy
loss:  31.856908798217773 1.0119208097457886
loss:  31.902202606201172 1.0286736488342285
loss:  32.092288970947266 1.0286558866500854
loss:  32.14059066772461 1.012595772743225
loss:  31.506580352783203 1.0312286615371704
loss:  31.53063201904297 0.9944579601287842
loss:  32.332305908203125 1.0029537677764893
loss:  31.61981964111328 0.9878997206687927
loss:  32.037803649902344 0.9697247743606567
loss:  32.4618034362793 0.9910528659820557
loss:  31.839155197143555 1.0026510953903198
loss:  31.816835403442383 1.0056554079055786
loss:  31.95193099975586 0.9976911544799805
loss:  31.172985076904297 0.9705715179443359
loss:  31.348758697509766 0.9676660299301147
loss:  31.82404136657715 0.9990220665931702
loss:  31.751977920532227 0.9779452085494995
loss:  31.95348358154297 1.0066081285476685
loss:  31.49369239807129 0.9716895222663879
loss:  32.79423522949219 1.0340168476104736
*******************Epoch 53 ****************** 1080 1.0
Validation Loss
*** pred loss:  25.30272102355957 pred acc: 0.583695650100708
*** stop loss:  6.1875715255737305 stop acc: 0.9188668131828308
*** template loss:  8.012751579284668 template acc: tensor(0.1013, device='cuda:0')
*** label loss:  6.352259159088135 label acc: tensor(0.3549, device='cuda:0')
Train Loss
---> pred loss: 22.30262451171875 pred acc: 0.6424804478883743
---> stop loss: 4.513994598388672 stop acc: 0.9474951535463333
---> template loss: 2.2291255950927735 tempalte acc: 0.5455498218536377
---> molecule label loss: 1.8260215759277343 molecule acc: 0.6307353973388672
---> kl loss: 0.999634075164795
---> reconstruction loss: 30.871767902374266
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-54-with.npy
loss:  31.843372344970703 1.0273483991622925
loss:  31.828271865844727 0.9914290904998779
loss:  31.7852725982666 1.0077153444290161
loss:  31.58087921142578 1.0356796979904175
loss:  31.86652946472168 1.0048748254776
loss:  31.72040367126465 0.990895688533783
loss:  31.655866622924805 0.9773250818252563
loss:  31.38582420349121 0.965695858001709
loss:  31.948692321777344 0.9818246364593506
loss:  32.37139129638672 1.012973427772522
loss:  31.84886360168457 0.9861129522323608
loss:  31.273313522338867 0.9738263487815857
loss:  31.66797637939453 0.9758777618408203
loss:  31.749755859375 1.000877857208252
loss:  31.69126319885254 1.018234133720398
loss:  31.499515533447266 0.9917376637458801
loss:  32.042476654052734 1.0088050365447998
loss:  31.91080093383789 1.0202720165252686
loss:  31.810075759887695 1.0105986595153809
loss:  31.059690475463867 1.0693106651306152
*******************Epoch 54 ****************** 1100 1.0
Validation Loss
*** pred loss:  25.172060012817383 pred acc: 0.5896134972572327
*** stop loss:  5.873348712921143 stop acc: 0.9228206872940063
*** template loss:  7.959936141967773 template acc: tensor(0.0981, device='cuda:0')
*** label loss:  6.384652137756348 label acc: tensor(0.3443, device='cuda:0')
Train Loss
---> pred loss: 22.202789306640625 pred acc: 0.6443480998277664
---> stop loss: 4.5238605499267575 stop acc: 0.9468214780092239
---> template loss: 2.2089799880981444 tempalte acc: 0.5478760719299316
---> molecule label loss: 1.7888113021850587 molecule acc: 0.6347978115081787
---> kl loss: 1.0025707244873048
---> reconstruction loss: 30.72444038391113
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-55-with.npy
loss:  31.615421295166016 0.9907007217407227
loss:  32.22081756591797 1.0169110298156738
loss:  32.00811004638672 1.0262117385864258
loss:  31.225772857666016 0.9779178500175476
loss:  31.75963592529297 1.0047104358673096
loss:  31.640220642089844 0.9974067807197571
loss:  31.795263290405273 0.9780281186103821
loss:  31.636682510375977 1.0047593116760254
loss:  31.297500610351562 0.9601364135742188
loss:  31.2490291595459 0.979463517665863
loss:  31.516767501831055 0.9624619483947754
loss:  31.58415985107422 1.0045791864395142
loss:  31.054931640625 0.9673622250556946
loss:  31.128759384155273 0.9861467480659485
loss:  31.3150691986084 0.971285879611969
loss:  31.71548843383789 1.0106030702590942
loss:  32.05406188964844 1.0116370916366577
loss:  31.561967849731445 0.9654673933982849
loss:  31.305686950683594 0.9698986411094666
loss:  31.23342514038086 1.020603895187378
*******************Epoch 55 ****************** 1120 1.0
Validation Loss
*** pred loss:  25.23282814025879 pred acc: 0.5874395966529846
*** stop loss:  5.988611221313477 stop acc: 0.9205479621887207
*** template loss:  8.00845718383789 template acc: tensor(0.0985, device='cuda:0')
*** label loss:  6.400017261505127 label acc: tensor(0.3522, device='cuda:0')
Train Loss
---> pred loss: 22.118937683105468 pred acc: 0.6454637914896011
---> stop loss: 4.47071533203125 stop acc: 0.947456443309784
---> template loss: 2.1954559326171874 tempalte acc: 0.5508805274963379
---> molecule label loss: 1.7705144882202148 molecule acc: 0.6376406192779541
---> kl loss: 0.9903145790100097
---> reconstruction loss: 30.555617427825926
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-56-with.npy
loss:  31.09657859802246 0.9685541391372681
loss:  31.308330535888672 0.9512916207313538
loss:  31.112316131591797 0.963774561882019
loss:  31.261499404907227 0.9840187430381775
loss:  31.15500259399414 0.9547661542892456
loss:  31.79613494873047 0.9781198501586914
loss:  31.389238357543945 1.0190860033035278
loss:  31.41131591796875 0.9758986234664917
loss:  31.764110565185547 0.9785614609718323
loss:  31.606048583984375 0.971405029296875
loss:  31.491548538208008 0.9635249376296997
loss:  31.542579650878906 0.9754730463027954
loss:  31.648433685302734 0.953899621963501
loss:  31.368030548095703 0.9848165512084961
loss:  31.332931518554688 0.9960355162620544
loss:  30.921031951904297 0.9752972722053528
loss:  31.479984283447266 0.9637444019317627
loss:  30.969980239868164 0.9785445928573608
loss:  31.278152465820312 0.9699423313140869
loss:  32.691951751708984 0.9686746001243591
*******************Epoch 56 ****************** 1140 1.0
Validation Loss
*** pred loss:  25.227067947387695 pred acc: 0.5865941643714905
*** stop loss:  5.971760272979736 stop acc: 0.9198319315910339
*** template loss:  8.052486419677734 template acc: tensor(0.0988, device='cuda:0')
*** label loss:  6.381326675415039 label acc: tensor(0.3417, device='cuda:0')
Train Loss
---> pred loss: 22.117372131347658 pred acc: 0.6451262593269348
---> stop loss: 4.455162048339844 stop acc: 0.9477419078350067
---> template loss: 2.149344253540039 tempalte acc: 0.558195161819458
---> molecule label loss: 1.7356107711791993 molecule acc: 0.6440908432006835
---> kl loss: 0.9737713813781739
---> reconstruction loss: 30.457487773895263
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-57-with.npy
loss:  31.160913467407227 0.9800199270248413
loss:  31.942028045654297 1.0162756443023682
loss:  31.529315948486328 1.047046184539795
loss:  31.799577713012695 1.026415228843689
loss:  31.403425216674805 1.0286576747894287
loss:  31.45396614074707 1.0521970987319946
loss:  31.082515716552734 1.0122007131576538
loss:  31.22695541381836 1.0559077262878418
loss:  31.395263671875 1.024949550628662
loss:  31.71231460571289 1.0259921550750732
loss:  31.760272979736328 1.0043959617614746
loss:  31.7086124420166 0.9966303706169128
loss:  31.564071655273438 0.9928585290908813
loss:  31.27249526977539 0.9894126057624817
loss:  31.885507583618164 0.9882847666740417
loss:  31.37871551513672 0.9609713554382324
loss:  31.510631561279297 1.0140868425369263
loss:  31.7982234954834 1.015844464302063
loss:  31.543413162231445 0.9868574738502502
loss:  30.57399559020996 0.98457270860672
*******************Epoch 57 ****************** 1160 1.0
Validation Loss
*** pred loss:  25.10653305053711 pred acc: 0.5885869264602661
*** stop loss:  5.784008502960205 stop acc: 0.9227584600448608
*** template loss:  8.064358711242676 template acc: tensor(0.0932, device='cuda:0')
*** label loss:  6.34859561920166 label acc: tensor(0.3340, device='cuda:0')
Train Loss
---> pred loss: 21.986357116699217 pred acc: 0.6461406290531159
---> stop loss: 4.436083602905273 stop acc: 0.9481367647647858
---> template loss: 2.2868934631347657 tempalte acc: 0.5324604511260986
---> molecule label loss: 1.7655956268310546 molecule acc: 0.6380037784576416
---> kl loss: 1.0101789474487304
---> reconstruction loss: 30.474931526184083
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-58-with.npy
loss:  31.3250732421875 1.015503168106079
loss:  31.48636245727539 1.0147501230239868
loss:  31.672910690307617 0.9931007027626038
loss:  31.168659210205078 1.0026931762695312
loss:  31.681337356567383 1.0158203840255737
loss:  31.48383331298828 1.0286985635757446
loss:  31.263883590698242 1.0202876329421997
loss:  31.193279266357422 1.0090134143829346
loss:  31.13804054260254 1.019701361656189
loss:  30.95134735107422 0.9785240888595581
loss:  30.975008010864258 0.9802315831184387
loss:  31.212846755981445 0.9945586323738098
loss:  31.108442306518555 0.9660603404045105
loss:  30.98219108581543 0.9442226886749268
loss:  31.280359268188477 0.9558005332946777
loss:  31.102182388305664 0.940115213394165
loss:  30.65034294128418 0.9459270238876343
loss:  31.056812286376953 0.9352216720581055
loss:  31.30432891845703 0.986808717250824
loss:  30.390539169311523 0.941847026348114
*******************Epoch 58 ****************** 1180 1.0
Validation Loss
*** pred loss:  25.324995040893555 pred acc: 0.5887681245803833
*** stop loss:  5.85956335067749 stop acc: 0.9219178557395935
*** template loss:  8.023785591125488 template acc: tensor(0.0978, device='cuda:0')
*** label loss:  6.34753942489624 label acc: tensor(0.3432, device='cuda:0')
Train Loss
---> pred loss: 21.93526611328125 pred acc: 0.6465959459543228
---> stop loss: 4.391928863525391 stop acc: 0.9483960151672364
---> template loss: 2.16522102355957 tempalte acc: 0.5556822299957276
---> molecule label loss: 1.6945281982421876 molecule acc: 0.6509881973266601
---> kl loss: 0.9844441413879395
---> reconstruction loss: 30.186945629119872
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-59-with.npy
loss:  30.92397117614746 0.972483217716217
loss:  31.160890579223633 0.9789285063743591
loss:  30.583335876464844 0.9691553115844727
loss:  31.6581974029541 0.9855111837387085
loss:  31.102893829345703 0.9757230281829834
loss:  30.66646957397461 0.9575290679931641
loss:  30.733301162719727 0.9698988795280457
loss:  31.052417755126953 0.9629462957382202
loss:  31.115997314453125 0.9720994234085083
loss:  31.453996658325195 0.9742774963378906
loss:  30.811363220214844 0.9674680829048157
loss:  30.516077041625977 0.965220034122467
loss:  31.274036407470703 0.9794983267784119
loss:  30.470552444458008 0.9660565853118896
loss:  30.835113525390625 0.9383244514465332
loss:  31.141286849975586 0.9356716871261597
loss:  31.08365821838379 0.9769194722175598
loss:  30.928325653076172 0.9553077816963196
loss:  31.03554916381836 0.9740792512893677
loss:  32.254180908203125 1.1095998287200928
*******************Epoch 59 ****************** 1200 1.0
Validation Loss
*** pred loss:  25.20253562927246 pred acc: 0.5881038308143616
*** stop loss:  6.196628570556641 stop acc: 0.9183064103126526
*** template loss:  8.014351844787598 template acc: tensor(0.1002, device='cuda:0')
*** label loss:  6.369258880615234 label acc: tensor(0.3520, device='cuda:0')
Train Loss
---> pred loss: 21.94031982421875 pred acc: 0.6482894003391266
---> stop loss: 4.417118835449219 stop acc: 0.948317113518715
---> template loss: 2.0821104049682617 tempalte acc: 0.568504524230957
---> molecule label loss: 1.6261987686157227 molecule acc: 0.6642673492431641
---> kl loss: 0.9743349075317382
---> reconstruction loss: 30.065746879577638
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-60-with.npy
loss:  30.748119354248047 0.9851177930831909
loss:  30.727649688720703 0.9873785376548767
loss:  30.96864891052246 0.9752816557884216
loss:  30.951684951782227 0.9871646165847778
loss:  31.428110122680664 0.9882687926292419
loss:  31.049665451049805 0.9748850464820862
loss:  30.554662704467773 0.9469089508056641
loss:  30.74632453918457 0.9585716724395752
loss:  30.550682067871094 0.9616822600364685
loss:  31.198986053466797 0.9932935833930969
loss:  30.921566009521484 0.9632909893989563
loss:  30.69028091430664 0.9534307718276978
loss:  30.95710563659668 0.9317229390144348
loss:  30.9410400390625 0.951375424861908
loss:  30.596149444580078 0.9702730774879456
loss:  30.743051528930664 0.9483191967010498
loss:  30.572843551635742 0.9803827404975891
loss:  31.478771209716797 0.9435096383094788
loss:  30.984447479248047 0.9576592445373535
loss:  31.116952896118164 0.9854834079742432
*******************Epoch 60 ****************** 1220 1.0
Validation Loss
*** pred loss:  25.261423110961914 pred acc: 0.5841183662414551
*** stop loss:  6.167112827301025 stop acc: 0.9184620380401611
*** template loss:  8.011611938476562 template acc: tensor(0.0957, device='cuda:0')
*** label loss:  6.426086902618408 label acc: tensor(0.3520, device='cuda:0')
Train Loss
---> pred loss: 21.86968994140625 pred acc: 0.6493004977703094
---> stop loss: 4.426403045654297 stop acc: 0.9481296598911285
---> template loss: 2.044864463806152 tempalte acc: 0.5771304607391358
---> molecule label loss: 1.5881781578063965 molecule acc: 0.6708485126495362
---> kl loss: 0.9671999931335449
---> reconstruction loss: 29.929134845733643
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-61-with.npy
loss:  31.146068572998047 1.0357712507247925
loss:  30.700542449951172 0.9842609167098999
loss:  31.02950668334961 0.9796350598335266
loss:  31.231481552124023 0.959391713142395
loss:  31.115163803100586 0.960725724697113
loss:  30.753671646118164 0.9539152979850769
loss:  30.30611801147461 0.9190903902053833
loss:  30.47609519958496 0.9467581510543823
loss:  30.721450805664062 0.9621416926383972
loss:  30.38763427734375 0.9520008563995361
loss:  30.67498779296875 0.9645054936408997
loss:  30.899309158325195 0.9478914737701416
loss:  30.45150375366211 0.9473239183425903
loss:  30.301782608032227 0.9574882984161377
loss:  30.527603149414062 0.9309973120689392
loss:  31.00867462158203 0.9704137444496155
loss:  31.449283599853516 0.9846800565719604
loss:  29.862552642822266 0.9383322596549988
loss:  30.59931182861328 0.9717986583709717
loss:  29.899616241455078 1.0391950607299805
*******************Epoch 61 ****************** 1240 1.0
Validation Loss
*** pred loss:  25.322486877441406 pred acc: 0.5841183662414551
*** stop loss:  6.253074645996094 stop acc: 0.9172790050506592
*** template loss:  8.008548736572266 template acc: tensor(0.1009, device='cuda:0')
*** label loss:  6.39058780670166 label acc: tensor(0.3547, device='cuda:0')
Train Loss
---> pred loss: 21.781268310546874 pred acc: 0.6503623515367508
---> stop loss: 4.350450134277343 stop acc: 0.9491944044828415
---> template loss: 2.01666259765625 tempalte acc: 0.5814448356628418
---> molecule label loss: 1.5634194374084474 molecule acc: 0.6755796432495117
---> kl loss: 0.9653156280517579
---> reconstruction loss: 29.711802291870118
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-62-with.npy
loss:  30.05057144165039 0.9534046053886414
loss:  30.82501220703125 0.9688374996185303
loss:  30.14017105102539 0.9180488586425781
loss:  30.685338973999023 0.9703662991523743
loss:  30.607654571533203 0.9511698484420776
loss:  30.679609298706055 0.9347665309906006
loss:  30.75913429260254 0.9458248615264893
loss:  30.51593780517578 0.9641987681388855
loss:  30.749160766601562 0.9566881060600281
loss:  30.636709213256836 0.9456698894500732
loss:  30.692760467529297 0.9921996593475342
loss:  30.228164672851562 0.9626004099845886
loss:  30.688501358032227 0.9752825498580933
loss:  30.323226928710938 0.9489274621009827
loss:  30.832029342651367 0.9761747121810913
loss:  30.562711715698242 0.9580703377723694
loss:  31.1699275970459 0.9939344525337219
loss:  31.201417922973633 1.002816915512085
loss:  30.431087493896484 0.9794593453407288
loss:  30.325544357299805 1.0129939317703247
*******************Epoch 62 ****************** 1260 1.0
Validation Loss
*** pred loss:  25.07210922241211 pred acc: 0.5899758338928223
*** stop loss:  6.171151638031006 stop acc: 0.9191469550132751
*** template loss:  7.999345302581787 template acc: tensor(0.1006, device='cuda:0')
*** label loss:  6.380270957946777 label acc: tensor(0.3526, device='cuda:0')
Train Loss
---> pred loss: 21.717684936523437 pred acc: 0.651534378528595
---> stop loss: 4.392113494873047 stop acc: 0.9482324242591857
---> template loss: 2.0020719528198243 tempalte acc: 0.5870271682739258
---> molecule label loss: 1.52778959274292 molecule acc: 0.6813065052032471
---> kl loss: 0.9655718803405762
---> reconstruction loss: 29.639661884307863
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-63-with.npy
loss:  30.740060806274414 0.9646952748298645
loss:  30.019941329956055 0.9605998396873474
loss:  30.486648559570312 0.9797922372817993
loss:  30.237300872802734 0.9984053373336792
loss:  30.524017333984375 1.0058296918869019
loss:  30.496095657348633 0.9828746914863586
loss:  30.986854553222656 0.9948737025260925
loss:  30.498931884765625 0.965829610824585
loss:  30.578737258911133 0.9866581559181213
loss:  30.284591674804688 0.9525367021560669
loss:  30.516124725341797 0.9469042420387268
loss:  30.319625854492188 0.9401025176048279
loss:  30.059783935546875 0.956964910030365
loss:  30.588354110717773 0.9536005854606628
loss:  30.40814208984375 0.9809439182281494
loss:  30.425264358520508 0.9341346621513367
loss:  30.648178100585938 0.9341027736663818
loss:  30.407922744750977 0.9425608515739441
loss:  30.762435913085938 0.9811139702796936
loss:  30.243789672851562 0.9650837182998657
*******************Epoch 63 ****************** 1280 1.0
Validation Loss
*** pred loss:  25.15822982788086 pred acc: 0.5890700221061707
*** stop loss:  5.792282581329346 stop acc: 0.9238480925559998
*** template loss:  8.038219451904297 template acc: tensor(0.1020, device='cuda:0')
*** label loss:  6.438702583312988 label acc: tensor(0.3590, device='cuda:0')
Train Loss
---> pred loss: 21.666436767578126 pred acc: 0.651881542801857
---> stop loss: 4.368978118896484 stop acc: 0.9487516611814499
---> template loss: 1.9689483642578125 tempalte acc: 0.5890659332275391
---> molecule label loss: 1.4908984184265137 molecule acc: 0.6876596450805664
---> kl loss: 0.9663803100585937
---> reconstruction loss: 29.49525604248047
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-64-with.npy
loss:  30.13943862915039 0.9542636275291443
loss:  30.058364868164062 0.9511982202529907
loss:  30.365589141845703 0.9818522930145264
loss:  30.16173553466797 0.9648346900939941
loss:  30.04543685913086 0.9732292890548706
loss:  30.609697341918945 0.971021294593811
loss:  30.422882080078125 0.9668920040130615
loss:  30.544321060180664 1.0006954669952393
loss:  30.14072036743164 0.9570931196212769
loss:  30.872512817382812 0.9705933332443237
loss:  30.321754455566406 0.966748058795929
loss:  30.05010986328125 0.9427171349525452
loss:  29.804346084594727 0.9577125310897827
loss:  30.20996856689453 0.9624249339103699
loss:  30.416259765625 0.9510111212730408
loss:  30.72970199584961 0.9575911164283752
loss:  30.391027450561523 0.9619859457015991
loss:  30.436878204345703 0.9609683156013489
loss:  30.378293991088867 0.9736126065254211
loss:  30.345169067382812 0.944887638092041
*******************Epoch 64 ****************** 1300 1.0
Validation Loss
*** pred loss:  25.097883224487305 pred acc: 0.5885265469551086
*** stop loss:  6.047562122344971 stop acc: 0.9212640523910522
*** template loss:  8.009214401245117 template acc: tensor(0.1020, device='cuda:0')
*** label loss:  6.373096942901611 label acc: tensor(0.3466, device='cuda:0')
Train Loss
---> pred loss: 21.611854553222656 pred acc: 0.6537904560565948
---> stop loss: 4.3285266876220705 stop acc: 0.9494958043098449
---> template loss: 1.9515535354614257 tempalte acc: 0.5933926105499268
---> molecule label loss: 1.466707706451416 molecule acc: 0.6920250415802002
---> kl loss: 0.9635665893554688
---> reconstruction loss: 29.358644104003904
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-65-with.npy
loss:  29.84775733947754 0.9591041207313538
loss:  30.174856185913086 0.9457225203514099
loss:  30.140546798706055 0.9490978717803955
loss:  30.074810028076172 0.9583913087844849
loss:  30.047576904296875 0.9356415867805481
loss:  30.190349578857422 0.9365944862365723
loss:  30.261329650878906 0.9457377791404724
loss:  30.014732360839844 0.9544503688812256
loss:  30.19516372680664 0.9412937164306641
loss:  30.235881805419922 0.9472537636756897
loss:  30.644798278808594 0.9753313064575195
loss:  29.98099136352539 0.9446440935134888
loss:  30.431909561157227 0.9483212828636169
loss:  30.43474578857422 0.9274983406066895
loss:  30.300363540649414 0.9724897742271423
loss:  29.80861473083496 0.9480838179588318
loss:  30.311111450195312 0.9550272822380066
loss:  30.305686950683594 0.9442486763000488
loss:  30.099634170532227 0.9365288615226746
loss:  30.73443031311035 0.9479033946990967
*******************Epoch 65 ****************** 1320 1.0
Validation Loss
*** pred loss:  25.11531639099121 pred acc: 0.5873792171478271
*** stop loss:  5.993244647979736 stop acc: 0.9202366471290588
*** template loss:  8.063076972961426 template acc: tensor(0.1041, device='cuda:0')
*** label loss:  6.404012203216553 label acc: tensor(0.3423, device='cuda:0')
Train Loss
---> pred loss: 21.581814575195313 pred acc: 0.653705483675003
---> stop loss: 4.289302062988281 stop acc: 0.9498903393745423
---> template loss: 1.939262580871582 tempalte acc: 0.5967408180236816
---> molecule label loss: 1.452718162536621 molecule acc: 0.6961059093475341
---> kl loss: 0.9486681938171386
---> reconstruction loss: 29.26309633255005
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-66-with.npy
loss:  29.5274658203125 0.9479987621307373
loss:  29.807191848754883 0.9773167967796326
loss:  30.293121337890625 0.9882163405418396
loss:  30.13161849975586 0.9468948245048523
loss:  30.144126892089844 0.949923038482666
loss:  30.205097198486328 0.934276819229126
loss:  30.2458553314209 0.9294342398643494
loss:  30.270353317260742 0.9176419377326965
loss:  30.10428810119629 0.9291977286338806
loss:  30.00466537475586 0.9292185306549072
loss:  29.908489227294922 0.9195988178253174
loss:  30.114572525024414 0.9068775773048401
loss:  30.245752334594727 0.9330472350120544
loss:  30.019121170043945 0.9463604092597961
loss:  29.911441802978516 0.9270049333572388
loss:  30.215858459472656 0.9383058547973633
loss:  29.95490837097168 0.972552478313446
loss:  29.887786865234375 0.9449256062507629
loss:  30.242000579833984 0.952448308467865
loss:  30.46021842956543 0.9679697155952454
*******************Epoch 66 ****************** 1340 1.0
Validation Loss
*** pred loss:  25.210737228393555 pred acc: 0.5855072140693665
*** stop loss:  5.8767876625061035 stop acc: 0.9228518605232239
*** template loss:  8.058897018432617 template acc: tensor(0.1052, device='cuda:0')
*** label loss:  6.4534149169921875 label acc: tensor(0.3611, device='cuda:0')
Train Loss
---> pred loss: 21.50389862060547 pred acc: 0.6544119238853454
---> stop loss: 4.304103088378906 stop acc: 0.9497743844985962
---> template loss: 1.9076765060424805 tempalte acc: 0.6022990703582763
---> molecule label loss: 1.4260587692260742 molecule acc: 0.6995582580566406
---> kl loss: 0.9429604530334472
---> reconstruction loss: 29.141734981536867
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-67-with.npy
loss:  29.500696182250977 0.9319472312927246
loss:  29.314102172851562 0.95635986328125
loss:  29.76049041748047 0.9487207531929016
loss:  29.767681121826172 0.9152669310569763
loss:  29.730037689208984 0.8909730315208435
loss:  30.634550094604492 0.9265877604484558
loss:  29.628183364868164 0.9539182186126709
loss:  29.954486846923828 0.9445981979370117
loss:  30.315290451049805 0.9331616759300232
loss:  29.75480079650879 0.9378288388252258
loss:  29.56599235534668 0.94461989402771
loss:  29.959503173828125 0.939957320690155
loss:  29.44692039489746 0.9582275152206421
loss:  29.9628963470459 0.9699579477310181
loss:  30.16585350036621 0.9530013799667358
loss:  29.639184951782227 0.9585106372833252
loss:  30.722021102905273 0.9867138862609863
loss:  30.25900650024414 0.9669547080993652
loss:  30.172626495361328 0.9750487208366394
loss:  29.499847412109375 0.9146925210952759
*******************Epoch 67 ****************** 1360 1.0
Validation Loss
*** pred loss:  25.18655014038086 pred acc: 0.5862922668457031
*** stop loss:  6.111539363861084 stop acc: 0.9209527373313904
*** template loss:  8.012273788452148 template acc: tensor(0.1133, device='cuda:0')
*** label loss:  6.465824127197266 label acc: tensor(0.3614, device='cuda:0')
Train Loss
---> pred loss: 21.423907470703124 pred acc: 0.6557419925928116
---> stop loss: 4.252230453491211 stop acc: 0.9502602189779281
---> template loss: 1.875817108154297 tempalte acc: 0.6056473731994629
---> molecule label loss: 1.3903990745544434 molecule acc: 0.7060689926147461
---> kl loss: 0.9453522682189941
---> reconstruction loss: 28.942355251312257
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-68-with.npy
loss:  29.67528533935547 0.9759522080421448
loss:  30.41059112548828 0.9775208234786987
loss:  29.835357666015625 0.9400331377983093
loss:  29.355321884155273 0.9187385439872742
loss:  30.210920333862305 0.9402644634246826
loss:  29.541078567504883 0.9384788870811462
loss:  29.954111099243164 0.8977375626564026
loss:  29.65707015991211 0.9507637023925781
loss:  29.930299758911133 0.9459025263786316
loss:  30.299137115478516 0.9423614144325256
loss:  29.908039093017578 0.9344589114189148
loss:  29.952131271362305 0.9478667378425598
loss:  29.7624454498291 0.9274916052818298
loss:  29.938125610351562 0.9856621026992798
loss:  30.283002853393555 0.9605876207351685
loss:  29.722274780273438 0.9705289602279663
loss:  29.798898696899414 0.9673323631286621
loss:  29.769277572631836 0.9654618501663208
loss:  29.31304359436035 0.9882583022117615
loss:  29.801044464111328 0.9039273262023926
*******************Epoch 68 ****************** 1380 1.0
Validation Loss
*** pred loss:  25.23845863342285 pred acc: 0.582608699798584
*** stop loss:  6.693957805633545 stop acc: 0.91310715675354
*** template loss:  8.070818901062012 template acc: tensor(0.1031, device='cuda:0')
*** label loss:  6.452270030975342 label acc: tensor(0.3374, device='cuda:0')
Train Loss
---> pred loss: 21.413743591308595 pred acc: 0.6550704091787338
---> stop loss: 4.276579666137695 stop acc: 0.9497060418128968
---> template loss: 1.8534759521484374 tempalte acc: 0.6107206821441651
---> molecule label loss: 1.3631087303161622 molecule acc: 0.710031795501709
---> kl loss: 0.9489664077758789
---> reconstruction loss: 28.90690517425537
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-69-with.npy
loss:  29.76309585571289 0.9840531945228577
loss:  30.00615882873535 0.9655255079269409
loss:  29.53565216064453 0.9684150815010071
loss:  29.385690689086914 0.9551092386245728
loss:  29.948802947998047 0.9709582924842834
loss:  29.89044761657715 0.9748054146766663
loss:  30.295730590820312 0.9582152366638184
loss:  29.76048469543457 0.9734561443328857
loss:  29.670366287231445 0.9436753988265991
loss:  29.620933532714844 0.950760543346405
loss:  30.517934799194336 0.9499868154525757
loss:  30.1246337890625 0.9522391557693481
loss:  29.5048828125 0.940354585647583
loss:  29.819515228271484 0.9352924823760986
loss:  29.87952995300293 0.8854233026504517
loss:  29.858421325683594 0.9512112140655518
loss:  30.071712493896484 0.9208360910415649
loss:  29.60205078125 0.9136741161346436
loss:  29.644474029541016 0.9552129507064819
loss:  29.053850173950195 0.9578308463096619
*******************Epoch 69 ****************** 1400 1.0
Validation Loss
*** pred loss:  25.2069034576416 pred acc: 0.5874395966529846
*** stop loss:  5.858521461486816 stop acc: 0.925000011920929
*** template loss:  8.053681373596191 template acc: tensor(0.1062, device='cuda:0')
*** label loss:  6.411903381347656 label acc: tensor(0.3443, device='cuda:0')
Train Loss
---> pred loss: 21.31554260253906 pred acc: 0.6575409293174743
---> stop loss: 4.358183670043945 stop acc: 0.9487017035484314
---> template loss: 1.8331893920898437 tempalte acc: 0.6130252838134765
---> molecule label loss: 1.3404529571533204 molecule acc: 0.7129940032958985
---> kl loss: 0.9503517150878906
---> reconstruction loss: 28.84736862182617
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-70-with.npy
loss:  29.45688819885254 0.9221062064170837
loss:  29.570472717285156 0.9152604341506958
loss:  29.510560989379883 0.8997476100921631
loss:  29.498437881469727 0.9232411980628967
loss:  30.159515380859375 0.9393597841262817
loss:  29.213550567626953 0.912388801574707
loss:  29.81314468383789 0.9119271636009216
loss:  29.69231605529785 0.9144276976585388
loss:  29.274221420288086 0.9186736941337585
loss:  30.011640548706055 0.9874171018600464
loss:  29.467243194580078 0.9326895475387573
loss:  29.398902893066406 0.9406254291534424
loss:  29.57220458984375 0.9550326466560364
loss:  29.686758041381836 0.9448301196098328
loss:  29.646282196044922 0.9441034197807312
loss:  29.434541702270508 0.9042171239852905
loss:  29.728727340698242 0.9154872298240662
loss:  29.3592472076416 0.9308110475540161
loss:  29.580549240112305 0.9237125515937805
loss:  30.688547134399414 0.9530124664306641
*******************Epoch 70 ****************** 1420 1.0
Validation Loss
*** pred loss:  25.259702682495117 pred acc: 0.5829105973243713
*** stop loss:  6.251272678375244 stop acc: 0.9190847277641296
*** template loss:  8.076970100402832 template acc: tensor(0.1024, device='cuda:0')
*** label loss:  6.500518321990967 label acc: tensor(0.3674, device='cuda:0')
Train Loss
---> pred loss: 21.346229553222656 pred acc: 0.6574196130037308
---> stop loss: 4.253821182250976 stop acc: 0.9502848982810974
---> template loss: 1.8002490997314453 tempalte acc: 0.6196396827697754
---> molecule label loss: 1.3084324836730956 molecule acc: 0.7182270526885987
---> kl loss: 0.9294534683227539
---> reconstruction loss: 28.708733177185056
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-71-with.npy
loss:  28.943546295166016 0.9175057411193848
loss:  29.594032287597656 0.9365221261978149
loss:  29.64026641845703 0.9636615514755249
loss:  29.563154220581055 0.9502074122428894
loss:  29.335880279541016 0.9416714906692505
loss:  29.810752868652344 0.9427880644798279
loss:  29.655000686645508 0.9489293694496155
loss:  29.6431884765625 0.946651041507721
loss:  29.49239158630371 0.9506375789642334
loss:  29.713674545288086 0.9530565142631531
loss:  29.350595474243164 0.9403702020645142
loss:  29.100711822509766 0.8805093169212341
loss:  29.792335510253906 0.9253702163696289
loss:  29.70878028869629 0.9566768407821655
loss:  29.8807373046875 0.9369054436683655
loss:  29.28327178955078 0.8931751847267151
loss:  29.617351531982422 0.9504046440124512
loss:  29.144128799438477 0.9180535078048706
loss:  29.929277420043945 0.9560946226119995
loss:  29.34673309326172 0.9351141452789307
*******************Epoch 71 ****************** 1440 1.0
Validation Loss
*** pred loss:  25.205421447753906 pred acc: 0.5835748910903931
*** stop loss:  6.019434928894043 stop acc: 0.9215442538261414
*** template loss:  8.111827850341797 template acc: tensor(0.1034, device='cuda:0')
*** label loss:  6.497067928314209 label acc: tensor(0.3573, device='cuda:0')
Train Loss
---> pred loss: 21.259474182128905 pred acc: 0.6584625154733658
---> stop loss: 4.258718109130859 stop acc: 0.9503389209508896
---> template loss: 1.788821029663086 tempalte acc: 0.6239465713500977
---> molecule label loss: 1.2830619812011719 molecule acc: 0.722327184677124
---> kl loss: 0.9372152328491211
---> reconstruction loss: 28.590073585510254
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-72-with.npy
loss:  29.034269332885742 0.9636905193328857
loss:  29.117778778076172 0.9555791020393372
loss:  29.430713653564453 0.9187737107276917
loss:  29.878904342651367 0.9521117210388184
loss:  29.768728256225586 0.940704882144928
loss:  29.238746643066406 0.9366019368171692
loss:  29.3629093170166 0.9283382296562195
loss:  29.233409881591797 0.9635072350502014
loss:  29.612953186035156 0.9278123378753662
loss:  29.34564208984375 0.9074550271034241
loss:  28.94878387451172 0.9251755475997925
loss:  29.515913009643555 0.9159550666809082
loss:  29.659894943237305 0.9230566620826721
loss:  29.429933547973633 0.929642379283905
loss:  29.198623657226562 0.9127615094184875
loss:  29.036577224731445 0.9090545177459717
loss:  29.329893112182617 0.9354148507118225
loss:  29.40764045715332 0.9253536462783813
loss:  29.05640411376953 0.9103654623031616
loss:  28.201072692871094 0.8762086033821106
*******************Epoch 72 ****************** 1460 1.0
Validation Loss
*** pred loss:  25.256662368774414 pred acc: 0.588707685470581
*** stop loss:  5.891071796417236 stop acc: 0.9226961731910706
*** template loss:  8.07596206665039 template acc: tensor(0.1119, device='cuda:0')
*** label loss:  6.44189977645874 label acc: tensor(0.3519, device='cuda:0')
Train Loss
---> pred loss: 21.154501342773436 pred acc: 0.6593547523021698
---> stop loss: 4.191188049316406 stop acc: 0.9511965960264206
---> template loss: 1.7693862915039062 tempalte acc: 0.6236315250396729
---> molecule label loss: 1.2474851608276367 molecule acc: 0.7296554565429687
---> kl loss: 0.9278782844543457
---> reconstruction loss: 28.362560558319093
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-73-with.npy
loss:  29.228612899780273 0.9335933327674866
loss:  29.244403839111328 0.934154212474823
loss:  29.25556182861328 0.9410956501960754
loss:  29.428264617919922 0.9278674125671387
loss:  29.091297149658203 0.9173593521118164
loss:  29.549095153808594 0.9319180250167847
loss:  29.08289337158203 0.9281327724456787
loss:  28.929676055908203 0.9238938689231873
loss:  29.590068817138672 0.9234393835067749
loss:  28.97045135498047 0.9268375039100647
loss:  29.125768661499023 0.9167537093162537
loss:  28.547691345214844 0.9106242060661316
loss:  28.83102035522461 0.9041807651519775
loss:  29.2149658203125 0.9423332214355469
loss:  29.360780715942383 0.9429561495780945
loss:  29.466880798339844 0.9430661201477051
loss:  28.968551635742188 0.9185428023338318
loss:  29.69655990600586 0.9319448471069336
loss:  29.49600601196289 0.9395573735237122
loss:  29.098669052124023 0.8877342343330383
*******************Epoch 73 ****************** 1480 1.0
Validation Loss
*** pred loss:  25.209129333496094 pred acc: 0.5897342562675476
*** stop loss:  5.974741458892822 stop acc: 0.9231942892074585
*** template loss:  8.086368560791016 template acc: tensor(0.1154, device='cuda:0')
*** label loss:  6.492223262786865 label acc: tensor(0.3566, device='cuda:0')
Train Loss
---> pred loss: 21.176542663574217 pred acc: 0.659536463022232
---> stop loss: 4.150162887573242 stop acc: 0.9516958147287369
---> template loss: 1.7345342636108398 tempalte acc: 0.6308799266815186
---> molecule label loss: 1.221322250366211 molecule acc: 0.7342307090759277
---> kl loss: 0.9262991905212402
---> reconstruction loss: 28.28256311416626
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-74-with.npy
loss:  29.013166427612305 0.9246919751167297
loss:  28.901838302612305 0.9165975451469421
loss:  29.011890411376953 0.9412748217582703
loss:  29.115341186523438 0.9518091678619385
loss:  28.839588165283203 0.9437289834022522
loss:  28.949281692504883 0.9435359835624695
loss:  28.894817352294922 0.9547408819198608
loss:  29.394346237182617 0.9171618819236755
loss:  29.182117462158203 0.9279240965843201
loss:  29.235803604125977 0.9239538908004761
loss:  29.27240562438965 0.9114935398101807
loss:  29.28775978088379 0.9249370098114014
loss:  28.511552810668945 0.9256901741027832
loss:  29.48515510559082 0.9212440252304077
loss:  29.153345108032227 0.8996665477752686
loss:  29.275741577148438 0.9250678420066833
loss:  29.510650634765625 0.9449650049209595
loss:  29.50043296813965 0.925784170627594
loss:  29.1466007232666 0.9309831857681274
loss:  29.099916458129883 1.009962558746338
*******************Epoch 74 ****************** 1500 1.0
Validation Loss
*** pred loss:  25.201208114624023 pred acc: 0.5867753624916077
*** stop loss:  6.058125019073486 stop acc: 0.9213574528694153
*** template loss:  8.064064025878906 template acc: tensor(0.1182, device='cuda:0')
*** label loss:  6.480775833129883 label acc: tensor(0.3575, device='cuda:0')
Train Loss
---> pred loss: 21.0959716796875 pred acc: 0.6610520511865616
---> stop loss: 4.16375503540039 stop acc: 0.9518372476100921
---> template loss: 1.7278398513793944 tempalte acc: 0.6332301616668701
---> molecule label loss: 1.2182581901550293 molecule acc: 0.7348821640014649
---> kl loss: 0.9332606315612793
---> reconstruction loss: 28.205829334259032
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-75-with.npy
loss:  28.683551788330078 0.9424481987953186
loss:  29.31340789794922 0.9604784846305847
loss:  28.880176544189453 0.892468273639679
loss:  29.3094425201416 0.9518179893493652
loss:  29.24237823486328 0.9486991167068481
loss:  28.9827880859375 0.9272044897079468
loss:  29.12506866455078 0.9362947344779968
loss:  28.890392303466797 0.9099712371826172
loss:  29.245895385742188 0.9022443294525146
loss:  29.039857864379883 0.9294009804725647
loss:  29.204620361328125 0.9264978170394897
loss:  29.294240951538086 0.9283689856529236
loss:  29.3344783782959 0.9321319460868835
loss:  28.85161018371582 0.9319683909416199
loss:  29.633377075195312 0.9267083406448364
loss:  28.67327308654785 0.9180359244346619
loss:  28.649141311645508 0.9495371580123901
loss:  28.49749183654785 0.9357872009277344
loss:  28.60859489440918 0.9369328618049622
loss:  29.233049392700195 0.9549632668495178
*******************Epoch 75 ****************** 1520 1.0
Validation Loss
*** pred loss:  25.268598556518555 pred acc: 0.5860506892204285
*** stop loss:  5.942219257354736 stop acc: 0.9229763746261597
*** template loss:  8.053866386413574 template acc: tensor(0.1147, device='cuda:0')
*** label loss:  6.496717929840088 label acc: tensor(0.3579, device='cuda:0')
Train Loss
---> pred loss: 21.084451293945314 pred acc: 0.6613549411296844
---> stop loss: 4.1243408203125 stop acc: 0.9521288216114044
---> template loss: 1.7065982818603516 tempalte acc: 0.6385233879089356
---> molecule label loss: 1.1871514320373535 molecule acc: 0.7408138275146484
---> kl loss: 0.9320980072021484
---> reconstruction loss: 28.102542495727537
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-76-with.npy
loss:  28.712717056274414 0.9351592063903809
loss:  29.526390075683594 0.9965484738349915
loss:  28.6920108795166 0.9511388540267944
loss:  29.570148468017578 0.9544828534126282
loss:  29.125995635986328 0.9624451398849487
loss:  28.874656677246094 0.9569112062454224
loss:  29.247272491455078 0.9431225061416626
loss:  28.498579025268555 0.9458452463150024
loss:  28.83722686767578 0.9506863355636597
loss:  29.402454376220703 0.9538004994392395
loss:  28.981586456298828 0.9495224356651306
loss:  28.773073196411133 0.9550238847732544
loss:  28.78926658630371 0.9322268962860107
loss:  29.080759048461914 0.9119306802749634
loss:  28.75638198852539 0.900449275970459
loss:  28.954130172729492 0.9173714518547058
loss:  29.538986206054688 0.9012524485588074
loss:  28.77688980102539 0.9092698097229004
loss:  28.871339797973633 0.9170053005218506
loss:  30.2174072265625 0.9027863144874573
*******************Epoch 76 ****************** 1540 1.0
Validation Loss
*** pred loss:  25.347293853759766 pred acc: 0.5825483202934265
*** stop loss:  5.905969619750977 stop acc: 0.9229763746261597
*** template loss:  8.142487525939941 template acc: tensor(0.1080, device='cuda:0')
*** label loss:  6.535431861877441 label acc: tensor(0.3545, device='cuda:0')
Train Loss
---> pred loss: 21.050985717773436 pred acc: 0.6612095355987548
---> stop loss: 4.193585205078125 stop acc: 0.951165235042572
---> template loss: 1.7126264572143555 tempalte acc: 0.6360767841339111
---> molecule label loss: 1.1668190956115723 molecule acc: 0.7447329044342041
---> kl loss: 0.9373489379882812
---> reconstruction loss: 28.12401580810547
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-77-with.npy
loss:  28.65336036682129 0.9266360998153687
loss:  28.970226287841797 0.9461695551872253
loss:  28.881954193115234 0.9402269721031189
loss:  28.692516326904297 0.9327393770217896
loss:  29.280746459960938 0.9591085910797119
loss:  28.587825775146484 0.9120283722877502
loss:  28.687135696411133 0.9385151267051697
loss:  29.193443298339844 0.9499236345291138
loss:  29.200397491455078 0.9580346345901489
loss:  28.23702621459961 0.9571995735168457
loss:  29.494718551635742 0.9609747529029846
loss:  28.949337005615234 0.927891731262207
loss:  28.906265258789062 0.9397421479225159
loss:  28.71432876586914 0.9168713092803955
loss:  28.800067901611328 0.9079105257987976
loss:  28.862926483154297 0.9127932190895081
loss:  29.13784408569336 0.972129225730896
loss:  29.01418113708496 0.9101365804672241
loss:  28.84596824645996 0.9131419658660889
loss:  30.69991683959961 0.9268227219581604
*******************Epoch 77 ****************** 1560 1.0
Validation Loss
*** pred loss:  25.317975997924805 pred acc: 0.5872584581375122
*** stop loss:  6.346080780029297 stop acc: 0.9188356399536133
*** template loss:  8.070171356201172 template acc: tensor(0.1119, device='cuda:0')
*** label loss:  6.466641902923584 label acc: tensor(0.3551, device='cuda:0')
Train Loss
---> pred loss: 21.0317138671875 pred acc: 0.6630565673112869
---> stop loss: 4.159955215454102 stop acc: 0.951938709616661
---> template loss: 1.7032697677612305 tempalte acc: 0.6378091335296631
---> molecule label loss: 1.160120677947998 molecule acc: 0.7431239604949951
---> kl loss: 0.9354496955871582
---> reconstruction loss: 28.055059337615965
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-78-with.npy
loss:  28.791614532470703 0.9476487636566162
loss:  28.546737670898438 0.9316596388816833
loss:  29.037639617919922 0.9541765451431274
loss:  28.539392471313477 0.9805049896240234
loss:  28.779830932617188 0.9715889692306519
loss:  29.002286911010742 0.9708570837974548
loss:  28.950475692749023 0.9628816843032837
loss:  28.527494430541992 0.9044710993766785
loss:  29.000730514526367 0.9224677085876465
loss:  28.883590698242188 0.9170044660568237
loss:  28.6905460357666 0.9484330415725708
loss:  28.900239944458008 0.9547970294952393
loss:  28.567359924316406 0.9254693984985352
loss:  29.04978370666504 0.962706446647644
loss:  28.964757919311523 0.9352062344551086
loss:  28.879722595214844 0.9636795520782471
loss:  28.729185104370117 0.9471893310546875
loss:  28.63811492919922 0.9518731236457825
loss:  28.908397674560547 0.9402373433113098
loss:  29.277341842651367 0.9924915432929993
*******************Epoch 78 ****************** 1580 1.0
Validation Loss
*** pred loss:  25.239398956298828 pred acc: 0.587077260017395
*** stop loss:  5.87933874130249 stop acc: 0.9235056638717651
*** template loss:  8.185534477233887 template acc: tensor(0.1090, device='cuda:0')
*** label loss:  6.5013628005981445 label acc: tensor(0.3592, device='cuda:0')
Train Loss
---> pred loss: 20.948141479492186 pred acc: 0.6634342640638351
---> stop loss: 4.138823699951172 stop acc: 0.9519120842218399
---> template loss: 1.6660821914672852 tempalte acc: 0.646434736251831
---> molecule label loss: 1.1309473991394043 molecule acc: 0.7502492904663086
---> kl loss: 0.9492671966552735
---> reconstruction loss: 27.883993911743165
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-79-with.npy
loss:  29.283519744873047 0.9265002012252808
loss:  28.64081573486328 0.9196544289588928
loss:  28.7900447845459 0.9494931697845459
loss:  28.58693504333496 0.8939191102981567
loss:  28.81114387512207 0.8992894887924194
loss:  28.928024291992188 0.8885189890861511
loss:  28.15033531188965 0.8892637491226196
loss:  28.655601501464844 0.88496333360672
loss:  28.995454788208008 0.9300069212913513
loss:  28.608606338500977 0.9371275305747986
loss:  28.990076065063477 0.9277640581130981
loss:  29.169353485107422 0.9247755408287048
loss:  28.586578369140625 0.908239483833313
loss:  28.2974853515625 0.8908186554908752
loss:  28.704364776611328 0.9188280701637268
loss:  28.634410858154297 0.9244115948677063
loss:  28.23758316040039 0.9248142838478088
loss:  28.491361618041992 0.9140922427177429
loss:  28.586856842041016 0.9356705546379089
loss:  27.779659271240234 0.9055502414703369
*******************Epoch 79 ****************** 1600 1.0
Validation Loss
*** pred loss:  25.378162384033203 pred acc: 0.583152174949646
*** stop loss:  6.007399559020996 stop acc: 0.923132061958313
*** template loss:  8.127202987670898 template acc: tensor(0.1090, device='cuda:0')
*** label loss:  6.49833345413208 label acc: tensor(0.3532, device='cuda:0')
Train Loss
---> pred loss: 20.855970764160155 pred acc: 0.6637137830257416
---> stop loss: 4.074621963500976 stop acc: 0.9523709416389465
---> template loss: 1.6709449768066407 tempalte acc: 0.6425412654876709
---> molecule label loss: 1.1301865577697754 molecule acc: 0.7500442504882813
---> kl loss: 0.91468505859375
---> reconstruction loss: 27.731723022460937
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-80-with.npy
loss:  28.700693130493164 0.9508224725723267
loss:  28.653989791870117 0.9158501029014587
loss:  28.324291229248047 0.8932486176490784
loss:  28.32765007019043 0.9266032576560974
loss:  28.726181030273438 0.9376257658004761
loss:  28.879789352416992 0.9248336553573608
loss:  28.860631942749023 0.9374470710754395
loss:  28.368545532226562 0.9245314002037048
loss:  28.08478546142578 0.912857174873352
loss:  28.39460563659668 0.9197953343391418
loss:  28.328420639038086 0.9196429252624512
loss:  28.607250213623047 0.9231870174407959
loss:  28.94045639038086 0.9455136060714722
loss:  28.146827697753906 0.9283918142318726
loss:  28.815868377685547 0.9261634945869446
loss:  28.28830337524414 0.9260669350624084
loss:  28.52737045288086 0.9143902063369751
loss:  28.721410751342773 0.9435067772865295
loss:  28.7043399810791 0.9350965023040771
loss:  28.390207290649414 0.9109311699867249
*******************Epoch 80 ****************** 1620 1.0
Validation Loss
*** pred loss:  25.308149337768555 pred acc: 0.5834540724754333
*** stop loss:  5.896049499511719 stop acc: 0.9229452610015869
*** template loss:  8.144328117370605 template acc: tensor(0.1115, device='cuda:0')
*** label loss:  6.518019676208496 label acc: tensor(0.3558, device='cuda:0')
Train Loss
---> pred loss: 20.844287109375 pred acc: 0.6627562999725342
---> stop loss: 4.0556598663330075 stop acc: 0.952998673915863
---> template loss: 1.6169166564941406 tempalte acc: 0.6552403450012207
---> molecule label loss: 1.0968918800354004 molecule acc: 0.7565369606018066
---> kl loss: 0.9258253097534179
---> reconstruction loss: 27.613752937316896
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-81-with.npy
loss:  27.919628143310547 0.91636723279953
loss:  28.61518669128418 0.9511789083480835
loss:  28.887365341186523 0.9606630802154541
loss:  28.028715133666992 0.9302535653114319
loss:  28.58474349975586 0.9713690876960754
loss:  29.134241104125977 0.9467881321907043
loss:  28.324064254760742 0.926641583442688
loss:  28.46454429626465 0.9279459714889526
loss:  28.457233428955078 0.9343066811561584
loss:  28.640357971191406 0.9509921073913574
loss:  28.630720138549805 0.9429690837860107
loss:  28.544723510742188 0.943088948726654
loss:  28.066577911376953 0.9473532438278198
loss:  28.56211280822754 0.9338023066520691
loss:  28.168779373168945 0.9212262034416199
loss:  28.355064392089844 0.9346367120742798
loss:  28.272830963134766 0.9280354380607605
loss:  28.592601776123047 0.9478957653045654
loss:  28.610458374023438 0.9117239713668823
loss:  28.093994140625 0.8958922028541565
*******************Epoch 81 ****************** 1640 1.0
Validation Loss
*** pred loss:  25.194032669067383 pred acc: 0.5884661674499512
*** stop loss:  6.108042240142822 stop acc: 0.9206725358963013
*** template loss:  8.143014907836914 template acc: tensor(0.1076, device='cuda:0')
*** label loss:  6.567626476287842 label acc: tensor(0.3704, device='cuda:0')
Train Loss
---> pred loss: 20.76393280029297 pred acc: 0.666123804450035
---> stop loss: 4.049156951904297 stop acc: 0.953303012251854
---> template loss: 1.6274700164794922 tempalte acc: 0.6499592304229737
---> molecule label loss: 1.0709792137145997 molecule acc: 0.760804271697998
---> kl loss: 0.9361565589904786
---> reconstruction loss: 27.511542415618894
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-82-with.npy
loss:  28.132925033569336 0.9593555331230164
loss:  28.968095779418945 0.9351908564567566
loss:  28.63319969177246 0.9358696937561035
loss:  28.475147247314453 0.9272653460502625
loss:  28.45758056640625 0.9269742965698242
loss:  28.400165557861328 0.9416904449462891
loss:  28.764141082763672 0.9597414135932922
loss:  28.52322006225586 0.9724317193031311
loss:  28.370126724243164 0.9573474526405334
loss:  28.60173988342285 0.9520517587661743
loss:  27.976051330566406 0.9666426777839661
loss:  28.295454025268555 0.9574025869369507
loss:  28.297637939453125 0.9119892716407776
loss:  28.583248138427734 0.9243406057357788
loss:  27.836286544799805 0.9296540021896362
loss:  28.29072380065918 0.9077491760253906
loss:  28.245685577392578 0.9223410487174988
loss:  28.122241973876953 0.9011570811271667
loss:  28.639883041381836 0.9303798079490662
loss:  26.619277954101562 0.8177837133407593
*******************Epoch 82 ****************** 1660 1.0
Validation Loss
*** pred loss:  25.347787857055664 pred acc: 0.5856884121894836
*** stop loss:  6.019388198852539 stop acc: 0.9233188629150391
*** template loss:  8.169032096862793 template acc: tensor(0.1129, device='cuda:0')
*** label loss:  6.510902404785156 label acc: tensor(0.3543, device='cuda:0')
Train Loss
---> pred loss: 20.699807739257814 pred acc: 0.6661985844373703
---> stop loss: 4.0386199951171875 stop acc: 0.9532023757696152
---> template loss: 1.5979244232177734 tempalte acc: 0.6570339202880859
---> molecule label loss: 1.0434208869934083 molecule acc: 0.7662450313568115
---> kl loss: 0.9318678855895997
---> reconstruction loss: 27.379771518707276
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-83-with.npy
loss:  27.331645965576172 0.9104088544845581
loss:  28.112035751342773 0.9430295825004578
loss:  28.226696014404297 0.9452486038208008
loss:  27.93260955810547 0.9352788925170898
loss:  28.341976165771484 0.9174443483352661
loss:  28.138002395629883 0.8804042339324951
loss:  28.508407592773438 0.9050207138061523
loss:  28.528032302856445 0.9162312150001526
loss:  28.66103744506836 0.950744092464447
loss:  28.04545783996582 0.9268841743469238
loss:  28.09355354309082 0.918547511100769
loss:  28.143657684326172 0.9114781022071838
loss:  28.865684509277344 0.9208062291145325
loss:  28.2740478515625 0.9628934860229492
loss:  28.29376983642578 0.9514751434326172
loss:  28.053997039794922 0.9459972381591797
loss:  28.537277221679688 0.9041562676429749
loss:  28.359159469604492 0.9305537939071655
loss:  28.223352432250977 0.911083459854126
loss:  28.147960662841797 0.8828104734420776
*******************Epoch 83 ****************** 1680 1.0
Validation Loss
*** pred loss:  25.38030242919922 pred acc: 0.5852053165435791
*** stop loss:  5.896876811981201 stop acc: 0.9239414930343628
*** template loss:  8.128683090209961 template acc: tensor(0.1164, device='cuda:0')
*** label loss:  6.534679412841797 label acc: tensor(0.3599, device='cuda:0')
Train Loss
---> pred loss: 20.682244873046876 pred acc: 0.666617351770401
---> stop loss: 4.030485534667969 stop acc: 0.9532634496688843
---> template loss: 1.5737483024597168 tempalte acc: 0.6607401847839356
---> molecule label loss: 1.0309130668640136 molecule acc: 0.7690148830413819
---> kl loss: 0.9235247611999512
---> reconstruction loss: 27.31739320755005
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-84-with.npy
loss:  28.274045944213867 0.9551824331283569
loss:  27.873329162597656 0.919542670249939
loss:  28.36151885986328 0.9374967813491821
loss:  28.03333282470703 0.9201309084892273
loss:  28.18966293334961 0.9149814248085022
loss:  27.955732345581055 0.9256444573402405
loss:  28.73974609375 0.9503895044326782
loss:  28.269886016845703 0.9094001054763794
loss:  28.321792602539062 0.929355263710022
loss:  28.107444763183594 0.9056721329689026
loss:  28.412187576293945 0.88890141248703
loss:  27.852201461791992 0.8980889320373535
loss:  28.162673950195312 0.9283676743507385
loss:  28.30830192565918 0.917893648147583
loss:  28.088512420654297 0.8971124887466431
loss:  28.11054039001465 0.9361202120780945
loss:  28.404569625854492 0.9696633815765381
loss:  28.59772300720215 0.9446055889129639
loss:  28.049739837646484 0.9362068772315979
loss:  29.325014114379883 0.9530156850814819
*******************Epoch 84 ****************** 1700 1.0
Validation Loss
*** pred loss:  25.22431182861328 pred acc: 0.5867753624916077
*** stop loss:  6.35082483291626 stop acc: 0.9183375239372253
*** template loss:  8.133838653564453 template acc: tensor(0.1108, device='cuda:0')
*** label loss:  6.625229358673096 label acc: tensor(0.3684, device='cuda:0')
Train Loss
---> pred loss: 20.724571228027344 pred acc: 0.6667942881584168
---> stop loss: 4.043972015380859 stop acc: 0.9535964071750641
---> template loss: 1.5660273551940918 tempalte acc: 0.6632243633270264
---> molecule label loss: 1.0104392051696778 molecule acc: 0.7736005783081055
---> kl loss: 0.9268886566162109
---> reconstruction loss: 27.345007705688477
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-85-with.npy
loss:  28.526350021362305 0.9512758851051331
loss:  28.187633514404297 0.9422966241836548
loss:  28.48406219482422 0.9449079632759094
loss:  28.098581314086914 0.9734833240509033
loss:  28.422883987426758 0.9507419466972351
loss:  28.393152236938477 0.9338775873184204
loss:  28.571399688720703 0.9518037438392639
loss:  28.417707443237305 0.9584670066833496
loss:  27.629335403442383 0.912542998790741
loss:  27.89029884338379 0.9350405335426331
loss:  27.991689682006836 0.9230471253395081
loss:  28.00922203063965 0.9397441148757935
loss:  27.899351119995117 0.9248669147491455
loss:  27.860137939453125 0.9337950944900513
loss:  27.97112464904785 0.9192790985107422
loss:  28.028827667236328 0.9248665571212769
loss:  28.26325798034668 0.957828164100647
loss:  28.47791290283203 0.9537465572357178
loss:  27.956329345703125 0.9222848415374756
loss:  28.475830078125 0.9214621186256409
*******************Epoch 85 ****************** 1720 1.0
Validation Loss
*** pred loss:  25.356752395629883 pred acc: 0.5825483202934265
*** stop loss:  6.209818363189697 stop acc: 0.9200498461723328
*** template loss:  8.164667129516602 template acc: tensor(0.1189, device='cuda:0')
*** label loss:  6.6278462409973145 label acc: tensor(0.3735, device='cuda:0')
Train Loss
---> pred loss: 20.664678955078124 pred acc: 0.666770139336586
---> stop loss: 4.047616958618164 stop acc: 0.9528753995895386
---> template loss: 1.5406792640686036 tempalte acc: 0.6668796062469482
---> molecule label loss: 0.9860134124755859 molecule acc: 0.7766220092773437
---> kl loss: 0.9387679100036621
---> reconstruction loss: 27.238984775543212
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-86-with.npy
loss:  27.9722900390625 0.9297695159912109
loss:  27.915639877319336 0.934313178062439
loss:  28.15072250366211 0.9556179642677307
loss:  28.42366600036621 0.9381905198097229
loss:  28.14750099182129 0.9296558499336243
loss:  28.295747756958008 0.9349390864372253
loss:  28.212913513183594 0.9218805432319641
loss:  28.50602912902832 0.929510235786438
loss:  28.152917861938477 0.9308136105537415
loss:  27.598064422607422 0.9321984648704529
loss:  27.397315979003906 0.9523342251777649
loss:  27.99093246459961 0.9083129167556763
loss:  28.30501365661621 0.953173041343689
loss:  27.901622772216797 0.9184261560440063
loss:  28.156871795654297 0.9234170913696289
loss:  27.493877410888672 0.930012047290802
loss:  28.462671279907227 0.9482858180999756
loss:  27.936939239501953 0.9287578463554382
loss:  28.336748123168945 0.9478495717048645
loss:  27.360774993896484 0.987350344657898
*******************Epoch 86 ****************** 1740 1.0
Validation Loss
*** pred loss:  25.437915802001953 pred acc: 0.5832729339599609
*** stop loss:  6.049203395843506 stop acc: 0.9227895736694336
*** template loss:  8.159062385559082 template acc: tensor(0.1171, device='cuda:0')
*** label loss:  6.627382755279541 label acc: tensor(0.3387, device='cuda:0')
Train Loss
---> pred loss: 20.546820068359374 pred acc: 0.6692680686712265
---> stop loss: 4.044819641113281 stop acc: 0.9530791878700257
---> template loss: 1.5262271881103515 tempalte acc: 0.6690573692321777
---> molecule label loss: 0.9813061714172363 molecule acc: 0.7764182567596436
---> kl loss: 0.9367403984069824
---> reconstruction loss: 27.09917268753052
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-87-with.npy
loss:  28.19385528564453 0.9301175475120544
loss:  27.806060791015625 0.8997882008552551
loss:  28.10990333557129 0.9126368761062622
loss:  28.0106258392334 0.9202055931091309
loss:  27.895200729370117 0.9041784405708313
loss:  28.04270362854004 0.9095931649208069
loss:  28.218786239624023 0.9060808420181274
loss:  28.374162673950195 0.8881587982177734
loss:  27.906888961791992 0.9073505997657776
loss:  27.909198760986328 0.9120309948921204
loss:  27.800655364990234 0.9013288021087646
loss:  28.033275604248047 0.9271818995475769
loss:  28.22743797302246 0.9419600963592529
loss:  28.157909393310547 0.9352797269821167
loss:  28.154563903808594 0.9268624186515808
loss:  27.806987762451172 0.9104924201965332
loss:  27.952009201049805 0.9341666102409363
loss:  28.192123413085938 0.9196084141731262
loss:  28.442073822021484 0.932188093662262
loss:  27.24798011779785 0.9397081732749939
*******************Epoch 87 ****************** 1760 1.0
Validation Loss
*** pred loss:  25.28790855407715 pred acc: 0.5853864550590515
*** stop loss:  5.969645023345947 stop acc: 0.923132061958313
*** template loss:  8.140361785888672 template acc: tensor(0.1122, device='cuda:0')
*** label loss:  6.597833156585693 label acc: tensor(0.3496, device='cuda:0')
Train Loss
---> pred loss: 20.490640258789064 pred acc: 0.6694551140069962
---> stop loss: 4.009538650512695 stop acc: 0.9538377821445465
---> template loss: 1.5753173828125 tempalte acc: 0.658070182800293
---> molecule label loss: 1.0306764602661134 molecule acc: 0.7629072189331054
---> kl loss: 0.9179459571838379
---> reconstruction loss: 27.10617208480835
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-88-with.npy
loss:  28.0081844329834 0.9420396089553833
loss:  28.154434204101562 0.9334615468978882
loss:  28.297588348388672 0.9317438006401062
loss:  28.117477416992188 0.9229857921600342
loss:  28.30103302001953 0.9413719177246094
loss:  27.804677963256836 0.9378724694252014
loss:  27.536832809448242 0.919390857219696
loss:  28.16963005065918 0.9209921360015869
loss:  28.109485626220703 0.9119719862937927
loss:  28.457801818847656 0.9575033187866211
loss:  27.837432861328125 0.8958362340927124
loss:  27.589418411254883 0.9281546473503113
loss:  28.057409286499023 0.9291314482688904
loss:  27.99734878540039 0.9536290168762207
loss:  27.876907348632812 0.9374971389770508
loss:  27.790943145751953 0.9189255833625793
loss:  27.78182029724121 0.9286481738090515
loss:  27.696687698364258 0.9448336362838745
loss:  27.348594665527344 0.9167594909667969
loss:  29.032474517822266 0.889237642288208
*******************Epoch 88 ****************** 1780 1.0
Validation Loss
*** pred loss:  25.377079010009766 pred acc: 0.5855675935745239
*** stop loss:  6.09243631362915 stop acc: 0.9226650595664978
*** template loss:  8.228721618652344 template acc: tensor(0.1157, device='cuda:0')
*** label loss:  6.5687150955200195 label acc: tensor(0.3596, device='cuda:0')
Train Loss
---> pred loss: 20.539434814453124 pred acc: 0.6692325919866562
---> stop loss: 3.9923938751220702 stop acc: 0.953684675693512
---> template loss: 1.5576343536376953 tempalte acc: 0.6639279842376709
---> molecule label loss: 0.9807475090026856 molecule acc: 0.7733353614807129
---> kl loss: 0.9280993461608886
---> reconstruction loss: 27.070209980010986
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-89-with.npy
loss:  27.98058319091797 0.9550410509109497
loss:  28.036123275756836 0.9461415410041809
loss:  28.221580505371094 0.942974865436554
loss:  27.601184844970703 0.9125657677650452
loss:  28.064132690429688 0.9574248790740967
loss:  28.14206886291504 0.9238685965538025
loss:  27.695566177368164 0.9044554233551025
loss:  27.193761825561523 0.9489121437072754
loss:  28.20306396484375 0.9096185564994812
loss:  27.814542770385742 0.9048987627029419
loss:  27.725141525268555 0.9212605953216553
loss:  27.52419090270996 0.9297896027565002
loss:  27.69414710998535 0.9026955962181091
loss:  27.999910354614258 0.9032662510871887
loss:  27.29157066345215 0.9357962608337402
loss:  28.175636291503906 0.9071298837661743
loss:  27.78472900390625 0.922450065612793
loss:  27.64818000793457 0.9202096462249756
loss:  27.582870483398438 0.9034739136695862
loss:  27.17047119140625 0.9612328410148621
*******************Epoch 89 ****************** 1800 1.0
Validation Loss
*** pred loss:  25.472434997558594 pred acc: 0.5856884121894836
*** stop loss:  6.04488468170166 stop acc: 0.9222602844238281
*** template loss:  8.141538619995117 template acc: tensor(0.1157, device='cuda:0')
*** label loss:  6.639254093170166 label acc: tensor(0.3718, device='cuda:0')
Train Loss
---> pred loss: 20.42272491455078 pred acc: 0.6692271381616592
---> stop loss: 3.9877410888671876 stop acc: 0.9536960244178772
---> template loss: 1.5072486877441407 tempalte acc: 0.6750153064727783
---> molecule label loss: 0.9340962409973145 molecule acc: 0.7871636867523193
---> kl loss: 0.9256604194641114
---> reconstruction loss: 26.85181150436401
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-90-with.npy
loss:  27.818159103393555 0.914995014667511
loss:  27.488147735595703 0.9127403497695923
loss:  26.993059158325195 0.8954391479492188
loss:  27.39225196838379 0.9014332294464111
loss:  27.848583221435547 0.9119386672973633
loss:  27.83800506591797 0.9121026992797852
loss:  27.366235733032227 0.9105767607688904
loss:  27.839950561523438 0.9036347270011902
loss:  27.873008728027344 0.8773810267448425
loss:  28.299476623535156 0.9036835432052612
loss:  27.840118408203125 0.8910427689552307
loss:  28.0345516204834 0.9093449711799622
loss:  27.722854614257812 0.9375956654548645
loss:  28.039443969726562 0.9277043342590332
loss:  27.669876098632812 0.9175106883049011
loss:  28.09211540222168 0.9281144738197327
loss:  27.986059188842773 0.921212911605835
loss:  27.488073348999023 0.9259184002876282
loss:  27.706501007080078 0.9204630851745605
loss:  28.737089157104492 0.9562210440635681
*******************Epoch 90 ****************** 1820 1.0
Validation Loss
*** pred loss:  25.357742309570312 pred acc: 0.5856280326843262
*** stop loss:  6.052657604217529 stop acc: 0.9233188629150391
*** template loss:  8.212180137634277 template acc: tensor(0.1150, device='cuda:0')
*** label loss:  6.660251617431641 label acc: tensor(0.3646, device='cuda:0')
Train Loss
---> pred loss: 20.468753051757812 pred acc: 0.6706227928400039
---> stop loss: 4.023459625244141 stop acc: 0.9538013190031052
---> template loss: 1.4831913948059081 tempalte acc: 0.6804784297943115
---> molecule label loss: 0.9143211364746093 molecule acc: 0.790516996383667
---> kl loss: 0.91395263671875
---> reconstruction loss: 26.889718627929685
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-91-with.npy
loss:  27.76626968383789 0.9178905487060547
loss:  27.300537109375 0.9425074458122253
loss:  27.911497116088867 0.9466971158981323
loss:  27.575016021728516 0.8947633504867554
loss:  27.47006607055664 0.932643473148346
loss:  27.78903579711914 0.942254364490509
loss:  27.537723541259766 0.9338417649269104
loss:  27.87890625 0.9400210380554199
loss:  27.7312068939209 0.9387179017066956
loss:  27.30606460571289 0.924835741519928
loss:  27.25255012512207 0.9319049715995789
loss:  27.66059684753418 0.9060077667236328
loss:  27.54172134399414 0.9435416460037231
loss:  28.15935707092285 0.987567663192749
loss:  27.74595832824707 0.9429047703742981
loss:  27.884395599365234 0.9336495399475098
loss:  27.742950439453125 0.9482182264328003
loss:  27.717369079589844 0.9376400113105774
loss:  27.119842529296875 0.9086422324180603
loss:  27.42215347290039 1.0231012105941772
*******************Epoch 91 ****************** 1840 1.0
Validation Loss
*** pred loss:  25.35984992980957 pred acc: 0.5878019332885742
*** stop loss:  5.975143909454346 stop acc: 0.9232876896858215
*** template loss:  8.183967590332031 template acc: tensor(0.1122, device='cuda:0')
*** label loss:  6.647993564605713 label acc: tensor(0.3673, device='cuda:0')
Train Loss
---> pred loss: 20.37968292236328 pred acc: 0.6710399001836777
---> stop loss: 3.9504467010498048 stop acc: 0.9544598937034607
---> template loss: 1.4656566619873046 tempalte acc: 0.6831565380096436
---> molecule label loss: 0.8910058021545411 molecule acc: 0.7948600769042968
---> kl loss: 0.9388675689697266
---> reconstruction loss: 26.686794662475585
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-92-with.npy
loss:  27.512393951416016 0.9152066111564636
loss:  27.858396530151367 0.9175912141799927
loss:  27.64380645751953 0.9150628447532654
loss:  27.392988204956055 0.9267686009407043
loss:  27.931367874145508 0.906402587890625
loss:  28.15912628173828 0.9314847588539124
loss:  27.40284538269043 0.9285326600074768
loss:  27.561220169067383 0.9219741225242615
loss:  27.440126419067383 0.9474395513534546
loss:  27.772483825683594 0.948071300983429
loss:  27.63556671142578 0.9217789173126221
loss:  27.30294418334961 0.9428790807723999
loss:  27.060958862304688 0.9157458543777466
loss:  27.823841094970703 0.9196043014526367
loss:  27.691593170166016 0.9158812165260315
loss:  27.132522583007812 0.939224362373352
loss:  27.844831466674805 0.9462164044380188
loss:  27.22181510925293 0.9331185221672058
loss:  27.5771427154541 0.9227114319801331
loss:  27.250532150268555 0.8598996996879578
*******************Epoch 92 ****************** 1860 1.0
Validation Loss
*** pred loss:  25.373641967773438 pred acc: 0.5865941643714905
*** stop loss:  5.98391580581665 stop acc: 0.9217932820320129
*** template loss:  8.19556999206543 template acc: tensor(0.1115, device='cuda:0')
*** label loss:  6.659729957580566 label acc: tensor(0.3701, device='cuda:0')
Train Loss
---> pred loss: 20.351441955566408 pred acc: 0.6724185466766357
---> stop loss: 3.935296630859375 stop acc: 0.954919844865799
---> template loss: 1.4592780113220214 tempalte acc: 0.6834047794342041
---> molecule label loss: 0.8910258293151856 molecule acc: 0.7951724529266357
---> kl loss: 0.9237796783447265
---> reconstruction loss: 26.6370418548584
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-93-with.npy
loss:  27.564760208129883 0.9278358817100525
loss:  27.254770278930664 0.9434257745742798
loss:  26.9772891998291 0.9299646019935608
loss:  27.829435348510742 0.951414942741394
loss:  26.95256805419922 0.9035534262657166
loss:  27.263179779052734 0.9582136273384094
loss:  27.234357833862305 0.9255697131156921
loss:  27.699291229248047 0.9450597763061523
loss:  27.338825225830078 0.898216962814331
loss:  27.72511100769043 0.9037331938743591
loss:  27.732141494750977 0.935373067855835
loss:  27.86773109436035 0.9408449530601501
loss:  27.622648239135742 0.9240290522575378
loss:  27.513355255126953 0.9231030941009521
loss:  27.851318359375 0.9388850331306458
loss:  27.460952758789062 0.8961902260780334
loss:  27.560152053833008 0.908035397529602
loss:  27.75577163696289 0.9164490699768066
loss:  27.395885467529297 0.9146247506141663
loss:  26.59270668029785 0.911134660243988
*******************Epoch 93 ****************** 1880 1.0
Validation Loss
*** pred loss:  25.464481353759766 pred acc: 0.5832125544548035
*** stop loss:  6.120230674743652 stop acc: 0.9224470853805542
*** template loss:  8.182320594787598 template acc: tensor(0.1133, device='cuda:0')
*** label loss:  6.687095642089844 label acc: tensor(0.3562, device='cuda:0')
Train Loss
---> pred loss: 20.267240905761717 pred acc: 0.6739772319793701
---> stop loss: 3.9302616119384766 stop acc: 0.9547438055276871
---> template loss: 1.4585054397583008 tempalte acc: 0.6859383583068848
---> molecule label loss: 0.8788226127624512 molecule acc: 0.7967918395996094
---> kl loss: 0.9247829437255859
---> reconstruction loss: 26.53483009338379
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-94-with.npy
loss:  27.713619232177734 0.9206516742706299
loss:  27.531124114990234 0.9173431396484375
loss:  27.50664710998535 0.9495314359664917
loss:  27.065269470214844 0.954371988773346
loss:  27.32093048095703 0.9284694790840149
loss:  27.720151901245117 0.9536060690879822
loss:  27.399452209472656 0.9518777132034302
loss:  26.946596145629883 0.9662601947784424
loss:  27.18828582763672 0.9005544781684875
loss:  27.716466903686523 0.9284244179725647
loss:  27.74261474609375 0.9334754347801208
loss:  27.371776580810547 0.937785804271698
loss:  27.5462646484375 0.9401045441627502
loss:  27.445188522338867 0.9538642764091492
loss:  27.24222755432129 0.9219524264335632
loss:  28.293188095092773 0.9200598001480103
loss:  27.407711029052734 0.9398230910301208
loss:  27.614009857177734 0.936416745185852
loss:  27.00613784790039 0.9247873425483704
loss:  26.091096878051758 0.9265808463096619
*******************Epoch 94 ****************** 1900 1.0
Validation Loss
*** pred loss:  25.4191837310791 pred acc: 0.584782600402832
*** stop loss:  6.045294761657715 stop acc: 0.9225404858589172
*** template loss:  8.240158081054688 template acc: tensor(0.1157, device='cuda:0')
*** label loss:  6.663256645202637 label acc: tensor(0.3573, device='cuda:0')
Train Loss
---> pred loss: 20.23802947998047 pred acc: 0.6736345291137695
---> stop loss: 3.9074047088623045 stop acc: 0.9550544083118438
---> template loss: 1.4450515747070312 tempalte acc: 0.6856013298034668
---> molecule label loss: 0.8676543235778809 molecule acc: 0.7979537010192871
---> kl loss: 0.9352971076965332
---> reconstruction loss: 26.45814161300659
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-95-with.npy
loss:  27.271934509277344 0.9727035760879517
loss:  27.124235153198242 0.9528135061264038
loss:  27.268173217773438 0.9714441299438477
loss:  27.32135009765625 0.9774506092071533
loss:  27.87523078918457 0.9415225386619568
loss:  27.30484962463379 0.976255476474762
loss:  27.876888275146484 0.975389838218689
loss:  27.209806442260742 0.945358157157898
loss:  27.742782592773438 0.9800978899002075
loss:  27.390865325927734 0.9991439580917358
loss:  27.85984230041504 0.9449108839035034
loss:  27.53548812866211 0.9459660053253174
loss:  27.940204620361328 0.9451153874397278
loss:  27.11456871032715 0.937128484249115
loss:  27.47422981262207 0.9306819438934326
loss:  27.787839889526367 0.9360619783401489
loss:  27.466955184936523 0.9615077376365662
loss:  27.610795974731445 0.9202746748924255
loss:  27.42890167236328 0.9363637566566467
loss:  26.765390396118164 0.9045916199684143
*******************Epoch 95 ****************** 1920 1.0
Validation Loss
*** pred loss:  25.49898338317871 pred acc: 0.5852053165435791
*** stop loss:  6.0784525871276855 stop acc: 0.9221668839454651
*** template loss:  8.214906692504883 template acc: tensor(0.1147, device='cuda:0')
*** label loss:  6.649324417114258 label acc: tensor(0.3609, device='cuda:0')
Train Loss
---> pred loss: 20.225201416015626 pred acc: 0.6751401931047439
---> stop loss: 3.9180648803710936 stop acc: 0.9545789748430252
---> template loss: 1.4770456314086915 tempalte acc: 0.6808646202087403
---> molecule label loss: 0.8954635620117187 molecule acc: 0.7886062622070312
---> kl loss: 0.9527390480041504
---> reconstruction loss: 26.5157790184021
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-96-with.npy
loss:  27.471628189086914 0.9520530700683594
loss:  26.869014739990234 0.9592307209968567
loss:  27.654258728027344 0.9379753470420837
loss:  27.42989158630371 0.9529014229774475
loss:  27.6647891998291 0.9425357580184937
loss:  27.24549674987793 0.9518938660621643
loss:  27.181713104248047 0.9215006828308105
loss:  27.794456481933594 0.9330096244812012
loss:  27.046329498291016 0.9106143116950989
loss:  27.042564392089844 0.9507305026054382
loss:  27.105491638183594 0.9297800064086914
loss:  27.063156127929688 0.942319929599762
loss:  27.29838752746582 0.9403291344642639
loss:  27.713193893432617 0.9255180954933167
loss:  27.86512565612793 0.9285483956336975
loss:  27.364639282226562 0.9246057868003845
loss:  27.275487899780273 0.9269434213638306
loss:  27.150833129882812 0.9005903601646423
loss:  27.723186492919922 0.904606819152832
loss:  27.827289581298828 0.9447137713432312
*******************Epoch 96 ****************** 1940 1.0
Validation Loss
*** pred loss:  25.5173282623291 pred acc: 0.5844202637672424
*** stop loss:  6.075997352600098 stop acc: 0.9239726662635803
*** template loss:  8.172689437866211 template acc: tensor(0.1157, device='cuda:0')
*** label loss:  6.594484329223633 label acc: tensor(0.3678, device='cuda:0')
Train Loss
---> pred loss: 20.23621826171875 pred acc: 0.6740466117858886
---> stop loss: 3.904806137084961 stop acc: 0.9549961090087891
---> template loss: 1.4483823776245117 tempalte acc: 0.6849372386932373
---> molecule label loss: 0.8659227371215821 molecule acc: 0.797803544998169
---> kl loss: 0.9340200424194336
---> reconstruction loss: 26.455326271057128
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-97-with.npy
loss:  27.101795196533203 0.8965847492218018
loss:  26.6199893951416 0.9048019051551819
loss:  27.46683120727539 0.9170504212379456
loss:  27.53468894958496 0.9034237265586853
loss:  27.2550106048584 0.9366072416305542
loss:  27.260251998901367 0.9343505501747131
loss:  27.290599822998047 0.8848994374275208
loss:  26.704450607299805 0.8989289999008179
loss:  27.566728591918945 0.9187319874763489
loss:  26.7086181640625 0.9039068222045898
loss:  27.551156997680664 0.9425163865089417
loss:  26.427217483520508 0.9237464070320129
loss:  27.03726577758789 0.9124288558959961
loss:  27.179655075073242 0.919687807559967
loss:  26.779987335205078 0.9265495538711548
loss:  27.39348793029785 0.9326755404472351
loss:  27.353042602539062 0.9361955523490906
loss:  27.711585998535156 0.919588565826416
loss:  27.353042602539062 0.890852153301239
loss:  27.913190841674805 0.965989351272583
*******************Epoch 97 ****************** 1960 1.0
Validation Loss
*** pred loss:  25.42767906188965 pred acc: 0.5885869264602661
*** stop loss:  6.230156421661377 stop acc: 0.921980082988739
*** template loss:  8.144954681396484 template acc: tensor(0.1143, device='cuda:0')
*** label loss:  6.600326061248779 label acc: tensor(0.3658, device='cuda:0')
Train Loss
---> pred loss: 20.192092895507812 pred acc: 0.6761929959058761
---> stop loss: 3.892047119140625 stop acc: 0.9553899139165878
---> template loss: 1.3935172080993652 tempalte acc: 0.6958992958068848
---> molecule label loss: 0.8142969131469726 molecule acc: 0.8081399917602539
---> kl loss: 0.9184758186340332
---> reconstruction loss: 26.291955089569093
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-98-with.npy
loss:  26.50521469116211 0.9226672053337097
loss:  26.903942108154297 0.9355877041816711
loss:  27.253280639648438 0.9288075566291809
loss:  27.508689880371094 0.8990362882614136
loss:  27.020233154296875 0.9207044839859009
loss:  27.465028762817383 0.9304302334785461
loss:  26.915435791015625 0.89523845911026
loss:  26.937002182006836 0.9249864220619202
loss:  26.731691360473633 0.8966036438941956
loss:  27.22415542602539 0.9141110777854919
loss:  26.883581161499023 0.8908942341804504
loss:  27.33399200439453 0.9270431399345398
loss:  27.203540802001953 0.9045151472091675
loss:  27.03089714050293 0.9002745747566223
loss:  27.35028648376465 0.9311383962631226
loss:  27.03396224975586 0.943347156047821
loss:  27.119056701660156 0.9256113767623901
loss:  27.612735748291016 0.921857476234436
loss:  27.299665451049805 0.9279471635818481
loss:  27.077486038208008 0.9324754476547241
*******************Epoch 98 ****************** 1980 1.0
Validation Loss
*** pred loss:  25.481618881225586 pred acc: 0.5864734053611755
*** stop loss:  6.082520484924316 stop acc: 0.9243773818016052
*** template loss:  8.168285369873047 template acc: tensor(0.1196, device='cuda:0')
*** label loss:  6.719386577606201 label acc: tensor(0.3740, device='cuda:0')
Train Loss
---> pred loss: 20.139376831054687 pred acc: 0.6752737462520599
---> stop loss: 3.9005081176757814 stop acc: 0.9552643984556198
---> template loss: 1.370353889465332 tempalte acc: 0.7034166336059571
---> molecule label loss: 0.7915903091430664 molecule acc: 0.8148189544677734
---> kl loss: 0.9186638832092285
---> reconstruction loss: 26.201828670501712
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-99-with.npy
loss:  26.85866928100586 0.9426279067993164
loss:  26.899105072021484 0.9129803776741028
loss:  27.218992233276367 0.9218307137489319
loss:  26.91661834716797 0.90620356798172
loss:  27.138771057128906 0.9178630709648132
loss:  26.906803131103516 0.9379315972328186
loss:  27.284265518188477 0.9389134049415588
loss:  26.697246551513672 0.9641943573951721
loss:  27.176347732543945 0.9561893939971924
loss:  27.379741668701172 0.9317553639411926
loss:  27.447063446044922 0.9709874987602234
loss:  27.23638153076172 0.9378899931907654
loss:  27.398521423339844 0.9766789078712463
loss:  27.113563537597656 0.9607943892478943
loss:  27.110992431640625 0.9487413167953491
loss:  27.090579986572266 0.9463201761245728
loss:  27.36697769165039 0.9383649826049805
loss:  27.022157669067383 0.9495407342910767
loss:  27.096609115600586 0.9300230145454407
loss:  25.26250457763672 0.9587063193321228
*******************Epoch 99 ****************** 2000 1.0
Validation Loss
*** pred loss:  25.526615142822266 pred acc: 0.5881038308143616
*** stop loss:  6.224426746368408 stop acc: 0.9213574528694153
*** template loss:  8.180824279785156 template acc: tensor(0.1147, device='cuda:0')
*** label loss:  6.705886363983154 label acc: tensor(0.3727, device='cuda:0')
Train Loss
---> pred loss: 20.014353942871093 pred acc: 0.677868103981018
---> stop loss: 3.91820068359375 stop acc: 0.9550873547792434
---> template loss: 1.3690503120422364 tempalte acc: 0.7035808086395263
---> molecule label loss: 0.787064504623413 molecule acc: 0.8146010398864746
---> kl loss: 0.9424267768859863
---> reconstruction loss: 26.088667583465575
saving file:weights/hidden_size_100_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-100-with.npy
