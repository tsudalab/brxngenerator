cuda is  True
loading data.....
size of reactant dic: 9766
size of template dic: 5567
size of fgm_trees: 20080
size of rxn_trees: 20080
size of fragment dic: 273
hidden size: 200 latent_size: 200 batch size: 1000 depth: 2
beta: 1.0 lr: 0.001
size of data pairs: 20080
trainng size: 19079
valid size: 1000
loss:  146.4814453125 2.8958568572998047
loss:  140.8214111328125 3.4961800575256348
loss:  136.56300354003906 5.404483318328857
loss:  130.40830993652344 8.869485855102539
loss:  120.95657348632812 14.644791603088379
loss:  110.22281646728516 23.902494430541992
loss:  102.68963623046875 37.63970947265625
loss:  95.45708465576172 42.46570587158203
loss:  90.57530212402344 44.02557373046875
loss:  87.71578979492188 44.718326568603516
loss:  84.64936828613281 44.136253356933594
loss:  81.62889099121094 44.426368713378906
loss:  79.24164581298828 43.86971664428711
loss:  78.89060974121094 45.234474182128906
loss:  78.34703063964844 46.19512939453125
loss:  76.8265609741211 47.67164993286133
loss:  77.06755828857422 47.7651481628418
loss:  75.4249267578125 48.72289276123047
loss:  74.0026626586914 49.25515365600586
loss:  75.58358001708984 50.15483474731445
*******************Epoch 0 ****************** 20 0.00095
Validation Loss
*** pred loss:  42.37726974487305 pred acc: 0.3089371919631958
*** stop loss:  11.473910331726074 stop acc: 0.8343088626861572
*** template loss:  8.731205940246582 template acc: tensor(0.0186, device='cuda:0')
*** label loss:  6.486017227172852 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 66.1382080078125 pred acc: 0.2587031798902899
---> stop loss: 16.46845397949219 stop acc: 0.7696436524391175
---> template loss: 7.831449127197265 tempalte acc: 0.01595812141895294
---> molecule label loss: 6.718756103515625 molecule acc: 0.36398992538452146
---> kl loss: 34.77471008300781
---> reconstruction loss: 97.14468008987427
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-1-with.npy
loss:  72.51005554199219 48.79204559326172
loss:  72.42225646972656 49.0714111328125
loss:  71.73641967773438 48.25672912597656
loss:  70.62454986572266 46.86031723022461
loss:  69.55867004394531 47.85935974121094
loss:  69.85152435302734 47.541969299316406
loss:  68.79329681396484 47.15593719482422
loss:  68.30809783935547 46.34697723388672
loss:  69.42981719970703 46.90498733520508
loss:  67.41704559326172 46.50914001464844
loss:  67.20651245117188 46.45602798461914
loss:  66.71017456054688 47.6816291809082
loss:  65.67874145507812 47.93369674682617
loss:  65.85636138916016 48.12971496582031
loss:  65.4825210571289 48.29227828979492
loss:  65.12942504882812 48.5651741027832
loss:  65.1326904296875 48.5223503112793
loss:  63.88248825073242 48.84297561645508
loss:  63.76424789428711 48.074424743652344
loss:  62.583656311035156 48.09437942504883
*******************Epoch 1 ****************** 40 0.0019500000000000001
Validation Loss
*** pred loss:  37.45545959472656 pred acc: 0.38146135210990906
*** stop loss:  9.510612487792969 stop acc: 0.8656288981437683
*** template loss:  8.5656099319458 template acc: tensor(0.0433, device='cuda:0')
*** label loss:  6.330955982208252 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 43.932595825195314 pred acc: 0.33316413313150406
---> stop loss: 10.7548095703125 stop acc: 0.8678107410669327
---> template loss: 7.237344360351562 tempalte acc: 0.03536310195922852
---> molecule label loss: 5.608634567260742 molecule acc: 0.3830722332000732
---> kl loss: 47.794577026367186
---> reconstruction loss: 67.51072513534545
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-2-with.npy
loss:  62.82817459106445 49.89801788330078
loss:  61.75926208496094 49.989707946777344
loss:  62.52629470825195 49.7852668762207
loss:  62.582950592041016 49.342567443847656
loss:  62.147621154785156 50.87031936645508
loss:  61.34230041503906 50.78550720214844
loss:  60.902034759521484 51.2723503112793
loss:  60.496368408203125 52.86750793457031
loss:  60.19522476196289 52.627777099609375
loss:  60.65809631347656 53.145240783691406
loss:  59.261959075927734 54.42829132080078
loss:  59.047908782958984 54.75685119628906
loss:  58.83375930786133 54.46377182006836
loss:  58.25263977050781 56.03887939453125
loss:  57.28387451171875 55.22212219238281
loss:  58.03538513183594 55.65040588378906
loss:  57.58531951904297 57.52431106567383
loss:  57.455345153808594 56.08954620361328
loss:  56.4914436340332 57.538700103759766
loss:  58.2519416809082 59.2314453125
*******************Epoch 2 ****************** 60 0.00295
Validation Loss
*** pred loss:  33.77225112915039 pred acc: 0.4420289695262909
*** stop loss:  9.18718433380127 stop acc: 0.8655666708946228
*** template loss:  8.343300819396973 template acc: tensor(0.0725, device='cuda:0')
*** label loss:  6.2829155921936035 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 38.8511962890625 pred acc: 0.3930117577314377
---> stop loss: 8.762469482421874 stop acc: 0.8943083435297012
---> template loss: 6.5508872985839846 tempalte acc: 0.08476144671440125
---> molecule label loss: 5.4989276885986325 molecule acc: 0.38367428779602053
---> kl loss: 53.576422119140624
---> reconstruction loss: 59.638842865295416
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-3-with.npy
loss:  56.414398193359375 57.009193420410156
loss:  55.88823699951172 57.927101135253906
loss:  56.06495666503906 57.2821159362793
loss:  55.35312271118164 56.827354431152344
loss:  54.81038284301758 56.730140686035156
loss:  54.96278762817383 57.79253387451172
loss:  54.513633728027344 57.62738800048828
loss:  56.056617736816406 58.630191802978516
loss:  54.94668197631836 57.87413024902344
loss:  53.54769515991211 58.024383544921875
loss:  53.1236686706543 59.035194396972656
loss:  53.64238739013672 58.26964569091797
loss:  53.00242614746094 59.5156135559082
loss:  52.48741912841797 60.07317352294922
loss:  52.91670608520508 60.029762268066406
loss:  52.64823913574219 61.169471740722656
loss:  52.13581085205078 60.520572662353516
loss:  51.53423309326172 60.48081588745117
loss:  52.11484146118164 61.47003173828125
loss:  50.935997009277344 60.51006317138672
*******************Epoch 3 ****************** 80 0.00395
Validation Loss
*** pred loss:  30.913206100463867 pred acc: 0.4996376633644104
*** stop loss:  7.499400615692139 stop acc: 0.8936176896095276
*** template loss:  8.21747875213623 template acc: tensor(0.0893, device='cuda:0')
*** label loss:  6.136737823486328 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 34.73900146484375 pred acc: 0.4635504722595215
---> stop loss: 7.796990966796875 stop acc: 0.9049377650022506
---> template loss: 5.772530746459961 tempalte acc: 0.14052315950393676
---> molecule label loss: 5.341624450683594 molecule acc: 0.3823610544204712
---> kl loss: 58.83994140625
---> reconstruction loss: 53.62259932128906
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-4-with.npy
loss:  50.949554443359375 60.67251968383789
loss:  50.10173797607422 61.55030059814453
loss:  50.56378936767578 61.48977279663086
loss:  50.67244338989258 63.45033264160156
loss:  50.19291687011719 61.5943489074707
loss:  50.128692626953125 61.23835754394531
loss:  50.04793930053711 61.960391998291016
loss:  49.21756362915039 61.78639221191406
loss:  48.920265197753906 60.94123840332031
loss:  49.155609130859375 59.67827606201172
loss:  48.823974609375 60.73029708862305
loss:  48.66879653930664 61.5660400390625
loss:  48.391693115234375 59.6832389831543
loss:  47.46407699584961 61.685386657714844
loss:  47.75517272949219 60.69072341918945
loss:  47.50675964355469 61.79079818725586
loss:  47.07939147949219 61.4964714050293
loss:  47.11252975463867 61.89436340332031
loss:  47.14738845825195 61.43103790283203
loss:  47.25859451293945 64.70246887207031
*******************Epoch 4 ****************** 100 0.0049499999999999995
Validation Loss
*** pred loss:  28.528352737426758 pred acc: 0.5453502535820007
*** stop loss:  6.965522289276123 stop acc: 0.9013698697090149
*** template loss:  7.96903657913208 template acc: tensor(0.1055, device='cuda:0')
*** label loss:  6.031932353973389 label acc: tensor(0.3468, device='cuda:0')
Train Loss
---> pred loss: 31.49908447265625 pred acc: 0.5190331012010574
---> stop loss: 6.9760993957519535 stop acc: 0.916129520535469
---> template loss: 5.072714233398438 tempalte acc: 0.1956457018852234
---> molecule label loss: 5.034769439697266 molecule acc: 0.3839629411697388
---> kl loss: 61.501641845703126
---> reconstruction loss: 48.55351365020752
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-5-with.npy
loss:  46.37663650512695 62.54964065551758
loss:  45.619388580322266 61.15253448486328
loss:  46.033321380615234 61.84849548339844
loss:  46.12910461425781 62.25591278076172
loss:  45.89051818847656 62.176971435546875
loss:  46.090755462646484 63.25958251953125
loss:  45.45454025268555 63.70594024658203
loss:  44.661354064941406 63.5721435546875
loss:  44.89094161987305 62.817848205566406
loss:  44.744117736816406 64.10196685791016
loss:  45.166690826416016 64.22467041015625
loss:  44.83504104614258 64.1248779296875
loss:  45.057212829589844 64.23753356933594
loss:  44.634254455566406 64.78521728515625
loss:  44.23576354980469 65.08404541015625
loss:  44.14945602416992 65.31230926513672
loss:  43.202388763427734 65.98439025878906
loss:  44.04895782470703 64.9878921508789
loss:  44.14973831176758 65.35939025878906
loss:  43.88523864746094 63.27745819091797
*******************Epoch 5 ****************** 120 0.0059499999999999996
Validation Loss
*** pred loss:  26.932533264160156 pred acc: 0.571739137172699
*** stop loss:  6.552200794219971 stop acc: 0.906102180480957
*** template loss:  7.8304057121276855 template acc: tensor(0.1150, device='cuda:0')
*** label loss:  6.041292190551758 label acc: tensor(0.3475, device='cuda:0')
Train Loss
---> pred loss: 29.050387573242187 pred acc: 0.5616354286670685
---> stop loss: 6.413011932373047 stop acc: 0.9245067149400711
---> template loss: 4.421617889404297 tempalte acc: 0.259456205368042
---> molecule label loss: 4.728465270996094 molecule acc: 0.3853128671646118
---> kl loss: 63.7409423828125
---> reconstruction loss: 44.58350994750977
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-6-with.npy
loss:  42.942726135253906 65.79227447509766
loss:  42.868526458740234 65.98226928710938
loss:  42.86906814575195 65.77295684814453
loss:  42.35527801513672 66.1959457397461
loss:  42.8765983581543 66.77018737792969
loss:  42.57701873779297 67.58777618408203
loss:  41.904056549072266 66.60954284667969
loss:  42.40354919433594 65.87881469726562
loss:  42.74042892456055 68.49493408203125
loss:  42.26940155029297 67.14453125
loss:  41.74663543701172 67.66954803466797
loss:  41.63304138183594 67.53147888183594
loss:  41.36820983886719 68.3873291015625
loss:  41.63181686401367 68.64618682861328
loss:  41.3587646484375 69.2998046875
loss:  41.45427703857422 68.44271850585938
loss:  41.448974609375 68.81019592285156
loss:  41.4659309387207 69.97708129882812
loss:  40.84866714477539 68.87025451660156
loss:  40.38821792602539 72.3490982055664
*******************Epoch 6 ****************** 140 0.00695
Validation Loss
*** pred loss:  25.91462516784668 pred acc: 0.5896738767623901
*** stop loss:  6.245442867279053 stop acc: 0.9135429859161377
*** template loss:  7.588546276092529 template acc: tensor(0.1270, device='cuda:0')
*** label loss:  5.998620986938477 label acc: tensor(0.3485, device='cuda:0')
Train Loss
---> pred loss: 27.25184020996094 pred acc: 0.5878381252288818
---> stop loss: 5.996580505371094 stop acc: 0.9299889206886292
---> template loss: 3.841817855834961 tempalte acc: 0.32904036045074464
---> molecule label loss: 4.427832794189453 molecule acc: 0.3888937711715698
---> kl loss: 67.81064453125
---> reconstruction loss: 41.486281328125
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-7-with.npy
loss:  40.75517272949219 69.44152069091797
loss:  40.44395446777344 70.08329772949219
loss:  40.02864456176758 70.05777740478516
loss:  40.16863250732422 70.04499053955078
loss:  40.55865478515625 70.54002380371094
loss:  40.291908264160156 70.74224853515625
loss:  39.54603958129883 69.43463897705078
loss:  39.351932525634766 71.1924057006836
loss:  40.40748977661133 70.20069122314453
loss:  39.476619720458984 70.76614379882812
loss:  39.19931411743164 70.56415557861328
loss:  39.633358001708984 70.142578125
loss:  39.12282180786133 70.29640197753906
loss:  39.619850158691406 70.93103790283203
loss:  38.74217224121094 70.35929107666016
loss:  39.25376892089844 70.7833251953125
loss:  38.902915954589844 72.146728515625
loss:  39.48942947387695 71.48822784423828
loss:  39.00442886352539 70.6063003540039
loss:  39.12272644042969 72.40502166748047
*******************Epoch 7 ****************** 160 0.00795
Validation Loss
*** pred loss:  24.820770263671875 pred acc: 0.6115338206291199
*** stop loss:  5.907674312591553 stop acc: 0.9188668131828308
*** template loss:  7.470407009124756 template acc: tensor(0.1467, device='cuda:0')
*** label loss:  6.0033488273620605 label acc: tensor(0.3500, device='cuda:0')
Train Loss
---> pred loss: 25.921817016601562 pred acc: 0.6076424360275269
---> stop loss: 5.686228561401367 stop acc: 0.9332342892885208
---> template loss: 3.3698284149169924 tempalte acc: 0.39253571033477785
---> molecule label loss: 4.1501506805419925 molecule acc: 0.3972236394882202
---> kl loss: 70.61134033203125
---> reconstruction loss: 39.094636548461914
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-8-with.npy
loss:  38.47227478027344 71.86677551269531
loss:  37.58856964111328 71.36346435546875
loss:  38.21052551269531 70.85921478271484
loss:  38.30367660522461 72.2542724609375
loss:  38.285987854003906 71.38800811767578
loss:  38.213680267333984 72.0228271484375
loss:  38.0475959777832 71.87854766845703
loss:  37.445068359375 71.69290924072266
loss:  37.932777404785156 71.87959289550781
loss:  37.0222282409668 72.51904296875
loss:  37.472686767578125 71.69679260253906
loss:  37.370792388916016 71.97796630859375
loss:  37.15169143676758 72.42414855957031
loss:  37.67942428588867 73.1837158203125
loss:  37.38444137573242 72.19580078125
loss:  36.757537841796875 73.18870544433594
loss:  36.56735610961914 72.81819152832031
loss:  36.3786735534668 72.12045288085938
loss:  36.80574035644531 73.54344940185547
loss:  36.00836181640625 71.69931030273438
*******************Epoch 8 ****************** 180 0.00895
Validation Loss
*** pred loss:  23.951765060424805 pred acc: 0.6236110925674438
*** stop loss:  5.729430675506592 stop acc: 0.9221980571746826
*** template loss:  7.3673224449157715 template acc: tensor(0.1530, device='cuda:0')
*** label loss:  6.010040283203125 label acc: tensor(0.3513, device='cuda:0')
Train Loss
---> pred loss: 24.633151245117187 pred acc: 0.6270202159881592
---> stop loss: 5.32386474609375 stop acc: 0.938303393125534
---> template loss: 2.979296875 tempalte acc: 0.44990811347961424
---> molecule label loss: 3.9072376251220704 molecule acc: 0.4073028564453125
---> kl loss: 72.128662109375
---> reconstruction loss: 36.80940452880859
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-9-with.npy
loss:  36.1751708984375 73.70307922363281
loss:  36.361968994140625 73.20726013183594
loss:  36.134151458740234 72.73699188232422
loss:  36.7829704284668 73.01956939697266
loss:  35.96977615356445 72.9303970336914
loss:  35.8940315246582 73.25672912597656
loss:  36.10448455810547 73.29202270507812
loss:  36.18167495727539 73.64447784423828
loss:  36.34946060180664 73.97715759277344
loss:  35.91546630859375 73.33251953125
loss:  35.218162536621094 73.68146514892578
loss:  35.305580139160156 72.7901382446289
loss:  36.10773849487305 73.06629180908203
loss:  35.7924690246582 74.72559356689453
loss:  35.73257827758789 73.07813262939453
loss:  35.601680755615234 72.98983764648438
loss:  35.44016647338867 73.3467788696289
loss:  35.21065139770508 74.70488739013672
loss:  35.88817596435547 74.33792877197266
loss:  34.1947135925293 73.15412902832031
*******************Epoch 9 ****************** 200 0.00995
Validation Loss
*** pred loss:  23.297853469848633 pred acc: 0.6320047974586487
*** stop loss:  5.647343635559082 stop acc: 0.9244707822799683
*** template loss:  7.268514633178711 template acc: tensor(0.1688, device='cuda:0')
*** label loss:  6.0157294273376465 label acc: tensor(0.3517, device='cuda:0')
Train Loss
---> pred loss: 23.560505676269532 pred acc: 0.640556788444519
---> stop loss: 5.186613845825195 stop acc: 0.9396263360977173
---> template loss: 2.6929651260375977 tempalte acc: 0.48749070167541503
---> molecule label loss: 3.6819873809814454 molecule acc: 0.42007946968078613
---> kl loss: 73.44876708984376
---> reconstruction loss: 35.0872389666748
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-10-with.npy
loss:  35.080955505371094 74.87545013427734
loss:  34.44840621948242 74.67046356201172
loss:  35.231117248535156 74.73019409179688
loss:  34.644126892089844 74.3861083984375
loss:  34.36298370361328 74.68949127197266
loss:  34.38656234741211 74.40711975097656
loss:  34.285648345947266 74.85820770263672
loss:  34.704139709472656 75.3934326171875
loss:  34.790435791015625 75.33433532714844
loss:  34.46479415893555 74.85917663574219
loss:  34.31882858276367 74.5010986328125
loss:  34.58095932006836 74.38601684570312
loss:  34.57990264892578 74.4245376586914
loss:  34.892921447753906 74.28727722167969
loss:  33.69369888305664 74.5591049194336
loss:  33.94790267944336 73.39392852783203
loss:  33.87352752685547 73.71800231933594
loss:  34.23373794555664 74.02011108398438
loss:  33.82291030883789 73.80985260009766
loss:  33.42958068847656 72.60173797607422
*******************Epoch 10 ****************** 220 0.01095
Validation Loss
*** pred loss:  22.616609573364258 pred acc: 0.6428139805793762
*** stop loss:  5.490692138671875 stop acc: 0.9265255928039551
*** template loss:  7.216998100280762 template acc: tensor(0.1702, device='cuda:0')
*** label loss:  5.95889139175415 label acc: tensor(0.3507, device='cuda:0')
Train Loss
---> pred loss: 22.641441345214844 pred acc: 0.6542746692895889
---> stop loss: 5.010746002197266 stop acc: 0.941727465391159
---> template loss: 2.4555212020874024 tempalte acc: 0.5279588222503662
---> molecule label loss: 3.5017845153808596 molecule acc: 0.4287423133850098
---> kl loss: 74.39528198242188
---> reconstruction loss: 33.57402827850342
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-11-with.npy
loss:  33.48952865600586 73.78804016113281
loss:  33.37546157836914 74.26409912109375
loss:  33.15313720703125 74.13433074951172
loss:  33.08588409423828 74.29798889160156
loss:  33.274898529052734 74.65831756591797
loss:  33.31047058105469 74.39490509033203
loss:  33.0211067199707 74.00098419189453
loss:  33.434024810791016 74.22840881347656
loss:  32.86637878417969 74.81708526611328
loss:  33.4776611328125 74.33708953857422
loss:  33.67124557495117 74.45458221435547
loss:  33.115150451660156 74.71238708496094
loss:  33.106773376464844 74.07268524169922
loss:  32.49862289428711 74.5802230834961
loss:  32.09627914428711 74.3277816772461
loss:  32.54209899902344 74.13563537597656
loss:  32.828739166259766 74.61544799804688
loss:  32.18362808227539 73.7920150756836
loss:  32.670894622802734 74.42396545410156
loss:  33.52843475341797 74.55077362060547
*******************Epoch 11 ****************** 240 0.01195
Validation Loss
*** pred loss:  22.186473846435547 pred acc: 0.6492149829864502
*** stop loss:  5.305312633514404 stop acc: 0.9299813508987427
*** template loss:  7.115194797515869 template acc: tensor(0.1681, device='cuda:0')
*** label loss:  5.978155612945557 label acc: tensor(0.3541, device='cuda:0')
Train Loss
---> pred loss: 21.866644287109374 pred acc: 0.6644402235746384
---> stop loss: 4.750129318237304 stop acc: 0.9455466628074646
---> template loss: 2.256096839904785 tempalte acc: 0.5564183712005615
---> molecule label loss: 3.3107063293457033 molecule acc: 0.44519762992858886
---> kl loss: 74.32933349609375
---> reconstruction loss: 32.14828485046387
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-12-with.npy
loss:  32.2311897277832 74.52725982666016
loss:  32.28814697265625 74.48046112060547
loss:  31.874530792236328 74.25341033935547
loss:  32.270511627197266 74.46505737304688
loss:  31.71778678894043 74.55347442626953
loss:  32.13560485839844 74.64634704589844
loss:  31.953397750854492 74.80282592773438
loss:  32.083309173583984 74.058837890625
loss:  32.163028717041016 73.94119262695312
loss:  32.0611686706543 74.62264251708984
loss:  32.241859436035156 74.42945861816406
loss:  32.2447395324707 74.16914367675781
loss:  31.526371002197266 74.22759246826172
loss:  31.713333129882812 74.21685028076172
loss:  31.742170333862305 73.76274108886719
loss:  31.5495662689209 73.9621353149414
loss:  31.22673797607422 73.62998962402344
loss:  31.896909713745117 74.12919616699219
loss:  31.81499671936035 74.19081115722656
loss:  31.43627166748047 72.25895690917969
*******************Epoch 12 ****************** 260 0.01295
Validation Loss
*** pred loss:  21.60174560546875 pred acc: 0.6562801599502563
*** stop loss:  5.305354595184326 stop acc: 0.9291096329689026
*** template loss:  7.05066442489624 template acc: tensor(0.1787, device='cuda:0')
*** label loss:  5.987064361572266 label acc: tensor(0.3560, device='cuda:0')
Train Loss
---> pred loss: 21.12972412109375 pred acc: 0.6739011257886887
---> stop loss: 4.627817916870117 stop acc: 0.9470239996910095
---> template loss: 2.0775146484375 tempalte acc: 0.5890015602111817
---> molecule label loss: 3.148396873474121 molecule acc: 0.4604020595550537
---> kl loss: 74.16641235351562
---> reconstruction loss: 30.948123451232913
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-13-with.npy
loss:  30.778406143188477 74.71876525878906
loss:  30.93590545654297 73.39131927490234
loss:  31.252161026000977 73.94757080078125
loss:  31.554473876953125 74.17609405517578
loss:  31.803024291992188 74.13227844238281
loss:  31.822168350219727 73.82737731933594
loss:  31.10222816467285 74.39594268798828
loss:  31.396480560302734 74.90291595458984
loss:  30.953432083129883 74.14199829101562
loss:  30.71737289428711 74.4488296508789
loss:  30.853282928466797 73.95027160644531
loss:  30.67770767211914 73.46210479736328
loss:  30.773691177368164 73.89923095703125
loss:  30.28546905517578 73.8358154296875
loss:  30.84226417541504 73.9864501953125
loss:  30.268245697021484 73.15300750732422
loss:  30.373754501342773 73.16522216796875
loss:  30.56270980834961 73.37789916992188
loss:  30.32134246826172 73.57585144042969
loss:  30.461393356323242 74.48453521728516
*******************Epoch 13 ****************** 280 0.01395
Validation Loss
*** pred loss:  21.405086517333984 pred acc: 0.6550120711326599
*** stop loss:  5.288477897644043 stop acc: 0.930137038230896
*** template loss:  6.97773551940918 template acc: tensor(0.1850, device='cuda:0')
*** label loss:  5.9917755126953125 label acc: tensor(0.3562, device='cuda:0')
Train Loss
---> pred loss: 20.50250701904297 pred acc: 0.6821011424064636
---> stop loss: 4.482226943969726 stop acc: 0.9487763673067093
---> template loss: 1.9097639083862306 tempalte acc: 0.6169763088226319
---> molecule label loss: 2.995874786376953 molecule acc: 0.4758645534515381
---> kl loss: 73.94866943359375
---> reconstruction loss: 29.855189743041993
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-14-with.npy
loss:  30.623111724853516 73.73751068115234
loss:  30.78034019470215 73.97724914550781
loss:  30.988046646118164 74.59645080566406
loss:  30.084144592285156 73.92593383789062
loss:  30.18779754638672 73.74943542480469
loss:  30.17633628845215 73.59608459472656
loss:  30.855167388916016 74.42269897460938
loss:  30.468172073364258 73.85041046142578
loss:  30.042917251586914 73.33268737792969
loss:  29.7155704498291 73.40771484375
loss:  29.836862564086914 73.53944396972656
loss:  30.244590759277344 73.4817123413086
loss:  30.09092140197754 72.53741455078125
loss:  29.81488800048828 72.30146789550781
loss:  29.493267059326172 72.94007110595703
loss:  30.108901977539062 73.0039291381836
loss:  29.876113891601562 72.38953399658203
loss:  30.419574737548828 73.00728607177734
loss:  29.834869384765625 72.78974914550781
loss:  29.048095703125 72.70892333984375
*******************Epoch 14 ****************** 300 0.014950000000000001
Validation Loss
*** pred loss:  21.11547088623047 pred acc: 0.6614130139350891
*** stop loss:  5.750965118408203 stop acc: 0.9255293011665344
*** template loss:  6.935259819030762 template acc: tensor(0.1980, device='cuda:0')
*** label loss:  5.963458061218262 label acc: tensor(0.3581, device='cuda:0')
Train Loss
---> pred loss: 19.914260864257812 pred acc: 0.6885613203048706
---> stop loss: 4.482342910766602 stop acc: 0.9483997404575348
---> template loss: 1.798856544494629 tempalte acc: 0.6374126434326172
---> molecule label loss: 2.877216339111328 molecule acc: 0.4871189594268799
---> kl loss: 73.36478271484376
---> reconstruction loss: 29.03767525817871
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-15-with.npy
loss:  30.749755859375 73.2013931274414
loss:  30.82732391357422 73.04615783691406
loss:  29.96750831604004 72.75662231445312
loss:  30.17327117919922 72.23408508300781
loss:  29.607009887695312 72.24583435058594
loss:  29.32689094543457 72.55496215820312
loss:  29.952409744262695 72.69668579101562
loss:  29.615554809570312 72.29124450683594
loss:  29.44264793395996 73.12394714355469
loss:  29.787508010864258 72.995361328125
loss:  29.374664306640625 72.75017547607422
loss:  29.351543426513672 72.81065368652344
loss:  29.430789947509766 72.88898468017578
loss:  29.613309860229492 72.70616912841797
loss:  29.4132080078125 72.4123764038086
loss:  28.936077117919922 72.43260192871094
loss:  29.033815383911133 71.91558074951172
loss:  28.983051300048828 72.21717834472656
loss:  29.122209548950195 71.90953063964844
loss:  29.263822555541992 71.13229370117188
*******************Epoch 15 ****************** 320 0.01595
Validation Loss
*** pred loss:  20.7840518951416 pred acc: 0.6658212542533875
*** stop loss:  5.102758884429932 stop acc: 0.9336550831794739
*** template loss:  6.888132095336914 template acc: tensor(0.1998, device='cuda:0')
*** label loss:  5.985239505767822 label acc: tensor(0.3543, device='cuda:0')
Train Loss
---> pred loss: 19.545559692382813 pred acc: 0.6939266949892045
---> stop loss: 4.506584930419922 stop acc: 0.9478377044200897
---> template loss: 1.6872360229492187 tempalte acc: 0.6562743663787842
---> molecule label loss: 2.737135314941406 molecule acc: 0.5025664806365967
---> kl loss: 72.51609497070312
---> reconstruction loss: 28.44198278717041
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-16-with.npy
loss:  28.7446346282959 72.16961669921875
loss:  28.746810913085938 72.76849365234375
loss:  28.659631729125977 72.5960922241211
loss:  28.778419494628906 72.72891235351562
loss:  28.42707633972168 73.2116470336914
loss:  28.741809844970703 72.92142486572266
loss:  28.760269165039062 72.6910400390625
loss:  28.636104583740234 72.69206237792969
loss:  28.404321670532227 72.23516845703125
loss:  28.99393653869629 71.73358917236328
loss:  28.949504852294922 72.22866821289062
loss:  28.487079620361328 70.76985931396484
loss:  28.3455810546875 71.35163879394531
loss:  28.32059097290039 71.41915893554688
loss:  28.349868774414062 71.79186248779297
loss:  28.144336700439453 71.39517974853516
loss:  28.58933448791504 71.00184631347656
loss:  28.370161056518555 71.34963989257812
loss:  28.475910186767578 71.2934799194336
loss:  27.908506393432617 70.0843505859375
*******************Epoch 16 ****************** 340 0.01695
Validation Loss
*** pred loss:  20.559839248657227 pred acc: 0.6722825765609741
*** stop loss:  4.9638285636901855 stop acc: 0.9361457228660583
*** template loss:  6.8761749267578125 template acc: tensor(0.2037, device='cuda:0')
*** label loss:  5.9734368324279785 label acc: tensor(0.3547, device='cuda:0')
Train Loss
---> pred loss: 18.925048828125 pred acc: 0.7034518957138062
---> stop loss: 4.223580169677734 stop acc: 0.9516442447900773
---> template loss: 1.587266731262207 tempalte acc: 0.673382568359375
---> molecule label loss: 2.621084785461426 molecule acc: 0.515168571472168
---> kl loss: 71.9216796875
---> reconstruction loss: 27.32262064453125
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-17-with.npy
loss:  28.382213592529297 71.54963684082031
loss:  28.120769500732422 70.91317749023438
loss:  28.344322204589844 71.14553833007812
loss:  27.964279174804688 70.24803924560547
loss:  27.906116485595703 70.72073364257812
loss:  28.035999298095703 70.5582275390625
loss:  28.12375259399414 70.703369140625
loss:  28.240930557250977 70.63079071044922
loss:  27.628652572631836 70.54495239257812
loss:  28.074726104736328 71.15866088867188
loss:  27.75446128845215 71.3344955444336
loss:  27.49189567565918 71.35296630859375
loss:  27.635021209716797 71.17786407470703
loss:  27.703784942626953 70.14966583251953
loss:  27.710649490356445 70.7958755493164
loss:  27.445058822631836 71.0421371459961
loss:  27.96163558959961 70.85477447509766
loss:  27.828094482421875 70.69709014892578
loss:  27.56202507019043 70.69252014160156
loss:  28.911964416503906 71.13230895996094
*******************Epoch 17 ****************** 360 0.01795
Validation Loss
*** pred loss:  20.342905044555664 pred acc: 0.6699275374412537
*** stop loss:  4.978853702545166 stop acc: 0.9360212087631226
*** template loss:  6.787787437438965 template acc: tensor(0.2086, device='cuda:0')
*** label loss:  5.953855991363525 label acc: tensor(0.3652, device='cuda:0')
Train Loss
---> pred loss: 18.594720458984376 pred acc: 0.7070489913225174
---> stop loss: 4.0820671081542965 stop acc: 0.953397473692894
---> template loss: 1.503946018218994 tempalte acc: 0.6879802227020264
---> molecule label loss: 2.5221321105957033 molecule acc: 0.5263322830200196
---> kl loss: 70.87013549804688
---> reconstruction loss: 26.669198816833497
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-18-with.npy
loss:  27.126686096191406 70.44194030761719
loss:  27.353164672851562 70.99042510986328
loss:  27.520126342773438 70.24637603759766
loss:  27.492481231689453 70.53919982910156
loss:  27.608901977539062 70.24942016601562
loss:  27.42877960205078 70.59989929199219
loss:  27.354623794555664 70.5167465209961
loss:  27.526081085205078 70.51121520996094
loss:  27.330486297607422 70.24335479736328
loss:  27.43226432800293 69.51100158691406
loss:  27.330734252929688 70.08470153808594
loss:  27.290884017944336 70.19580841064453
loss:  27.273847579956055 69.68323516845703
loss:  27.83834457397461 69.65311431884766
loss:  26.937082290649414 69.74988555908203
loss:  28.06450653076172 69.45713806152344
loss:  26.852651596069336 70.78373718261719
loss:  27.62926483154297 70.12298583984375
loss:  27.18288803100586 69.54717254638672
loss:  28.297544479370117 69.92463684082031
*******************Epoch 18 ****************** 380 0.01895
Validation Loss
*** pred loss:  20.14528465270996 pred acc: 0.6767511963844299
*** stop loss:  5.1555938720703125 stop acc: 0.9358966946601868
*** template loss:  6.747518062591553 template acc: tensor(0.2103, device='cuda:0')
*** label loss:  5.955077171325684 label acc: tensor(0.3626, device='cuda:0')
Train Loss
---> pred loss: 18.2283935546875 pred acc: 0.7120357722043991
---> stop loss: 3.995401382446289 stop acc: 0.9549675107002258
---> template loss: 1.4797263145446777 tempalte acc: 0.6913886070251465
---> molecule label loss: 2.444050979614258 molecule acc: 0.5357460498809814
---> kl loss: 70.15259399414063
---> reconstruction loss: 26.114175238342288
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-19-with.npy
loss:  26.58980941772461 68.78690338134766
loss:  26.796226501464844 69.07565307617188
loss:  27.25884246826172 69.68589782714844
loss:  27.121299743652344 69.97887420654297
loss:  26.934762954711914 68.98990631103516
loss:  26.922832489013672 69.24859619140625
loss:  27.087034225463867 69.62652587890625
loss:  26.87176513671875 69.50350189208984
loss:  27.08984375 69.08621215820312
loss:  26.6400089263916 68.8917236328125
loss:  27.18540382385254 68.62435913085938
loss:  27.05213737487793 68.67399597167969
loss:  26.717199325561523 68.69985961914062
loss:  26.498781204223633 69.35340881347656
loss:  26.627357482910156 68.46824645996094
loss:  26.709144592285156 69.01148986816406
loss:  26.884244918823242 69.16252899169922
loss:  26.81822395324707 69.08154296875
loss:  25.998905181884766 68.38455963134766
loss:  25.56873893737793 66.18479919433594
*******************Epoch 19 ****************** 400 0.019950000000000002
Validation Loss
*** pred loss:  19.871387481689453 pred acc: 0.6780192852020264
*** stop loss:  5.034534454345703 stop acc: 0.9359278082847595
*** template loss:  6.77735710144043 template acc: tensor(0.2058, device='cuda:0')
*** label loss:  5.935992240905762 label acc: tensor(0.3616, device='cuda:0')
Train Loss
---> pred loss: 17.766734313964843 pred acc: 0.7185648381710052
---> stop loss: 3.946555328369141 stop acc: 0.9549083769321441
---> template loss: 1.3684814453125 tempalte acc: 0.7125569343566894
---> molecule label loss: 2.3446449279785155 molecule acc: 0.5499696731567383
---> kl loss: 68.925927734375
---> reconstruction loss: 25.393555671386718
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-20-with.npy
loss:  93.40255737304688 68.75531005859375
loss:  88.17401123046875 62.69660186767578
loss:  81.39728546142578 55.518123626708984
loss:  76.94499206542969 49.85913848876953
loss:  72.29130554199219 44.00929260253906
loss:  67.4825210571289 38.68211364746094
loss:  63.572021484375 33.33780288696289
loss:  58.749656677246094 27.988370895385742
loss:  57.64422607421875 23.925119400024414
loss:  56.11935043334961 18.84616470336914
loss:  52.110069274902344 15.43333911895752
loss:  46.97724533081055 11.845638275146484
loss:  48.65465545654297 10.305004119873047
loss:  45.29753875732422 8.387834548950195
loss:  45.489105224609375 7.179876327514648
loss:  43.09268569946289 5.9470696449279785
loss:  43.41175079345703 5.452930927276611
loss:  42.340293884277344 4.676055908203125
loss:  42.515167236328125 4.513263702392578
loss:  41.72331237792969 4.039056777954102
*******************Epoch 20 ****************** 420 1.0
Validation Loss
*** pred loss:  25.80459213256836 pred acc: 0.5714371800422668
*** stop loss:  6.047514915466309 stop acc: 0.9189290404319763
*** template loss:  8.122730255126953 template acc: tensor(0.0355, device='cuda:0')
*** label loss:  6.023793697357178 label acc: tensor(0.3481, device='cuda:0')
Train Loss
---> pred loss: 21.504580688476562 pred acc: 0.654245576262474
---> stop loss: 5.0265052795410154 stop acc: 0.9406819105148315
---> template loss: 3.49810905456543 tempalte acc: 0.3700292110443115
---> molecule label loss: 3.2703884124755858 molecule acc: 0.4454068183898926
---> kl loss: 25.069906616210936
---> reconstruction loss: 33.29957580566406
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-21-with.npy
loss:  41.10274887084961 3.6055328845977783
loss:  40.446372985839844 3.231874704360962
loss:  40.449623107910156 3.215951681137085
loss:  40.448760986328125 3.0187160968780518
loss:  40.16291427612305 2.8575310707092285
loss:  39.59882354736328 2.6952006816864014
loss:  39.66378402709961 2.7450244426727295
loss:  39.565547943115234 2.615208864212036
loss:  38.65132522583008 2.432393789291382
loss:  38.809146881103516 2.450878858566284
loss:  38.36162185668945 2.4881396293640137
loss:  37.87897491455078 2.445024251937866
loss:  37.86932373046875 2.6033620834350586
loss:  38.108009338378906 2.4324727058410645
loss:  37.675987243652344 2.365021228790283
loss:  38.02799606323242 2.4423670768737793
loss:  37.57195281982422 2.4264397621154785
loss:  37.17696762084961 2.3456735610961914
loss:  37.267757415771484 2.421618700027466
loss:  37.66133499145508 2.1665918827056885
*******************Epoch 21 ****************** 440 1.0
Validation Loss
*** pred loss:  25.308156967163086 pred acc: 0.5810386538505554
*** stop loss:  6.1675519943237305 stop acc: 0.9179016351699829
*** template loss:  7.718968391418457 template acc: tensor(0.0601, device='cuda:0')
*** label loss:  6.1400556564331055 label acc: tensor(0.3489, device='cuda:0')
Train Loss
---> pred loss: 23.806808471679688 pred acc: 0.6196926027536392
---> stop loss: 5.0577545166015625 stop acc: 0.9401403307914734
---> template loss: 4.022187805175781 tempalte acc: 0.27880308628082273
---> molecule label loss: 3.2879451751708983 molecule acc: 0.4423354148864746
---> kl loss: 2.6502511978149412
---> reconstruction loss: 36.17469997406006
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-22-with.npy
loss:  36.75532913208008 2.330061912536621
loss:  36.66658020019531 2.2172112464904785
loss:  36.78860855102539 2.3039395809173584
loss:  37.207637786865234 2.3593485355377197
loss:  36.59172058105469 2.260162115097046
loss:  36.395973205566406 2.3285412788391113
loss:  36.323795318603516 2.3381826877593994
loss:  36.09539031982422 2.335874557495117
loss:  36.00175094604492 2.2986207008361816
loss:  36.37184143066406 2.2659947872161865
loss:  36.350914001464844 2.3239192962646484
loss:  36.335086822509766 2.2827582359313965
loss:  36.59234619140625 2.2600793838500977
loss:  36.225379943847656 2.2053213119506836
loss:  36.5474967956543 2.249628782272339
loss:  36.001007080078125 2.1511974334716797
loss:  36.055782318115234 2.260690212249756
loss:  35.66115188598633 2.1970620155334473
loss:  35.44350814819336 2.192997932434082
loss:  34.46628952026367 2.089902400970459
*******************Epoch 22 ****************** 460 1.0
Validation Loss
*** pred loss:  24.850929260253906 pred acc: 0.585326075553894
*** stop loss:  5.803958415985107 stop acc: 0.9223848581314087
*** template loss:  7.744760990142822 template acc: tensor(0.0739, device='cuda:0')
*** label loss:  5.99706506729126 label acc: tensor(0.3513, device='cuda:0')
Train Loss
---> pred loss: 22.994419860839844 pred acc: 0.632515349984169
---> stop loss: 4.841286849975586 stop acc: 0.9426210552453995
---> template loss: 3.292669677734375 tempalte acc: 0.3805250883102417
---> molecule label loss: 2.852927589416504 molecule acc: 0.4813239097595215
---> kl loss: 2.262574577331543
---> reconstruction loss: 33.98130359649658
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-23-with.npy
loss:  35.48244094848633 2.2627694606781006
loss:  35.6947021484375 2.21761155128479
loss:  35.712581634521484 2.209584951400757
loss:  35.11829376220703 2.209094762802124
loss:  35.19195556640625 2.1121504306793213
loss:  35.53117370605469 2.0830578804016113
loss:  35.3490104675293 2.0835111141204834
loss:  35.14728927612305 2.0647575855255127
loss:  35.220218658447266 1.9734896421432495
loss:  35.17203140258789 2.090646505355835
loss:  35.348995208740234 2.0586905479431152
loss:  34.90558624267578 2.0263595581054688
loss:  34.68836212158203 1.9336259365081787
loss:  35.01655960083008 1.9758312702178955
loss:  35.099605560302734 2.022718906402588
loss:  34.49733352661133 1.9199820756912231
loss:  34.847930908203125 1.960056185722351
loss:  34.56451416015625 2.0223560333251953
loss:  34.81965637207031 1.9675959348678589
loss:  34.05262756347656 1.9981648921966553
*******************Epoch 23 ****************** 480 1.0
Validation Loss
*** pred loss:  24.98625946044922 pred acc: 0.5840579271316528
*** stop loss:  5.830738067626953 stop acc: 0.9227584600448608
*** template loss:  7.542212009429932 template acc: tensor(0.0855, device='cuda:0')
*** label loss:  6.029559135437012 label acc: tensor(0.3489, device='cuda:0')
Train Loss
---> pred loss: 22.694795227050783 pred acc: 0.6352939426898956
---> stop loss: 4.745800018310547 stop acc: 0.943501091003418
---> template loss: 2.9397760391235352 tempalte acc: 0.42575864791870116
---> molecule label loss: 2.633069610595703 molecule acc: 0.5045300006866456
---> kl loss: 2.059602737426758
---> reconstruction loss: 33.013438034057614
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-24-with.npy
loss:  34.44657516479492 1.9476643800735474
loss:  34.4776611328125 1.9947130680084229
loss:  34.253963470458984 1.9290169477462769
loss:  34.799415588378906 1.972267985343933
loss:  34.39899444580078 1.910335659980774
loss:  34.2772331237793 1.9839482307434082
loss:  34.60023880004883 1.9327213764190674
loss:  34.98554992675781 1.9284662008285522
loss:  34.28258514404297 1.9405912160873413
loss:  34.43123245239258 1.9326043128967285
loss:  34.03120040893555 1.8637052774429321
loss:  34.71123123168945 1.863105297088623
loss:  33.606143951416016 1.8631463050842285
loss:  34.03575134277344 1.8536601066589355
loss:  33.96689224243164 1.8797067403793335
loss:  34.44306945800781 1.8203538656234741
loss:  34.19025421142578 1.8256596326828003
loss:  33.7940788269043 1.8318798542022705
loss:  34.51555252075195 1.8314071893692017
loss:  34.34138870239258 1.6236143112182617
*******************Epoch 24 ****************** 500 1.0
Validation Loss
*** pred loss:  25.20073890686035 pred acc: 0.5841183662414551
*** stop loss:  5.853248119354248 stop acc: 0.9228518605232239
*** template loss:  7.576343536376953 template acc: tensor(0.0886, device='cuda:0')
*** label loss:  6.0292510986328125 label acc: tensor(0.3592, device='cuda:0')
Train Loss
---> pred loss: 22.5465576171875 pred acc: 0.6407592803239822
---> stop loss: 4.698667526245117 stop acc: 0.9445034772157669
---> template loss: 2.7259218215942385 tempalte acc: 0.46179804801940916
---> molecule label loss: 2.4718753814697267 molecule acc: 0.5279425621032715
---> kl loss: 1.886428451538086
---> reconstruction loss: 32.443021011352535
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-25-with.npy
loss:  33.7974739074707 1.8021188974380493
loss:  34.003631591796875 1.8293087482452393
loss:  33.814144134521484 1.8445913791656494
loss:  34.07543182373047 1.7842847108840942
loss:  34.105079650878906 1.8047215938568115
loss:  34.181427001953125 1.8156055212020874
loss:  34.278114318847656 1.8466906547546387
loss:  34.10343933105469 1.810428261756897
loss:  33.66222381591797 1.7873011827468872
loss:  33.78813934326172 1.7725083827972412
loss:  33.53705978393555 1.7559130191802979
loss:  33.90913391113281 1.7390751838684082
loss:  33.600521087646484 1.8107668161392212
loss:  33.028194427490234 1.7491366863250732
loss:  33.46337127685547 1.837585210800171
loss:  33.324119567871094 1.789911150932312
loss:  33.506935119628906 1.799896240234375
loss:  33.17995071411133 1.7709007263183594
loss:  33.66214370727539 1.739649772644043
loss:  33.95200729370117 1.8095855712890625
*******************Epoch 25 ****************** 520 1.0
Validation Loss
*** pred loss:  24.974851608276367 pred acc: 0.58423912525177
*** stop loss:  5.733349800109863 stop acc: 0.9235990643501282
*** template loss:  7.525394916534424 template acc: tensor(0.0872, device='cuda:0')
*** label loss:  6.035093307495117 label acc: tensor(0.3537, device='cuda:0')
Train Loss
---> pred loss: 22.38465270996094 pred acc: 0.6401639103889465
---> stop loss: 4.64293327331543 stop acc: 0.944948673248291
---> template loss: 2.579574394226074 tempalte acc: 0.4875302314758301
---> molecule label loss: 2.3464693069458007 molecule acc: 0.5464422225952148
---> kl loss: 1.794999122619629
---> reconstruction loss: 31.953627586364746
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-26-with.npy
loss:  33.17108917236328 1.671555757522583
loss:  33.18334197998047 1.7269232273101807
loss:  33.09230041503906 1.7258694171905518
loss:  33.663734436035156 1.6716570854187012
loss:  33.453060150146484 1.7333029508590698
loss:  33.383506774902344 1.6578547954559326
loss:  32.99410629272461 1.7070544958114624
loss:  32.56743621826172 1.6972259283065796
loss:  33.9852180480957 1.6850714683532715
loss:  33.46500015258789 1.7186894416809082
loss:  32.898006439208984 1.697908639907837
loss:  33.10690689086914 1.6974866390228271
loss:  33.526222229003906 1.6636836528778076
loss:  33.16071319580078 1.684287667274475
loss:  33.06059265136719 1.6716291904449463
loss:  32.95122146606445 1.6302549839019775
loss:  32.86845397949219 1.6630853414535522
loss:  32.91102600097656 1.6505194902420044
loss:  32.926395416259766 1.6391180753707886
loss:  32.903953552246094 1.5525140762329102
*******************Epoch 26 ****************** 540 1.0
Validation Loss
*** pred loss:  24.716552734375 pred acc: 0.5835748910903931
*** stop loss:  6.314133167266846 stop acc: 0.9162515997886658
*** template loss:  7.525938987731934 template acc: tensor(0.0922, device='cuda:0')
*** label loss:  6.054068088531494 label acc: tensor(0.3543, device='cuda:0')
Train Loss
---> pred loss: 22.264041137695312 pred acc: 0.6428312093019486
---> stop loss: 4.590167236328125 stop acc: 0.9460266083478928
---> template loss: 2.4171270370483398 tempalte acc: 0.5121132850646972
---> molecule label loss: 2.2149932861328123 molecule acc: 0.5651422023773194
---> kl loss: 1.6772846221923827
---> reconstruction loss: 31.486329269409183
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-27-with.npy
loss:  32.75062561035156 1.6697943210601807
loss:  33.002052307128906 1.655031681060791
loss:  32.6214599609375 1.6122549772262573
loss:  32.462013244628906 1.6187188625335693
loss:  32.74544143676758 1.5948073863983154
loss:  33.19281768798828 1.6410173177719116
loss:  32.863548278808594 1.5951861143112183
loss:  32.51066207885742 1.5780504941940308
loss:  32.74184036254883 1.5834299325942993
loss:  32.68642807006836 1.5834861993789673
loss:  33.012298583984375 1.5779129266738892
loss:  32.688682556152344 1.5982885360717773
loss:  32.29902648925781 1.543449878692627
loss:  33.310272216796875 1.6417053937911987
loss:  32.16789627075195 1.5668234825134277
loss:  32.78422164916992 1.6016604900360107
loss:  32.4235725402832 1.6002821922302246
loss:  32.423187255859375 1.5683099031448364
loss:  32.45964050292969 1.5999616384506226
loss:  32.2663459777832 1.5169782638549805
*******************Epoch 27 ****************** 560 1.0
Validation Loss
*** pred loss:  24.865676879882812 pred acc: 0.5889492630958557
*** stop loss:  5.87872314453125 stop acc: 0.9224470853805542
*** template loss:  7.50809907913208 template acc: tensor(0.0957, device='cuda:0')
*** label loss:  6.054783344268799 label acc: tensor(0.3524, device='cuda:0')
Train Loss
---> pred loss: 22.048573303222657 pred acc: 0.6466990292072297
---> stop loss: 4.597024917602539 stop acc: 0.9460873991250992
---> template loss: 2.3235395431518553 tempalte acc: 0.529015302658081
---> molecule label loss: 2.104108428955078 molecule acc: 0.5831217288970947
---> kl loss: 1.5973575592041016
---> reconstruction loss: 31.073244857788087
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-28-with.npy
loss:  32.44501495361328 1.6203877925872803
loss:  31.95623779296875 1.5694891214370728
loss:  31.939157485961914 1.5869208574295044
loss:  32.231807708740234 1.5540125370025635
loss:  31.953872680664062 1.5412108898162842
loss:  32.296573638916016 1.5808889865875244
loss:  32.24581527709961 1.5361627340316772
loss:  32.03959655761719 1.5392624139785767
loss:  32.23271179199219 1.5182361602783203
loss:  32.53902816772461 1.469574213027954
loss:  31.486642837524414 1.4456236362457275
loss:  32.111228942871094 1.5030183792114258
loss:  32.27465057373047 1.4710290431976318
loss:  32.22677993774414 1.5039710998535156
loss:  32.24962615966797 1.4610280990600586
loss:  32.241432189941406 1.5248939990997314
loss:  32.027339935302734 1.4653255939483643
loss:  31.857202529907227 1.5001665353775024
loss:  31.784597396850586 1.4858633279800415
loss:  31.58677864074707 1.4818185567855835
*******************Epoch 28 ****************** 580 1.0
Validation Loss
*** pred loss:  24.98676109313965 pred acc: 0.5842995047569275
*** stop loss:  5.9466400146484375 stop acc: 0.921980082988739
*** template loss:  7.4799089431762695 template acc: tensor(0.1009, device='cuda:0')
*** label loss:  6.047418594360352 label acc: tensor(0.3534, device='cuda:0')
Train Loss
---> pred loss: 21.907733154296874 pred acc: 0.6501484841108323
---> stop loss: 4.451121520996094 stop acc: 0.948142871260643
---> template loss: 2.193001365661621 tempalte acc: 0.5542620182037353
---> molecule label loss: 2.0165027618408202 molecule acc: 0.5961994647979736
---> kl loss: 1.5179441452026368
---> reconstruction loss: 30.568362617492678
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-29-with.npy
loss:  31.445167541503906 1.4876619577407837
loss:  31.996339797973633 1.485377550125122
loss:  31.797142028808594 1.4677107334136963
loss:  31.80081558227539 1.5374586582183838
loss:  31.731534957885742 1.5190685987472534
loss:  31.52980613708496 1.4556642770767212
loss:  31.696918487548828 1.504920244216919
loss:  31.684913635253906 1.454498529434204
loss:  31.900222778320312 1.4923537969589233
loss:  32.19582748413086 1.5314545631408691
loss:  31.50017738342285 1.4883482456207275
loss:  31.977725982666016 1.452959656715393
loss:  31.799846649169922 1.4526780843734741
loss:  31.670686721801758 1.474133014678955
loss:  31.76383399963379 1.47740638256073
loss:  30.952402114868164 1.4627611637115479
loss:  32.2740592956543 1.4894722700119019
loss:  31.482521057128906 1.3961448669433594
loss:  31.80097198486328 1.3845514059066772
loss:  31.42502212524414 1.3343435525894165
*******************Epoch 29 ****************** 600 1.0
Validation Loss
*** pred loss:  24.809749603271484 pred acc: 0.5858091711997986
*** stop loss:  6.314294815063477 stop acc: 0.916905403137207
*** template loss:  7.491732120513916 template acc: tensor(0.1038, device='cuda:0')
*** label loss:  6.018672943115234 label acc: tensor(0.3524, device='cuda:0')
Train Loss
---> pred loss: 21.778062438964845 pred acc: 0.6501440554857254
---> stop loss: 4.443147659301758 stop acc: 0.9477465569972991
---> template loss: 2.105235290527344 tempalte acc: 0.5677024841308593
---> molecule label loss: 1.927404022216797 molecule acc: 0.6117655277252197
---> kl loss: 1.4674482345581055
---> reconstruction loss: 30.25384693145752
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-30-with.npy
loss:  31.572799682617188 1.396706223487854
loss:  31.831083297729492 1.4475258588790894
loss:  31.72917938232422 1.449485182762146
loss:  31.535930633544922 1.4384078979492188
loss:  30.925064086914062 1.4021925926208496
loss:  31.69915008544922 1.4015953540802002
loss:  31.406879425048828 1.3869142532348633
loss:  31.294816970825195 1.4146662950515747
loss:  32.69257354736328 1.4432390928268433
loss:  31.499210357666016 1.3806313276290894
loss:  31.27029037475586 1.3917876482009888
loss:  31.556306838989258 1.388362169265747
loss:  31.092979431152344 1.3992558717727661
loss:  31.17283821105957 1.3758331537246704
loss:  31.424602508544922 1.4173638820648193
loss:  31.569618225097656 1.4024056196212769
loss:  31.3701114654541 1.377587080001831
loss:  30.923250198364258 1.362167239189148
loss:  31.310813903808594 1.3700695037841797
loss:  29.75389862060547 1.401685118675232
*******************Epoch 30 ****************** 620 1.0
Validation Loss
*** pred loss:  24.92074966430664 pred acc: 0.5855072140693665
*** stop loss:  6.389847755432129 stop acc: 0.9171856045722961
*** template loss:  7.471638202667236 template acc: tensor(0.1062, device='cuda:0')
*** label loss:  6.10827112197876 label acc: tensor(0.3620, device='cuda:0')
Train Loss
---> pred loss: 21.613543701171874 pred acc: 0.6540369480848313
---> stop loss: 4.5076862335205075 stop acc: 0.9470123469829559
---> template loss: 2.020731735229492 tempalte acc: 0.581681203842163
---> molecule label loss: 1.837214469909668 molecule acc: 0.6266724586486816
---> kl loss: 1.4023941040039063
---> reconstruction loss: 29.979176330566407
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-31-with.npy
loss:  31.64975929260254 1.3902233839035034
loss:  31.68705177307129 1.363739252090454
loss:  31.39029312133789 1.3479238748550415
loss:  30.301780700683594 1.354526162147522
loss:  30.980072021484375 1.3441296815872192
loss:  30.881383895874023 1.3697571754455566
loss:  30.780244827270508 1.3951438665390015
loss:  30.589521408081055 1.3850865364074707
loss:  30.78023910522461 1.3500258922576904
loss:  30.98882293701172 1.3502227067947388
loss:  31.540748596191406 1.3962475061416626
loss:  31.145763397216797 1.3882033824920654
loss:  30.610122680664062 1.352191686630249
loss:  30.731815338134766 1.3321352005004883
loss:  31.130443572998047 1.3077117204666138
loss:  30.99468421936035 1.3781192302703857
loss:  31.080810546875 1.3506383895874023
loss:  30.812618255615234 1.2932237386703491
loss:  30.45372772216797 1.3327668905258179
loss:  31.567363739013672 1.2444179058074951
*******************Epoch 31 ****************** 640 1.0
Validation Loss
*** pred loss:  25.11180877685547 pred acc: 0.5839975476264954
*** stop loss:  5.835690498352051 stop acc: 0.9231008887290955
*** template loss:  7.502925872802734 template acc: tensor(0.1027, device='cuda:0')
*** label loss:  6.095071792602539 label acc: tensor(0.3528, device='cuda:0')
Train Loss
---> pred loss: 21.508328247070313 pred acc: 0.6559049725532532
---> stop loss: 4.422493362426758 stop acc: 0.9482062846422196
---> template loss: 1.9543066024780273 tempalte acc: 0.5939282417297364
---> molecule label loss: 1.7684158325195312 molecule acc: 0.6383764266967773
---> kl loss: 1.3513216972351074
---> reconstruction loss: 29.65354280471802
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-32-with.npy
loss:  30.088632583618164 1.2700368165969849
loss:  30.943334579467773 1.2822009325027466
loss:  30.37810707092285 1.309393048286438
loss:  30.995100021362305 1.3178282976150513
loss:  30.85413932800293 1.3028504848480225
loss:  30.271488189697266 1.2742940187454224
loss:  30.608125686645508 1.2934633493423462
loss:  30.485408782958984 1.2789734601974487
loss:  30.590370178222656 1.2776117324829102
loss:  31.21348762512207 1.2994091510772705
loss:  30.644107818603516 1.2854945659637451
loss:  31.101747512817383 1.2708146572113037
loss:  30.56498908996582 1.301213026046753
loss:  30.641944885253906 1.2648133039474487
loss:  30.848697662353516 1.277186393737793
loss:  30.702402114868164 1.3171169757843018
loss:  30.46296501159668 1.3105883598327637
loss:  30.505599975585938 1.294360637664795
loss:  29.955724716186523 1.2826828956604004
loss:  30.11611557006836 1.2843698263168335
*******************Epoch 32 ****************** 660 1.0
Validation Loss
*** pred loss:  24.92067527770996 pred acc: 0.5862318873405457
*** stop loss:  5.9063262939453125 stop acc: 0.9240660071372986
*** template loss:  7.509305477142334 template acc: tensor(0.1048, device='cuda:0')
*** label loss:  6.054758071899414 label acc: tensor(0.3528, device='cuda:0')
Train Loss
---> pred loss: 21.341944885253906 pred acc: 0.6576722681522369
---> stop loss: 4.334859848022461 stop acc: 0.949332183599472
---> template loss: 1.9111400604248048 tempalte acc: 0.5984113216400146
---> molecule label loss: 1.720944595336914 molecule acc: 0.6468008041381836
---> kl loss: 1.2897352218627929
---> reconstruction loss: 29.30888843536377
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-33-with.npy
loss:  29.94049835205078 1.2906888723373413
loss:  29.95277976989746 1.2792690992355347
loss:  30.26517105102539 1.2944822311401367
loss:  30.55554962158203 1.2792502641677856
loss:  30.175729751586914 1.3408522605895996
loss:  30.185317993164062 1.3223567008972168
loss:  30.361522674560547 1.3057903051376343
loss:  30.175315856933594 1.2962056398391724
loss:  30.446596145629883 1.2267662286758423
loss:  30.13157844543457 1.2593711614608765
loss:  29.888816833496094 1.2871809005737305
loss:  30.25871467590332 1.2635176181793213
loss:  30.258041381835938 1.2086060047149658
loss:  30.223575592041016 1.3004804849624634
loss:  30.017181396484375 1.273860216140747
loss:  30.353750228881836 1.2567076683044434
loss:  30.124797821044922 1.2369626760482788
loss:  30.179643630981445 1.2279824018478394
loss:  30.28827667236328 1.243860125541687
loss:  30.737550735473633 1.275054931640625
*******************Epoch 33 ****************** 680 1.0
Validation Loss
*** pred loss:  24.93822479248047 pred acc: 0.5851449370384216
*** stop loss:  6.305939674377441 stop acc: 0.9184620380401611
*** template loss:  7.454654216766357 template acc: tensor(0.1115, device='cuda:0')
*** label loss:  6.07109260559082 label acc: tensor(0.3492, device='cuda:0')
Train Loss
---> pred loss: 21.27843475341797 pred acc: 0.6606298565864563
---> stop loss: 4.209962463378906 stop acc: 0.9516035467386246
---> template loss: 1.8335250854492187 tempalte acc: 0.6159913063049316
---> molecule label loss: 1.6306333541870117 molecule acc: 0.6617433071136475
---> kl loss: 1.2734622955322266
---> reconstruction loss: 28.952556991577147
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-34-with.npy
loss:  30.007001876831055 1.2300442457199097
loss:  30.17705535888672 1.2400665283203125
loss:  29.84787940979004 1.2487848997116089
loss:  30.010761260986328 1.299639344215393
loss:  29.90470314025879 1.2349051237106323
loss:  30.045366287231445 1.2509294748306274
loss:  30.023176193237305 1.226119875907898
loss:  29.786056518554688 1.2350246906280518
loss:  30.076679229736328 1.1979655027389526
loss:  29.89219856262207 1.2211856842041016
loss:  30.689332962036133 1.2173969745635986
loss:  29.93135643005371 1.214279055595398
loss:  30.5356388092041 1.2639644145965576
loss:  29.898757934570312 1.2568765878677368
loss:  30.068405151367188 1.253849983215332
loss:  29.881845474243164 1.2017245292663574
loss:  29.881938934326172 1.2296382188796997
loss:  30.421981811523438 1.2403745651245117
loss:  30.03490447998047 1.2139278650283813
loss:  28.918752670288086 1.1645065546035767
*******************Epoch 34 ****************** 700 1.0
Validation Loss
*** pred loss:  25.298534393310547 pred acc: 0.5815821290016174
*** stop loss:  5.934619426727295 stop acc: 0.9233499765396118
*** template loss:  7.457526206970215 template acc: tensor(0.1129, device='cuda:0')
*** label loss:  6.132775783538818 label acc: tensor(0.3609, device='cuda:0')
Train Loss
---> pred loss: 21.0877197265625 pred acc: 0.6600093692541122
---> stop loss: 4.293124389648438 stop acc: 0.9494722813367844
---> template loss: 1.7952262878417968 tempalte acc: 0.6187546730041504
---> molecule label loss: 1.5935586929321288 molecule acc: 0.6697081565856934
---> kl loss: 1.232060146331787
---> reconstruction loss: 28.76963052749634
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-35-with.npy
loss:  29.495759963989258 1.2203466892242432
loss:  29.942527770996094 1.223763108253479
loss:  29.751117706298828 1.2363691329956055
loss:  29.3911190032959 1.2179704904556274
loss:  30.08868980407715 1.1931232213974
loss:  29.706579208374023 1.204152226448059
loss:  29.48867416381836 1.1791694164276123
loss:  29.473756790161133 1.2028768062591553
loss:  30.138290405273438 1.1843864917755127
loss:  29.58688735961914 1.2087559700012207
loss:  29.558889389038086 1.1958218812942505
loss:  29.44459342956543 1.175469994544983
loss:  29.912761688232422 1.1909563541412354
loss:  29.744373321533203 1.1581465005874634
loss:  29.302776336669922 1.1656850576400757
loss:  29.932035446166992 1.1911574602127075
loss:  29.48474884033203 1.2011425495147705
loss:  29.798213958740234 1.2044413089752197
loss:  29.425064086914062 1.193608283996582
loss:  29.830286026000977 1.1712297201156616
*******************Epoch 35 ****************** 720 1.0
Validation Loss
*** pred loss:  25.153766632080078 pred acc: 0.5792270302772522
*** stop loss:  5.9729084968566895 stop acc: 0.9222602844238281
*** template loss:  7.4823198318481445 template acc: tensor(0.1097, device='cuda:0')
*** label loss:  6.250261306762695 label acc: tensor(0.3712, device='cuda:0')
Train Loss
---> pred loss: 21.04905548095703 pred acc: 0.6609238833189011
---> stop loss: 4.197994995117187 stop acc: 0.9511865824460983
---> template loss: 1.7119352340698242 tempalte acc: 0.6389340400695801
---> molecule label loss: 1.5199451446533203 molecule acc: 0.6836859226226807
---> kl loss: 1.1959287643432617
---> reconstruction loss: 28.47892475128174
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-36-with.npy
loss:  29.677047729492188 1.206909418106079
loss:  29.48809814453125 1.229327917098999
loss:  28.96708106994629 1.20857572555542
loss:  29.747081756591797 1.2646405696868896
loss:  29.466806411743164 1.1958789825439453
loss:  29.489643096923828 1.2102057933807373
loss:  30.06671142578125 1.1865159273147583
loss:  29.088899612426758 1.1621782779693604
loss:  29.382104873657227 1.1585339307785034
loss:  29.691585540771484 1.1487945318222046
loss:  29.592336654663086 1.1523158550262451
loss:  29.305984497070312 1.1347465515136719
loss:  28.729637145996094 1.1293333768844604
loss:  29.453718185424805 1.148465633392334
loss:  29.02787208557129 1.1451133489608765
loss:  28.813209533691406 1.1242115497589111
loss:  29.60828399658203 1.1335604190826416
loss:  29.327058792114258 1.1449947357177734
loss:  29.434988021850586 1.143242359161377
loss:  27.706817626953125 1.0704495906829834
*******************Epoch 36 ****************** 740 1.0
Validation Loss
*** pred loss:  25.06256675720215 pred acc: 0.5823671221733093
*** stop loss:  5.910062789916992 stop acc: 0.9240971803665161
*** template loss:  7.450315952301025 template acc: tensor(0.1108, device='cuda:0')
*** label loss:  6.09005069732666 label acc: tensor(0.3596, device='cuda:0')
Train Loss
---> pred loss: 20.831645202636718 pred acc: 0.6656464457511901
---> stop loss: 4.167823791503906 stop acc: 0.9517151117324829
---> template loss: 1.6652111053466796 tempalte acc: 0.6468945980072022
---> molecule label loss: 1.4736674308776856 molecule acc: 0.6889269828796387
---> kl loss: 1.164899730682373
---> reconstruction loss: 28.13834733963013
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-37-with.npy
loss:  29.381933212280273 1.1191977262496948
loss:  29.046775817871094 1.1069104671478271
loss:  28.63590431213379 1.1389172077178955
loss:  29.191452026367188 1.1555217504501343
loss:  29.092161178588867 1.125124454498291
loss:  29.300369262695312 1.146801233291626
loss:  29.436532974243164 1.1060625314712524
loss:  29.70635986328125 1.1239147186279297
loss:  28.997331619262695 1.1197482347488403
loss:  29.750465393066406 1.1264170408248901
loss:  28.49462890625 1.083928108215332
loss:  28.40766143798828 1.1094807386398315
loss:  29.257549285888672 1.1162569522857666
loss:  28.87282371520996 1.14030122756958
loss:  29.48383140563965 1.1432746648788452
loss:  29.2987003326416 1.1307969093322754
loss:  29.056781768798828 1.116471290588379
loss:  29.004056930541992 1.1323148012161255
loss:  28.685972213745117 1.1140835285186768
loss:  29.426883697509766 1.0999095439910889
*******************Epoch 37 ****************** 760 1.0
Validation Loss
*** pred loss:  25.191556930541992 pred acc: 0.5818236470222473
*** stop loss:  5.924020290374756 stop acc: 0.9237546920776367
*** template loss:  7.472471714019775 template acc: tensor(0.1119, device='cuda:0')
*** label loss:  6.111930847167969 label acc: tensor(0.3582, device='cuda:0')
Train Loss
---> pred loss: 20.797993469238282 pred acc: 0.6657661765813827
---> stop loss: 4.126346206665039 stop acc: 0.9522143542766571
---> template loss: 1.6387475967407226 tempalte acc: 0.6511178016662598
---> molecule label loss: 1.4405515670776368 molecule acc: 0.6938050270080567
---> kl loss: 1.1227715492248536
---> reconstruction loss: 28.003635311126708
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-38-with.npy
loss:  28.833377838134766 1.0924735069274902
loss:  29.023866653442383 1.1244608163833618
loss:  28.827035903930664 1.1435753107070923
loss:  28.249282836914062 1.0810502767562866
loss:  28.721487045288086 1.1163371801376343
loss:  28.702415466308594 1.0956975221633911
loss:  28.59486961364746 1.107709288597107
loss:  29.24108123779297 1.0807918310165405
loss:  29.07095718383789 1.0555119514465332
loss:  29.03183364868164 1.057762861251831
loss:  28.5484619140625 1.09074866771698
loss:  28.3817081451416 1.0885807275772095
loss:  28.584514617919922 1.1075600385665894
loss:  28.350908279418945 1.1261554956436157
loss:  28.525712966918945 1.122086763381958
loss:  28.752723693847656 1.0909978151321411
loss:  28.698896408081055 1.1063123941421509
loss:  29.013700485229492 1.074638843536377
loss:  29.00851058959961 1.1220910549163818
loss:  30.55695343017578 1.142379879951477
*******************Epoch 38 ****************** 780 1.0
Validation Loss
*** pred loss:  25.22273063659668 pred acc: 0.5809178352355957
*** stop loss:  6.310764789581299 stop acc: 0.9206725358963013
*** template loss:  7.459767818450928 template acc: tensor(0.1171, device='cuda:0')
*** label loss:  6.158292770385742 label acc: tensor(0.3718, device='cuda:0')
Train Loss
---> pred loss: 20.702799987792968 pred acc: 0.6671401768922806
---> stop loss: 4.0739086151123045 stop acc: 0.9529234170913696
---> template loss: 1.5868735313415527 tempalte acc: 0.6598052024841309
---> molecule label loss: 1.3709848403930665 molecule acc: 0.7086024761199952
---> kl loss: 1.1013461112976075
---> reconstruction loss: 27.734563922882078
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-39-with.npy
loss:  28.785320281982422 1.097080945968628
loss:  28.758487701416016 1.0798386335372925
loss:  28.791181564331055 1.0820499658584595
loss:  29.051542282104492 1.0882325172424316
loss:  28.825687408447266 1.087650179862976
loss:  28.245548248291016 1.0734776258468628
loss:  28.165781021118164 1.0411522388458252
loss:  29.112415313720703 1.0421726703643799
loss:  28.169376373291016 1.060138463973999
loss:  28.633712768554688 1.0698024034500122
loss:  28.820009231567383 1.090971827507019
loss:  28.012670516967773 1.0550509691238403
loss:  28.902069091796875 1.0611193180084229
loss:  27.84987449645996 1.0572967529296875
loss:  28.750818252563477 1.0908894538879395
loss:  28.474557876586914 1.0836619138717651
loss:  28.28125762939453 1.0592761039733887
loss:  28.140522003173828 1.0359187126159668
loss:  28.20929718017578 1.0422018766403198
loss:  28.265308380126953 0.9589980840682983
*******************Epoch 39 ****************** 800 1.0
Validation Loss
*** pred loss:  25.135238647460938 pred acc: 0.5818236470222473
*** stop loss:  5.8281378746032715 stop acc: 0.9249066114425659
*** template loss:  7.516290664672852 template acc: tensor(0.1164, device='cuda:0')
*** label loss:  6.150254726409912 label acc: tensor(0.3693, device='cuda:0')
Train Loss
---> pred loss: 20.54127197265625 pred acc: 0.6697649419307709
---> stop loss: 4.046602630615235 stop acc: 0.9532743155956268
---> template loss: 1.5351531028747558 tempalte acc: 0.669625997543335
---> molecule label loss: 1.3263938903808594 molecule acc: 0.7161764621734619
---> kl loss: 1.0628490447998047
---> reconstruction loss: 27.449422073364257
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-40-with.npy
loss:  28.004831314086914 1.0478764772415161
loss:  27.779783248901367 1.0568757057189941
loss:  27.927637100219727 1.0408821105957031
loss:  27.918529510498047 1.039318323135376
loss:  28.46526527404785 1.0339707136154175
loss:  28.02709197998047 1.0613445043563843
loss:  28.340078353881836 1.0980161428451538
loss:  27.988605499267578 1.0668284893035889
loss:  28.6307315826416 1.0725029706954956
loss:  27.98274803161621 1.0495222806930542
loss:  28.04703140258789 1.0087674856185913
loss:  28.102813720703125 1.053134560585022
loss:  27.988454818725586 1.0379129648208618
loss:  28.492229461669922 1.0187588930130005
loss:  28.357192993164062 1.038517951965332
loss:  27.863862991333008 0.9748108386993408
loss:  28.592960357666016 1.0181052684783936
loss:  28.59446144104004 1.044340968132019
loss:  28.658620834350586 1.0273722410202026
loss:  27.21712303161621 1.1112964153289795
*******************Epoch 40 ****************** 820 1.0
Validation Loss
*** pred loss:  25.2034912109375 pred acc: 0.5829709768295288
*** stop loss:  5.949073314666748 stop acc: 0.9218244552612305
*** template loss:  7.473299980163574 template acc: tensor(0.1143, device='cuda:0')
*** label loss:  6.118823051452637 label acc: tensor(0.3689, device='cuda:0')
Train Loss
---> pred loss: 20.36676025390625 pred acc: 0.671969798207283
---> stop loss: 3.987560272216797 stop acc: 0.9540490359067917
---> template loss: 1.4884515762329102 tempalte acc: 0.6776705741882324
---> molecule label loss: 1.261221218109131 molecule acc: 0.729525375366211
---> kl loss: 1.0450077056884766
---> reconstruction loss: 27.103994369506836
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-41-with.npy
loss:  27.846555709838867 1.048949122428894
loss:  28.06652069091797 1.013129472732544
loss:  27.873937606811523 1.0099555253982544
loss:  28.54928970336914 1.0191130638122559
loss:  29.05270767211914 1.0367168188095093
loss:  27.91005516052246 1.0162303447723389
loss:  28.055339813232422 1.0622495412826538
loss:  28.080211639404297 1.0510239601135254
loss:  27.961776733398438 1.0474803447723389
loss:  28.000900268554688 1.0531738996505737
loss:  28.112937927246094 1.0334291458129883
loss:  28.3700008392334 1.0135349035263062
loss:  28.489871978759766 1.045408010482788
loss:  28.21265411376953 1.065638780593872
loss:  28.165874481201172 1.0367857217788696
loss:  28.25630760192871 1.0637568235397339
loss:  28.26689910888672 1.0265867710113525
loss:  28.29246711730957 1.055643916130066
loss:  28.592792510986328 1.0322651863098145
loss:  26.58307647705078 0.9618757367134094
*******************Epoch 41 ****************** 840 1.0
Validation Loss
*** pred loss:  25.27412223815918 pred acc: 0.5791666507720947
*** stop loss:  5.88405179977417 stop acc: 0.9259029030799866
*** template loss:  7.578880786895752 template acc: tensor(0.1154, device='cuda:0')
*** label loss:  6.330353260040283 label acc: tensor(0.3706, device='cuda:0')
Train Loss
---> pred loss: 20.199534606933593 pred acc: 0.6751547455787659
---> stop loss: 3.996975326538086 stop acc: 0.9537975311279296
---> template loss: 1.5943385124206544 tempalte acc: 0.657796049118042
---> molecule label loss: 1.311511516571045 molecule acc: 0.716126823425293
---> kl loss: 1.034647274017334
---> reconstruction loss: 27.102361392974853
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-42-with.npy
loss:  27.96987533569336 0.9994193911552429
loss:  27.78859519958496 1.0336326360702515
loss:  28.24985694885254 1.0163880586624146
loss:  28.289583206176758 1.0377764701843262
loss:  27.592487335205078 1.0319955348968506
loss:  27.923372268676758 1.0256448984146118
loss:  27.94600486755371 1.0248690843582153
loss:  28.051956176757812 1.0343923568725586
loss:  27.456995010375977 1.0118883848190308
loss:  27.632869720458984 0.9969366192817688
loss:  28.09111213684082 1.009329915046692
loss:  28.02423667907715 0.9820954203605652
loss:  27.90683364868164 0.9715357422828674
loss:  28.31899642944336 0.9827563166618347
loss:  27.90433692932129 0.949317216873169
loss:  28.050067901611328 0.963200569152832
loss:  27.65753173828125 0.9756625890731812
loss:  27.76911735534668 0.9349889159202576
loss:  28.26362419128418 0.9618510603904724
loss:  27.267799377441406 0.9811388850212097
*******************Epoch 42 ****************** 860 1.0
Validation Loss
*** pred loss:  25.416324615478516 pred acc: 0.5774154663085938
*** stop loss:  5.972353458404541 stop acc: 0.9231008887290955
*** template loss:  7.41485071182251 template acc: tensor(0.1273, device='cuda:0')
*** label loss:  6.084052562713623 label acc: tensor(0.3526, device='cuda:0')
Train Loss
---> pred loss: 20.208111572265626 pred acc: 0.6755404740571975
---> stop loss: 3.9279598236083983 stop acc: 0.9549655854701996
---> template loss: 1.508400821685791 tempalte acc: 0.673042631149292
---> molecule label loss: 1.2670489311218263 molecule acc: 0.7218573093414307
---> kl loss: 0.9962409019470215
---> reconstruction loss: 26.911522769927977
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-43-with.npy
loss:  27.920547485351562 0.994444727897644
loss:  28.05812644958496 0.9991917014122009
loss:  27.663610458374023 1.0136477947235107
loss:  27.787212371826172 0.9796422719955444
loss:  27.60154914855957 0.9689733982086182
loss:  27.72463035583496 0.9938961267471313
loss:  27.877260208129883 1.0071051120758057
loss:  27.893497467041016 1.0090373754501343
loss:  28.078672409057617 0.9736762642860413
loss:  27.076374053955078 0.9866659641265869
loss:  27.625947952270508 0.954364001750946
loss:  27.43454360961914 0.9639215469360352
loss:  27.734329223632812 0.9559512734413147
loss:  27.550443649291992 0.9484471678733826
loss:  27.653764724731445 0.9834999442100525
loss:  27.745628356933594 0.9712834358215332
loss:  27.707656860351562 0.9553370475769043
loss:  27.201488494873047 0.9653316736221313
loss:  27.395837783813477 0.9442479014396667
loss:  27.14963150024414 1.0063108205795288
*******************Epoch 43 ****************** 880 1.0
Validation Loss
*** pred loss:  25.446338653564453 pred acc: 0.5727657079696655
*** stop loss:  5.960383892059326 stop acc: 0.9249688982963562
*** template loss:  7.443730354309082 template acc: tensor(0.1228, device='cuda:0')
*** label loss:  6.137453079223633 label acc: tensor(0.3765, device='cuda:0')
Train Loss
---> pred loss: 20.132418823242187 pred acc: 0.6751839637756347
---> stop loss: 3.9222644805908202 stop acc: 0.9548555850982666
---> template loss: 1.4230356216430664 tempalte acc: 0.692271089553833
---> molecule label loss: 1.1875688552856445 molecule acc: 0.7387370586395263
---> kl loss: 0.978748893737793
---> reconstruction loss: 26.665291023254394
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-44-with.npy
loss:  27.282346725463867 0.9614851474761963
loss:  27.438554763793945 0.9858304262161255
loss:  27.09786033630371 0.9534125328063965
loss:  27.345535278320312 0.9674980044364929
loss:  27.336952209472656 0.9278087019920349
loss:  27.23274040222168 0.9577307105064392
loss:  27.67668914794922 0.9604862928390503
loss:  27.79863739013672 0.9418755173683167
loss:  26.93083953857422 0.9308908581733704
loss:  27.414569854736328 0.9468510746955872
loss:  27.416780471801758 0.9499239325523376
loss:  27.59373664855957 0.917488157749176
loss:  27.358524322509766 0.9170191287994385
loss:  27.097824096679688 0.9296484589576721
loss:  27.833660125732422 0.9460437297821045
loss:  27.39578628540039 0.9326623678207397
loss:  27.33255386352539 0.9340168833732605
loss:  27.425167083740234 0.940683901309967
loss:  27.06926155090332 0.9168118834495544
loss:  26.873903274536133 0.9680386781692505
*******************Epoch 44 ****************** 900 1.0
Validation Loss
*** pred loss:  25.405344009399414 pred acc: 0.576751172542572
*** stop loss:  6.165408134460449 stop acc: 0.9229452610015869
*** template loss:  7.470566749572754 template acc: tensor(0.1175, device='cuda:0')
*** label loss:  6.2669525146484375 label acc: tensor(0.3787, device='cuda:0')
Train Loss
---> pred loss: 20.018121337890626 pred acc: 0.677057757973671
---> stop loss: 3.910492706298828 stop acc: 0.9549514442682266
---> template loss: 1.3611814498901367 tempalte acc: 0.7021614074707031
---> molecule label loss: 1.1134915351867676 molecule acc: 0.7549455165863037
---> kl loss: 0.944310188293457
---> reconstruction loss: 26.403285026550293
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-45-with.npy
loss:  27.392562866210938 0.9559177756309509
loss:  26.987165451049805 0.9209936857223511
loss:  27.224027633666992 0.9359626173973083
loss:  27.64582061767578 0.9272032976150513
loss:  27.16975975036621 0.9414843320846558
loss:  27.104740142822266 0.9523662328720093
loss:  26.954837799072266 0.9307330250740051
loss:  27.03951644897461 0.9384479522705078
loss:  26.888063430786133 0.949903666973114
loss:  26.89542007446289 0.9095705151557922
loss:  27.147933959960938 0.9529383182525635
loss:  27.117206573486328 0.9584502577781677
loss:  26.961584091186523 0.9359023571014404
loss:  27.186296463012695 0.9363994002342224
loss:  27.605850219726562 0.9317811131477356
loss:  27.53341293334961 0.941463828086853
loss:  26.839200973510742 0.9255737662315369
loss:  27.24167251586914 0.9095931649208069
loss:  26.902341842651367 0.8865169882774353
loss:  27.51976776123047 0.8702123165130615
*******************Epoch 45 ****************** 920 1.0
Validation Loss
*** pred loss:  25.24607276916504 pred acc: 0.5864130258560181
*** stop loss:  6.056670188903809 stop acc: 0.9251245856285095
*** template loss:  7.4538445472717285 template acc: tensor(0.1214, device='cuda:0')
*** label loss:  6.15875244140625 label acc: tensor(0.3689, device='cuda:0')
Train Loss
---> pred loss: 19.930335998535156 pred acc: 0.680658507347107
---> stop loss: 3.8722930908203126 stop acc: 0.9556744337081909
---> template loss: 1.337198257446289 tempalte acc: 0.7077908039093017
---> molecule label loss: 1.0974620819091796 molecule acc: 0.7581707000732422
---> kl loss: 0.9305706977844238
---> reconstruction loss: 26.237288188934325
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-46-with.npy
loss:  27.41766357421875 0.9358037710189819
loss:  26.518529891967773 0.9298654198646545
loss:  27.13217544555664 0.9230356216430664
loss:  27.156354904174805 0.9215549826622009
loss:  26.978260040283203 0.8985974192619324
loss:  26.736061096191406 0.8944671154022217
loss:  27.337562561035156 0.913088321685791
loss:  27.230607986450195 0.8740778565406799
loss:  26.585168838500977 0.8953275084495544
loss:  26.994543075561523 0.9161155819892883
loss:  26.90015983581543 0.9060094356536865
loss:  26.971708297729492 0.9082261919975281
loss:  26.802642822265625 0.9013543725013733
loss:  26.313188552856445 0.8941441774368286
loss:  26.81549072265625 0.9000357389450073
loss:  26.601572036743164 0.8814378976821899
loss:  27.041154861450195 0.8995610475540161
loss:  26.74093246459961 0.8855148553848267
loss:  26.84564208984375 0.8984262347221375
loss:  26.898679733276367 0.8236063122749329
*******************Epoch 46 ****************** 940 1.0
Validation Loss
*** pred loss:  25.209991455078125 pred acc: 0.576751172542572
*** stop loss:  5.889715194702148 stop acc: 0.9276775121688843
*** template loss:  7.419941425323486 template acc: tensor(0.1259, device='cuda:0')
*** label loss:  6.111902236938477 label acc: tensor(0.3682, device='cuda:0')
Train Loss
---> pred loss: 19.796348571777344 pred acc: 0.6802837789058686
---> stop loss: 3.8703243255615236 stop acc: 0.9556520789861679
---> template loss: 1.284954833984375 tempalte acc: 0.7183740615844727
---> molecule label loss: 1.0492632865905762 molecule acc: 0.7671617031097412
---> kl loss: 0.9000124931335449
---> reconstruction loss: 26.00089387893677
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-47-with.npy
loss:  26.49158477783203 0.875593900680542
loss:  26.63288688659668 0.8959107995033264
loss:  26.629077911376953 0.8955432176589966
loss:  27.038734436035156 0.8907008767127991
loss:  26.059724807739258 0.877917468547821
loss:  26.968149185180664 0.8715161085128784
loss:  26.51401710510254 0.8826249837875366
loss:  26.71111297607422 0.8721988797187805
loss:  26.48853874206543 0.8687783479690552
loss:  27.196470260620117 0.8889061808586121
loss:  26.851726531982422 0.8830796480178833
loss:  26.77244758605957 0.8833406567573547
loss:  26.799633026123047 0.8845207095146179
loss:  26.88347053527832 0.9215110540390015
loss:  26.62977409362793 0.9044800400733948
loss:  26.769142150878906 0.8870987296104431
loss:  26.49789810180664 0.8908908367156982
loss:  26.37606430053711 0.897014319896698
loss:  26.210905075073242 0.8585125803947449
loss:  25.50347900390625 0.819511890411377
*******************Epoch 47 ****************** 960 1.0
Validation Loss
*** pred loss:  25.574975967407227 pred acc: 0.5759661793708801
*** stop loss:  6.035991668701172 stop acc: 0.9244707822799683
*** template loss:  7.497220516204834 template acc: tensor(0.1242, device='cuda:0')
*** label loss:  6.126274108886719 label acc: tensor(0.3706, device='cuda:0')
Train Loss
---> pred loss: 19.663417053222656 pred acc: 0.6821890234947204
---> stop loss: 3.788596343994141 stop acc: 0.9563636749982833
---> template loss: 1.2482585906982422 tempalte acc: 0.7259079933166503
---> molecule label loss: 1.0184879302978516 molecule acc: 0.7741094589233398
---> kl loss: 0.8824825286865234
---> reconstruction loss: 25.718759536743164
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-48-with.npy
loss:  26.703006744384766 0.9050460457801819
loss:  26.649944305419922 0.8870960474014282
loss:  26.501436233520508 0.8904432654380798
loss:  26.60054588317871 0.8774933218955994
loss:  27.093429565429688 0.9071287512779236
loss:  26.753204345703125 0.8693888187408447
loss:  26.857995986938477 0.889802873134613
loss:  26.663864135742188 0.8676855564117432
loss:  26.675668716430664 0.8500855565071106
loss:  27.06981086730957 0.8743155002593994
loss:  26.61092758178711 0.8364711403846741
loss:  26.51140022277832 0.8373657464981079
loss:  26.254161834716797 0.832004725933075
loss:  26.3080997467041 0.8480518460273743
loss:  26.630481719970703 0.8791778087615967
loss:  26.604034423828125 0.8874958753585815
loss:  26.54136085510254 0.8642491102218628
loss:  26.54996681213379 0.8780813813209534
loss:  26.609464645385742 0.8877488970756531
loss:  25.39331817626953 0.8912537693977356
*******************Epoch 48 ****************** 980 1.0
Validation Loss
*** pred loss:  25.580059051513672 pred acc: 0.5774154663085938
*** stop loss:  6.017332553863525 stop acc: 0.9254047870635986
*** template loss:  7.470716953277588 template acc: tensor(0.1217, device='cuda:0')
*** label loss:  6.176645278930664 label acc: tensor(0.3680, device='cuda:0')
Train Loss
---> pred loss: 19.564622497558595 pred acc: 0.6837669521570205
---> stop loss: 3.875889205932617 stop acc: 0.9550213068723679
---> template loss: 1.2588994026184082 tempalte acc: 0.7195896625518798
---> molecule label loss: 1.0066750526428223 molecule acc: 0.7738600730895996
---> kl loss: 0.8730194091796875
---> reconstruction loss: 25.706088256835937
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-49-with.npy
loss:  26.066604614257812 0.8700823187828064
loss:  26.457988739013672 0.8652259111404419
loss:  25.990795135498047 0.8421128988265991
loss:  26.525009155273438 0.8611425757408142
loss:  26.379043579101562 0.8757889866828918
loss:  26.724388122558594 0.8613205552101135
loss:  26.18387794494629 0.8456129431724548
loss:  26.037620544433594 0.834192156791687
loss:  26.228965759277344 0.8555165529251099
loss:  26.533933639526367 0.857019305229187
loss:  26.349180221557617 0.8508331179618835
loss:  26.26337242126465 0.838513970375061
loss:  26.418920516967773 0.8427340388298035
loss:  26.55474090576172 0.8639041781425476
loss:  26.178747177124023 0.8507483601570129
loss:  26.361116409301758 0.8515558838844299
loss:  26.06385040283203 0.8756328225135803
loss:  26.32704734802246 0.8482916355133057
loss:  26.127450942993164 0.8572977185249329
loss:  26.852928161621094 0.9004191756248474
*******************Epoch 49 ****************** 1000 1.0
Validation Loss
*** pred loss:  25.320669174194336 pred acc: 0.5785627961158752
*** stop loss:  6.077357769012451 stop acc: 0.9249066114425659
*** template loss:  7.516355991363525 template acc: tensor(0.1206, device='cuda:0')
*** label loss:  6.150026798248291 label acc: tensor(0.3688, device='cuda:0')
Train Loss
---> pred loss: 19.529917907714843 pred acc: 0.6860133856534958
---> stop loss: 3.743099594116211 stop acc: 0.9572643309831619
---> template loss: 1.2327511787414551 tempalte acc: 0.7278389453887939
---> molecule label loss: 0.968114185333252 molecule acc: 0.7791507244110107
---> kl loss: 0.8573972702026367
---> reconstruction loss: 25.473880195617678
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-50-with.npy
loss:  26.10511589050293 0.8454538583755493
loss:  26.34148406982422 0.8662706613540649
loss:  26.63103485107422 0.8476146459579468
loss:  26.21790313720703 0.8518175482749939
loss:  26.230159759521484 0.841854453086853
loss:  26.243728637695312 0.8390806317329407
loss:  26.198577880859375 0.8392597436904907
loss:  26.648038864135742 0.832379937171936
loss:  26.14235496520996 0.8631415963172913
loss:  25.700550079345703 0.8578053116798401
loss:  25.976566314697266 0.8516693115234375
loss:  25.948850631713867 0.8429378271102905
loss:  26.14957046508789 0.8149420022964478
loss:  25.797204971313477 0.8247249126434326
loss:  26.17473602294922 0.8177511692047119
loss:  26.526399612426758 0.8435642123222351
loss:  26.091569900512695 0.8360458016395569
loss:  26.000768661499023 0.8442853093147278
loss:  26.33514404296875 0.8221398591995239
loss:  25.41792106628418 0.8787881135940552
*******************Epoch 50 ****************** 1020 1.0
Validation Loss
*** pred loss:  25.25938606262207 pred acc: 0.5841183662414551
*** stop loss:  6.171884059906006 stop acc: 0.924408495426178
*** template loss:  7.5116705894470215 template acc: tensor(0.1171, device='cuda:0')
*** label loss:  6.1546549797058105 label acc: tensor(0.3504, device='cuda:0')
Train Loss
---> pred loss: 19.45892333984375 pred acc: 0.686482897400856
---> stop loss: 3.663554382324219 stop acc: 0.9582844853401185
---> template loss: 1.2291763305664063 tempalte acc: 0.7287825584411621
---> molecule label loss: 0.9491510391235352 molecule acc: 0.7842483043670654
---> kl loss: 0.8430763244628906
---> reconstruction loss: 25.30080795288086
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-51-with.npy
loss:  26.00438117980957 0.8300508856773376
loss:  26.389781951904297 0.8537467122077942
loss:  25.988849639892578 0.8476714491844177
loss:  25.639280319213867 0.8261113166809082
loss:  25.818675994873047 0.8298941254615784
loss:  25.962675094604492 0.8169605135917664
loss:  26.483062744140625 0.8243738412857056
loss:  25.8424072265625 0.8076467514038086
loss:  25.954084396362305 0.8213805556297302
loss:  26.240442276000977 0.8144582509994507
loss:  25.91191864013672 0.8147957921028137
loss:  26.13054847717285 0.8092500567436218
loss:  25.89691925048828 0.8156417012214661
loss:  25.629297256469727 0.8006612062454224
loss:  25.387868881225586 0.8026118278503418
loss:  25.87264633178711 0.830502986907959
loss:  25.98829460144043 0.8420314192771912
loss:  25.739561080932617 0.8326283693313599
loss:  25.836288452148438 0.8215062618255615
loss:  25.62476921081543 0.8285702466964722
*******************Epoch 51 ****************** 1040 1.0
Validation Loss
*** pred loss:  25.533445358276367 pred acc: 0.5882246494293213
*** stop loss:  5.969729900360107 stop acc: 0.9251245856285095
*** template loss:  7.57976770401001 template acc: tensor(0.1263, device='cuda:0')
*** label loss:  6.20917272567749 label acc: tensor(0.3658, device='cuda:0')
Train Loss
---> pred loss: 19.333096313476563 pred acc: 0.6881901562213898
---> stop loss: 3.689630889892578 stop acc: 0.9578257828950882
---> template loss: 1.15966739654541 tempalte acc: 0.7430949211120605
---> molecule label loss: 0.9111689567565918 molecule acc: 0.7908906936645508
---> kl loss: 0.8235246658325195
---> reconstruction loss: 25.093562126159668
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-52-with.npy
loss:  25.22096061706543 0.8309710621833801
loss:  25.758426666259766 0.8221665620803833
loss:  26.53352165222168 0.8346943259239197
loss:  26.03493881225586 0.8096116781234741
loss:  25.973176956176758 0.834039032459259
loss:  25.71552848815918 0.8081989884376526
loss:  25.981416702270508 0.8142830729484558
loss:  25.678918838500977 0.7888728380203247
loss:  26.434974670410156 0.788865864276886
loss:  25.58816146850586 0.793653130531311
loss:  26.082551956176758 0.8225308656692505
loss:  25.767518997192383 0.805099606513977
loss:  25.537851333618164 0.8252769112586975
loss:  25.591886520385742 0.8046818971633911
loss:  26.069555282592773 0.801632285118103
loss:  25.736867904663086 0.8139967918395996
loss:  25.566804885864258 0.8135910630226135
loss:  25.826383590698242 0.8107091188430786
loss:  25.469581604003906 0.807616651058197
loss:  26.96685791015625 0.8325867652893066
*******************Epoch 52 ****************** 1060 1.0
Validation Loss
*** pred loss:  25.56336784362793 pred acc: 0.5803743600845337
*** stop loss:  6.553189754486084 stop acc: 0.9203611612319946
*** template loss:  7.504436492919922 template acc: tensor(0.1259, device='cuda:0')
*** label loss:  6.237272262573242 label acc: tensor(0.3808, device='cuda:0')
Train Loss
---> pred loss: 19.305242919921874 pred acc: 0.6911069989204407
---> stop loss: 3.7014793395996093 stop acc: 0.9579782634973526
---> template loss: 1.155369472503662 tempalte acc: 0.7436371326446534
---> molecule label loss: 0.901547622680664 molecule acc: 0.7915440082550049
---> kl loss: 0.8131539344787597
---> reconstruction loss: 25.063640499114992
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-53-with.npy
loss:  25.965900421142578 0.8140875101089478
loss:  25.516080856323242 0.7987928986549377
loss:  25.767541885375977 0.8278883099555969
loss:  26.133682250976562 0.8353121280670166
loss:  25.797056198120117 0.8418672680854797
loss:  26.184188842773438 0.8100811839103699
loss:  25.428638458251953 0.7883203029632568
loss:  25.919187545776367 0.8135395050048828
loss:  25.924612045288086 0.8041626811027527
loss:  25.51040267944336 0.7941592335700989
loss:  25.90688133239746 0.7839153409004211
loss:  25.797494888305664 0.7782095670700073
loss:  25.515893936157227 0.7855058908462524
loss:  25.612024307250977 0.7963609099388123
loss:  25.67472267150879 0.7955763339996338
loss:  25.803390502929688 0.817661464214325
loss:  25.005083084106445 0.7824276685714722
loss:  25.885700225830078 0.7976712584495544
loss:  25.393524169921875 0.7997755408287048
loss:  25.54835319519043 0.7670073509216309
*******************Epoch 53 ****************** 1080 1.0
Validation Loss
*** pred loss:  25.51854705810547 pred acc: 0.5827898383140564
*** stop loss:  6.043891906738281 stop acc: 0.9243773818016052
*** template loss:  7.566452980041504 template acc: tensor(0.1242, device='cuda:0')
*** label loss:  6.234860420227051 label acc: tensor(0.3796, device='cuda:0')
Train Loss
---> pred loss: 19.199107360839843 pred acc: 0.6898436784744263
---> stop loss: 3.7189796447753904 stop acc: 0.9571669340133667
---> template loss: 1.1328006744384767 tempalte acc: 0.7460265636444092
---> molecule label loss: 0.8620148658752441 molecule acc: 0.799563980102539
---> kl loss: 0.801616096496582
---> reconstruction loss: 24.912904167175295
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-54-with.npy
loss:  25.165945053100586 0.7948880195617676
loss:  25.715288162231445 0.7854523062705994
loss:  25.683074951171875 0.7789182662963867
loss:  25.782794952392578 0.7772791385650635
loss:  25.529626846313477 0.7658459544181824
loss:  25.810335159301758 0.773386538028717
loss:  25.592769622802734 0.7928401231765747
loss:  25.93561553955078 0.8110650777816772
loss:  25.48872947692871 0.7664395570755005
loss:  25.518266677856445 0.8114909529685974
loss:  25.405141830444336 0.8139788508415222
loss:  25.26036262512207 0.8279159069061279
loss:  25.34781265258789 0.8026906251907349
loss:  25.85142707824707 0.8062282204627991
loss:  25.40055274963379 0.7827923893928528
loss:  25.725236892700195 0.7805808186531067
loss:  25.225603103637695 0.7926493883132935
loss:  25.616718292236328 0.8029863238334656
loss:  25.114025115966797 0.7963523864746094
loss:  26.13405990600586 0.7849045395851135
*******************Epoch 54 ****************** 1100 1.0
Validation Loss
*** pred loss:  25.470773696899414 pred acc: 0.5823067426681519
*** stop loss:  6.285190105438232 stop acc: 0.9236612915992737
*** template loss:  7.526375770568848 template acc: tensor(0.1294, device='cuda:0')
*** label loss:  6.171131134033203 label acc: tensor(0.3641, device='cuda:0')
Train Loss
---> pred loss: 19.08482208251953 pred acc: 0.6915445685386657
---> stop loss: 3.7253849029541017 stop acc: 0.9573053449392319
---> template loss: 1.1086586952209472 tempalte acc: 0.7531840801239014
---> molecule label loss: 0.8538702011108399 molecule acc: 0.8031796455383301
---> kl loss: 0.7924342632293702
---> reconstruction loss: 24.772737550735474
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-55-with.npy
loss:  24.967519760131836 0.7764464020729065
loss:  24.929277420043945 0.7843379974365234
loss:  25.195308685302734 0.7653390169143677
loss:  25.527677536010742 0.7825548052787781
loss:  25.288124084472656 0.7781054377555847
loss:  25.581880569458008 0.8051526546478271
loss:  25.52718162536621 0.79291832447052
loss:  25.659549713134766 0.774791955947876
loss:  25.361173629760742 0.7636111974716187
loss:  25.334375381469727 0.7779481410980225
loss:  25.44614028930664 0.7686609029769897
loss:  25.94774627685547 0.7760159373283386
loss:  24.86155128479004 0.758489727973938
loss:  25.104297637939453 0.7681751847267151
loss:  25.304109573364258 0.7785385251045227
loss:  25.155437469482422 0.7603804469108582
loss:  24.977054595947266 0.7728392481803894
loss:  25.160457611083984 0.7774854302406311
loss:  25.016645431518555 0.7476086020469666
loss:  24.347808837890625 0.7333847880363464
*******************Epoch 55 ****************** 1120 1.0
Validation Loss
*** pred loss:  25.567317962646484 pred acc: 0.5842995047569275
*** stop loss:  6.105255126953125 stop acc: 0.9251556992530823
*** template loss:  7.535856246948242 template acc: tensor(0.1294, device='cuda:0')
*** label loss:  6.398052215576172 label acc: tensor(0.3892, device='cuda:0')
Train Loss
---> pred loss: 18.98623046875 pred acc: 0.692492538690567
---> stop loss: 3.6383346557617187 stop acc: 0.958569797873497
---> template loss: 1.0473380088806152 tempalte acc: 0.7659751415252686
---> molecule label loss: 0.7906240463256836 molecule acc: 0.8163642883300781
---> kl loss: 0.7721392631530761
---> reconstruction loss: 24.462525653839112
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-56-with.npy
loss:  25.011564254760742 0.7827717661857605
loss:  24.798227310180664 0.7606017589569092
loss:  24.71572494506836 0.7641820311546326
loss:  25.648080825805664 0.766457736492157
loss:  25.04741668701172 0.7358391284942627
loss:  24.972679138183594 0.7136802673339844
loss:  25.04582405090332 0.7315554022789001
loss:  25.32844352722168 0.755736231803894
loss:  25.19515037536621 0.758826732635498
loss:  25.857452392578125 0.7532614469528198
loss:  25.037572860717773 0.7428342700004578
loss:  25.010425567626953 0.7561747431755066
loss:  25.612119674682617 0.7638601660728455
loss:  25.134239196777344 0.7652634382247925
loss:  24.881103515625 0.75941401720047
loss:  25.15216827392578 0.750455379486084
loss:  24.54837989807129 0.7605416774749756
loss:  25.162994384765625 0.7510061264038086
loss:  25.496252059936523 0.7862715721130371
loss:  26.1109561920166 0.7982885837554932
*******************Epoch 56 ****************** 1140 1.0
Validation Loss
*** pred loss:  25.631999969482422 pred acc: 0.5805555582046509
*** stop loss:  6.823004245758057 stop acc: 0.9207970499992371
*** template loss:  7.535008430480957 template acc: tensor(0.1319, device='cuda:0')
*** label loss:  6.25784969329834 label acc: tensor(0.3778, device='cuda:0')
Train Loss
---> pred loss: 18.964984130859374 pred acc: 0.694583785533905
---> stop loss: 3.6623001098632812 stop acc: 0.9581972777843475
---> template loss: 1.0238885879516602 tempalte acc: 0.7706271171569824
---> molecule label loss: 0.7793176651000977 molecule acc: 0.8171299934387207
---> kl loss: 0.7578511238098145
---> reconstruction loss: 24.430488109588623
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-57-with.npy
loss:  25.133102416992188 0.7399775385856628
loss:  25.203250885009766 0.770384669303894
loss:  25.026065826416016 0.7508053779602051
loss:  25.227149963378906 0.7580248117446899
loss:  25.165348052978516 0.7627289295196533
loss:  25.369043350219727 0.7466417551040649
loss:  25.09630012512207 0.7555063366889954
loss:  24.53899574279785 0.7534664869308472
loss:  24.778404235839844 0.7487061619758606
loss:  24.800004959106445 0.7235544323921204
loss:  24.783424377441406 0.7426778674125671
loss:  24.763622283935547 0.7451794147491455
loss:  25.054656982421875 0.7515485882759094
loss:  24.915584564208984 0.7652806639671326
loss:  24.85394287109375 0.7697376012802124
loss:  25.084745407104492 0.7571390867233276
loss:  25.23982048034668 0.7439761757850647
loss:  24.627002716064453 0.7556655406951904
loss:  25.06616973876953 0.7558143138885498
loss:  23.49608039855957 0.6856600642204285
*******************Epoch 57 ****************** 1160 1.0
Validation Loss
*** pred loss:  25.775014877319336 pred acc: 0.5760265588760376
*** stop loss:  6.062613010406494 stop acc: 0.9266812205314636
*** template loss:  7.558226108551025 template acc: tensor(0.1308, device='cuda:0')
*** label loss:  6.187643051147461 label acc: tensor(0.3656, device='cuda:0')
Train Loss
---> pred loss: 18.810504150390624 pred acc: 0.6966511696577072
---> stop loss: 3.619829559326172 stop acc: 0.9587016195058823
---> template loss: 0.9863433837890625 tempalte acc: 0.7796061992645263
---> molecule label loss: 0.7453353404998779 molecule acc: 0.8239878654479981
---> kl loss: 0.7491238594055176
---> reconstruction loss: 24.162012004852294
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-58-with.npy
loss:  24.317153930664062 0.7429819703102112
loss:  24.420310974121094 0.7295578122138977
loss:  24.649396896362305 0.7386913895606995
loss:  24.86998748779297 0.7320038080215454
loss:  24.480480194091797 0.7443356513977051
loss:  24.812450408935547 0.7257950901985168
loss:  24.611534118652344 0.7166262865066528
loss:  24.747852325439453 0.7249737977981567
loss:  24.936731338500977 0.7070099115371704
loss:  24.640419006347656 0.7192909121513367
loss:  24.8000431060791 0.7534357309341431
loss:  24.665971755981445 0.7208421230316162
loss:  24.298404693603516 0.7324630618095398
loss:  24.606027603149414 0.7329502701759338
loss:  24.67495346069336 0.7248430252075195
loss:  25.286102294921875 0.7065175771713257
loss:  24.913585662841797 0.7346064448356628
loss:  24.965547561645508 0.7143687009811401
loss:  24.394481658935547 0.6900339126586914
loss:  24.56719207763672 0.7235215902328491
*******************Epoch 58 ****************** 1180 1.0
Validation Loss
*** pred loss:  25.68682098388672 pred acc: 0.5783212184906006
*** stop loss:  6.157007217407227 stop acc: 0.9249377846717834
*** template loss:  7.545312881469727 template acc: tensor(0.1344, device='cuda:0')
*** label loss:  6.254432201385498 label acc: tensor(0.3800, device='cuda:0')
Train Loss
---> pred loss: 18.765234375 pred acc: 0.697506308555603
---> stop loss: 3.491168212890625 stop acc: 0.9605446487665177
---> template loss: 0.9772911071777344 tempalte acc: 0.7802216529846191
---> molecule label loss: 0.723495626449585 molecule acc: 0.8279231071472168
---> kl loss: 0.7257424354553222
---> reconstruction loss: 23.957189083099365
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-59-with.npy
loss:  24.366764068603516 0.7058378458023071
loss:  24.478557586669922 0.720650315284729
loss:  24.2733154296875 0.7369596362113953
loss:  24.685834884643555 0.7394723296165466
loss:  24.447532653808594 0.7472569942474365
loss:  24.3953914642334 0.7198901176452637
loss:  24.609188079833984 0.7274170517921448
loss:  24.67736053466797 0.724187970161438
loss:  24.64234733581543 0.7230887413024902
loss:  24.640056610107422 0.7259194850921631
loss:  24.704849243164062 0.7100178003311157
loss:  24.279258728027344 0.729920506477356
loss:  24.887910842895508 0.7152960896492004
loss:  24.729013442993164 0.7136403322219849
loss:  24.556655883789062 0.7308117151260376
loss:  24.60124397277832 0.7359412312507629
loss:  24.576507568359375 0.7258994579315186
loss:  24.416173934936523 0.7274981737136841
loss:  24.672061920166016 0.7220858931541443
loss:  24.243310928344727 0.7412713766098022
*******************Epoch 59 ****************** 1200 1.0
Validation Loss
*** pred loss:  25.657331466674805 pred acc: 0.5833333134651184
*** stop loss:  6.139808654785156 stop acc: 0.9257161021232605
*** template loss:  7.557338714599609 template acc: tensor(0.1305, device='cuda:0')
*** label loss:  6.23944091796875 label acc: tensor(0.3558, device='cuda:0')
Train Loss
---> pred loss: 18.671719360351563 pred acc: 0.6983879446983338
---> stop loss: 3.4814300537109375 stop acc: 0.9604024052619934
---> template loss: 0.9600947380065918 tempalte acc: 0.7861185073852539
---> molecule label loss: 0.7047686100006103 molecule acc: 0.8330777168273926
---> kl loss: 0.7261531352996826
---> reconstruction loss: 23.818013429641724
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-60-with.npy
loss:  24.400745391845703 0.7110797762870789
loss:  24.430747985839844 0.710318386554718
loss:  24.697032928466797 0.7137457132339478
loss:  24.380176544189453 0.7262401580810547
loss:  24.68242073059082 0.7273023128509521
loss:  24.28382682800293 0.699398398399353
loss:  24.48977279663086 0.7052571773529053
loss:  24.58457374572754 0.7070134282112122
loss:  24.35321044921875 0.7071442008018494
loss:  24.449316024780273 0.7115147113800049
loss:  24.165372848510742 0.6975414156913757
loss:  24.584590911865234 0.7148116827011108
loss:  24.415294647216797 0.7031436562538147
loss:  24.585872650146484 0.7125686407089233
loss:  24.524261474609375 0.7208659648895264
loss:  24.697650909423828 0.7287651896476746
loss:  24.000497817993164 0.7008020281791687
loss:  24.15843963623047 0.7013144493103027
loss:  24.706056594848633 0.6873446106910706
loss:  24.349687576293945 0.6697259545326233
*******************Epoch 60 ****************** 1220 1.0
Validation Loss
*** pred loss:  25.66141128540039 pred acc: 0.5847222208976746
*** stop loss:  6.105630874633789 stop acc: 0.9250311851501465
*** template loss:  7.564325332641602 template acc: tensor(0.1365, device='cuda:0')
*** label loss:  6.261322498321533 label acc: tensor(0.3804, device='cuda:0')
Train Loss
---> pred loss: 18.63104705810547 pred acc: 0.6987568974494934
---> stop loss: 3.4800209045410155 stop acc: 0.9605801910161972
---> template loss: 0.941291618347168 tempalte acc: 0.7890400409698486
---> molecule label loss: 0.6868227958679199 molecule acc: 0.8370738983154297
---> kl loss: 0.7077948570251464
---> reconstruction loss: 23.73918390274048
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-61-with.npy
loss:  23.955476760864258 0.6934667825698853
loss:  24.502756118774414 0.699929416179657
loss:  24.499248504638672 0.7031700611114502
loss:  24.14691925048828 0.6941239833831787
loss:  24.39255714416504 0.6937647461891174
loss:  24.7666015625 0.6827858686447144
loss:  24.6363525390625 0.7097286581993103
loss:  24.407777786254883 0.6910654306411743
loss:  24.037403106689453 0.6967227458953857
loss:  23.929052352905273 0.7024072408676147
loss:  24.26959991455078 0.7125394344329834
loss:  24.460399627685547 0.7009336352348328
loss:  24.361122131347656 0.7316110134124756
loss:  24.223438262939453 0.7018017768859863
loss:  24.218534469604492 0.7112746834754944
loss:  24.641693115234375 0.7325877547264099
loss:  24.338619232177734 0.7178118824958801
loss:  24.177032470703125 0.6925304532051086
loss:  24.11016082763672 0.7033389210700989
loss:  24.311960220336914 0.7002893686294556
*******************Epoch 61 ****************** 1240 1.0
Validation Loss
*** pred loss:  25.715909957885742 pred acc: 0.5829709768295288
*** stop loss:  6.099368572235107 stop acc: 0.9248443841934204
*** template loss:  7.596107006072998 template acc: tensor(0.1266, device='cuda:0')
*** label loss:  6.332073211669922 label acc: tensor(0.3691, device='cuda:0')
Train Loss
---> pred loss: 18.567393493652343 pred acc: 0.7009586066007614
---> stop loss: 3.459122085571289 stop acc: 0.9610051780939102
---> template loss: 0.9253994941711425 tempalte acc: 0.7910043239593506
---> molecule label loss: 0.6638244152069092 molecule acc: 0.8412442207336426
---> kl loss: 0.7035942077636719
---> reconstruction loss: 23.61574020385742
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-62-with.npy
loss:  24.17911148071289 0.7146883010864258
loss:  24.116609573364258 0.7028526663780212
loss:  24.187023162841797 0.6877257227897644
loss:  24.173755645751953 0.6868041753768921
loss:  24.841663360595703 0.6753813624382019
loss:  24.339509963989258 0.7013030648231506
loss:  24.26306915283203 0.7030611038208008
loss:  24.984786987304688 0.683516800403595
loss:  24.324851989746094 0.6623709797859192
loss:  24.40018653869629 0.675554096698761
loss:  24.62887954711914 0.6754780411720276
loss:  24.934791564941406 0.6642221212387085
loss:  24.670310974121094 0.679115355014801
loss:  23.981361389160156 0.6466876268386841
loss:  24.719959259033203 0.6728366017341614
loss:  24.33393096923828 0.6823514103889465
loss:  24.775354385375977 0.6959824562072754
loss:  24.201427459716797 0.6874822378158569
loss:  24.347383499145508 0.6945634484291077
loss:  23.992130279541016 0.6983356475830078
*******************Epoch 62 ****************** 1260 1.0
Validation Loss
*** pred loss:  25.761690139770508 pred acc: 0.5799517035484314
*** stop loss:  6.118660926818848 stop acc: 0.9263076186180115
*** template loss:  7.5920939445495605 template acc: tensor(0.1270, device='cuda:0')
*** label loss:  6.260493755340576 label acc: tensor(0.3489, device='cuda:0')
Train Loss
---> pred loss: 18.481338500976562 pred acc: 0.7004685789346695
---> stop loss: 3.4408130645751953 stop acc: 0.9610297918319702
---> template loss: 1.0202366828918457 tempalte acc: 0.7689707756042481
---> molecule label loss: 0.7929000854492188 molecule acc: 0.803769588470459
---> kl loss: 0.6845156669616699
---> reconstruction loss: 23.73528871536255
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-63-with.npy
loss:  24.0488224029541 0.6975122690200806
loss:  24.343175888061523 0.7018821835517883
loss:  24.351274490356445 0.708015501499176
loss:  24.911680221557617 0.7195633053779602
loss:  24.421010971069336 0.7053802609443665
loss:  24.53499984741211 0.7050616145133972
loss:  24.699832916259766 0.6980700492858887
loss:  24.28862190246582 0.6923114061355591
loss:  23.840957641601562 0.6965956091880798
loss:  24.527191162109375 0.6909220814704895
loss:  24.545743942260742 0.7100859880447388
loss:  24.27149772644043 0.6916734576225281
loss:  24.475482940673828 0.6675084233283997
loss:  24.51764678955078 0.6856798529624939
loss:  24.33229637145996 0.6722434163093567
loss:  24.542686462402344 0.6735605001449585
loss:  24.061983108520508 0.6795486211776733
loss:  24.202070236206055 0.686010479927063
loss:  24.279935836791992 0.6852652430534363
loss:  23.32207489013672 0.6700284481048584
*******************Epoch 63 ****************** 1280 1.0
Validation Loss
*** pred loss:  25.636512756347656 pred acc: 0.5818236470222473
*** stop loss:  6.176673889160156 stop acc: 0.9260274171829224
*** template loss:  7.6122565269470215 template acc: tensor(0.1266, device='cuda:0')
*** label loss:  6.364716529846191 label acc: tensor(0.3868, device='cuda:0')
Train Loss
---> pred loss: 18.373455810546876 pred acc: 0.7037429451942444
---> stop loss: 3.503961181640625 stop acc: 0.9601707220077514
---> template loss: 1.0152467727661132 tempalte acc: 0.7687515258789063
---> molecule label loss: 0.7414393424987793 molecule acc: 0.8169718742370605
---> kl loss: 0.6918458461761474
---> reconstruction loss: 23.63410325050354
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-64-with.npy
loss:  23.942245483398438 0.6622472405433655
loss:  24.405630111694336 0.683307409286499
loss:  23.98843002319336 0.6899389624595642
loss:  23.99380111694336 0.684840202331543
loss:  24.355819702148438 0.6740850210189819
loss:  23.89729118347168 0.6853318810462952
loss:  23.914527893066406 0.6789538264274597
loss:  23.697355270385742 0.6774453520774841
loss:  23.878835678100586 0.6864553093910217
loss:  23.63469886779785 0.6695368885993958
loss:  24.140487670898438 0.6660337448120117
loss:  23.979005813598633 0.6820036768913269
loss:  23.733551025390625 0.6843951344490051
loss:  23.774253845214844 0.7006901502609253
loss:  23.927509307861328 0.683684766292572
loss:  23.24180793762207 0.6648663878440857
loss:  23.90610694885254 0.6728413701057434
loss:  24.156007766723633 0.665377676486969
loss:  23.982742309570312 0.6682659983634949
loss:  25.044891357421875 0.6810590624809265
*******************Epoch 64 ****************** 1300 1.0
Validation Loss
*** pred loss:  25.86399269104004 pred acc: 0.5817028880119324
*** stop loss:  6.299261093139648 stop acc: 0.925186812877655
*** template loss:  7.6463623046875 template acc: tensor(0.1305, device='cuda:0')
*** label loss:  6.20842981338501 label acc: tensor(0.3622, device='cuda:0')
Train Loss
---> pred loss: 18.34369354248047 pred acc: 0.7045225262641907
---> stop loss: 3.382191848754883 stop acc: 0.9618695914745331
---> template loss: 0.9225048065185547 tempalte acc: 0.791339635848999
---> molecule label loss: 0.6532932758331299 molecule acc: 0.8380950927734375
---> kl loss: 0.678067970275879
---> reconstruction loss: 23.301682090759275
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-65-with.npy
loss:  23.655818939208984 0.652091920375824
loss:  23.881994247436523 0.6485466361045837
loss:  23.815048217773438 0.6435618996620178
loss:  24.181575775146484 0.6428717374801636
loss:  24.114845275878906 0.6303719878196716
loss:  23.79530143737793 0.6573037505149841
loss:  23.87962532043457 0.6529470682144165
loss:  23.8230037689209 0.648614764213562
loss:  24.174909591674805 0.6662549376487732
loss:  24.152128219604492 0.671946108341217
loss:  24.0202579498291 0.6749829649925232
loss:  24.220247268676758 0.6567530632019043
loss:  23.717037200927734 0.6736816763877869
loss:  23.812870025634766 0.6483257412910461
loss:  23.870849609375 0.6422872543334961
loss:  23.60093116760254 0.6521762609481812
loss:  24.231098175048828 0.661132276058197
loss:  23.937030792236328 0.6599435806274414
loss:  23.992908477783203 0.6461524367332458
loss:  26.081336975097656 0.659022331237793
*******************Epoch 65 ****************** 1320 1.0
Validation Loss
*** pred loss:  25.971921920776367 pred acc: 0.5803139805793762
*** stop loss:  6.3426408767700195 stop acc: 0.923723578453064
*** template loss:  7.582732677459717 template acc: tensor(0.1340, device='cuda:0')
*** label loss:  6.242401599884033 label acc: tensor(0.3828, device='cuda:0')
Train Loss
---> pred loss: 18.402629089355468 pred acc: 0.7041827976703644
---> stop loss: 3.399031066894531 stop acc: 0.9618028491735459
---> template loss: 0.9324438095092773 tempalte acc: 0.7885018348693847
---> molecule label loss: 0.6593864440917969 molecule acc: 0.8373042106628418
---> kl loss: 0.654448413848877
---> reconstruction loss: 23.393493175506592
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-66-with.npy
loss:  23.918659210205078 0.6502237319946289
loss:  23.56143569946289 0.6663619875907898
loss:  23.73932647705078 0.6467461585998535
loss:  24.547094345092773 0.6732296943664551
loss:  24.171175003051758 0.665023922920227
loss:  23.846342086791992 0.6630451083183289
loss:  23.657655715942383 0.6669444441795349
loss:  23.904085159301758 0.6672727465629578
loss:  23.7091007232666 0.6494680047035217
loss:  23.323043823242188 0.64717698097229
loss:  23.74874496459961 0.6700992584228516
loss:  24.032888412475586 0.64479660987854
loss:  24.03144073486328 0.6319859027862549
loss:  23.664501190185547 0.6501471400260925
loss:  23.412857055664062 0.6338384747505188
loss:  24.004884719848633 0.6375858187675476
loss:  23.922483444213867 0.6605933904647827
loss:  23.318998336791992 0.6671546101570129
loss:  23.759374618530273 0.6405633091926575
loss:  23.69462776184082 0.6243282556533813
*******************Epoch 66 ****************** 1340 1.0
Validation Loss
*** pred loss:  25.955810546875 pred acc: 0.5757849812507629
*** stop loss:  6.187265396118164 stop acc: 0.9259029030799866
*** template loss:  7.541967868804932 template acc: tensor(0.1323, device='cuda:0')
*** label loss:  6.23341178894043 label acc: tensor(0.3798, device='cuda:0')
Train Loss
---> pred loss: 18.214492797851562 pred acc: 0.7047578573226929
---> stop loss: 3.3704044342041017 stop acc: 0.9620763003826142
---> template loss: 0.929515266418457 tempalte acc: 0.7902300357818604
---> molecule label loss: 0.6311921596527099 molecule acc: 0.8451371192932129
---> kl loss: 0.6528292179107666
---> reconstruction loss: 23.14560523033142
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-67-with.npy
loss:  23.452743530273438 0.6536787152290344
loss:  24.088459014892578 0.6594404578208923
loss:  23.620723724365234 0.6617644429206848
loss:  24.067550659179688 0.6448296904563904
loss:  23.51921844482422 0.627703070640564
loss:  24.030447006225586 0.636803925037384
loss:  23.523174285888672 0.6500973105430603
loss:  23.231279373168945 0.654217541217804
loss:  23.783472061157227 0.6613299250602722
loss:  23.778369903564453 0.651803195476532
loss:  23.452987670898438 0.6556659936904907
loss:  23.78544044494629 0.6762775778770447
loss:  23.72901725769043 0.6497417092323303
loss:  23.480709075927734 0.6453850865364075
loss:  23.598533630371094 0.6708571314811707
loss:  23.68990135192871 0.6606075763702393
loss:  23.996305465698242 0.6476740837097168
loss:  23.781352996826172 0.6625633835792542
loss:  23.52858543395996 0.6366004943847656
loss:  22.959386825561523 0.6505826711654663
*******************Epoch 67 ****************** 1360 1.0
Validation Loss
*** pred loss:  26.087862014770508 pred acc: 0.5770531296730042
*** stop loss:  6.272310256958008 stop acc: 0.9260274171829224
*** template loss:  7.605213165283203 template acc: tensor(0.1287, device='cuda:0')
*** label loss:  6.272335052490234 label acc: tensor(0.3842, device='cuda:0')
Train Loss
---> pred loss: 18.140895080566406 pred acc: 0.7056753396987915
---> stop loss: 3.3561027526855467 stop acc: 0.9620672285556793
---> template loss: 0.8889246940612793 tempalte acc: 0.7976778030395508
---> molecule label loss: 0.6160794258117676 molecule acc: 0.847409439086914
---> kl loss: 0.6528811931610108
---> reconstruction loss: 23.002001619338987
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-68-with.npy
loss:  23.400197982788086 0.64162278175354
loss:  23.16224479675293 0.6425119638442993
loss:  23.807342529296875 0.6451148390769958
loss:  23.557296752929688 0.6397140026092529
loss:  23.617712020874023 0.6676313281059265
loss:  23.49078941345215 0.6527358293533325
loss:  23.703065872192383 0.6500867605209351
loss:  23.0671443939209 0.6482895612716675
loss:  23.717729568481445 0.6492310166358948
loss:  23.57923126220703 0.6184704899787903
loss:  23.339515686035156 0.6340723037719727
loss:  23.42743492126465 0.6146511435508728
loss:  23.963380813598633 0.6305596232414246
loss:  23.41015625 0.6237465143203735
loss:  23.21805763244629 0.615821897983551
loss:  23.700382232666016 0.6234092712402344
loss:  23.11994171142578 0.6363248825073242
loss:  23.799293518066406 0.633709728717804
loss:  23.487701416015625 0.6265007257461548
loss:  22.672595977783203 0.6652030348777771
*******************Epoch 68 ****************** 1380 1.0
Validation Loss
*** pred loss:  26.150177001953125 pred acc: 0.575664222240448
*** stop loss:  6.403749465942383 stop acc: 0.923225462436676
*** template loss:  7.584856986999512 template acc: tensor(0.1337, device='cuda:0')
*** label loss:  6.327195644378662 label acc: tensor(0.3892, device='cuda:0')
Train Loss
---> pred loss: 18.070611572265626 pred acc: 0.707202622294426
---> stop loss: 3.3140628814697264 stop acc: 0.9625181972980499
---> template loss: 0.8556657791137695 tempalte acc: 0.8071780204772949
---> molecule label loss: 0.5837500095367432 molecule acc: 0.8556586265563965
---> kl loss: 0.6379704475402832
---> reconstruction loss: 22.82408857345581
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-69-with.npy
loss:  23.484966278076172 0.6272340416908264
loss:  23.275680541992188 0.6352449059486389
loss:  23.6038761138916 0.6459956169128418
loss:  23.211912155151367 0.6318895220756531
loss:  23.31233024597168 0.6210939288139343
loss:  23.39277458190918 0.6085495948791504
loss:  23.02849578857422 0.5987392067909241
loss:  23.459671020507812 0.6222496032714844
loss:  23.162263870239258 0.6364807486534119
loss:  23.460668563842773 0.631357729434967
loss:  23.41872215270996 0.6268463134765625
loss:  23.455909729003906 0.6315857172012329
loss:  23.433780670166016 0.6547147035598755
loss:  23.1939640045166 0.6292921900749207
loss:  23.306840896606445 0.6403867602348328
loss:  23.275487899780273 0.6436551809310913
loss:  23.16267204284668 0.6165709495544434
loss:  23.322345733642578 0.6295367479324341
loss:  23.131446838378906 0.6169291734695435
loss:  22.72594451904297 0.5813238620758057
*******************Epoch 69 ****************** 1400 1.0
Validation Loss
*** pred loss:  25.995180130004883 pred acc: 0.5807970762252808
*** stop loss:  6.243722915649414 stop acc: 0.9250311851501465
*** template loss:  7.589277267456055 template acc: tensor(0.1368, device='cuda:0')
*** label loss:  6.366792678833008 label acc: tensor(0.3787, device='cuda:0')
Train Loss
---> pred loss: 17.98064727783203 pred acc: 0.7086443722248077
---> stop loss: 3.320347213745117 stop acc: 0.9627529114484787
---> template loss: 0.8142181396484375 tempalte acc: 0.8169493675231934
---> molecule label loss: 0.5492924690246582 molecule acc: 0.8635808944702148
---> kl loss: 0.6264838218688965
---> reconstruction loss: 22.664502811431888
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-70-with.npy
loss:  23.002988815307617 0.6147372126579285
loss:  23.752687454223633 0.6209352612495422
loss:  23.474205017089844 0.6375622153282166
loss:  23.316242218017578 0.6309688091278076
loss:  23.450769424438477 0.6158950328826904
loss:  23.099979400634766 0.6335091590881348
loss:  23.228271484375 0.6143048405647278
loss:  23.481813430786133 0.6279479265213013
loss:  23.141632080078125 0.6293039321899414
loss:  23.028772354125977 0.622663676738739
loss:  23.274816513061523 0.6156808137893677
loss:  22.83819007873535 0.6053141951560974
loss:  22.969018936157227 0.6155408024787903
loss:  23.039249420166016 0.6132151484489441
loss:  22.6729679107666 0.6156262159347534
loss:  22.8010311126709 0.6068114042282104
loss:  22.78407096862793 0.6002990007400513
loss:  23.201927185058594 0.6162052154541016
loss:  23.502952575683594 0.6123029589653015
loss:  22.107328414916992 0.5969086289405823
*******************Epoch 70 ****************** 1420 1.0
Validation Loss
*** pred loss:  26.022151947021484 pred acc: 0.5832125544548035
*** stop loss:  6.267138481140137 stop acc: 0.925186812877655
*** template loss:  7.59321928024292 template acc: tensor(0.1354, device='cuda:0')
*** label loss:  6.320539951324463 label acc: tensor(0.3868, device='cuda:0')
Train Loss
---> pred loss: 17.905302429199217 pred acc: 0.7107832700014114
---> stop loss: 3.255125045776367 stop acc: 0.9636769026517868
---> template loss: 0.8005363464355468 tempalte acc: 0.8184504508972168
---> molecule label loss: 0.5301959991455079 molecule acc: 0.8691132545471192
---> kl loss: 0.6172866344451904
---> reconstruction loss: 22.49116063117981
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-71-with.npy
loss:  22.81082534790039 0.593069851398468
loss:  22.838512420654297 0.612947940826416
loss:  22.697444915771484 0.6069268584251404
loss:  22.767850875854492 0.5873128771781921
loss:  22.809812545776367 0.5954055786132812
loss:  22.966962814331055 0.6043169498443604
loss:  23.310352325439453 0.6038174033164978
loss:  23.338584899902344 0.6147747039794922
loss:  22.623960494995117 0.5981687903404236
loss:  22.845882415771484 0.605418860912323
loss:  23.012788772583008 0.6097527146339417
loss:  23.010169982910156 0.6072996258735657
loss:  22.783226013183594 0.6056349277496338
loss:  23.229516983032227 0.5987614989280701
loss:  22.948246002197266 0.6142628192901611
loss:  23.04779052734375 0.6127437949180603
loss:  22.93668556213379 0.6091628670692444
loss:  23.767234802246094 0.6135420799255371
loss:  22.993850708007812 0.6054816842079163
loss:  22.982967376708984 0.6614588499069214
*******************Epoch 71 ****************** 1440 1.0
Validation Loss
*** pred loss:  26.153512954711914 pred acc: 0.5790458917617798
*** stop loss:  6.4489359855651855 stop acc: 0.9243462085723877
*** template loss:  7.627788543701172 template acc: tensor(0.1396, device='cuda:0')
*** label loss:  6.32297945022583 label acc: tensor(0.3571, device='cuda:0')
Train Loss
---> pred loss: 17.842144775390626 pred acc: 0.7116755574941636
---> stop loss: 3.2565845489501952 stop acc: 0.9635419368743896
---> template loss: 0.7745679378509521 tempalte acc: 0.8245512008666992
---> molecule label loss: 0.504822063446045 molecule acc: 0.8748112678527832
---> kl loss: 0.6080130577087403
---> reconstruction loss: 22.37811975479126
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-72-with.npy
loss:  23.17997169494629 0.6197889447212219
loss:  22.799501419067383 0.6209472417831421
loss:  22.833955764770508 0.6229837536811829
loss:  22.941757202148438 0.6175885796546936
loss:  23.06283187866211 0.6045529842376709
loss:  23.093780517578125 0.602541446685791
loss:  22.758678436279297 0.6146420836448669
loss:  22.69282341003418 0.6200272440910339
loss:  22.916854858398438 0.6013041734695435
loss:  22.988847732543945 0.620576024055481
loss:  22.53705406188965 0.6103090047836304
loss:  23.073814392089844 0.6091011166572571
loss:  22.94839096069336 0.6116275191307068
loss:  23.153736114501953 0.5992168188095093
loss:  22.81583595275879 0.612659752368927
loss:  22.743093490600586 0.5904170870780945
loss:  22.785192489624023 0.6007861495018005
loss:  22.596988677978516 0.5924279093742371
loss:  23.108646392822266 0.5840566754341125
loss:  24.46701431274414 0.6089192628860474
*******************Epoch 72 ****************** 1460 1.0
Validation Loss
*** pred loss:  26.20572280883789 pred acc: 0.5743961334228516
*** stop loss:  6.276034355163574 stop acc: 0.9240348935127258
*** template loss:  7.678507328033447 template acc: tensor(0.1354, device='cuda:0')
*** label loss:  6.3363542556762695 label acc: tensor(0.3905, device='cuda:0')
Train Loss
---> pred loss: 17.830487060546876 pred acc: 0.7126345336437225
---> stop loss: 3.2775440216064453 stop acc: 0.9635265737771987
---> template loss: 0.7588255882263184 tempalte acc: 0.829340648651123
---> molecule label loss: 0.49985761642456056 molecule acc: 0.8755392074584961
---> kl loss: 0.6082236766815186
---> reconstruction loss: 22.366715288162233
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-73-with.npy
loss:  23.1698055267334 0.5934041738510132
loss:  22.729028701782227 0.6099685430526733
loss:  22.658096313476562 0.6255902051925659
loss:  23.0023250579834 0.6246876120567322
loss:  23.372676849365234 0.6287991404533386
loss:  22.72187614440918 0.6233270168304443
loss:  23.23211669921875 0.6162503361701965
loss:  23.133291244506836 0.6036468744277954
loss:  22.44891357421875 0.6048995852470398
loss:  22.9150390625 0.6019659042358398
loss:  22.866775512695312 0.6041879057884216
loss:  22.521474838256836 0.606584370136261
loss:  23.221843719482422 0.587090253829956
loss:  23.205963134765625 0.597400963306427
loss:  22.919002532958984 0.5696850419044495
loss:  22.792776107788086 0.5853415727615356
loss:  22.8341121673584 0.5752809643745422
loss:  22.803848266601562 0.5893945097923279
loss:  22.83743667602539 0.5870795249938965
loss:  22.113937377929688 0.6024635434150696
*******************Epoch 73 ****************** 1480 1.0
Validation Loss
*** pred loss:  26.155302047729492 pred acc: 0.5841787457466125
*** stop loss:  7.059773921966553 stop acc: 0.9199875593185425
*** template loss:  7.613507270812988 template acc: tensor(0.1351, device='cuda:0')
*** label loss:  6.405179977416992 label acc: tensor(0.3821, device='cuda:0')
Train Loss
---> pred loss: 17.765452575683593 pred acc: 0.7127844750881195
---> stop loss: 3.3015262603759767 stop acc: 0.9626909852027893
---> template loss: 0.7285595417022706 tempalte acc: 0.8361889839172363
---> molecule label loss: 0.47762837409973147 molecule acc: 0.8808058738708496
---> kl loss: 0.6018523693084716
---> reconstruction loss: 22.27316288948059
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-74-with.npy
loss:  23.223125457763672 0.5882937908172607
loss:  23.198055267333984 0.5996013283729553
loss:  22.407445907592773 0.5854068398475647
loss:  22.898366928100586 0.5796492695808411
loss:  22.63994789123535 0.5924800634384155
loss:  22.910701751708984 0.6016861796379089
loss:  22.91787338256836 0.5824310183525085
loss:  22.8360652923584 0.6025874614715576
loss:  22.716899871826172 0.6095167994499207
loss:  22.709951400756836 0.5997186899185181
loss:  22.80264663696289 0.5942062735557556
loss:  22.92730140686035 0.6077882647514343
loss:  22.821796417236328 0.5921788811683655
loss:  22.511934280395508 0.602112352848053
loss:  22.69731330871582 0.5824821591377258
loss:  22.650169372558594 0.5907829403877258
loss:  22.327415466308594 0.5912714004516602
loss:  22.8485107421875 0.589000403881073
loss:  22.724422454833984 0.5676218271255493
loss:  22.324138641357422 0.5626753568649292
*******************Epoch 74 ****************** 1500 1.0
Validation Loss
*** pred loss:  26.426443099975586 pred acc: 0.5745168924331665
*** stop loss:  6.363325595855713 stop acc: 0.9256538152694702
*** template loss:  7.622770309448242 template acc: tensor(0.1389, device='cuda:0')
*** label loss:  6.345020294189453 label acc: tensor(0.3733, device='cuda:0')
Train Loss
---> pred loss: 17.681629943847657 pred acc: 0.7129144340753555
---> stop loss: 3.2943374633789064 stop acc: 0.9629651665687561
---> template loss: 0.7209290504455567 tempalte acc: 0.8363640785217286
---> molecule label loss: 0.46673221588134767 molecule acc: 0.8834761619567871
---> kl loss: 0.5910746097564697
---> reconstruction loss: 22.163631200790405
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-75-with.npy
loss:  22.42796516418457 0.5763458013534546
loss:  22.39806365966797 0.5898300409317017
loss:  22.9886474609375 0.5860189199447632
loss:  22.49949836730957 0.5722962021827698
loss:  22.362293243408203 0.5755353569984436
loss:  22.612279891967773 0.5973330736160278
loss:  22.438491821289062 0.5774458646774292
loss:  22.572275161743164 0.5840176343917847
loss:  22.934368133544922 0.5908288955688477
loss:  22.79050636291504 0.6011550426483154
loss:  22.377405166625977 0.584532618522644
loss:  22.80170440673828 0.5886962413787842
loss:  22.742263793945312 0.5806902050971985
loss:  22.425138473510742 0.5997501015663147
loss:  22.565141677856445 0.5848668217658997
loss:  22.522871017456055 0.5928261280059814
loss:  22.76205062866211 0.5755807161331177
loss:  22.706457138061523 0.5764091610908508
loss:  22.828899383544922 0.5663020610809326
loss:  21.735403060913086 0.5581517219543457
*******************Epoch 75 ****************** 1520 1.0
Validation Loss
*** pred loss:  26.27246856689453 pred acc: 0.5805555582046509
*** stop loss:  6.410881519317627 stop acc: 0.9256538152694702
*** template loss:  7.6187005043029785 template acc: tensor(0.1432, device='cuda:0')
*** label loss:  6.357991695404053 label acc: tensor(0.3768, device='cuda:0')
Train Loss
---> pred loss: 17.612759399414063 pred acc: 0.7146370232105255
---> stop loss: 3.2133552551269533 stop acc: 0.9636642873287201
---> template loss: 0.7058442592620849 tempalte acc: 0.841454029083252
---> molecule label loss: 0.45969762802124026 molecule acc: 0.8839867591857911
---> kl loss: 0.5829306602478027
---> reconstruction loss: 21.991657352447508
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-76-with.npy
loss:  22.281118392944336 0.5864297747612
loss:  22.63413429260254 0.5835086107254028
loss:  22.030723571777344 0.575749397277832
loss:  22.65692710876465 0.5842190384864807
loss:  22.715810775756836 0.5872158408164978
loss:  22.268829345703125 0.5991898775100708
loss:  22.731260299682617 0.5973667502403259
loss:  22.523439407348633 0.589641809463501
loss:  22.650842666625977 0.5742775797843933
loss:  22.535799026489258 0.5761414170265198
loss:  22.564870834350586 0.5910032987594604
loss:  22.74397850036621 0.5615847110748291
loss:  22.928678512573242 0.592468798160553
loss:  22.502431869506836 0.5880458950996399
loss:  22.67406463623047 0.578825056552887
loss:  22.398469924926758 0.5756045579910278
loss:  22.550092697143555 0.5931695103645325
loss:  22.343769073486328 0.5751484036445618
loss:  22.39234161376953 0.5728868842124939
loss:  23.05930519104004 0.5480132699012756
*******************Epoch 76 ****************** 1540 1.0
Validation Loss
*** pred loss:  26.359493255615234 pred acc: 0.5766907930374146
*** stop loss:  6.226016044616699 stop acc: 0.9259651899337769
*** template loss:  7.657601356506348 template acc: tensor(0.1368, device='cuda:0')
*** label loss:  6.431381702423096 label acc: tensor(0.3858, device='cuda:0')
Train Loss
---> pred loss: 17.597311401367186 pred acc: 0.7156201422214508
---> stop loss: 3.2390426635742187 stop acc: 0.9637113332748413
---> template loss: 0.6898279666900635 tempalte acc: 0.8467551231384277
---> molecule label loss: 0.4516387939453125 molecule acc: 0.885129165649414
---> kl loss: 0.5815245151519776
---> reconstruction loss: 21.977819967269898
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-77-with.npy
loss:  22.19354248046875 0.5818801522254944
loss:  22.436687469482422 0.5802245140075684
loss:  22.088729858398438 0.5836012959480286
loss:  22.543684005737305 0.560515820980072
loss:  22.38248062133789 0.560482382774353
loss:  22.35163116455078 0.5535805821418762
loss:  22.436208724975586 0.5552682280540466
loss:  22.655658721923828 0.5580324530601501
loss:  22.517879486083984 0.5614268779754639
loss:  22.694759368896484 0.5532118082046509
loss:  22.2416934967041 0.553124725818634
loss:  22.21108055114746 0.5615580081939697
loss:  21.990772247314453 0.5840088725090027
loss:  22.311946868896484 0.5713948011398315
loss:  22.352027893066406 0.5874764323234558
loss:  22.56570816040039 0.5590938925743103
loss:  22.911605834960938 0.570589005947113
loss:  22.59617805480957 0.5707805156707764
loss:  22.14702606201172 0.582252025604248
loss:  22.674423217773438 0.5887620449066162
*******************Epoch 77 ****************** 1560 1.0
Validation Loss
*** pred loss:  26.40066146850586 pred acc: 0.5757849812507629
*** stop loss:  6.206361770629883 stop acc: 0.9266812205314636
*** template loss:  7.647179126739502 template acc: tensor(0.1432, device='cuda:0')
*** label loss:  6.465717792510986 label acc: tensor(0.3834, device='cuda:0')
Train Loss
---> pred loss: 17.579914855957032 pred acc: 0.7150486141443253
---> stop loss: 3.1205434799194336 stop acc: 0.9650262802839279
---> template loss: 0.6968281745910645 tempalte acc: 0.8454879760742188
---> molecule label loss: 0.4490354061126709 molecule acc: 0.8876057624816894
---> kl loss: 0.5688632011413575
---> reconstruction loss: 21.846325397491455
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-78-with.npy
loss:  22.169628143310547 0.5737169981002808
loss:  22.41291618347168 0.5943124294281006
loss:  22.4265079498291 0.5785708427429199
loss:  22.218782424926758 0.5692634582519531
loss:  21.98824691772461 0.5813467502593994
loss:  22.420635223388672 0.5787636041641235
loss:  22.324296951293945 0.5879420042037964
loss:  22.477750778198242 0.5683978199958801
loss:  22.321643829345703 0.5774314999580383
loss:  22.477392196655273 0.5674554705619812
loss:  22.317344665527344 0.5551639199256897
loss:  22.280803680419922 0.5733798146247864
loss:  22.085405349731445 0.5545458793640137
loss:  22.653295516967773 0.5676915049552917
loss:  22.158489227294922 0.5698058009147644
loss:  22.390867233276367 0.5692256689071655
loss:  22.285499572753906 0.5551578402519226
loss:  22.306621551513672 0.5774025321006775
loss:  22.185274124145508 0.5641812682151794
loss:  22.23461151123047 0.5706682801246643
*******************Epoch 78 ****************** 1580 1.0
Validation Loss
*** pred loss:  26.369140625 pred acc: 0.5848429799079895
*** stop loss:  6.321789741516113 stop acc: 0.9272727370262146
*** template loss:  7.628686428070068 template acc: tensor(0.1425, device='cuda:0')
*** label loss:  6.5036797523498535 label acc: tensor(0.3879, device='cuda:0')
Train Loss
---> pred loss: 17.483824157714842 pred acc: 0.7168550580739975
---> stop loss: 3.114030456542969 stop acc: 0.9651994466781616
---> template loss: 0.6898560047149658 tempalte acc: 0.8455450057983398
---> molecule label loss: 0.44736814498901367 molecule acc: 0.8860610008239747
---> kl loss: 0.5717211723327636
---> reconstruction loss: 21.735078144073483
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-79-with.npy
loss:  22.184999465942383 0.5609087944030762
loss:  21.927370071411133 0.5629163384437561
loss:  22.149168014526367 0.5685352683067322
loss:  22.40883445739746 0.5496148467063904
loss:  22.14707374572754 0.5600912570953369
loss:  22.351926803588867 0.5556899905204773
loss:  22.44314956665039 0.564928412437439
loss:  22.400592803955078 0.557243824005127
loss:  22.15264892578125 0.5545010566711426
loss:  22.243955612182617 0.5558002591133118
loss:  21.999910354614258 0.5372296571731567
loss:  21.937891006469727 0.5422799587249756
loss:  22.195505142211914 0.5404170751571655
loss:  21.912673950195312 0.5504576563835144
loss:  22.0238037109375 0.5442104935646057
loss:  22.476646423339844 0.558722734451294
loss:  22.2463436126709 0.5495065450668335
loss:  22.413694381713867 0.5688585042953491
loss:  22.223323822021484 0.5611559748649597
loss:  21.502714157104492 0.5700568556785583
*******************Epoch 79 ****************** 1600 1.0
Validation Loss
*** pred loss:  26.420299530029297 pred acc: 0.5847222208976746
*** stop loss:  6.260681629180908 stop acc: 0.9266812205314636
*** template loss:  7.714366912841797 template acc: tensor(0.1382, device='cuda:0')
*** label loss:  6.551729679107666 label acc: tensor(0.3898, device='cuda:0')
Train Loss
---> pred loss: 17.39056396484375 pred acc: 0.7185823380947113
---> stop loss: 3.1182811737060545 stop acc: 0.965179905295372
---> template loss: 0.6717284202575684 tempalte acc: 0.8497179985046387
---> molecule label loss: 0.4308811664581299 molecule acc: 0.8909296035766602
---> kl loss: 0.5556562423706055
---> reconstruction loss: 21.611454963684082
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-80-with.npy
loss:  22.119962692260742 0.5542015433311462
loss:  21.908065795898438 0.5715901851654053
loss:  22.250513076782227 0.5734978914260864
loss:  21.912105560302734 0.5616119503974915
loss:  21.894676208496094 0.5574615001678467
loss:  22.109355926513672 0.5705807209014893
loss:  22.126840591430664 0.5394429564476013
loss:  22.060949325561523 0.5574400424957275
loss:  22.189912796020508 0.5621929168701172
loss:  21.755704879760742 0.5512533783912659
loss:  22.161823272705078 0.5455193519592285
loss:  22.107730865478516 0.5634729862213135
loss:  22.316368103027344 0.5550887584686279
loss:  22.35573387145996 0.5601211190223694
loss:  22.363121032714844 0.5499541163444519
loss:  22.397695541381836 0.5451915264129639
loss:  21.840164184570312 0.544497013092041
loss:  21.99114227294922 0.5403165817260742
loss:  22.33308219909668 0.5411514639854431
loss:  23.08549690246582 0.5327833890914917
*******************Epoch 80 ****************** 1620 1.0
Validation Loss
*** pred loss:  26.411821365356445 pred acc: 0.5833936929702759
*** stop loss:  6.5989484786987305 stop acc: 0.924595296382904
*** template loss:  7.700251579284668 template acc: tensor(0.1330, device='cuda:0')
*** label loss:  6.658900737762451 label acc: tensor(0.3898, device='cuda:0')
Train Loss
---> pred loss: 17.37965087890625 pred acc: 0.7177268177270889
---> stop loss: 3.0905357360839845 stop acc: 0.965726351737976
---> template loss: 0.6948141098022461 tempalte acc: 0.8432145118713379
---> molecule label loss: 0.44515366554260255 molecule acc: 0.8873786926269531
---> kl loss: 0.5538684368133545
---> reconstruction loss: 21.610154390335083
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-81-with.npy
loss:  21.86472511291504 0.5512845516204834
loss:  22.088516235351562 0.5506150722503662
loss:  21.613630294799805 0.5310686826705933
loss:  21.98311424255371 0.5377370715141296
loss:  21.963863372802734 0.5450012683868408
loss:  22.275800704956055 0.5582563281059265
loss:  22.3449764251709 0.5543164014816284
loss:  22.16324234008789 0.537726104259491
loss:  22.478208541870117 0.5615149140357971
loss:  22.307296752929688 0.5620734095573425
loss:  21.927536010742188 0.5405775904655457
loss:  21.743183135986328 0.5437343716621399
loss:  22.192996978759766 0.5413610339164734
loss:  22.079566955566406 0.548867404460907
loss:  22.104625701904297 0.5520247220993042
loss:  22.11444091796875 0.5523496270179749
loss:  22.01519012451172 0.5442847013473511
loss:  21.940807342529297 0.5500869154930115
loss:  22.073457717895508 0.541567862033844
loss:  22.7114315032959 0.5831971764564514
*******************Epoch 81 ****************** 1640 1.0
Validation Loss
*** pred loss:  26.509695053100586 pred acc: 0.5729468464851379
*** stop loss:  6.456664085388184 stop acc: 0.9246886968612671
*** template loss:  7.682438850402832 template acc: tensor(0.1421, device='cuda:0')
*** label loss:  6.489365100860596 label acc: tensor(0.3847, device='cuda:0')
Train Loss
---> pred loss: 17.30877227783203 pred acc: 0.719371497631073
---> stop loss: 3.121748161315918 stop acc: 0.9648933708667755
---> template loss: 0.6760362148284912 tempalte acc: 0.8478885650634765
---> molecule label loss: 0.4433900833129883 molecule acc: 0.8855555534362793
---> kl loss: 0.5493822574615479
---> reconstruction loss: 21.549946355819703
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-82-with.npy
loss:  22.117950439453125 0.5477378964424133
loss:  21.63539695739746 0.5509111881256104
loss:  21.911041259765625 0.5485970377922058
loss:  21.842805862426758 0.5670955181121826
loss:  21.87937355041504 0.5469583868980408
loss:  22.420133590698242 0.5673192739486694
loss:  21.660924911499023 0.5605858564376831
loss:  22.06045150756836 0.5627496838569641
loss:  21.894010543823242 0.5431860685348511
loss:  21.503158569335938 0.524257242679596
loss:  22.098297119140625 0.5259820818901062
loss:  22.03153419494629 0.5395838618278503
loss:  21.97785186767578 0.533889651298523
loss:  21.880422592163086 0.5395711660385132
loss:  21.858680725097656 0.5411752462387085
loss:  21.87959861755371 0.5186907052993774
loss:  21.89431381225586 0.5393416285514832
loss:  21.639802932739258 0.5312008261680603
loss:  22.050521850585938 0.5357295274734497
loss:  23.047775268554688 0.6002660393714905
*******************Epoch 82 ****************** 1660 1.0
Validation Loss
*** pred loss:  26.613723754882812 pred acc: 0.5785024166107178
*** stop loss:  6.387345790863037 stop acc: 0.9260897040367126
*** template loss:  7.72400426864624 template acc: tensor(0.1439, device='cuda:0')
*** label loss:  6.455765247344971 label acc: tensor(0.3787, device='cuda:0')
Train Loss
---> pred loss: 17.282066345214844 pred acc: 0.718674224615097
---> stop loss: 3.063384246826172 stop acc: 0.9656071037054061
---> template loss: 0.6622977256774902 tempalte acc: 0.8504984855651856
---> molecule label loss: 0.4102138042449951 molecule acc: 0.8950571060180664
---> kl loss: 0.5462414741516113
---> reconstruction loss: 21.417961406707764
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-83-with.npy
loss:  21.72938346862793 0.5333565473556519
loss:  22.007192611694336 0.5501381158828735
loss:  21.772974014282227 0.5351770520210266
loss:  21.84865379333496 0.5533604025840759
loss:  22.213224411010742 0.5308526158332825
loss:  22.105613708496094 0.517913818359375
loss:  21.801013946533203 0.5362515449523926
loss:  22.281936645507812 0.5426709651947021
loss:  22.14956283569336 0.5610902905464172
loss:  22.04830551147461 0.5279161930084229
loss:  21.994112014770508 0.5593011379241943
loss:  21.908037185668945 0.5458963513374329
loss:  21.585426330566406 0.548180103302002
loss:  22.18073272705078 0.5580832958221436
loss:  22.222503662109375 0.559647798538208
loss:  21.526161193847656 0.5517888069152832
loss:  22.20452117919922 0.5582289695739746
loss:  21.709428787231445 0.5618586540222168
loss:  22.324064254760742 0.5361770391464233
loss:  21.994787216186523 0.5583052635192871
*******************Epoch 83 ****************** 1680 1.0
Validation Loss
*** pred loss:  26.7523250579834 pred acc: 0.577294647693634
*** stop loss:  6.521302700042725 stop acc: 0.9253736138343811
*** template loss:  7.693338394165039 template acc: tensor(0.1428, device='cuda:0')
*** label loss:  6.3916239738464355 label acc: tensor(0.3620, device='cuda:0')
Train Loss
---> pred loss: 17.177165222167968 pred acc: 0.7205625683069229
---> stop loss: 3.0754343032836915 stop acc: 0.9657138228416443
---> template loss: 0.7176777839660644 tempalte acc: 0.8369235992431641
---> molecule label loss: 0.4637930870056152 molecule acc: 0.8780133247375488
---> kl loss: 0.5463097572326661
---> reconstruction loss: 21.434072017669678
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-84-with.npy
loss:  22.00040054321289 0.5419809818267822
loss:  21.57320785522461 0.5565208196640015
loss:  21.818504333496094 0.5453792810440063
loss:  22.07682991027832 0.5442187190055847
loss:  22.562767028808594 0.5366637110710144
loss:  21.82823944091797 0.5301874876022339
loss:  21.90520668029785 0.5550721883773804
loss:  21.68336296081543 0.5287822484970093
loss:  22.009302139282227 0.5281422734260559
loss:  21.791215896606445 0.5373523235321045
loss:  21.676166534423828 0.5194081664085388
loss:  22.36442756652832 0.5242642164230347
loss:  22.12081527709961 0.5266275405883789
loss:  21.581878662109375 0.53617262840271
loss:  22.196855545043945 0.5494493842124939
loss:  22.025413513183594 0.5318396687507629
loss:  22.11708641052246 0.5098141431808472
loss:  21.527727127075195 0.5285621881484985
loss:  21.831993103027344 0.5154390335083008
loss:  21.453107833862305 0.4805735945701599
*******************Epoch 84 ****************** 1700 1.0
Validation Loss
*** pred loss:  26.605749130249023 pred acc: 0.5795893669128418
*** stop loss:  6.428008079528809 stop acc: 0.9271793365478516
*** template loss:  7.6382365226745605 template acc: tensor(0.1491, device='cuda:0')
*** label loss:  6.55983304977417 label acc: tensor(0.3930, device='cuda:0')
Train Loss
---> pred loss: 17.174223327636717 pred acc: 0.7208376616239548
---> stop loss: 3.0913368225097657 stop acc: 0.9654500544071197
---> template loss: 0.6844244003295898 tempalte acc: 0.8435422897338867
---> molecule label loss: 0.4259175300598145 molecule acc: 0.8879742622375488
---> kl loss: 0.5313225746154785
---> reconstruction loss: 21.375905513763428
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-85-with.npy
loss:  21.510133743286133 0.5279468297958374
loss:  21.395944595336914 0.5112138986587524
loss:  21.59647560119629 0.5219675898551941
loss:  21.6275634765625 0.5250061750411987
loss:  21.690921783447266 0.5267869234085083
loss:  21.81884002685547 0.5301148891448975
loss:  21.83071517944336 0.5288106203079224
loss:  21.853124618530273 0.5489442944526672
loss:  22.101869583129883 0.541619598865509
loss:  21.73969841003418 0.5417118668556213
loss:  21.611495971679688 0.5553818941116333
loss:  21.48118019104004 0.5480087995529175
loss:  22.184545516967773 0.5467279553413391
loss:  21.967683792114258 0.5400279760360718
loss:  21.52086639404297 0.5343968272209167
loss:  21.799909591674805 0.538611114025116
loss:  21.982717514038086 0.537910521030426
loss:  21.416418075561523 0.53045654296875
loss:  21.551300048828125 0.5336379408836365
loss:  20.826065063476562 0.5385664105415344
*******************Epoch 85 ****************** 1720 1.0
Validation Loss
*** pred loss:  26.45351791381836 pred acc: 0.5769927501678467
*** stop loss:  6.48838996887207 stop acc: 0.9254359006881714
*** template loss:  7.686583042144775 template acc: tensor(0.1400, device='cuda:0')
*** label loss:  6.454005241394043 label acc: tensor(0.3905, device='cuda:0')
Train Loss
---> pred loss: 17.090534973144532 pred acc: 0.7229267597198487
---> stop loss: 3.0070127487182616 stop acc: 0.9663971990346909
---> template loss: 0.6475109100341797 tempalte acc: 0.8546933174133301
---> molecule label loss: 0.3949218034744263 molecule acc: 0.8976689338684082
---> kl loss: 0.5353924751281738
---> reconstruction loss: 21.13997983932495
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-86-with.npy
loss:  21.21843719482422 0.5317291021347046
loss:  21.818941116333008 0.5279489159584045
loss:  21.578006744384766 0.5282633900642395
loss:  21.97613525390625 0.5241162776947021
loss:  22.02971839904785 0.5268777012825012
loss:  21.708105087280273 0.5396799445152283
loss:  21.735952377319336 0.5354010462760925
loss:  21.628297805786133 0.5366910099983215
loss:  21.635883331298828 0.5264855027198792
loss:  21.635698318481445 0.5287533402442932
loss:  21.94855308532715 0.531906008720398
loss:  21.550607681274414 0.5295741558074951
loss:  21.31344223022461 0.5258854627609253
loss:  21.662494659423828 0.5202087163925171
loss:  21.483829498291016 0.5306024551391602
loss:  21.328405380249023 0.525607705116272
loss:  21.17687225341797 0.5102848410606384
loss:  21.44849967956543 0.527423620223999
loss:  21.584163665771484 0.5272477269172668
loss:  22.580808639526367 0.5061467289924622
*******************Epoch 86 ****************** 1740 1.0
Validation Loss
*** pred loss:  26.486440658569336 pred acc: 0.5811594128608704
*** stop loss:  6.43230676651001 stop acc: 0.9261519908905029
*** template loss:  7.663789749145508 template acc: tensor(0.1442, device='cuda:0')
*** label loss:  6.468502998352051 label acc: tensor(0.3661, device='cuda:0')
Train Loss
---> pred loss: 17.09600067138672 pred acc: 0.7230018675327301
---> stop loss: 3.0441329956054686 stop acc: 0.9660141110420227
---> template loss: 0.6156748771667481 tempalte acc: 0.8624582290649414
---> molecule label loss: 0.36929447650909425 molecule acc: 0.9035053253173828
---> kl loss: 0.5270416736602783
---> reconstruction loss: 21.125100660324097
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-87-with.npy
loss:  20.97967529296875 0.5525936484336853
loss:  21.51226043701172 0.5560010671615601
loss:  21.520776748657227 0.5400911569595337
loss:  21.37137222290039 0.5430905222892761
loss:  21.677431106567383 0.5419618487358093
loss:  22.070934295654297 0.5139662623405457
loss:  22.076007843017578 0.5061163902282715
loss:  21.203571319580078 0.505412757396698
loss:  21.848793029785156 0.5134002566337585
loss:  21.46581268310547 0.5105391144752502
loss:  21.565797805786133 0.5100650191307068
loss:  21.680749893188477 0.5037415623664856
loss:  21.835777282714844 0.520954430103302
loss:  21.794111251831055 0.5191552042961121
loss:  21.52219581604004 0.5298446416854858
loss:  21.782432556152344 0.5164409279823303
loss:  21.436674118041992 0.5228267908096313
loss:  21.59632682800293 0.5173321962356567
loss:  21.879140853881836 0.5102879405021667
loss:  22.292451858520508 0.555100679397583
*******************Epoch 87 ****************** 1760 1.0
Validation Loss
*** pred loss:  26.889198303222656 pred acc: 0.5780797004699707
*** stop loss:  6.690817356109619 stop acc: 0.9242839813232422
*** template loss:  7.7681779861450195 template acc: tensor(0.1414, device='cuda:0')
*** label loss:  6.67473840713501 label acc: tensor(0.3964, device='cuda:0')
Train Loss
---> pred loss: 17.043661499023436 pred acc: 0.7239649206399917
---> stop loss: 2.973072052001953 stop acc: 0.966816920042038
---> template loss: 0.7073101043701172 tempalte acc: 0.8390415191650391
---> molecule label loss: 0.40712451934814453 molecule acc: 0.8921261787414551
---> kl loss: 0.5244461536407471
---> reconstruction loss: 21.13116755485535
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-88-with.npy
loss:  21.536739349365234 0.5239740014076233
loss:  21.896217346191406 0.5156015753746033
loss:  22.09208106994629 0.5369572639465332
loss:  21.919485092163086 0.519966721534729
loss:  21.931734085083008 0.5241801142692566
loss:  21.592098236083984 0.5189564824104309
loss:  22.094358444213867 0.5383785367012024
loss:  21.505125045776367 0.5315597057342529
loss:  21.55034065246582 0.5319753885269165
loss:  22.244115829467773 0.5328299403190613
loss:  21.379886627197266 0.5210379362106323
loss:  21.402427673339844 0.536134660243988
loss:  22.072168350219727 0.5386466383934021
loss:  21.860368728637695 0.5258301496505737
loss:  21.846933364868164 0.5370017290115356
loss:  21.784452438354492 0.5142098665237427
loss:  21.552629470825195 0.5124460458755493
loss:  21.9583683013916 0.5190329551696777
loss:  21.854272842407227 0.5081844925880432
loss:  21.449552536010742 0.4746578335762024
*******************Epoch 88 ****************** 1780 1.0
Validation Loss
*** pred loss:  26.693334579467773 pred acc: 0.5774154663085938
*** stop loss:  6.7453460693359375 stop acc: 0.9225404858589172
*** template loss:  7.739433288574219 template acc: tensor(0.1386, device='cuda:0')
*** label loss:  6.438916206359863 label acc: tensor(0.3870, device='cuda:0')
Train Loss
---> pred loss: 16.969636535644533 pred acc: 0.7241617888212204
---> stop loss: 3.065475082397461 stop acc: 0.9654617071151733
---> template loss: 0.7314321994781494 tempalte acc: 0.8327384948730469
---> molecule label loss: 0.48654627799987793 molecule acc: 0.869499397277832
---> kl loss: 0.5230781078338623
---> reconstruction loss: 21.253090715408327
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-89-with.npy
loss:  21.85750389099121 0.5145450830459595
loss:  21.56757164001465 0.5001547932624817
loss:  21.143945693969727 0.4995031952857971
loss:  21.456483840942383 0.5110527276992798
loss:  22.03908920288086 0.510932445526123
loss:  21.319604873657227 0.5061050057411194
loss:  22.032657623291016 0.5160812139511108
loss:  21.494951248168945 0.5056322813034058
loss:  21.488012313842773 0.5197399854660034
loss:  21.752098083496094 0.4971136152744293
loss:  21.49881362915039 0.5115034580230713
loss:  21.47418785095215 0.5166260004043579
loss:  21.725200653076172 0.5003746151924133
loss:  21.6624698638916 0.49100062251091003
loss:  21.27705955505371 0.5024620890617371
loss:  21.403541564941406 0.4879210889339447
loss:  21.383604049682617 0.48898378014564514
loss:  21.257484436035156 0.5004531145095825
loss:  21.578147888183594 0.5045472383499146
loss:  21.874418258666992 0.5000576376914978
*******************Epoch 89 ****************** 1800 1.0
Validation Loss
*** pred loss:  26.704322814941406 pred acc: 0.5781400799751282
*** stop loss:  7.185980796813965 stop acc: 0.9201743602752686
*** template loss:  7.7552103996276855 template acc: tensor(0.1372, device='cuda:0')
*** label loss:  6.625227928161621 label acc: tensor(0.4005, device='cuda:0')
Train Loss
---> pred loss: 16.90942840576172 pred acc: 0.7249292224645615
---> stop loss: 3.0348943710327148 stop acc: 0.9657899171113968
---> template loss: 0.673198652267456 tempalte acc: 0.8470385551452637
---> molecule label loss: 0.4425808429718018 molecule acc: 0.8812932014465332
---> kl loss: 0.5042395114898681
---> reconstruction loss: 21.060102224349976
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-90-with.npy
loss:  21.072351455688477 0.5141096711158752
loss:  21.76398468017578 0.5027164220809937
loss:  21.324161529541016 0.517731249332428
loss:  21.958200454711914 0.5205405950546265
loss:  21.64724349975586 0.5311954617500305
loss:  21.520479202270508 0.5227934122085571
loss:  21.652809143066406 0.5110800862312317
loss:  21.31288719177246 0.5161259174346924
loss:  21.52989387512207 0.48463454842567444
loss:  21.25398826599121 0.5044398903846741
loss:  21.903791427612305 0.5039140582084656
loss:  21.46541976928711 0.511782705783844
loss:  21.48963165283203 0.5234313607215881
loss:  21.363744735717773 0.5055062174797058
loss:  21.895105361938477 0.5106409788131714
loss:  21.35382080078125 0.5097146034240723
loss:  21.50701141357422 0.5047509074211121
loss:  21.43341064453125 0.49892500042915344
loss:  21.34982681274414 0.5001680850982666
loss:  21.494295120239258 0.4685339331626892
*******************Epoch 90 ****************** 1820 1.0
Validation Loss
*** pred loss:  26.674959182739258 pred acc: 0.5791062712669373
*** stop loss:  6.620075702667236 stop acc: 0.9236301779747009
*** template loss:  7.683050632476807 template acc: tensor(0.1410, device='cuda:0')
*** label loss:  6.613639831542969 label acc: tensor(0.4016, device='cuda:0')
Train Loss
---> pred loss: 16.891807556152344 pred acc: 0.7262178093194962
---> stop loss: 3.0192453384399416 stop acc: 0.96619533598423
---> template loss: 0.6705941200256348 tempalte acc: 0.8490451812744141
---> molecule label loss: 0.4248193264007568 molecule acc: 0.8850831985473633
---> kl loss: 0.5081367492675781
---> reconstruction loss: 21.006464385986327
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-91-with.npy
loss:  21.113277435302734 0.49863526225090027
loss:  21.514341354370117 0.4994773268699646
loss:  21.486820220947266 0.5005792379379272
loss:  21.246925354003906 0.4902314245700836
loss:  21.35479736328125 0.5115652084350586
loss:  21.334823608398438 0.5007060170173645
loss:  21.59041404724121 0.5080417394638062
loss:  21.018686294555664 0.48022252321243286
loss:  21.256288528442383 0.5083379149436951
loss:  21.01892852783203 0.498360812664032
loss:  21.32270050048828 0.48691150546073914
loss:  21.399751663208008 0.4994724690914154
loss:  21.277742385864258 0.49669188261032104
loss:  21.357337951660156 0.4906269311904907
loss:  21.30817985534668 0.4968498647212982
loss:  21.026700973510742 0.4998577833175659
loss:  21.23933219909668 0.49606770277023315
loss:  21.390146255493164 0.4953290820121765
loss:  21.343477249145508 0.4977954924106598
loss:  22.311655044555664 0.5348032116889954
*******************Epoch 91 ****************** 1840 1.0
Validation Loss
*** pred loss:  26.90961456298828 pred acc: 0.5735507011413574
*** stop loss:  6.597557067871094 stop acc: 0.9242528080940247
*** template loss:  7.727532863616943 template acc: tensor(0.1432, device='cuda:0')
*** label loss:  6.5067315101623535 label acc: tensor(0.3975, device='cuda:0')
Train Loss
---> pred loss: 16.84331359863281 pred acc: 0.7264791160821915
---> stop loss: 2.9858978271484373 stop acc: 0.9665772914886475
---> template loss: 0.6209868431091309 tempalte acc: 0.8599159240722656
---> molecule label loss: 0.3958893775939941 molecule acc: 0.8935582160949707
---> kl loss: 0.4995281219482422
---> reconstruction loss: 20.84608497619629
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-92-with.npy
loss:  21.446516036987305 0.514794647693634
loss:  21.240150451660156 0.5011748671531677
loss:  21.604450225830078 0.5093605518341064
loss:  20.867177963256836 0.5014246106147766
loss:  21.00973129272461 0.5048364996910095
loss:  21.3853816986084 0.5086430311203003
loss:  21.169082641601562 0.5067999362945557
loss:  21.21465301513672 0.5046799182891846
loss:  21.20956802368164 0.49843713641166687
loss:  21.229583740234375 0.5234318971633911
loss:  21.44756317138672 0.5108421444892883
loss:  21.18620491027832 0.4863911271095276
loss:  21.615467071533203 0.5072826743125916
loss:  20.87628746032715 0.49305471777915955
loss:  21.039077758789062 0.5137240290641785
loss:  20.990734100341797 0.49056276679039
loss:  21.424543380737305 0.49705156683921814
loss:  21.16522216796875 0.5133676528930664
loss:  21.08973503112793 0.4956497251987457
loss:  21.082155227661133 0.48917871713638306
*******************Epoch 92 ****************** 1860 1.0
Validation Loss
*** pred loss:  26.779279708862305 pred acc: 0.5795289874076843
*** stop loss:  6.485822677612305 stop acc: 0.926245391368866
*** template loss:  7.680172443389893 template acc: tensor(0.1410, device='cuda:0')
*** label loss:  6.539753437042236 label acc: tensor(0.3986, device='cuda:0')
Train Loss
---> pred loss: 16.788414001464844 pred acc: 0.7273498922586441
---> stop loss: 2.9337549209594727 stop acc: 0.967416524887085
---> template loss: 0.6102447986602784 tempalte acc: 0.8631044387817383
---> molecule label loss: 0.3787174463272095 molecule acc: 0.8985487937927246
---> kl loss: 0.5035343647003174
---> reconstruction loss: 20.71112780570984
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-93-with.npy
loss:  21.079256057739258 0.513556182384491
loss:  21.296566009521484 0.505029022693634
loss:  21.141860961914062 0.5067269206047058
loss:  20.960901260375977 0.5071013569831848
loss:  21.129013061523438 0.5093769431114197
loss:  20.830488204956055 0.5055209398269653
loss:  21.26821517944336 0.5016933083534241
loss:  20.74894905090332 0.5088671445846558
loss:  21.18397331237793 0.4870867431163788
loss:  21.36748504638672 0.48740166425704956
loss:  20.697113037109375 0.48743757605552673
loss:  20.916866302490234 0.49222061038017273
loss:  21.03601837158203 0.4802792966365814
loss:  21.058053970336914 0.5052977800369263
loss:  20.751686096191406 0.48663344979286194
loss:  21.419275283813477 0.4757043719291687
loss:  20.77141571044922 0.4803105890750885
loss:  20.851932525634766 0.48382580280303955
loss:  20.97429084777832 0.47649523615837097
loss:  20.867156982421875 0.49986422061920166
*******************Epoch 93 ****************** 1880 1.0
Validation Loss
*** pred loss:  27.002437591552734 pred acc: 0.5788646936416626
*** stop loss:  6.574461460113525 stop acc: 0.925186812877655
*** template loss:  7.676729202270508 template acc: tensor(0.1421, device='cuda:0')
*** label loss:  6.448331832885742 label acc: tensor(0.3950, device='cuda:0')
Train Loss
---> pred loss: 16.706771850585938 pred acc: 0.7279562681913376
---> stop loss: 2.88116512298584 stop acc: 0.9680106997489929
---> template loss: 0.5810317516326904 tempalte acc: 0.8722204208374024
---> molecule label loss: 0.3535356044769287 molecule acc: 0.9059213638305664
---> kl loss: 0.4950214385986328
---> reconstruction loss: 20.522504806518555
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-94-with.npy
loss:  20.370784759521484 0.4798005223274231
loss:  21.052515029907227 0.49033769965171814
loss:  20.86663246154785 0.5055717825889587
loss:  20.807586669921875 0.5022592544555664
loss:  21.00764274597168 0.49734482169151306
loss:  21.125049591064453 0.507049560546875
loss:  21.16200828552246 0.5031017661094666
loss:  20.97602653503418 0.5052521824836731
loss:  20.840200424194336 0.48696768283843994
loss:  20.827272415161133 0.4995972216129303
loss:  21.086219787597656 0.4981454312801361
loss:  20.673755645751953 0.4882637560367584
loss:  21.002220153808594 0.4789547920227051
loss:  21.00865936279297 0.4835379421710968
loss:  20.64535140991211 0.4814753532409668
loss:  20.998498916625977 0.5000626444816589
loss:  21.018709182739258 0.48037514090538025
loss:  21.44325065612793 0.48108741641044617
loss:  21.056547164916992 0.45974013209342957
loss:  21.68879508972168 0.4754526913166046
*******************Epoch 94 ****************** 1900 1.0
Validation Loss
*** pred loss:  27.000211715698242 pred acc: 0.5768115520477295
*** stop loss:  6.671792984008789 stop acc: 0.9246886968612671
*** template loss:  7.65369987487793 template acc: tensor(0.1442, device='cuda:0')
*** label loss:  6.564537525177002 label acc: tensor(0.4027, device='cuda:0')
Train Loss
---> pred loss: 16.732888793945314 pred acc: 0.7274885177612305
---> stop loss: 2.8986371994018554 stop acc: 0.9678326725959778
---> template loss: 0.5437516212463379 tempalte acc: 0.8813179969787598
---> molecule label loss: 0.31739139556884766 molecule acc: 0.9170533180236816
---> kl loss: 0.4902188301086426
---> reconstruction loss: 20.492665386199953
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-95-with.npy
loss:  20.77426528930664 0.4886119067668915
loss:  20.976839065551758 0.4775089621543884
loss:  21.07364273071289 0.4886001646518707
loss:  20.692569732666016 0.4854052662849426
loss:  21.041275024414062 0.4720298945903778
loss:  21.07661247253418 0.4873294532299042
loss:  20.726205825805664 0.4945729672908783
loss:  20.877784729003906 0.49533936381340027
loss:  20.73697853088379 0.469946026802063
loss:  20.798311233520508 0.48284512758255005
loss:  20.802356719970703 0.4830310642719269
loss:  20.553443908691406 0.4922753572463989
loss:  21.098388671875 0.48555850982666016
loss:  20.98725128173828 0.46585947275161743
loss:  20.866539001464844 0.48102185130119324
loss:  20.75050926208496 0.4745160639286041
loss:  20.8470401763916 0.48533669114112854
loss:  20.460371017456055 0.4838458299636841
loss:  20.79633140563965 0.47684141993522644
loss:  20.274633407592773 0.426082581281662
*******************Epoch 95 ****************** 1920 1.0
Validation Loss
*** pred loss:  26.886180877685547 pred acc: 0.5791062712669373
*** stop loss:  6.5676655769348145 stop acc: 0.9268369078636169
*** template loss:  7.677441120147705 template acc: tensor(0.1495, device='cuda:0')
*** label loss:  6.497300148010254 label acc: tensor(0.3875, device='cuda:0')
Train Loss
---> pred loss: 16.63282165527344 pred acc: 0.7298080384731293
---> stop loss: 2.846996879577637 stop acc: 0.9684130728244782
---> template loss: 0.5369286060333252 tempalte acc: 0.8819995880126953
---> molecule label loss: 0.31399288177490237 molecule acc: 0.9168066024780274
---> kl loss: 0.479827880859375
---> reconstruction loss: 20.330738830566407
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-96-with.npy
loss:  20.20858383178711 0.4602058231830597
loss:  21.0364990234375 0.4916469156742096
loss:  21.15616226196289 0.4774042069911957
loss:  21.434354782104492 0.4714018404483795
loss:  20.556528091430664 0.46763235330581665
loss:  21.11404037475586 0.4893144369125366
loss:  20.561491012573242 0.4808257222175598
loss:  20.858394622802734 0.4815615713596344
loss:  20.52065086364746 0.47307196259498596
loss:  21.024059295654297 0.49892428517341614
loss:  21.103574752807617 0.4750594198703766
loss:  20.78434181213379 0.49180173873901367
loss:  20.60881996154785 0.4859771430492401
loss:  20.635173797607422 0.4648011326789856
loss:  20.586837768554688 0.4755896329879761
loss:  21.021820068359375 0.46463456749916077
loss:  20.552637100219727 0.4626503884792328
loss:  20.738901138305664 0.47007888555526733
loss:  20.69699478149414 0.47248372435569763
loss:  19.97283363342285 0.4557098150253296
*******************Epoch 96 ****************** 1940 1.0
Validation Loss
*** pred loss:  27.192256927490234 pred acc: 0.5770531296730042
*** stop loss:  6.819806098937988 stop acc: 0.9235056638717651
*** template loss:  7.690933704376221 template acc: tensor(0.1414, device='cuda:0')
*** label loss:  6.595137596130371 label acc: tensor(0.4044, device='cuda:0')
Train Loss
---> pred loss: 16.571705627441407 pred acc: 0.7300025165081024
---> stop loss: 2.8342557907104493 stop acc: 0.968465918302536
---> template loss: 0.5542096614837646 tempalte acc: 0.8774389266967774
---> molecule label loss: 0.32292470932006834 molecule acc: 0.9150410652160644
---> kl loss: 0.4755387306213379
---> reconstruction loss: 20.28309621810913
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-97-with.npy
loss:  20.929222106933594 0.4715847969055176
loss:  21.232181549072266 0.45559653639793396
loss:  20.87615966796875 0.4703952968120575
loss:  20.926034927368164 0.47594714164733887
loss:  20.691608428955078 0.4728085994720459
loss:  20.72046661376953 0.47076648473739624
loss:  20.968469619750977 0.48007693886756897
loss:  20.55133056640625 0.480722039937973
loss:  20.895896911621094 0.4638625681400299
loss:  21.155780792236328 0.4771687686443329
loss:  20.837425231933594 0.48010051250457764
loss:  20.58673858642578 0.4753667414188385
loss:  20.82101058959961 0.46632814407348633
loss:  20.721656799316406 0.4841345548629761
loss:  20.855575561523438 0.48375317454338074
loss:  20.806665420532227 0.48708462715148926
loss:  20.567310333251953 0.4609645903110504
loss:  20.56264877319336 0.4624320864677429
loss:  21.046470642089844 0.46606048941612244
loss:  20.517696380615234 0.47921016812324524
*******************Epoch 97 ****************** 1960 1.0
Validation Loss
*** pred loss:  27.315040588378906 pred acc: 0.5797101259231567
*** stop loss:  6.621249198913574 stop acc: 0.9262765049934387
*** template loss:  7.6686859130859375 template acc: tensor(0.1453, device='cuda:0')
*** label loss:  6.4810004234313965 label acc: tensor(0.3857, device='cuda:0')
Train Loss
---> pred loss: 16.560252380371093 pred acc: 0.7295976519584656
---> stop loss: 2.926668167114258 stop acc: 0.9671844393014908
---> template loss: 0.5353054523468017 tempalte acc: 0.8831883430480957
---> molecule label loss: 0.3180715560913086 molecule acc: 0.914975929260254
---> kl loss: 0.4732182025909424
---> reconstruction loss: 20.340299558639526
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-98-with.npy
loss:  20.829465866088867 0.4784912168979645
loss:  20.556781768798828 0.47568953037261963
loss:  21.023000717163086 0.47882479429244995
loss:  20.492969512939453 0.4925821125507355
loss:  20.712751388549805 0.47489404678344727
loss:  20.433687210083008 0.4762548804283142
loss:  20.99146842956543 0.47041693329811096
loss:  20.78002166748047 0.4738031327724457
loss:  20.728551864624023 0.4766818583011627
loss:  20.8346004486084 0.46746039390563965
loss:  20.536712646484375 0.4658931493759155
loss:  20.418853759765625 0.47209256887435913
loss:  20.418006896972656 0.4580429494380951
loss:  20.344087600708008 0.45703595876693726
loss:  20.24402618408203 0.4692257046699524
loss:  20.42239761352539 0.46222367882728577
loss:  20.8624267578125 0.4634780287742615
loss:  20.825550079345703 0.44576147198677063
loss:  20.577260971069336 0.45108407735824585
loss:  19.435054779052734 0.4212697148323059
*******************Epoch 98 ****************** 1980 1.0
Validation Loss
*** pred loss:  27.148386001586914 pred acc: 0.5783212184906006
*** stop loss:  6.9319047927856445 stop acc: 0.9233188629150391
*** template loss:  7.718769550323486 template acc: tensor(0.1467, device='cuda:0')
*** label loss:  6.553601264953613 label acc: tensor(0.3969, device='cuda:0')
Train Loss
---> pred loss: 16.489659118652344 pred acc: 0.7322372943162918
---> stop loss: 2.806367111206055 stop acc: 0.9692105412483215
---> template loss: 0.5129745960235595 tempalte acc: 0.8884184837341309
---> molecule label loss: 0.2978231906890869 molecule acc: 0.921596908569336
---> kl loss: 0.46656031608581544
---> reconstruction loss: 20.106823778152467
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-99-with.npy
loss:  20.955738067626953 0.4665706157684326
loss:  20.89659881591797 0.4629618227481842
loss:  20.47905921936035 0.4583767354488373
loss:  20.77284812927246 0.4592917263507843
loss:  20.882659912109375 0.4713934361934662
loss:  20.53515625 0.4486561715602875
loss:  20.439138412475586 0.4719722270965576
loss:  20.75757598876953 0.4649808406829834
loss:  20.616695404052734 0.4634750187397003
loss:  20.712793350219727 0.46738535165786743
loss:  20.729923248291016 0.4593919813632965
loss:  20.137847900390625 0.4670109450817108
loss:  20.430213928222656 0.4564547836780548
loss:  20.672311782836914 0.4593452215194702
loss:  20.649036407470703 0.44933003187179565
loss:  20.488412857055664 0.4600090980529785
loss:  20.136585235595703 0.4495515823364258
loss:  20.80274200439453 0.45951712131500244
loss:  20.460115432739258 0.4568791687488556
loss:  19.620227813720703 0.45528849959373474
*******************Epoch 99 ****************** 2000 1.0
Validation Loss
*** pred loss:  27.335542678833008 pred acc: 0.5753019452095032
*** stop loss:  6.673768043518066 stop acc: 0.9240971803665161
*** template loss:  7.696637153625488 template acc: tensor(0.1432, device='cuda:0')
*** label loss:  6.516332626342773 label acc: tensor(0.3868, device='cuda:0')
Train Loss
---> pred loss: 16.414956665039064 pred acc: 0.731857243180275
---> stop loss: 2.816013717651367 stop acc: 0.9688271820545197
---> template loss: 0.5407673358917237 tempalte acc: 0.8794232368469238
---> molecule label loss: 0.3266535043716431 molecule acc: 0.9132237434387207
---> kl loss: 0.4603921413421631
---> reconstruction loss: 20.09839234352112
saving file:weights/hidden_size_200_latent_size_200_depth_2_beta_1.0_lr_0.001/bvae_iter-100-with.npy
