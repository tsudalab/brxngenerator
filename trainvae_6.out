cuda is  True
loading data.....
size of reactant dic: 9766
size of template dic: 5567
size of fgm_trees: 20080
size of rxn_trees: 20080
size of fragment dic: 273
hidden size: 300 latent_size: 100 batch size: 1000 depth: 2
beta: 1.0 lr: 0.001
size of data pairs: 20080
trainng size: 19079
valid size: 1000
loss:  144.18690490722656 1.4207186698913574
loss:  136.72254943847656 2.530503749847412
loss:  127.60281372070312 5.316511631011963
loss:  118.11967468261719 11.178326606750488
loss:  107.54454803466797 21.5134220123291
loss:  97.67314910888672 28.438278198242188
loss:  94.50711822509766 29.207210540771484
loss:  86.88410949707031 28.678855895996094
loss:  83.6397476196289 28.510467529296875
loss:  82.13643646240234 28.598283767700195
loss:  79.91755676269531 28.812255859375
loss:  78.54357147216797 28.344324111938477
loss:  77.8468017578125 28.477161407470703
loss:  75.54692077636719 28.20439910888672
loss:  73.66835021972656 27.819780349731445
loss:  72.47689819335938 27.70264434814453
loss:  72.60155487060547 27.25213623046875
loss:  70.82721710205078 27.582075119018555
loss:  70.05270385742188 27.294755935668945
loss:  68.42456817626953 28.10011100769043
*******************Epoch 0 ****************** 20 0.00095
Validation Loss
*** pred loss:  39.8177375793457 pred acc: 0.376086950302124
*** stop loss:  11.358187675476074 stop acc: 0.8442403674125671
*** template loss:  8.626875877380371 template acc: tensor(0.0274, device='cuda:0')
*** label loss:  6.400803565979004 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 60.264703369140626 pred acc: 0.2772632331820205
---> stop loss: 16.462495422363283 stop acc: 0.7641147002577782
---> template loss: 7.758066558837891 tempalte acc: 0.016339963674545287
---> molecule label loss: 6.447937774658203 molecule acc: 0.3639880657196045
---> kl loss: 23.249110412597656
---> reconstruction loss: 90.92408033729554
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-1-with.npy
loss:  69.05419921875 27.626537322998047
loss:  67.29369354248047 27.47475814819336
loss:  67.07178497314453 27.973731994628906
loss:  65.83506774902344 27.84292984008789
loss:  65.52250671386719 27.9128360748291
loss:  64.8991928100586 28.368242263793945
loss:  64.11454772949219 28.601274490356445
loss:  63.92226791381836 29.161277770996094
loss:  63.95112228393555 29.530298233032227
loss:  62.888126373291016 29.605424880981445
loss:  61.959163665771484 30.202180862426758
loss:  61.5308952331543 30.629608154296875
loss:  60.761173248291016 30.355911254882812
loss:  60.45838165283203 30.896942138671875
loss:  59.09722137451172 31.51852798461914
loss:  60.34297561645508 31.8869571685791
loss:  58.152984619140625 32.86064910888672
loss:  58.35823059082031 32.830833435058594
loss:  57.96540451049805 33.534889221191406
loss:  57.869197845458984 33.18727493286133
*******************Epoch 1 ****************** 40 0.0019500000000000001
Validation Loss
*** pred loss:  33.39704132080078 pred acc: 0.4491545855998993
*** stop loss:  9.091710090637207 stop acc: 0.8727273344993591
*** template loss:  8.505971908569336 template acc: tensor(0.0573, device='cuda:0')
*** label loss:  6.277233123779297 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 39.502618408203126 pred acc: 0.3896928131580353
---> stop loss: 10.45669174194336 stop acc: 0.8740761995315551
---> template loss: 7.0142356872558596 tempalte acc: 0.051709705591201784
---> molecule label loss: 5.533903121948242 molecule acc: 0.3828406572341919
---> kl loss: 30.100054931640624
---> reconstruction loss: 62.49370967803955
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-2-with.npy
loss:  56.753021240234375 34.80963134765625
loss:  56.16379928588867 35.3809700012207
loss:  56.19462203979492 35.78456115722656
loss:  55.838191986083984 37.190895080566406
loss:  54.4504508972168 37.06914520263672
loss:  55.042091369628906 37.651947021484375
loss:  54.68394470214844 37.92188262939453
loss:  54.994571685791016 38.057960510253906
loss:  53.541419982910156 38.29679489135742
loss:  53.13764572143555 39.013694763183594
loss:  53.59311294555664 38.38880920410156
loss:  52.25911331176758 38.79243469238281
loss:  52.838741302490234 39.357994079589844
loss:  52.016090393066406 38.850303649902344
loss:  51.96697235107422 40.051212310791016
loss:  51.743003845214844 40.899085998535156
loss:  50.74747085571289 40.75251007080078
loss:  50.38665008544922 41.1378288269043
loss:  50.11056900024414 41.405067443847656
loss:  50.987300872802734 41.90032958984375
*******************Epoch 2 ****************** 60 0.00295
Validation Loss
*** pred loss:  29.692466735839844 pred acc: 0.5116545557975769
*** stop loss:  8.59495735168457 stop acc: 0.8741594552993774
*** template loss:  8.27324104309082 template acc: tensor(0.0742, device='cuda:0')
*** label loss:  6.197212219238281 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 33.43513793945313 pred acc: 0.4830458626151085
---> stop loss: 8.3468994140625 stop acc: 0.900470420718193
---> template loss: 6.195940399169922 tempalte acc: 0.11274259090423584
---> molecule label loss: 5.298285293579101 molecule acc: 0.38389809131622316
---> kl loss: 38.63565368652344
---> reconstruction loss: 53.25846744857788
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-3-with.npy
loss:  49.738948822021484 40.96556854248047
loss:  48.492591857910156 41.376766204833984
loss:  49.47517013549805 41.834312438964844
loss:  49.27202224731445 41.599449157714844
loss:  48.75457000732422 41.717037200927734
loss:  48.390018463134766 41.474971771240234
loss:  48.01435470581055 41.52824401855469
loss:  48.53825759887695 40.840938568115234
loss:  48.06252670288086 41.355133056640625
loss:  47.675132751464844 41.125267028808594
loss:  47.752403259277344 41.081058502197266
loss:  47.68942642211914 40.946083068847656
loss:  46.50206756591797 41.438873291015625
loss:  46.7227668762207 41.55348205566406
loss:  46.82954025268555 41.3958740234375
loss:  46.89361572265625 41.432613372802734
loss:  46.381107330322266 41.813716888427734
loss:  46.412967681884766 41.334861755371094
loss:  45.64311218261719 41.39148712158203
loss:  43.473182678222656 39.903438568115234
*******************Epoch 3 ****************** 80 0.00395
Validation Loss
*** pred loss:  27.699424743652344 pred acc: 0.5481280088424683
*** stop loss:  7.289907455444336 stop acc: 0.8995641469955444
*** template loss:  8.016812324523926 template acc: tensor(0.0904, device='cuda:0')
*** label loss:  6.077761650085449 label acc: tensor(0.3474, device='cuda:0')
Train Loss
---> pred loss: 29.793246459960937 pred acc: 0.5460176140069961
---> stop loss: 7.337818145751953 stop acc: 0.9106630891561508
---> template loss: 5.280755615234375 tempalte acc: 0.18780614137649537
---> molecule label loss: 4.980365753173828 molecule acc: 0.3829488754272461
---> kl loss: 41.30545654296875
---> reconstruction loss: 47.372536806030276
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-4-with.npy
loss:  45.477684020996094 40.587989807128906
loss:  44.868934631347656 40.614295959472656
loss:  44.83930969238281 41.116905212402344
loss:  44.87972640991211 40.07011413574219
loss:  44.9631233215332 41.35327911376953
loss:  44.54855728149414 40.89105987548828
loss:  44.73409652709961 41.085784912109375
loss:  43.71772766113281 40.200218200683594
loss:  43.78593444824219 41.025665283203125
loss:  43.80929183959961 41.532196044921875
loss:  43.510250091552734 40.928585052490234
loss:  43.68712615966797 41.20074462890625
loss:  43.18454360961914 41.128135681152344
loss:  42.90007781982422 41.715911865234375
loss:  42.43806076049805 41.24058532714844
loss:  42.77281188964844 40.69783401489258
loss:  42.74284362792969 41.0006103515625
loss:  41.9421272277832 41.043174743652344
loss:  42.26508712768555 41.10498046875
loss:  44.332088470458984 42.04978942871094
*******************Epoch 4 ****************** 100 0.0049499999999999995
Validation Loss
*** pred loss:  26.159679412841797 pred acc: 0.5703502297401428
*** stop loss:  8.102396965026855 stop acc: 0.8810710310935974
*** template loss:  7.752252101898193 template acc: tensor(0.1024, device='cuda:0')
*** label loss:  6.067876815795898 label acc: tensor(0.3485, device='cuda:0')
Train Loss
---> pred loss: 27.821038818359376 pred acc: 0.5753743678331376
---> stop loss: 6.696363830566407 stop acc: 0.9200524359941482
---> template loss: 4.426061630249023 tempalte acc: 0.27278110980987547
---> molecule label loss: 4.64283447265625 molecule acc: 0.38905043601989747
---> kl loss: 41.02939453125
---> reconstruction loss: 43.56687825195313
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-5-with.npy
loss:  42.028602600097656 41.990264892578125
loss:  41.66962432861328 41.99957275390625
loss:  41.63105010986328 41.47697448730469
loss:  40.71758270263672 41.24262619018555
loss:  41.495506286621094 41.655906677246094
loss:  40.933773040771484 41.058189392089844
loss:  41.100345611572266 40.937408447265625
loss:  40.61001968383789 41.43104934692383
loss:  40.904449462890625 42.266517639160156
loss:  40.959835052490234 41.638771057128906
loss:  40.42381286621094 41.96198272705078
loss:  40.24150466918945 42.02583312988281
loss:  39.9130859375 42.289794921875
loss:  40.49030685424805 41.62588119506836
loss:  40.07261657714844 42.39387512207031
loss:  40.095375061035156 42.005279541015625
loss:  39.47719192504883 41.89836883544922
loss:  39.32568359375 41.90989685058594
loss:  39.86530685424805 42.2954216003418
loss:  39.19533920288086 42.77728271484375
*******************Epoch 5 ****************** 120 0.0059499999999999996
Validation Loss
*** pred loss:  24.94667625427246 pred acc: 0.5909420251846313
*** stop loss:  6.431271553039551 stop acc: 0.9096824526786804
*** template loss:  7.571657657623291 template acc: tensor(0.1228, device='cuda:0')
*** label loss:  6.047277450561523 label acc: tensor(0.3500, device='cuda:0')
Train Loss
---> pred loss: 26.087484741210936 pred acc: 0.5980857819318771
---> stop loss: 6.248991012573242 stop acc: 0.9258787989616394
---> template loss: 3.713887405395508 tempalte acc: 0.3583120584487915
---> molecule label loss: 4.278018569946289 molecule acc: 0.40033688545227053
---> kl loss: 41.84404296875
---> reconstruction loss: 40.308577993164064
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-6-with.npy
loss:  39.267181396484375 42.415992736816406
loss:  38.83546447753906 41.895301818847656
loss:  38.01266860961914 42.04991912841797
loss:  38.57078552246094 41.832637786865234
loss:  37.63257598876953 42.01667022705078
loss:  37.8863525390625 41.99212646484375
loss:  38.51503372192383 42.41990661621094
loss:  37.736976623535156 42.602012634277344
loss:  37.47550964355469 41.70332336425781
loss:  37.736305236816406 42.25711441040039
loss:  37.728328704833984 42.889495849609375
loss:  37.340309143066406 42.32139205932617
loss:  37.059410095214844 42.349212646484375
loss:  37.992733001708984 42.73773956298828
loss:  37.29889678955078 42.18158721923828
loss:  37.828617095947266 42.04899597167969
loss:  36.698486328125 42.35688018798828
loss:  36.688682556152344 42.57067108154297
loss:  36.78709411621094 42.5247802734375
loss:  38.399471282958984 43.490997314453125
*******************Epoch 6 ****************** 140 0.00695
Validation Loss
*** pred loss:  24.06581687927246 pred acc: 0.6079710125923157
*** stop loss:  6.1269097328186035 stop acc: 0.9146326780319214
*** template loss:  7.404148578643799 template acc: tensor(0.1323, device='cuda:0')
*** label loss:  5.994126796722412 label acc: tensor(0.3524, device='cuda:0')
Train Loss
---> pred loss: 24.686056518554686 pred acc: 0.620323184132576
---> stop loss: 5.735393905639649 stop acc: 0.9330049455165863
---> template loss: 3.172290229797363 tempalte acc: 0.4307404041290283
---> molecule label loss: 3.9066333770751953 molecule acc: 0.41666078567504883
---> kl loss: 42.3328369140625
---> reconstruction loss: 37.48032901977539
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-7-with.npy
loss:  36.04364013671875 42.810604095458984
loss:  36.51511764526367 43.35814666748047
loss:  35.962745666503906 43.14806365966797
loss:  36.137481689453125 43.31206130981445
loss:  35.86507797241211 43.52199935913086
loss:  35.77996063232422 44.047706604003906
loss:  35.725868225097656 43.301361083984375
loss:  35.81569290161133 43.78834533691406
loss:  35.75359344482422 43.629066467285156
loss:  36.003658294677734 43.32860565185547
loss:  35.6058235168457 43.59221649169922
loss:  36.05156707763672 44.18640899658203
loss:  35.21060562133789 43.661338806152344
loss:  35.234474182128906 43.05626678466797
loss:  35.52236557006836 43.88043212890625
loss:  35.221641540527344 43.905521392822266
loss:  35.09092330932617 43.766475677490234
loss:  34.59553527832031 43.61315155029297
loss:  34.99769592285156 43.545249938964844
loss:  35.64827346801758 44.17364501953125
*******************Epoch 7 ****************** 160 0.00795
Validation Loss
*** pred loss:  23.217529296875 pred acc: 0.6211956143379211
*** stop loss:  6.352932929992676 stop acc: 0.9119551777839661
*** template loss:  7.1979804039001465 template acc: tensor(0.1477, device='cuda:0')
*** label loss:  5.982929229736328 label acc: tensor(0.3522, device='cuda:0')
Train Loss
---> pred loss: 23.409042358398438 pred acc: 0.637501448392868
---> stop loss: 5.4939430236816404 stop acc: 0.9358369588851929
---> template loss: 2.7793462753295897 tempalte acc: 0.49101815223693845
---> molecule label loss: 3.630929183959961 molecule acc: 0.4298557758331299
---> kl loss: 43.58133239746094
---> reconstruction loss: 35.29261532150269
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-8-with.npy
loss:  34.395057678222656 43.355743408203125
loss:  34.49989318847656 44.146305084228516
loss:  33.96847915649414 43.82246398925781
loss:  34.16238021850586 44.19894790649414
loss:  34.594947814941406 44.11298370361328
loss:  33.964168548583984 43.976341247558594
loss:  33.520626068115234 44.249900817871094
loss:  33.920528411865234 43.9093132019043
loss:  33.48502731323242 43.97972106933594
loss:  33.93595504760742 44.01152801513672
loss:  34.04179000854492 44.35076141357422
loss:  33.5046272277832 43.962615966796875
loss:  33.0518913269043 44.254295349121094
loss:  33.41453170776367 44.298545837402344
loss:  33.82050323486328 44.22666931152344
loss:  32.962615966796875 44.49867248535156
loss:  33.19875717163086 44.56891632080078
loss:  33.0978889465332 44.768157958984375
loss:  32.785316467285156 44.39329528808594
loss:  32.3494758605957 45.28942108154297
*******************Epoch 8 ****************** 180 0.00895
Validation Loss
*** pred loss:  22.843109130859375 pred acc: 0.626630425453186
*** stop loss:  5.8159260749816895 stop acc: 0.9197696447372437
*** template loss:  7.07481575012207 template acc: tensor(0.1660, device='cuda:0')
*** label loss:  5.941730976104736 label acc: tensor(0.3577, device='cuda:0')
Train Loss
---> pred loss: 22.311767578125 pred acc: 0.6526008993387222
---> stop loss: 5.197005844116211 stop acc: 0.939107546210289
---> template loss: 2.410524368286133 tempalte acc: 0.5414387702941894
---> molecule label loss: 3.3395885467529296 molecule acc: 0.45093412399291993
---> kl loss: 44.21873168945312
---> reconstruction loss: 33.237964275207524
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-9-with.npy
loss:  32.61312484741211 44.65431213378906
loss:  32.969417572021484 44.859622955322266
loss:  32.32184982299805 44.973731994628906
loss:  33.24778366088867 44.91924285888672
loss:  32.26943588256836 44.994117736816406
loss:  32.33829116821289 44.786590576171875
loss:  32.023681640625 44.56568145751953
loss:  32.518985748291016 45.17021942138672
loss:  31.918432235717773 44.57863998413086
loss:  32.1722412109375 44.737022399902344
loss:  31.989887237548828 45.152801513671875
loss:  32.6876335144043 44.94668960571289
loss:  32.46357727050781 45.19349670410156
loss:  32.09174346923828 45.44266128540039
loss:  31.81949234008789 45.25072479248047
loss:  31.786474227905273 45.02269744873047
loss:  31.23365592956543 45.19007873535156
loss:  31.562660217285156 45.14283752441406
loss:  31.71881675720215 45.25276565551758
loss:  31.757740020751953 46.466270446777344
*******************Epoch 9 ****************** 200 0.00995
Validation Loss
*** pred loss:  22.077878952026367 pred acc: 0.6471014618873596
*** stop loss:  5.576833248138428 stop acc: 0.925186812877655
*** template loss:  6.900291919708252 template acc: tensor(0.1847, device='cuda:0')
*** label loss:  5.935246467590332 label acc: tensor(0.3556, device='cuda:0')
Train Loss
---> pred loss: 21.517356872558594 pred acc: 0.6641427725553513
---> stop loss: 5.00750961303711 stop acc: 0.9419852405786514
---> template loss: 2.1279579162597657 tempalte acc: 0.5860424041748047
---> molecule label loss: 3.0953569412231445 molecule acc: 0.4699577331542969
---> kl loss: 45.065008544921874
---> reconstruction loss: 31.72685035736084
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-10-with.npy
loss:  30.83552360534668 45.13257598876953
loss:  31.014286041259766 45.03871154785156
loss:  31.040651321411133 44.930633544921875
loss:  31.328018188476562 45.35437774658203
loss:  31.227537155151367 45.574256896972656
loss:  31.368366241455078 45.433509826660156
loss:  30.758268356323242 45.33100891113281
loss:  30.80918312072754 45.833274841308594
loss:  31.059614181518555 45.52983093261719
loss:  30.787620544433594 45.24583435058594
loss:  30.94357681274414 45.1021614074707
loss:  30.281673431396484 45.35276794433594
loss:  30.02924346923828 45.32318115234375
loss:  29.63669204711914 44.88987350463867
loss:  30.655344009399414 45.128807067871094
loss:  30.086456298828125 45.36792755126953
loss:  30.573213577270508 45.29970932006836
loss:  30.537124633789062 45.35554504394531
loss:  30.708797454833984 45.121192932128906
loss:  29.042131423950195 45.55249786376953
*******************Epoch 10 ****************** 220 0.01095
Validation Loss
*** pred loss:  21.53777503967285 pred acc: 0.6508454084396362
*** stop loss:  5.62162446975708 stop acc: 0.9229763746261597
*** template loss:  6.791210651397705 template acc: tensor(0.1931, device='cuda:0')
*** label loss:  5.8807501792907715 label acc: tensor(0.3612, device='cuda:0')
Train Loss
---> pred loss: 20.507369995117188 pred acc: 0.6789303064346314
---> stop loss: 4.761377334594727 stop acc: 0.9450873047113418
---> template loss: 1.9444965362548827 tempalte acc: 0.616543197631836
---> molecule label loss: 2.9484537124633787 molecule acc: 0.48338780403137205
---> kl loss: 45.294882202148436
---> reconstruction loss: 30.1401843699646
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-11-with.npy
loss:  29.43269157409668 45.57455825805664
loss:  29.587940216064453 45.429447174072266
loss:  29.977828979492188 44.818241119384766
loss:  29.733789443969727 45.40979766845703
loss:  30.04482078552246 45.448795318603516
loss:  30.65179443359375 45.548988342285156
loss:  29.469135284423828 44.92515563964844
loss:  29.67859649658203 45.49568176269531
loss:  29.51016616821289 45.54823303222656
loss:  29.236352920532227 45.71442413330078
loss:  29.680875778198242 45.26310729980469
loss:  30.023836135864258 45.675804138183594
loss:  29.379074096679688 45.53142166137695
loss:  29.080286026000977 45.34888458251953
loss:  28.841279983520508 45.432334899902344
loss:  28.78624153137207 45.481109619140625
loss:  28.283018112182617 45.28217697143555
loss:  28.715679168701172 45.46515655517578
loss:  28.915651321411133 45.63984298706055
loss:  27.29636001586914 45.63341522216797
*******************Epoch 11 ****************** 240 0.01195
Validation Loss
*** pred loss:  21.2369441986084 pred acc: 0.6553139686584473
*** stop loss:  5.396923065185547 stop acc: 0.9287360310554504
*** template loss:  6.685116767883301 template acc: tensor(0.2008, device='cuda:0')
*** label loss:  5.895290374755859 label acc: tensor(0.3616, device='cuda:0')
Train Loss
---> pred loss: 19.6953125 pred acc: 0.6886729747056961
---> stop loss: 4.657721710205078 stop acc: 0.9460534155368805
---> template loss: 1.7141698837280273 tempalte acc: 0.6563539981842041
---> molecule label loss: 2.727701950073242 molecule acc: 0.5098870277404786
---> kl loss: 45.43332214355469
---> reconstruction loss: 28.773346824798583
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-12-with.npy
loss:  28.658218383789062 45.66346740722656
loss:  28.827669143676758 45.54686737060547
loss:  28.88523292541504 45.581295013427734
loss:  28.682058334350586 45.697078704833984
loss:  28.429685592651367 45.75592041015625
loss:  28.951343536376953 45.853904724121094
loss:  28.148441314697266 45.70551300048828
loss:  28.30225372314453 45.701942443847656
loss:  28.465246200561523 45.668357849121094
loss:  28.65635108947754 45.57372283935547
loss:  28.454692840576172 45.72896957397461
loss:  28.364830017089844 45.66181182861328
loss:  28.105993270874023 45.844146728515625
loss:  28.45877456665039 45.70452880859375
loss:  28.128536224365234 45.33905792236328
loss:  28.056509017944336 45.370391845703125
loss:  27.669754028320312 45.74482727050781
loss:  27.899044036865234 45.20794677734375
loss:  27.967815399169922 45.308387756347656
loss:  26.73216438293457 45.521629333496094
*******************Epoch 12 ****************** 260 0.01295
Validation Loss
*** pred loss:  20.94818687438965 pred acc: 0.657185971736908
*** stop loss:  5.328227996826172 stop acc: 0.9295454621315002
*** template loss:  6.679825782775879 template acc: tensor(0.2114, device='cuda:0')
*** label loss:  5.886039733886719 label acc: tensor(0.3641, device='cuda:0')
Train Loss
---> pred loss: 19.027064514160156 pred acc: 0.6994825690984726
---> stop loss: 4.614134216308594 stop acc: 0.9465148180723191
---> template loss: 1.5424773216247558 tempalte acc: 0.6855969429016113
---> molecule label loss: 2.5396072387695314 molecule acc: 0.5331615924835205
---> kl loss: 45.608987426757814
---> reconstruction loss: 27.701593837432863
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-13-with.npy
loss:  28.0625057220459 45.449581146240234
loss:  27.735395431518555 45.599853515625
loss:  28.06861686706543 45.99785614013672
loss:  27.197505950927734 45.53758239746094
loss:  28.022117614746094 45.57378387451172
loss:  27.348979949951172 45.61521530151367
loss:  27.19076919555664 45.62268829345703
loss:  27.30262565612793 45.772193908691406
loss:  27.160594940185547 45.588584899902344
loss:  27.265098571777344 45.25162887573242
loss:  27.1400146484375 45.34009552001953
loss:  26.810272216796875 45.444435119628906
loss:  27.202661514282227 45.43384552001953
loss:  26.950960159301758 45.00501251220703
loss:  26.23198890686035 45.05701446533203
loss:  26.90763282775879 45.13930130004883
loss:  27.212657928466797 44.898948669433594
loss:  26.995479583740234 45.02333450317383
loss:  26.876487731933594 44.86134338378906
loss:  27.977210998535156 45.202972412109375
*******************Epoch 13 ****************** 280 0.01395
Validation Loss
*** pred loss:  20.371009826660156 pred acc: 0.6686593890190125
*** stop loss:  5.27191162109375 stop acc: 0.9314757585525513
*** template loss:  6.613260746002197 template acc: tensor(0.2160, device='cuda:0')
*** label loss:  5.890717029571533 label acc: tensor(0.3706, device='cuda:0')
Train Loss
---> pred loss: 18.442726135253906 pred acc: 0.7077750831842422
---> stop loss: 4.3344676971435545 stop acc: 0.9508356928825379
---> template loss: 1.4623140335083007 tempalte acc: 0.6992547035217285
---> molecule label loss: 2.4321718215942383 molecule acc: 0.54576416015625
---> kl loss: 45.370758056640625
---> reconstruction loss: 26.65005827178955
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-14-with.npy
loss:  27.020849227905273 45.02153015136719
loss:  26.57745361328125 45.09736251831055
loss:  26.944265365600586 45.227447509765625
loss:  26.433244705200195 45.250205993652344
loss:  26.8922176361084 45.175926208496094
loss:  26.326385498046875 45.159912109375
loss:  26.609859466552734 45.254920959472656
loss:  26.63164710998535 45.170677185058594
loss:  26.093549728393555 44.82466125488281
loss:  26.491680145263672 45.308570861816406
loss:  26.3088321685791 45.38313674926758
loss:  26.443227767944336 44.979129791259766
loss:  25.87982940673828 45.115116119384766
loss:  26.4293212890625 45.35496520996094
loss:  25.961105346679688 45.529541015625
loss:  26.005517959594727 45.16640853881836
loss:  25.825742721557617 45.06034469604492
loss:  26.24663543701172 45.06352233886719
loss:  25.808889389038086 45.06580352783203
loss:  26.599533081054688 45.4582405090332
*******************Epoch 14 ****************** 300 0.014950000000000001
Validation Loss
*** pred loss:  20.171489715576172 pred acc: 0.6751207709312439
*** stop loss:  5.184584140777588 stop acc: 0.9318181872367859
*** template loss:  6.586291313171387 template acc: tensor(0.2258, device='cuda:0')
*** label loss:  5.861714839935303 label acc: tensor(0.3671, device='cuda:0')
Train Loss
---> pred loss: 17.85454406738281 pred acc: 0.7163297832012177
---> stop loss: 4.257270431518554 stop acc: 0.9514786958694458
---> template loss: 1.3331725120544433 tempalte acc: 0.7244324207305908
---> molecule label loss: 2.2774642944335937 molecule acc: 0.5661529064178467
---> kl loss: 45.1833740234375
---> reconstruction loss: 25.70099781616211
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-15-with.npy
loss:  25.657955169677734 45.07694625854492
loss:  25.738384246826172 44.96913146972656
loss:  25.98455047607422 45.23974609375
loss:  25.550188064575195 45.12840270996094
loss:  25.27155113220215 45.26250457763672
loss:  25.379318237304688 45.2823486328125
loss:  25.40670394897461 45.28221893310547
loss:  25.09989356994629 45.189056396484375
loss:  25.50724220275879 44.97882843017578
loss:  25.183307647705078 44.970367431640625
loss:  25.33223533630371 44.75986099243164
loss:  25.69854164123535 44.801124572753906
loss:  25.16851806640625 45.04246520996094
loss:  25.59427261352539 45.14268493652344
loss:  25.47722816467285 45.105186462402344
loss:  25.694805145263672 44.63551330566406
loss:  25.56704330444336 44.89128112792969
loss:  25.181604385375977 44.685791015625
loss:  25.49770164489746 44.89067077636719
loss:  23.913772583007812 43.92045211791992
*******************Epoch 15 ****************** 320 0.01595
Validation Loss
*** pred loss:  20.36427879333496 pred acc: 0.6684178709983826
*** stop loss:  5.1281046867370605 stop acc: 0.9338418841362
*** template loss:  6.541264533996582 template acc: tensor(0.2290, device='cuda:0')
*** label loss:  5.811275482177734 label acc: tensor(0.3718, device='cuda:0')
Train Loss
---> pred loss: 17.27156982421875 pred acc: 0.724535557627678
---> stop loss: 4.098529815673828 stop acc: 0.9537406295537949
---> template loss: 1.2021059036254882 tempalte acc: 0.7498872756958008
---> molecule label loss: 2.1272951126098634 molecule acc: 0.5900566101074218
---> kl loss: 44.96273193359375
---> reconstruction loss: 24.678086735229492
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-16-with.npy
loss:  25.193750381469727 44.70549774169922
loss:  24.914735794067383 44.45091247558594
loss:  25.03899574279785 44.665138244628906
loss:  24.737930297851562 44.583885192871094
loss:  24.461593627929688 44.25044631958008
loss:  24.893327713012695 44.67564392089844
loss:  24.791200637817383 44.726524353027344
loss:  24.917659759521484 44.830299377441406
loss:  24.74010467529297 44.94953918457031
loss:  25.196712493896484 44.809181213378906
loss:  24.767169952392578 44.967708587646484
loss:  24.8488826751709 44.94733810424805
loss:  24.744647979736328 44.799415588378906
loss:  24.982013702392578 44.98357391357422
loss:  24.667634963989258 44.810218811035156
loss:  24.273324966430664 44.64411544799805
loss:  24.18629264831543 45.02235794067383
loss:  25.084856033325195 44.58360290527344
loss:  24.245641708374023 44.49600601196289
loss:  24.028564453125 45.47456741333008
*******************Epoch 16 ****************** 340 0.01695
Validation Loss
*** pred loss:  20.380342483520508 pred acc: 0.6683574914932251
*** stop loss:  5.44426155090332 stop acc: 0.9311644434928894
*** template loss:  6.463383197784424 template acc: tensor(0.2314, device='cuda:0')
*** label loss:  5.845229148864746 label acc: tensor(0.3742, device='cuda:0')
Train Loss
---> pred loss: 16.900526428222655 pred acc: 0.7306022584438324
---> stop loss: 3.98192138671875 stop acc: 0.9549642950296402
---> template loss: 1.1128177642822266 tempalte acc: 0.7671854019165039
---> molecule label loss: 2.002885627746582 molecule acc: 0.6078377723693847
---> kl loss: 44.768801879882815
---> reconstruction loss: 23.97692167678833
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-17-with.npy
loss:  25.168140411376953 44.76007843017578
loss:  24.274316787719727 44.72758483886719
loss:  24.8145751953125 44.630859375
loss:  24.387657165527344 44.417945861816406
loss:  24.532026290893555 44.33684539794922
loss:  24.44359588623047 44.307029724121094
loss:  24.510812759399414 44.2784423828125
loss:  24.703676223754883 44.4863166809082
loss:  24.42449378967285 44.58242416381836
loss:  24.50811004638672 44.34002685546875
loss:  23.980445861816406 44.221622467041016
loss:  23.823963165283203 44.305809020996094
loss:  23.873294830322266 44.405052185058594
loss:  24.5146427154541 44.37493133544922
loss:  24.11648941040039 44.56098175048828
loss:  23.977266311645508 44.6046142578125
loss:  23.90675926208496 44.54024887084961
loss:  23.642623901367188 44.28776550292969
loss:  23.79724884033203 44.777313232421875
loss:  23.634689331054688 43.94572448730469
*******************Epoch 17 ****************** 360 0.01795
Validation Loss
*** pred loss:  19.646484375 pred acc: 0.6799516677856445
*** stop loss:  5.2445502281188965 stop acc: 0.9319427609443665
*** template loss:  6.432973384857178 template acc: tensor(0.2350, device='cuda:0')
*** label loss:  5.817944526672363 label acc: tensor(0.3744, device='cuda:0')
Train Loss
---> pred loss: 16.6271240234375 pred acc: 0.7322396546602249
---> stop loss: 3.9018627166748048 stop acc: 0.9559283375740051
---> template loss: 1.038911724090576 tempalte acc: 0.7817023754119873
---> molecule label loss: 1.9071914672851562 molecule acc: 0.6238811492919922
---> kl loss: 44.444583129882815
---> reconstruction loss: 23.45396228652954
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-18-with.npy
loss:  23.66228675842285 44.589317321777344
loss:  23.341346740722656 44.21152877807617
loss:  23.44485092163086 44.17728805541992
loss:  23.163454055786133 44.36815643310547
loss:  24.287872314453125 44.43817138671875
loss:  23.246227264404297 44.15887451171875
loss:  23.48916244506836 44.63220977783203
loss:  23.34046173095703 44.078590393066406
loss:  23.808395385742188 44.312496185302734
loss:  23.544363021850586 44.281436920166016
loss:  23.8734073638916 44.12577819824219
loss:  23.59739875793457 44.25452423095703
loss:  23.038734436035156 44.230804443359375
loss:  23.831422805786133 44.1708984375
loss:  23.36764144897461 43.927940368652344
loss:  23.35025405883789 43.96518325805664
loss:  22.85146713256836 44.19532775878906
loss:  22.939956665039062 43.785118103027344
loss:  23.195735931396484 44.04315185546875
loss:  23.44172477722168 44.292266845703125
*******************Epoch 18 ****************** 380 0.01895
Validation Loss
*** pred loss:  19.390695571899414 pred acc: 0.6817632913589478
*** stop loss:  5.206876277923584 stop acc: 0.9326899647712708
*** template loss:  6.418403148651123 template acc: tensor(0.2360, device='cuda:0')
*** label loss:  5.802921295166016 label acc: tensor(0.3770, device='cuda:0')
Train Loss
---> pred loss: 15.981932067871094 pred acc: 0.7436182945966721
---> stop loss: 3.863881301879883 stop acc: 0.9563590943813324
---> template loss: 0.9767931938171387 tempalte acc: 0.7941154956817627
---> molecule label loss: 1.801419448852539 molecule acc: 0.6395246028900147
---> kl loss: 44.21195068359375
---> reconstruction loss: 22.60299164001465
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-19-with.npy
loss:  22.666841506958008 43.86864471435547
loss:  23.154964447021484 43.97398376464844
loss:  22.624465942382812 44.213748931884766
loss:  23.2937068939209 43.98558807373047
loss:  23.106800079345703 43.87651824951172
loss:  23.363828659057617 44.15726852416992
loss:  22.95516586303711 43.757144927978516
loss:  22.834672927856445 43.96558380126953
loss:  22.94130516052246 43.57164764404297
loss:  23.206323623657227 43.77886199951172
loss:  22.81943130493164 43.635108947753906
loss:  22.607030868530273 43.599491119384766
loss:  22.756690979003906 43.75505828857422
loss:  23.054595947265625 43.44164276123047
loss:  23.079010009765625 43.70306396484375
loss:  22.741992950439453 43.88693618774414
loss:  22.636445999145508 43.486873626708984
loss:  22.473342895507812 43.34749984741211
loss:  22.199451446533203 43.67230224609375
loss:  23.235084533691406 43.715606689453125
*******************Epoch 19 ****************** 400 0.019950000000000002
Validation Loss
*** pred loss:  19.39989471435547 pred acc: 0.680676281452179
*** stop loss:  5.2140302658081055 stop acc: 0.93471360206604
*** template loss:  6.425570964813232 template acc: tensor(0.2455, device='cuda:0')
*** label loss:  5.807364463806152 label acc: tensor(0.3725, device='cuda:0')
Train Loss
---> pred loss: 15.573878479003906 pred acc: 0.7501291841268539
---> stop loss: 3.7852264404296876 stop acc: 0.9569538027048111
---> template loss: 0.9454480171203613 tempalte acc: 0.7995648384094238
---> molecule label loss: 1.7306343078613282 molecule acc: 0.6494871139526367
---> kl loss: 43.76962890625
---> reconstruction loss: 22.01435541259766
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-20-with.npy
loss:  65.69413757324219 43.91007995605469
loss:  62.30821990966797 40.51161193847656
loss:  58.69197082519531 36.75154113769531
loss:  56.394134521484375 33.52056121826172
loss:  54.35874938964844 31.07657814025879
loss:  52.74187469482422 29.055557250976562
loss:  50.93901062011719 27.423860549926758
loss:  49.79144287109375 26.015514373779297
loss:  48.72434616088867 24.64923858642578
loss:  47.95914840698242 23.349660873413086
loss:  46.2332763671875 21.633628845214844
loss:  45.024261474609375 20.07503890991211
loss:  43.80279541015625 18.209938049316406
loss:  42.85171890258789 15.93807315826416
loss:  41.86017990112305 13.524879455566406
loss:  40.374732971191406 11.306753158569336
loss:  39.8209114074707 9.234578132629395
loss:  39.14128875732422 7.880349636077881
loss:  38.594215393066406 6.768341064453125
loss:  37.625370025634766 5.436488628387451
*******************Epoch 20 ****************** 420 1.0
Validation Loss
*** pred loss:  25.31020164489746 pred acc: 0.5865941643714905
*** stop loss:  5.789681434631348 stop acc: 0.9254047870635986
*** template loss:  7.41002082824707 template acc: tensor(0.0658, device='cuda:0')
*** label loss:  5.641860008239746 label acc: tensor(0.3733, device='cuda:0')
Train Loss
---> pred loss: 17.014920043945313 pred acc: 0.7233772248029708
---> stop loss: 4.083523941040039 stop acc: 0.9525251060724258
---> template loss: 2.419683837890625 tempalte acc: 0.5378796577453613
---> molecule label loss: 2.3148468017578123 molecule acc: 0.5548179149627686
---> kl loss: 22.313613891601562
---> reconstruction loss: 25.83298034667969
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-21-with.npy
loss:  38.76418685913086 5.626981258392334
loss:  37.838321685791016 5.122453212738037
loss:  36.28236770629883 4.809281349182129
loss:  36.49525451660156 4.352339744567871
loss:  35.99220275878906 4.115835189819336
loss:  35.81267547607422 4.196890830993652
loss:  35.38718032836914 3.7636027336120605
loss:  34.86970901489258 3.707212209701538
loss:  35.2432861328125 3.721586227416992
loss:  34.57908630371094 3.793489933013916
loss:  34.689334869384766 3.6918115615844727
loss:  34.38862991333008 3.722075939178467
loss:  34.157711029052734 3.5269248485565186
loss:  33.98371887207031 3.4577016830444336
loss:  33.429386138916016 3.339137077331543
loss:  33.91605758666992 3.463534355163574
loss:  33.25385665893555 3.266068935394287
loss:  33.368377685546875 3.2737045288085938
loss:  33.168861389160156 3.2296009063720703
loss:  32.01170349121094 2.995177745819092
*******************Epoch 21 ****************** 440 1.0
Validation Loss
*** pred loss:  23.935182571411133 pred acc: 0.6015096306800842
*** stop loss:  5.844233512878418 stop acc: 0.9240037798881531
*** template loss:  7.166304111480713 template acc: tensor(0.0953, device='cuda:0')
*** label loss:  5.806223392486572 label acc: tensor(0.3776, device='cuda:0')
Train Loss
---> pred loss: 21.116474914550782 pred acc: 0.6555214196443557
---> stop loss: 4.427063369750977 stop acc: 0.9478398352861405
---> template loss: 3.0503522872924806 tempalte acc: 0.43032197952270507
---> molecule label loss: 2.428933525085449 molecule acc: 0.5396275043487548
---> kl loss: 3.8587703704833984
---> reconstruction loss: 31.02283058166504
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-22-with.npy
loss:  32.818485260009766 3.217707395553589
loss:  32.51640701293945 3.203240394592285
loss:  31.90995979309082 3.1053102016448975
loss:  31.890583038330078 3.1789989471435547
loss:  31.877635955810547 3.185786485671997
loss:  32.10853576660156 3.1896536350250244
loss:  32.01499938964844 3.1338536739349365
loss:  31.89097023010254 3.0950489044189453
loss:  31.672893524169922 2.974802255630493
loss:  31.985061645507812 2.9107308387756348
loss:  31.55389976501465 2.8952765464782715
loss:  31.481367111206055 2.8486697673797607
loss:  31.23378562927246 2.8101296424865723
loss:  31.713733673095703 2.828701972961426
loss:  31.096172332763672 2.8683884143829346
loss:  30.825044631958008 2.817692518234253
loss:  30.987884521484375 2.8509514331817627
loss:  30.958961486816406 2.7681360244750977
loss:  31.285409927368164 2.8193299770355225
loss:  31.111780166625977 2.599519729614258
*******************Epoch 22 ****************** 460 1.0
Validation Loss
*** pred loss:  24.131195068359375 pred acc: 0.5967391133308411
*** stop loss:  5.8839311599731445 stop acc: 0.9235056638717651
*** template loss:  7.068908214569092 template acc: tensor(0.1126, device='cuda:0')
*** label loss:  5.654346466064453 label acc: tensor(0.3802, device='cuda:0')
Train Loss
---> pred loss: 20.070010375976562 pred acc: 0.6724900424480438
---> stop loss: 4.268269729614258 stop acc: 0.9502550184726715
---> template loss: 2.3659694671630858 tempalte acc: 0.5287891387939453
---> molecule label loss: 1.9773319244384766 molecule acc: 0.6054824352264404
---> kl loss: 2.965096282958984
---> reconstruction loss: 28.681580352783204
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-23-with.npy
loss:  30.652509689331055 2.744109869003296
loss:  30.6217041015625 2.6324472427368164
loss:  31.183513641357422 2.5564963817596436
loss:  30.828807830810547 2.638396978378296
loss:  30.660037994384766 2.5578837394714355
loss:  31.01719856262207 2.5355300903320312
loss:  30.526620864868164 2.4900448322296143
loss:  30.687641143798828 2.542187452316284
loss:  30.901611328125 2.579921007156372
loss:  30.701839447021484 2.5440850257873535
loss:  30.418888092041016 2.556077003479004
loss:  30.436128616333008 2.516151189804077
loss:  30.321229934692383 2.4844489097595215
loss:  29.70863151550293 2.493929624557495
loss:  30.020185470581055 2.5292699337005615
loss:  30.318374633789062 2.446356773376465
loss:  29.95516014099121 2.4748358726501465
loss:  30.42991065979004 2.53222393989563
loss:  30.227741241455078 2.4392247200012207
loss:  28.671871185302734 2.3088889122009277
*******************Epoch 23 ****************** 480 1.0
Validation Loss
*** pred loss:  23.82073974609375 pred acc: 0.6067632436752319
*** stop loss:  5.819738388061523 stop acc: 0.9248443841934204
*** template loss:  6.967241287231445 template acc: tensor(0.1206, device='cuda:0')
*** label loss:  5.673868656158447 label acc: tensor(0.3811, device='cuda:0')
Train Loss
---> pred loss: 19.89820251464844 pred acc: 0.6750690579414368
---> stop loss: 4.211275482177735 stop acc: 0.9512701660394669
---> template loss: 2.0360906600952147 tempalte acc: 0.582636547088623
---> molecule label loss: 1.738785171508789 molecule acc: 0.6427050113677979
---> kl loss: 2.5301254272460936
---> reconstruction loss: 27.884352111816405
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-24-with.npy
loss:  30.320144653320312 2.4242308139801025
loss:  29.871707916259766 2.468127727508545
loss:  30.038414001464844 2.4011454582214355
loss:  29.627893447875977 2.3889198303222656
loss:  29.802907943725586 2.3332102298736572
loss:  29.897098541259766 2.282804250717163
loss:  29.56155014038086 2.370816946029663
loss:  29.6592960357666 2.3466145992279053
loss:  29.51815414428711 2.436232566833496
loss:  29.311323165893555 2.334501028060913
loss:  29.600772857666016 2.323906898498535
loss:  29.63522720336914 2.286198616027832
loss:  29.39850425720215 2.2102320194244385
loss:  29.625621795654297 2.1878433227539062
loss:  29.1905517578125 2.197786569595337
loss:  29.081098556518555 2.2175443172454834
loss:  29.36979866027832 2.1952898502349854
loss:  29.349979400634766 2.2210636138916016
loss:  28.849933624267578 2.169321060180664
loss:  29.045108795166016 2.1019392013549805
*******************Epoch 24 ****************** 500 1.0
Validation Loss
*** pred loss:  24.013940811157227 pred acc: 0.6019323468208313
*** stop loss:  5.842779636383057 stop acc: 0.9259340167045593
*** template loss:  6.949826717376709 template acc: tensor(0.1312, device='cuda:0')
*** label loss:  5.6802215576171875 label acc: tensor(0.3776, device='cuda:0')
Train Loss
---> pred loss: 19.682501220703124 pred acc: 0.6793556630611419
---> stop loss: 4.141601181030273 stop acc: 0.9518744081258774
---> template loss: 1.8377281188964845 tempalte acc: 0.6163093566894531
---> molecule label loss: 1.5810362815856933 molecule acc: 0.6731289386749267
---> kl loss: 2.294886589050293
---> reconstruction loss: 27.242866706848144
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-25-with.npy
loss:  28.69835090637207 2.221898317337036
loss:  29.012704849243164 2.166559934616089
loss:  29.433414459228516 2.2095186710357666
loss:  28.927448272705078 2.2709431648254395
loss:  28.80878257751465 2.2087905406951904
loss:  28.911136627197266 2.174682855606079
loss:  28.98517417907715 2.1532280445098877
loss:  28.738117218017578 2.1515390872955322
loss:  28.31186294555664 2.0905919075012207
loss:  28.563770294189453 2.1595892906188965
loss:  28.716400146484375 2.1009342670440674
loss:  28.836029052734375 2.1503849029541016
loss:  28.691505432128906 2.0892534255981445
loss:  28.681747436523438 2.107513427734375
loss:  28.93028450012207 2.147251844406128
loss:  28.607744216918945 2.162506103515625
loss:  29.319473266601562 2.144476890563965
loss:  28.866863250732422 2.171947717666626
loss:  28.225502014160156 2.079866886138916
loss:  28.262588500976562 2.037944793701172
*******************Epoch 25 ****************** 520 1.0
Validation Loss
*** pred loss:  23.96120262145996 pred acc: 0.5987922549247742
*** stop loss:  5.770310878753662 stop acc: 0.9247509837150574
*** template loss:  6.956288814544678 template acc: tensor(0.1316, device='cuda:0')
*** label loss:  5.735325813293457 label acc: tensor(0.3862, device='cuda:0')
Train Loss
---> pred loss: 19.447958374023436 pred acc: 0.6832716792821885
---> stop loss: 4.046233749389648 stop acc: 0.9534881055355072
---> template loss: 1.6797740936279297 tempalte acc: 0.6463375091552734
---> molecule label loss: 1.4525074005126952 molecule acc: 0.6953930854797363
---> kl loss: 2.1499711990356447
---> reconstruction loss: 26.62647533416748
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-26-with.npy
loss:  28.21990203857422 1.9984221458435059
loss:  28.221046447753906 2.0016446113586426
loss:  28.205379486083984 1.9697778224945068
loss:  28.743085861206055 2.062062978744507
loss:  28.34011459350586 1.9979374408721924
loss:  28.75948143005371 2.031618356704712
loss:  28.369110107421875 1.9642614126205444
loss:  28.005290985107422 1.9879324436187744
loss:  27.98975372314453 1.9575754404067993
loss:  28.834468841552734 1.9781129360198975
loss:  28.126543045043945 1.9644112586975098
loss:  28.15247917175293 1.9810469150543213
loss:  28.392841339111328 1.9641348123550415
loss:  28.340356826782227 1.9892041683197021
loss:  28.637155532836914 2.022498607635498
loss:  28.18541145324707 1.9278733730316162
loss:  27.778118133544922 1.9466595649719238
loss:  28.684160232543945 1.9526667594909668
loss:  28.059646606445312 1.9169018268585205
loss:  27.81003189086914 2.0976369380950928
*******************Epoch 26 ****************** 540 1.0
Validation Loss
*** pred loss:  24.076820373535156 pred acc: 0.5974637269973755
*** stop loss:  6.3095903396606445 stop acc: 0.9191781282424927
*** template loss:  6.970926284790039 template acc: tensor(0.1287, device='cuda:0')
*** label loss:  5.68788480758667 label acc: tensor(0.3828, device='cuda:0')
Train Loss
---> pred loss: 19.33918151855469 pred acc: 0.6862652093172074
---> stop loss: 4.040464782714844 stop acc: 0.9534302085638047
---> template loss: 1.5688386917114259 tempalte acc: 0.6652366638183593
---> molecule label loss: 1.3586160659790039 molecule acc: 0.7119936943054199
---> kl loss: 1.9856189727783202
---> reconstruction loss: 26.30710258483887
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-27-with.npy
loss:  27.80589485168457 1.9175845384597778
loss:  28.378952026367188 1.933261513710022
loss:  27.460872650146484 1.9470702409744263
loss:  28.493425369262695 1.990160584449768
loss:  28.243642807006836 1.9934518337249756
loss:  28.09941291809082 1.9497915506362915
loss:  27.84101676940918 1.9274293184280396
loss:  28.405364990234375 1.9119031429290771
loss:  27.499479293823242 1.9042905569076538
loss:  27.83543586730957 1.9032008647918701
loss:  28.036563873291016 1.8966103792190552
loss:  27.87958526611328 1.842188835144043
loss:  27.661855697631836 1.8564831018447876
loss:  27.544261932373047 1.8433750867843628
loss:  27.328704833984375 1.851520299911499
loss:  27.565200805664062 1.820613980293274
loss:  27.61285400390625 1.829851508140564
loss:  27.620153427124023 1.8261947631835938
loss:  27.68463706970215 1.8763805627822876
loss:  25.421188354492188 1.646540641784668
*******************Epoch 27 ****************** 560 1.0
Validation Loss
*** pred loss:  24.357927322387695 pred acc: 0.5977053046226501
*** stop loss:  5.77069091796875 stop acc: 0.9261831045150757
*** template loss:  6.912389755249023 template acc: tensor(0.1421, device='cuda:0')
*** label loss:  5.654923915863037 label acc: tensor(0.3793, device='cuda:0')
Train Loss
---> pred loss: 19.10765686035156 pred acc: 0.6876312136650086
---> stop loss: 4.002024078369141 stop acc: 0.9535291314125061
---> template loss: 1.4640726089477538 tempalte acc: 0.6857406616210937
---> molecule label loss: 1.2637786865234375 molecule acc: 0.7285998344421387
---> kl loss: 1.8833951950073242
---> reconstruction loss: 25.83753070831299
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-28-with.npy
loss:  27.55797004699707 1.8177546262741089
loss:  27.402435302734375 1.8378592729568481
loss:  27.409687042236328 1.8544700145721436
loss:  27.618850708007812 1.883697748184204
loss:  27.367919921875 1.803985595703125
loss:  27.79977035522461 1.92387855052948
loss:  27.63800048828125 1.8831851482391357
loss:  27.546279907226562 1.9059873819351196
loss:  27.260759353637695 1.8487428426742554
loss:  27.559593200683594 1.8111324310302734
loss:  26.92841911315918 1.7814773321151733
loss:  27.596982955932617 1.8483728170394897
loss:  27.18170738220215 1.7897363901138306
loss:  26.811233520507812 1.78036367893219
loss:  27.051006317138672 1.7598029375076294
loss:  27.043622970581055 1.7331045866012573
loss:  27.520673751831055 1.7443218231201172
loss:  27.1123046875 1.7874102592468262
loss:  26.88331413269043 1.7682079076766968
loss:  26.903749465942383 1.851517915725708
*******************Epoch 28 ****************** 580 1.0
Validation Loss
*** pred loss:  24.297924041748047 pred acc: 0.5975241661071777
*** stop loss:  5.989753723144531 stop acc: 0.9235367774963379
*** template loss:  6.921285629272461 template acc: tensor(0.1379, device='cuda:0')
*** label loss:  5.732463836669922 label acc: tensor(0.3887, device='cuda:0')
Train Loss
---> pred loss: 19.002117919921876 pred acc: 0.6913128137588501
---> stop loss: 3.9067108154296877 stop acc: 0.9550838738679885
---> template loss: 1.3879756927490234 tempalte acc: 0.7009457111358642
---> molecule label loss: 1.1921588897705078 molecule acc: 0.7435465812683105
---> kl loss: 1.8207504272460937
---> reconstruction loss: 25.48896026611328
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-29-with.npy
loss:  26.7894287109375 1.7812775373458862
loss:  27.161457061767578 1.7448586225509644
loss:  27.187410354614258 1.6928893327713013
loss:  27.059341430664062 1.7664214372634888
loss:  27.164997100830078 1.7179477214813232
loss:  26.793386459350586 1.7281874418258667
loss:  26.992950439453125 1.663167119026184
loss:  26.19444465637207 1.6488021612167358
loss:  26.917362213134766 1.6845513582229614
loss:  27.304718017578125 1.6719212532043457
loss:  27.351930618286133 1.7452112436294556
loss:  26.939123153686523 1.7262588739395142
loss:  26.648221969604492 1.7141441106796265
loss:  26.63810920715332 1.6667935848236084
loss:  26.543424606323242 1.6563677787780762
loss:  26.83128547668457 1.7144076824188232
loss:  26.504594802856445 1.6600412130355835
loss:  26.832481384277344 1.6857362985610962
loss:  26.61873435974121 1.667306661605835
loss:  27.38248062133789 1.7765945196151733
*******************Epoch 29 ****************** 600 1.0
Validation Loss
*** pred loss:  24.35590171813965 pred acc: 0.597403347492218
*** stop loss:  5.721336364746094 stop acc: 0.9269925355911255
*** template loss:  6.920217514038086 template acc: tensor(0.1400, device='cuda:0')
*** label loss:  5.770756721496582 label acc: tensor(0.3838, device='cuda:0')
Train Loss
---> pred loss: 18.859152221679686 pred acc: 0.6935548484325409
---> stop loss: 3.852578353881836 stop acc: 0.9561937689781189
---> template loss: 1.332197666168213 tempalte acc: 0.7115528106689453
---> molecule label loss: 1.1432232856750488 molecule acc: 0.7517337322235107
---> kl loss: 1.7056442260742188
---> reconstruction loss: 25.18715362548828
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-30-with.npy
loss:  26.556825637817383 1.713097333908081
loss:  26.621768951416016 1.6360433101654053
loss:  26.462799072265625 1.6292905807495117
loss:  26.940542221069336 1.6828659772872925
loss:  27.101818084716797 1.6321749687194824
loss:  26.39328956604004 1.640419840812683
loss:  26.80796241760254 1.623003602027893
loss:  26.848499298095703 1.6664953231811523
loss:  26.285383224487305 1.6080188751220703
loss:  26.50237274169922 1.6547738313674927
loss:  26.56743049621582 1.6803699731826782
loss:  26.267742156982422 1.6544078588485718
loss:  25.95374870300293 1.63301420211792
loss:  26.35498046875 1.6160287857055664
loss:  26.357402801513672 1.653278112411499
loss:  26.10358428955078 1.6100044250488281
loss:  26.749963760375977 1.652644395828247
loss:  26.079303741455078 1.6251507997512817
loss:  26.151996612548828 1.6070268154144287
loss:  25.875354766845703 1.5196268558502197
*******************Epoch 30 ****************** 620 1.0
Validation Loss
*** pred loss:  24.375078201293945 pred acc: 0.5959541201591492
*** stop loss:  5.86082649230957 stop acc: 0.9270548224449158
*** template loss:  6.9130024909973145 template acc: tensor(0.1421, device='cuda:0')
*** label loss:  5.734414100646973 label acc: tensor(0.3795, device='cuda:0')
Train Loss
---> pred loss: 18.694488525390625 pred acc: 0.696036958694458
---> stop loss: 3.784004974365234 stop acc: 0.9567332923412323
---> template loss: 1.2603410720825194 tempalte acc: 0.7293577194213867
---> molecule label loss: 1.0734172821044923 molecule acc: 0.764698600769043
---> kl loss: 1.636886978149414
---> reconstruction loss: 24.812252426147463
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-31-with.npy
loss:  25.85951805114746 1.569753885269165
loss:  26.38666534423828 1.5726840496063232
loss:  26.135133743286133 1.5607248544692993
loss:  26.707717895507812 1.6177105903625488
loss:  26.409732818603516 1.5898643732070923
loss:  26.2755126953125 1.6004713773727417
loss:  25.956710815429688 1.5981260538101196
loss:  25.991670608520508 1.5742822885513306
loss:  25.86224937438965 1.5773353576660156
loss:  25.91415023803711 1.6271699666976929
loss:  26.670560836791992 1.633941888809204
loss:  26.296401977539062 1.5780534744262695
loss:  26.417583465576172 1.587640643119812
loss:  25.991226196289062 1.5885205268859863
loss:  26.18272590637207 1.605926275253296
loss:  26.518739700317383 1.5869964361190796
loss:  26.744876861572266 1.5597798824310303
loss:  26.356847763061523 1.5212008953094482
loss:  26.638227462768555 1.5188294649124146
loss:  26.736600875854492 1.4711246490478516
*******************Epoch 31 ****************** 640 1.0
Validation Loss
*** pred loss:  24.320648193359375 pred acc: 0.6026569604873657
*** stop loss:  6.05282735824585 stop acc: 0.924501895904541
*** template loss:  6.875860691070557 template acc: tensor(0.1502, device='cuda:0')
*** label loss:  5.746836185455322 label acc: tensor(0.3883, device='cuda:0')
Train Loss
---> pred loss: 18.62285614013672 pred acc: 0.6967572897672654
---> stop loss: 3.790559005737305 stop acc: 0.9562445044517517
---> template loss: 1.2559288024902344 tempalte acc: 0.7270435333251953
---> molecule label loss: 1.0562894821166993 molecule acc: 0.7649724006652832
---> kl loss: 1.577006721496582
---> reconstruction loss: 24.725633049011233
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-32-with.npy
loss:  26.23363494873047 1.544100284576416
loss:  25.782596588134766 1.5378694534301758
loss:  26.143844604492188 1.5377602577209473
loss:  26.678909301757812 1.5603055953979492
loss:  25.828197479248047 1.5396604537963867
loss:  26.44569206237793 1.589834451675415
loss:  25.868438720703125 1.5458190441131592
loss:  26.370197296142578 1.5784943103790283
loss:  26.22494125366211 1.5273743867874146
loss:  26.097063064575195 1.5185840129852295
loss:  25.832897186279297 1.5000659227371216
loss:  25.967453002929688 1.5101007223129272
loss:  25.818693161010742 1.48235285282135
loss:  25.97110366821289 1.493399739265442
loss:  26.1190242767334 1.5063687562942505
loss:  25.849924087524414 1.5078794956207275
loss:  26.121320724487305 1.4725838899612427
loss:  25.938867568969727 1.4484837055206299
loss:  25.900136947631836 1.4655382633209229
loss:  24.03531265258789 1.4603896141052246
*******************Epoch 32 ****************** 660 1.0
Validation Loss
*** pred loss:  24.499160766601562 pred acc: 0.5978260636329651
*** stop loss:  5.852286338806152 stop acc: 0.9264010190963745
*** template loss:  6.910435199737549 template acc: tensor(0.1488, device='cuda:0')
*** label loss:  5.7717719078063965 label acc: tensor(0.3920, device='cuda:0')
Train Loss
---> pred loss: 18.448588562011718 pred acc: 0.6993613451719284
---> stop loss: 3.818933868408203 stop acc: 0.9561280488967896
---> template loss: 1.189584732055664 tempalte acc: 0.7420937538146972
---> molecule label loss: 0.9879555702209473 molecule acc: 0.7779339790344239
---> kl loss: 1.5163483619689941
---> reconstruction loss: 24.445065212249755
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-33-with.npy
loss:  25.25953483581543 1.5398368835449219
loss:  25.737096786499023 1.5192897319793701
loss:  25.725954055786133 1.5170432329177856
loss:  25.314193725585938 1.5020910501480103
loss:  25.348770141601562 1.5052071809768677
loss:  25.82760238647461 1.502952218055725
loss:  25.8786678314209 1.5112887620925903
loss:  25.47652816772461 1.4629625082015991
loss:  25.261491775512695 1.4554654359817505
loss:  25.569793701171875 1.4699786901474
loss:  25.44533348083496 1.4418940544128418
loss:  25.774145126342773 1.4369604587554932
loss:  25.593908309936523 1.462423324584961
loss:  25.286287307739258 1.468735933303833
loss:  25.565425872802734 1.5051839351654053
loss:  25.3389892578125 1.4760541915893555
loss:  24.90673828125 1.4527559280395508
loss:  25.09366226196289 1.440262794494629
loss:  25.112192153930664 1.397160291671753
loss:  26.385000228881836 1.3805030584335327
*******************Epoch 33 ****************** 680 1.0
Validation Loss
*** pred loss:  24.589975357055664 pred acc: 0.5944444537162781
*** stop loss:  6.479650497436523 stop acc: 0.9193337559700012
*** template loss:  6.89906644821167 template acc: tensor(0.1484, device='cuda:0')
*** label loss:  5.796666145324707 label acc: tensor(0.3935, device='cuda:0')
Train Loss
---> pred loss: 18.279206848144533 pred acc: 0.7032801121473312
---> stop loss: 3.7171436309814454 stop acc: 0.9574413180351258
---> template loss: 1.1149305343627929 tempalte acc: 0.7568171977996826
---> molecule label loss: 0.9113825798034668 molecule acc: 0.7947952270507812
---> kl loss: 1.472402286529541
---> reconstruction loss: 24.02266302108765
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-34-with.npy
loss:  25.1745548248291 1.3647700548171997
loss:  25.377744674682617 1.3903053998947144
loss:  25.51422119140625 1.44123113155365
loss:  25.84970474243164 1.422416090965271
loss:  25.10494613647461 1.4165030717849731
loss:  25.259193420410156 1.4392622709274292
loss:  25.502573013305664 1.4408133029937744
loss:  24.743091583251953 1.3806179761886597
loss:  25.663000106811523 1.4205811023712158
loss:  25.369245529174805 1.411910891532898
loss:  25.192855834960938 1.4055064916610718
loss:  25.173301696777344 1.404496192932129
loss:  24.869735717773438 1.3804875612258911
loss:  24.912771224975586 1.3952209949493408
loss:  24.830120086669922 1.378495693206787
loss:  25.181352615356445 1.4014618396759033
loss:  25.448379516601562 1.4087258577346802
loss:  24.90455436706543 1.3898767232894897
loss:  24.794219970703125 1.4137053489685059
loss:  25.764347076416016 1.3974614143371582
*******************Epoch 34 ****************** 700 1.0
Validation Loss
*** pred loss:  24.726604461669922 pred acc: 0.6007850170135498
*** stop loss:  5.939976215362549 stop acc: 0.9261208176612854
*** template loss:  6.930987358093262 template acc: tensor(0.1495, device='cuda:0')
*** label loss:  5.77610969543457 label acc: tensor(0.3866, device='cuda:0')
Train Loss
---> pred loss: 18.163310241699218 pred acc: 0.7041772782802582
---> stop loss: 3.7570655822753904 stop acc: 0.9569897204637527
---> template loss: 1.0499607086181642 tempalte acc: 0.7700729370117188
---> molecule label loss: 0.8559679985046387 molecule acc: 0.8046844482421875
---> kl loss: 1.4051925659179687
---> reconstruction loss: 23.82630310058594
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-35-with.npy
loss:  24.52044677734375 1.4125216007232666
loss:  24.949420928955078 1.3700432777404785
loss:  24.660537719726562 1.3732727766036987
loss:  24.862180709838867 1.3447017669677734
loss:  24.758214950561523 1.3944909572601318
loss:  25.13075065612793 1.3674490451812744
loss:  24.801090240478516 1.3996014595031738
loss:  24.63302993774414 1.3697305917739868
loss:  25.033458709716797 1.3672435283660889
loss:  24.659528732299805 1.3626517057418823
loss:  24.612323760986328 1.329067349433899
loss:  24.648178100585938 1.3404170274734497
loss:  24.480670928955078 1.3389614820480347
loss:  25.142805099487305 1.3828150033950806
loss:  25.014490127563477 1.4196170568466187
loss:  24.890853881835938 1.3640366792678833
loss:  24.714292526245117 1.3597526550292969
loss:  24.698701858520508 1.3282486200332642
loss:  24.446008682250977 1.3105090856552124
loss:  23.913799285888672 1.2812001705169678
*******************Epoch 35 ****************** 720 1.0
Validation Loss
*** pred loss:  24.68825912475586 pred acc: 0.5994564890861511
*** stop loss:  6.10573673248291 stop acc: 0.9251556992530823
*** template loss:  6.917895317077637 template acc: tensor(0.1498, device='cuda:0')
*** label loss:  5.750706195831299 label acc: tensor(0.3900, device='cuda:0')
Train Loss
---> pred loss: 17.991229248046874 pred acc: 0.7066602528095245
---> stop loss: 3.5779014587402345 stop acc: 0.9595117509365082
---> template loss: 0.9926554679870605 tempalte acc: 0.7824222087860108
---> molecule label loss: 0.805936622619629 molecule acc: 0.8147032737731934
---> kl loss: 1.3608165740966798
---> reconstruction loss: 23.367721939086913
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-36-with.npy
loss:  24.41320037841797 1.3373528718948364
loss:  24.82273292541504 1.3780237436294556
loss:  24.260616302490234 1.3869483470916748
loss:  24.265966415405273 1.4148257970809937
loss:  24.61414337158203 1.3403962850570679
loss:  24.448408126831055 1.3710942268371582
loss:  24.23129653930664 1.3335795402526855
loss:  24.718013763427734 1.3855472803115845
loss:  24.533763885498047 1.3209242820739746
loss:  24.63076400756836 1.322540521621704
loss:  24.7380428314209 1.3385605812072754
loss:  24.591524124145508 1.3141875267028809
loss:  24.484397888183594 1.3266611099243164
loss:  24.2795467376709 1.3286737203598022
loss:  24.7158260345459 1.2923122644424438
loss:  24.64884376525879 1.3371669054031372
loss:  24.58428382873535 1.3335044384002686
loss:  24.322175979614258 1.3095953464508057
loss:  24.314189910888672 1.3165818452835083
loss:  24.201282501220703 1.1989907026290894
*******************Epoch 36 ****************** 740 1.0
Validation Loss
*** pred loss:  24.828460693359375 pred acc: 0.5910627841949463
*** stop loss:  5.895656585693359 stop acc: 0.9264010190963745
*** template loss:  6.88192081451416 template acc: tensor(0.1544, device='cuda:0')
*** label loss:  5.812881946563721 label acc: tensor(0.3849, device='cuda:0')
Train Loss
---> pred loss: 17.899581909179688 pred acc: 0.7076793015003204
---> stop loss: 3.5243083953857424 stop acc: 0.9599720865488053
---> template loss: 0.9665698051452637 tempalte acc: 0.7888677597045899
---> molecule label loss: 0.7661165714263916 molecule acc: 0.8232499122619629
---> kl loss: 1.3343734741210938
---> reconstruction loss: 23.156578063964844
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-37-with.npy
loss:  24.837078094482422 1.3327722549438477
loss:  24.109832763671875 1.3197214603424072
loss:  24.249408721923828 1.3164379596710205
loss:  24.327457427978516 1.3182425498962402
loss:  24.213224411010742 1.3193953037261963
loss:  24.56023406982422 1.341803789138794
loss:  24.312278747558594 1.317525863647461
loss:  24.578046798706055 1.299111247062683
loss:  24.134389877319336 1.2887470722198486
loss:  23.8702392578125 1.2848341464996338
loss:  24.17722511291504 1.2543798685073853
loss:  24.273252487182617 1.25261652469635
loss:  23.708595275878906 1.2659173011779785
loss:  24.482540130615234 1.258535385131836
loss:  24.230863571166992 1.2790992259979248
loss:  23.938901901245117 1.254823088645935
loss:  24.039609909057617 1.2934606075286865
loss:  23.750701904296875 1.2720627784729004
loss:  24.052080154418945 1.2985637187957764
loss:  25.328250885009766 1.3533239364624023
*******************Epoch 37 ****************** 760 1.0
Validation Loss
*** pred loss:  24.66968536376953 pred acc: 0.6029589176177979
*** stop loss:  6.054739475250244 stop acc: 0.9262765049934387
*** template loss:  6.944939613342285 template acc: tensor(0.1449, device='cuda:0')
*** label loss:  5.831643104553223 label acc: tensor(0.3917, device='cuda:0')
Train Loss
---> pred loss: 17.802735900878908 pred acc: 0.7105699837207794
---> stop loss: 3.5003448486328126 stop acc: 0.9605290740728378
---> template loss: 0.9330674171447754 tempalte acc: 0.7931216716766357
---> molecule label loss: 0.7264920711517334 molecule acc: 0.8316924095153808
---> kl loss: 1.2960685729980468
---> reconstruction loss: 22.962642669677734
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-38-with.npy
loss:  23.876962661743164 1.2874970436096191
loss:  23.654132843017578 1.2659717798233032
loss:  23.61798858642578 1.242451548576355
loss:  23.826446533203125 1.2817368507385254
loss:  24.2508602142334 1.2753790616989136
loss:  23.708860397338867 1.2542580366134644
loss:  24.000797271728516 1.2782096862792969
loss:  24.118213653564453 1.285597801208496
loss:  23.87102699279785 1.2777411937713623
loss:  23.741313934326172 1.2436975240707397
loss:  23.941253662109375 1.27867591381073
loss:  24.00850486755371 1.264515995979309
loss:  24.063404083251953 1.2545336484909058
loss:  23.79349136352539 1.2579727172851562
loss:  24.048025131225586 1.2595666646957397
loss:  23.50921630859375 1.2568820714950562
loss:  23.61566162109375 1.2305419445037842
loss:  23.5402774810791 1.2106465101242065
loss:  24.031646728515625 1.1850006580352783
loss:  24.753965377807617 1.2065603733062744
*******************Epoch 38 ****************** 780 1.0
Validation Loss
*** pred loss:  25.18883514404297 pred acc: 0.5901569724082947
*** stop loss:  5.843900680541992 stop acc: 0.9280511140823364
*** template loss:  6.901768684387207 template acc: tensor(0.1516, device='cuda:0')
*** label loss:  5.8418049812316895 label acc: tensor(0.3751, device='cuda:0')
Train Loss
---> pred loss: 17.599082946777344 pred acc: 0.7125967592000961
---> stop loss: 3.4586963653564453 stop acc: 0.9609428524971009
---> template loss: 0.8944121360778808 tempalte acc: 0.803311824798584
---> molecule label loss: 0.6915385246276855 molecule acc: 0.8384056091308594
---> kl loss: 1.2548717498779296
---> reconstruction loss: 22.64373207092285
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-39-with.npy
loss:  23.355751037597656 1.2175289392471313
loss:  24.02591323852539 1.2724699974060059
loss:  23.85517692565918 1.2737637758255005
loss:  23.85495376586914 1.2722793817520142
loss:  23.67213249206543 1.2723681926727295
loss:  23.615428924560547 1.2424652576446533
loss:  23.953554153442383 1.2552460432052612
loss:  23.888715744018555 1.2191238403320312
loss:  23.70795249938965 1.215583086013794
loss:  23.652799606323242 1.2001739740371704
loss:  23.672407150268555 1.2064464092254639
loss:  23.56064224243164 1.2040765285491943
loss:  23.692712783813477 1.2533091306686401
loss:  23.78438377380371 1.2168638706207275
loss:  24.194591522216797 1.236803650856018
loss:  23.944868087768555 1.222531795501709
loss:  23.70852279663086 1.2025690078735352
loss:  23.623493194580078 1.2276421785354614
loss:  23.712547302246094 1.2062859535217285
loss:  22.9753475189209 1.286171793937683
*******************Epoch 39 ****************** 800 1.0
Validation Loss
*** pred loss:  24.887563705444336 pred acc: 0.5967994928359985
*** stop loss:  5.852746486663818 stop acc: 0.9299190640449524
*** template loss:  6.929592609405518 template acc: tensor(0.1512, device='cuda:0')
*** label loss:  5.824752330780029 label acc: tensor(0.3950, device='cuda:0')
Train Loss
---> pred loss: 17.514385986328126 pred acc: 0.7142039448022842
---> stop loss: 3.4342277526855467 stop acc: 0.9613391399383545
---> template loss: 0.8599915504455566 tempalte acc: 0.8126472473144531
---> molecule label loss: 0.6788049697875976 molecule acc: 0.8378780364990235
---> kl loss: 1.2351849555969239
---> reconstruction loss: 22.487410259246825
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-40-with.npy
loss:  23.76091957092285 1.2488340139389038
loss:  23.26725959777832 1.2127416133880615
loss:  23.203109741210938 1.1952753067016602
loss:  23.88206672668457 1.2142071723937988
loss:  23.157886505126953 1.1983648538589478
loss:  23.11933708190918 1.1568405628204346
loss:  23.714820861816406 1.206488013267517
loss:  23.556947708129883 1.1955783367156982
loss:  23.02706527709961 1.2069687843322754
loss:  23.50728988647461 1.2006621360778809
loss:  23.2193603515625 1.174133539199829
loss:  23.584789276123047 1.188860297203064
loss:  22.88538360595703 1.1762359142303467
loss:  23.40474510192871 1.1644915342330933
loss:  23.36279296875 1.1942243576049805
loss:  23.568586349487305 1.17430579662323
loss:  23.53567886352539 1.1647659540176392
loss:  22.970726013183594 1.17491614818573
loss:  23.630615234375 1.1801856756210327
loss:  23.014493942260742 1.2333042621612549
*******************Epoch 40 ****************** 820 1.0
Validation Loss
*** pred loss:  24.91372299194336 pred acc: 0.5965579748153687
*** stop loss:  6.21554708480835 stop acc: 0.9241594076156616
*** template loss:  6.936775207519531 template acc: tensor(0.1509, device='cuda:0')
*** label loss:  5.87905216217041 label acc: tensor(0.3962, device='cuda:0')
Train Loss
---> pred loss: 17.360575866699218 pred acc: 0.7172943443059921
---> stop loss: 3.374231719970703 stop acc: 0.9620112895965576
---> template loss: 0.8177357673645019 tempalte acc: 0.8207178115844727
---> molecule label loss: 0.6230834484100342 molecule acc: 0.8511354446411132
---> kl loss: 1.1930691719055175
---> reconstruction loss: 22.17562437057495
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-41-with.npy
loss:  23.126001358032227 1.1672412157058716
loss:  24.546489715576172 1.1971076726913452
loss:  23.827110290527344 1.1439279317855835
loss:  23.08475112915039 1.1734905242919922
loss:  23.7470645904541 1.1742202043533325
loss:  23.628639221191406 1.186427116394043
loss:  23.359230041503906 1.164851188659668
loss:  23.59400749206543 1.2246150970458984
loss:  23.35804557800293 1.167123556137085
loss:  23.528087615966797 1.1569185256958008
loss:  23.95838165283203 1.1466878652572632
loss:  23.45673370361328 1.1697202920913696
loss:  23.538837432861328 1.1534103155136108
loss:  23.13995933532715 1.1706907749176025
loss:  23.285350799560547 1.169314980506897
loss:  22.883413314819336 1.1549351215362549
loss:  22.854080200195312 1.151716947555542
loss:  23.15145492553711 1.1766180992126465
loss:  22.960697174072266 1.220131278038025
loss:  22.38531494140625 1.151231288909912
*******************Epoch 41 ****************** 840 1.0
Validation Loss
*** pred loss:  25.114498138427734 pred acc: 0.6013284921646118
*** stop loss:  5.948951244354248 stop acc: 0.9280199408531189
*** template loss:  6.94783878326416 template acc: tensor(0.1569, device='cuda:0')
*** label loss:  5.836045265197754 label acc: tensor(0.3776, device='cuda:0')
Train Loss
---> pred loss: 17.23017272949219 pred acc: 0.7190177530050278
---> stop loss: 3.5772865295410154 stop acc: 0.9593183398246765
---> template loss: 0.7954042434692383 tempalte acc: 0.8256848335266114
---> molecule label loss: 0.5968003749847413 molecule acc: 0.857856559753418
---> kl loss: 1.1710190773010254
---> reconstruction loss: 22.199664211273195
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-42-with.npy
loss:  22.7824764251709 1.1709462404251099
loss:  22.85544776916504 1.1414282321929932
loss:  23.00989532470703 1.1465469598770142
loss:  22.99581527709961 1.1580016613006592
loss:  22.684648513793945 1.1228801012039185
loss:  22.559249877929688 1.1585054397583008
loss:  22.94955062866211 1.163516879081726
loss:  22.638689041137695 1.1473933458328247
loss:  22.812942504882812 1.177032709121704
loss:  23.032207489013672 1.1432315111160278
loss:  22.692167282104492 1.153493046760559
loss:  23.065095901489258 1.1378508806228638
loss:  23.121248245239258 1.1472288370132446
loss:  23.178653717041016 1.1434497833251953
loss:  22.848464965820312 1.150312066078186
loss:  22.96050453186035 1.1201069355010986
loss:  22.933656692504883 1.1659003496170044
loss:  22.6435604095459 1.1343618631362915
loss:  23.013072967529297 1.1278107166290283
loss:  21.628398895263672 1.0695691108703613
*******************Epoch 42 ****************** 860 1.0
Validation Loss
*** pred loss:  25.27956771850586 pred acc: 0.5939613580703735
*** stop loss:  5.9558939933776855 stop acc: 0.9277709126472473
*** template loss:  6.91274356842041 template acc: tensor(0.1586, device='cuda:0')
*** label loss:  5.96457576751709 label acc: tensor(0.3924, device='cuda:0')
Train Loss
---> pred loss: 17.077420043945313 pred acc: 0.721909710764885
---> stop loss: 3.2769424438476564 stop acc: 0.9632590264081955
---> template loss: 0.7564870834350585 tempalte acc: 0.8361049652099609
---> molecule label loss: 0.5654594898223877 molecule acc: 0.8637283325195313
---> kl loss: 1.1439784049987793
---> reconstruction loss: 21.676308155059814
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-43-with.npy
loss:  22.75956916809082 1.1254247426986694
loss:  22.49077033996582 1.107446312904358
loss:  22.57317352294922 1.1238011121749878
loss:  22.783424377441406 1.1259206533432007
loss:  23.19512367248535 1.138761281967163
loss:  22.4779052734375 1.1250494718551636
loss:  22.396625518798828 1.0918114185333252
loss:  22.81354331970215 1.119376301765442
loss:  23.246898651123047 1.144555687904358
loss:  22.97072982788086 1.11154043674469
loss:  22.38411521911621 1.1353137493133545
loss:  22.860576629638672 1.1207138299942017
loss:  22.893436431884766 1.1191341876983643
loss:  22.813373565673828 1.1104838848114014
loss:  22.694881439208984 1.108621597290039
loss:  22.70989990234375 1.1099090576171875
loss:  22.5607967376709 1.112853765487671
loss:  23.03650665283203 1.0932844877243042
loss:  22.939390182495117 1.1354920864105225
loss:  24.31717300415039 1.1377067565917969
*******************Epoch 43 ****************** 880 1.0
Validation Loss
*** pred loss:  25.260009765625 pred acc: 0.5911231637001038
*** stop loss:  6.165865421295166 stop acc: 0.9252802133560181
*** template loss:  6.993130683898926 template acc: tensor(0.1495, device='cuda:0')
*** label loss:  5.964313983917236 label acc: tensor(0.3984, device='cuda:0')
Train Loss
---> pred loss: 17.132293701171875 pred acc: 0.7213777542114258
---> stop loss: 3.2728424072265625 stop acc: 0.9635478675365448
---> template loss: 0.7550282001495361 tempalte acc: 0.8357666015625
---> molecule label loss: 0.5658709049224854 molecule acc: 0.8612852096557617
---> kl loss: 1.1198601722717285
---> reconstruction loss: 21.72603521347046
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-44-with.npy
loss:  22.713499069213867 1.1276695728302002
loss:  22.52785873413086 1.1531543731689453
loss:  22.58913803100586 1.127807855606079
loss:  22.364696502685547 1.1324938535690308
loss:  22.163053512573242 1.1289993524551392
loss:  22.40391731262207 1.107991337776184
loss:  22.5893611907959 1.1091389656066895
loss:  22.52495002746582 1.114062786102295
loss:  22.521286010742188 1.1252652406692505
loss:  22.69270896911621 1.1111130714416504
loss:  22.262731552124023 1.109102487564087
loss:  22.388193130493164 1.1170272827148438
loss:  22.2164249420166 1.09258234500885
loss:  23.179264068603516 1.122705340385437
loss:  22.41763687133789 1.1355010271072388
loss:  22.584312438964844 1.117627739906311
loss:  22.312114715576172 1.1089434623718262
loss:  22.474788665771484 1.1129481792449951
loss:  22.511005401611328 1.0944472551345825
loss:  22.31846809387207 1.0301711559295654
*******************Epoch 44 ****************** 900 1.0
Validation Loss
*** pred loss:  25.16753578186035 pred acc: 0.5978260636329651
*** stop loss:  6.405098915100098 stop acc: 0.9245330095291138
*** template loss:  6.910628795623779 template acc: tensor(0.1534, device='cuda:0')
*** label loss:  5.932447910308838 label acc: tensor(0.3943, device='cuda:0')
Train Loss
---> pred loss: 16.92757568359375 pred acc: 0.7244818806648254
---> stop loss: 3.2156417846679686 stop acc: 0.9641712665557861
---> template loss: 0.7019029140472413 tempalte acc: 0.849820327758789
---> molecule label loss: 0.5287118911743164 molecule acc: 0.8702857971191407
---> kl loss: 1.1139376640319825
---> reconstruction loss: 21.373832416534423
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-45-with.npy
loss:  22.152297973632812 1.0797967910766602
loss:  23.543476104736328 1.106224536895752
loss:  22.551231384277344 1.0771677494049072
loss:  22.21112632751465 1.0476073026657104
loss:  22.76519012451172 1.0957224369049072
loss:  22.564193725585938 1.0861103534698486
loss:  22.457550048828125 1.0903420448303223
loss:  22.964920043945312 1.1441072225570679
loss:  22.37497329711914 1.0964109897613525
loss:  22.010391235351562 1.1147886514663696
loss:  22.29358673095703 1.1161798238754272
loss:  22.16396713256836 1.0590649843215942
loss:  21.780689239501953 1.069199562072754
loss:  22.4920711517334 1.071480393409729
loss:  22.504352569580078 1.0532056093215942
loss:  22.384668350219727 1.0762255191802979
loss:  22.536245346069336 1.0624903440475464
loss:  22.02594566345215 1.061822772026062
loss:  21.937149047851562 1.0540380477905273
loss:  21.432903289794922 1.040976881980896
*******************Epoch 45 ****************** 920 1.0
Validation Loss
*** pred loss:  25.487627029418945 pred acc: 0.5905796885490417
*** stop loss:  6.169750690460205 stop acc: 0.9255604147911072
*** template loss:  6.93180513381958 template acc: tensor(0.1569, device='cuda:0')
*** label loss:  5.92127799987793 label acc: tensor(0.3827, device='cuda:0')
Train Loss
---> pred loss: 16.796131896972657 pred acc: 0.7261399805545807
---> stop loss: 3.2966991424560548 stop acc: 0.9627424150705337
---> template loss: 0.6789883613586426 tempalte acc: 0.852473258972168
---> molecule label loss: 0.505381965637207 molecule acc: 0.8758893013000488
---> kl loss: 1.0801481246948241
---> reconstruction loss: 21.277198982238772
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-46-with.npy
loss:  22.044933319091797 1.0798969268798828
loss:  22.464550018310547 1.0807212591171265
loss:  21.671119689941406 1.0545111894607544
loss:  21.983135223388672 1.0593632459640503
loss:  22.22794532775879 1.0667016506195068
loss:  22.69276237487793 1.097104787826538
loss:  22.335845947265625 1.0991401672363281
loss:  21.720897674560547 1.0998640060424805
loss:  22.468496322631836 1.075804591178894
loss:  22.545907974243164 1.0652302503585815
loss:  21.87154769897461 1.085364580154419
loss:  21.89543342590332 1.0970405340194702
loss:  22.03391456604004 1.0992560386657715
loss:  22.000747680664062 1.0539844036102295
loss:  22.026945114135742 1.0751876831054688
loss:  22.090991973876953 1.0649428367614746
loss:  21.753080368041992 1.0174657106399536
loss:  22.09075927734375 1.0323917865753174
loss:  21.66128158569336 1.0345544815063477
loss:  21.378881454467773 1.0675774812698364
*******************Epoch 46 ****************** 940 1.0
Validation Loss
*** pred loss:  25.442733764648438 pred acc: 0.5964371562004089
*** stop loss:  6.44899320602417 stop acc: 0.9226338863372803
*** template loss:  6.95944356918335 template acc: tensor(0.1512, device='cuda:0')
*** label loss:  5.993691444396973 label acc: tensor(0.3945, device='cuda:0')
Train Loss
---> pred loss: 16.700164794921875 pred acc: 0.7275135189294815
---> stop loss: 3.144437789916992 stop acc: 0.9651448637247085
---> template loss: 0.6529617786407471 tempalte acc: 0.8597441673278808
---> molecule label loss: 0.4800907611846924 molecule acc: 0.8804863929748535
---> kl loss: 1.0703052520751952
---> reconstruction loss: 20.977653121948244
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-47-with.npy
loss:  21.869808197021484 1.0742830038070679
loss:  22.337419509887695 1.1024914979934692
loss:  21.502994537353516 1.0866670608520508
loss:  22.07400894165039 1.1047431230545044
loss:  21.95587158203125 1.082621455192566
loss:  21.731578826904297 1.0813329219818115
loss:  22.649572372436523 1.0888627767562866
loss:  22.107200622558594 1.0780271291732788
loss:  22.00494384765625 1.0611517429351807
loss:  22.563852310180664 1.0587401390075684
loss:  22.165563583374023 1.0595920085906982
loss:  22.13966178894043 1.0483919382095337
loss:  21.975360870361328 1.0434716939926147
loss:  21.618709564208984 1.0332850217819214
loss:  22.025131225585938 1.0406994819641113
loss:  21.836275100708008 1.0338984727859497
loss:  21.838184356689453 1.047547698020935
loss:  22.02754783630371 1.033560037612915
loss:  21.939952850341797 1.0199605226516724
loss:  22.303625106811523 1.0778729915618896
*******************Epoch 47 ****************** 960 1.0
Validation Loss
*** pred loss:  25.396677017211914 pred acc: 0.5957125425338745
*** stop loss:  6.364965438842773 stop acc: 0.92391037940979
*** template loss:  6.921904563903809 template acc: tensor(0.1579, device='cuda:0')
*** label loss:  5.996192932128906 label acc: tensor(0.4026, device='cuda:0')
Train Loss
---> pred loss: 16.58287811279297 pred acc: 0.730790200829506
---> stop loss: 3.274600601196289 stop acc: 0.9632530897855759
---> template loss: 0.6421578884124756 tempalte acc: 0.8619823455810547
---> molecule label loss: 0.47086663246154786 molecule acc: 0.8841595649719238
---> kl loss: 1.062860107421875
---> reconstruction loss: 20.97050323486328
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-48-with.npy
loss:  21.767974853515625 1.0133641958236694
loss:  21.717924118041992 1.0111329555511475
loss:  21.97916030883789 1.034152865409851
loss:  21.766300201416016 1.0248003005981445
loss:  22.017253875732422 1.0684285163879395
loss:  21.7316837310791 1.0805336236953735
loss:  21.94122886657715 1.0573467016220093
loss:  22.27747917175293 1.0435603857040405
loss:  21.670557022094727 1.0384620428085327
loss:  21.604511260986328 1.0131858587265015
loss:  21.805665969848633 1.033332109451294
loss:  21.484140396118164 1.0169639587402344
loss:  21.606727600097656 1.0378727912902832
loss:  21.704425811767578 1.0795177221298218
loss:  21.20966148376465 1.0501668453216553
loss:  21.51513671875 1.0647307634353638
loss:  21.554201126098633 1.0645198822021484
loss:  21.68244171142578 1.028761863708496
loss:  21.905120849609375 1.0282633304595947
loss:  21.38325309753418 0.9456807374954224
*******************Epoch 48 ****************** 980 1.0
Validation Loss
*** pred loss:  25.591814041137695 pred acc: 0.5866546034812927
*** stop loss:  6.978269577026367 stop acc: 0.9182752370834351
*** template loss:  6.993907928466797 template acc: tensor(0.1467, device='cuda:0')
*** label loss:  6.252431869506836 label acc: tensor(0.4129, device='cuda:0')
Train Loss
---> pred loss: 16.488064575195313 pred acc: 0.7307589739561081
---> stop loss: 3.115828514099121 stop acc: 0.9652262240648269
---> template loss: 0.6201478004455566 tempalte acc: 0.8689799308776855
---> molecule label loss: 0.4554616451263428 molecule acc: 0.8874258995056152
---> kl loss: 1.0367388725280762
---> reconstruction loss: 20.67950258255005
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-49-with.npy
loss:  21.79109764099121 0.9897614121437073
loss:  21.282917022705078 0.991405189037323
loss:  22.080711364746094 1.0183674097061157
loss:  22.041545867919922 1.0031094551086426
loss:  21.67491912841797 0.9988377094268799
loss:  22.4156436920166 0.9897114634513855
loss:  22.014902114868164 0.9937155842781067
loss:  21.50023651123047 0.9834175109863281
loss:  21.69496726989746 0.990125834941864
loss:  21.58693504333496 1.017248511314392
loss:  21.946706771850586 1.0327404737472534
loss:  21.277116775512695 1.0286979675292969
loss:  21.763132095336914 1.053601861000061
loss:  22.005708694458008 1.0391336679458618
loss:  21.389060974121094 1.019608736038208
loss:  22.118873596191406 1.036436915397644
loss:  21.813926696777344 1.0187088251113892
loss:  21.57948112487793 1.022047519683838
loss:  21.757095336914062 1.036243200302124
loss:  20.746150970458984 0.9158723950386047
*******************Epoch 49 ****************** 1000 1.0
Validation Loss
*** pred loss:  25.818559646606445 pred acc: 0.5901569724082947
*** stop loss:  6.830751895904541 stop acc: 0.9212640523910522
*** template loss:  6.947567939758301 template acc: tensor(0.1495, device='cuda:0')
*** label loss:  6.132562637329102 label acc: tensor(0.4003, device='cuda:0')
Train Loss
---> pred loss: 16.38908996582031 pred acc: 0.7321856379508972
---> stop loss: 3.2812145233154295 stop acc: 0.9628005951642991
---> template loss: 0.5972873210906983 tempalte acc: 0.8742142677307129
---> molecule label loss: 0.4475239276885986 molecule acc: 0.8860952377319335
---> kl loss: 1.008939552307129
---> reconstruction loss: 20.715114402770997
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-50-with.npy
loss:  21.57110595703125 1.0017718076705933
loss:  21.355606079101562 1.0329704284667969
loss:  21.63006019592285 1.0438464879989624
loss:  21.398563385009766 1.0153944492340088
loss:  21.582666397094727 1.0121936798095703
loss:  21.566944122314453 1.0427902936935425
loss:  21.232254028320312 1.0343073606491089
loss:  21.860889434814453 1.0270445346832275
loss:  21.164642333984375 1.0013725757598877
loss:  21.683122634887695 1.0111274719238281
loss:  21.569931030273438 0.9999822378158569
loss:  21.390499114990234 0.9952014088630676
loss:  21.353439331054688 1.0130791664123535
loss:  21.22947883605957 0.993979275226593
loss:  21.605785369873047 0.9948001503944397
loss:  21.22079086303711 1.0118088722229004
loss:  21.10506248474121 1.0112489461898804
loss:  21.282079696655273 1.002869725227356
loss:  21.340988159179688 1.006885290145874
loss:  21.177169799804688 1.02403724193573
*******************Epoch 50 ****************** 1020 1.0
Validation Loss
*** pred loss:  25.425140380859375 pred acc: 0.5986111164093018
*** stop loss:  6.312803745269775 stop acc: 0.9246264100074768
*** template loss:  6.982814311981201 template acc: tensor(0.1534, device='cuda:0')
*** label loss:  6.036077976226807 label acc: tensor(0.4014, device='cuda:0')
Train Loss
---> pred loss: 16.331468200683595 pred acc: 0.7335893034934997
---> stop loss: 3.0916889190673826 stop acc: 0.9656472533941269
---> template loss: 0.5677114486694336 tempalte acc: 0.8783514022827148
---> molecule label loss: 0.4113465309143066 molecule acc: 0.8960712432861329
---> kl loss: 1.013835620880127
---> reconstruction loss: 20.402219676971438
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-51-with.npy
loss:  20.964624404907227 0.9693135619163513
loss:  21.02817726135254 0.9680880904197693
loss:  21.340309143066406 0.9760609865188599
loss:  20.974536895751953 0.9794563055038452
loss:  21.32282257080078 0.9603073000907898
loss:  21.2298526763916 0.9732860922813416
loss:  21.237241744995117 0.9755286574363708
loss:  21.533981323242188 0.9920473098754883
loss:  21.19020652770996 1.0141857862472534
loss:  21.042566299438477 0.999606728553772
loss:  21.056631088256836 0.9803805947303772
loss:  20.96227264404297 0.9952913522720337
loss:  20.860050201416016 0.9704819321632385
loss:  21.139854431152344 0.9858618974685669
loss:  20.94060516357422 0.9912631511688232
loss:  20.938098907470703 0.9619630575180054
loss:  20.975576400756836 0.9580956697463989
loss:  21.242286682128906 0.9779423475265503
loss:  21.366992950439453 0.9936094284057617
loss:  20.986454010009766 1.0028489828109741
*******************Epoch 51 ****************** 1040 1.0
Validation Loss
*** pred loss:  25.738134384155273 pred acc: 0.5923308730125427
*** stop loss:  6.336108684539795 stop acc: 0.9263699054718018
*** template loss:  6.9663238525390625 template acc: tensor(0.1544, device='cuda:0')
*** label loss:  6.05587911605835 label acc: tensor(0.4011, device='cuda:0')
Train Loss
---> pred loss: 16.19100341796875 pred acc: 0.7353273093700409
---> stop loss: 3.014631462097168 stop acc: 0.9665197432041168
---> template loss: 0.5462934494018554 tempalte acc: 0.8852784156799316
---> molecule label loss: 0.38344907760620117 molecule acc: 0.9048447608947754
---> kl loss: 0.9812810897827149
---> reconstruction loss: 20.135376930236816
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-52-with.npy
loss:  20.622257232666016 0.9602428078651428
loss:  21.241321563720703 0.992001473903656
loss:  20.857378005981445 0.9739215970039368
loss:  21.277297973632812 0.9988839030265808
loss:  21.11229705810547 0.9907373189926147
loss:  20.67936897277832 0.9959675669670105
loss:  20.764598846435547 0.9779596328735352
loss:  20.7965030670166 0.9855908751487732
loss:  20.764312744140625 0.9900368452072144
loss:  21.12698745727539 0.9950861930847168
loss:  20.936994552612305 0.9672524929046631
loss:  20.919185638427734 0.96586012840271
loss:  20.98114776611328 0.9806824922561646
loss:  21.430335998535156 0.9751474857330322
loss:  20.896604537963867 0.9765130877494812
loss:  21.282339096069336 0.9468517303466797
loss:  21.135887145996094 0.977203369140625
loss:  21.58587646484375 1.0031076669692993
loss:  21.35367774963379 0.9659980535507202
loss:  23.601903915405273 0.9616233706474304
*******************Epoch 52 ****************** 1060 1.0
Validation Loss
*** pred loss:  25.816503524780273 pred acc: 0.6006038784980774
*** stop loss:  6.48608922958374 stop acc: 0.9231008887290955
*** template loss:  7.043365955352783 template acc: tensor(0.1460, device='cuda:0')
*** label loss:  6.146810531616211 label acc: tensor(0.3988, device='cuda:0')
Train Loss
---> pred loss: 16.15050811767578 pred acc: 0.7363101452589035
---> stop loss: 3.0055168151855467 stop acc: 0.966766682267189
---> template loss: 0.6011617660522461 tempalte acc: 0.8726404190063477
---> molecule label loss: 0.43209500312805177 molecule acc: 0.8897958755493164
---> kl loss: 0.979033374786377
---> reconstruction loss: 20.18928022384644
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-53-with.npy
loss:  21.261859893798828 0.987226665019989
loss:  21.19338035583496 0.975976288318634
loss:  21.258777618408203 0.9751101136207581
loss:  21.320276260375977 0.9572857618331909
loss:  21.24565887451172 0.989745557308197
loss:  21.093610763549805 1.0058143138885498
loss:  21.260560989379883 0.9914323091506958
loss:  21.259679794311523 0.9504072070121765
loss:  20.994905471801758 0.9585433602333069
loss:  21.299785614013672 0.9471290111541748
loss:  20.711692810058594 0.9637901186943054
loss:  20.803409576416016 0.9362643957138062
loss:  20.788537979125977 0.9628892540931702
loss:  21.099626541137695 0.9786493182182312
loss:  21.176429748535156 0.9942488074302673
loss:  21.39890480041504 0.9726002216339111
loss:  20.604520797729492 0.9625508189201355
loss:  21.183805465698242 0.9562294483184814
loss:  21.003475189208984 0.9536803364753723
loss:  21.11499786376953 0.8880070447921753
*******************Epoch 53 ****************** 1080 1.0
Validation Loss
*** pred loss:  26.077396392822266 pred acc: 0.5902173519134521
*** stop loss:  6.356851100921631 stop acc: 0.9266189336776733
*** template loss:  7.008493423461914 template acc: tensor(0.1481, device='cuda:0')
*** label loss:  6.061128616333008 label acc: tensor(0.3982, device='cuda:0')
Train Loss
---> pred loss: 16.015945434570312 pred acc: 0.738528436422348
---> stop loss: 2.932534027099609 stop acc: 0.9675883531570435
---> template loss: 0.6858049392700195 tempalte acc: 0.8524303436279297
---> molecule label loss: 0.504030990600586 molecule acc: 0.8688446998596191
---> kl loss: 0.9653789520263671
---> reconstruction loss: 20.138315200805664
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-54-with.npy
loss:  20.986984252929688 0.9711052179336548
loss:  20.56275177001953 0.9672031998634338
loss:  21.06956672668457 0.9750391840934753
loss:  21.026432037353516 0.9875198602676392
loss:  20.80190086364746 0.95704585313797
loss:  20.6096134185791 0.9441197514533997
loss:  20.815210342407227 0.9408196806907654
loss:  20.80052375793457 0.9589537978172302
loss:  20.804134368896484 0.9581189751625061
loss:  21.05447006225586 0.9409242272377014
loss:  20.965742111206055 0.9468250870704651
loss:  20.78959846496582 0.9329437017440796
loss:  20.760412216186523 0.945132315158844
loss:  21.009044647216797 0.962953507900238
loss:  20.64722442626953 0.9633644223213196
loss:  20.73642921447754 0.95531165599823
loss:  21.125669479370117 0.9449331760406494
loss:  20.719768524169922 0.9523769617080688
loss:  20.7060604095459 0.9598761200904846
loss:  20.798139572143555 0.956920325756073
*******************Epoch 54 ****************** 1100 1.0
Validation Loss
*** pred loss:  26.054710388183594 pred acc: 0.588164210319519
*** stop loss:  6.349710941314697 stop acc: 0.9280511140823364
*** template loss:  6.978333473205566 template acc: tensor(0.1523, device='cuda:0')
*** label loss:  6.013557434082031 label acc: tensor(0.3868, device='cuda:0')
Train Loss
---> pred loss: 15.879476928710938 pred acc: 0.7419241011142731
---> stop loss: 2.9063203811645506 stop acc: 0.9680147767066956
---> template loss: 0.6451717376708984 tempalte acc: 0.8606189727783203
---> molecule label loss: 0.45243988037109373 molecule acc: 0.8835940361022949
---> kl loss: 0.9560745239257813
---> reconstruction loss: 19.883407592773438
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-55-with.npy
loss:  20.798690795898438 0.9584571719169617
loss:  20.611940383911133 0.9929810762405396
loss:  20.626012802124023 0.9838798642158508
loss:  21.134321212768555 0.9741842150688171
loss:  20.45821189880371 0.9760671854019165
loss:  20.97163963317871 0.958088755607605
loss:  20.71779441833496 0.9470899105072021
loss:  20.898643493652344 0.9363487362861633
loss:  20.62261199951172 0.9490391612052917
loss:  20.746713638305664 0.9464644193649292
loss:  20.334341049194336 0.9635622501373291
loss:  20.78853416442871 0.9507225751876831
loss:  20.564136505126953 0.9552527070045471
loss:  20.72443389892578 0.9625809788703918
loss:  20.71335792541504 0.9704663157463074
loss:  20.469762802124023 0.9274996519088745
loss:  20.424135208129883 0.9249165654182434
loss:  20.466678619384766 0.9135532379150391
loss:  20.891868591308594 0.9492661952972412
loss:  20.59331703186035 0.970513105392456
*******************Epoch 55 ****************** 1120 1.0
Validation Loss
*** pred loss:  25.998706817626953 pred acc: 0.593478262424469
*** stop loss:  6.528433799743652 stop acc: 0.9260274171829224
*** template loss:  6.966152667999268 template acc: tensor(0.1639, device='cuda:0')
*** label loss:  6.18646240234375 label acc: tensor(0.4067, device='cuda:0')
Train Loss
---> pred loss: 15.85074462890625 pred acc: 0.7401279121637344
---> stop loss: 2.894316864013672 stop acc: 0.9680143833160401
---> template loss: 0.5802541732788086 tempalte acc: 0.8753284454345703
---> molecule label loss: 0.3969957113265991 molecule acc: 0.8983429908752442
---> kl loss: 0.955546760559082
---> reconstruction loss: 19.72230968475342
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-56-with.npy
loss:  20.134546279907227 0.9166018962860107
loss:  20.565603256225586 0.9095967411994934
loss:  20.681257247924805 0.9261243343353271
loss:  20.49393653869629 0.9102712273597717
loss:  20.664098739624023 0.908499538898468
loss:  20.349863052368164 0.9249886274337769
loss:  20.495458602905273 0.9406504034996033
loss:  20.529329299926758 0.9376055002212524
loss:  20.372703552246094 0.9514179825782776
loss:  20.600948333740234 0.9461550712585449
loss:  20.444671630859375 0.9637465476989746
loss:  20.337242126464844 0.9607619047164917
loss:  20.007667541503906 0.968657374382019
loss:  20.694700241088867 0.9718729257583618
loss:  20.179367065429688 0.9537534713745117
loss:  20.404104232788086 0.9486068487167358
loss:  20.30869483947754 0.9581525325775146
loss:  20.439701080322266 0.9434176683425903
loss:  20.224435806274414 0.9498276114463806
loss:  21.57068634033203 0.8972637057304382
*******************Epoch 56 ****************** 1140 1.0
Validation Loss
*** pred loss:  26.234739303588867 pred acc: 0.5931159257888794
*** stop loss:  6.430898189544678 stop acc: 0.9283624291419983
*** template loss:  6.969588756561279 template acc: tensor(0.1565, device='cuda:0')
*** label loss:  6.241443634033203 label acc: tensor(0.4084, device='cuda:0')
Train Loss
---> pred loss: 15.763656616210938 pred acc: 0.7428984403610229
---> stop loss: 2.8852039337158204 stop acc: 0.9681480586528778
---> template loss: 0.5288503170013428 tempalte acc: 0.8886232376098633
---> molecule label loss: 0.3578404664993286 molecule acc: 0.9083739280700683
---> kl loss: 0.9393986701965332
---> reconstruction loss: 19.535550975799563
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-57-with.npy
loss:  20.493906021118164 0.9099572896957397
loss:  20.464319229125977 0.9367153644561768
loss:  20.125885009765625 0.9403827786445618
loss:  20.353864669799805 0.9481856226921082
loss:  20.43899917602539 0.9585962295532227
loss:  20.211505889892578 0.9378458261489868
loss:  20.06139373779297 0.9312961101531982
loss:  20.407917022705078 0.944366991519928
loss:  20.096515655517578 0.9480591416358948
loss:  20.183313369750977 0.9192218780517578
loss:  20.489181518554688 0.9371832013130188
loss:  20.324146270751953 0.9247336387634277
loss:  20.668485641479492 0.9490092992782593
loss:  20.262487411499023 0.9530222415924072
loss:  19.921783447265625 0.9383301734924316
loss:  20.286582946777344 0.9287472367286682
loss:  20.113880157470703 0.91544508934021
loss:  20.195276260375977 0.932662844657898
loss:  20.221036911010742 0.9338679313659668
loss:  20.737308502197266 1.0168554782867432
*******************Epoch 57 ****************** 1160 1.0
Validation Loss
*** pred loss:  26.221168518066406 pred acc: 0.596859872341156
*** stop loss:  6.604417324066162 stop acc: 0.9250622987747192
*** template loss:  6.957448959350586 template acc: tensor(0.1551, device='cuda:0')
*** label loss:  6.084035396575928 label acc: tensor(0.3967, device='cuda:0')
Train Loss
---> pred loss: 15.708863830566406 pred acc: 0.7428807556629181
---> stop loss: 2.8210117340087892 stop acc: 0.9690853774547576
---> template loss: 0.5005074501037597 tempalte acc: 0.8978887557983398
---> molecule label loss: 0.33228259086608886 molecule acc: 0.9158562660217285
---> kl loss: 0.9402241706848145
---> reconstruction loss: 19.362665843963622
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-58-with.npy
loss:  19.797605514526367 0.9422675967216492
loss:  20.281362533569336 0.9560436010360718
loss:  19.940189361572266 0.9692115783691406
loss:  20.11893653869629 0.9525835514068604
loss:  20.163951873779297 0.9661152362823486
loss:  20.21050262451172 0.9347723722457886
loss:  19.90814971923828 0.9586396813392639
loss:  19.919124603271484 0.9404391050338745
loss:  20.27126121520996 0.9603148102760315
loss:  19.81566619873047 0.9167796969413757
loss:  20.042369842529297 0.9443244338035583
loss:  20.13716697692871 0.9158567190170288
loss:  19.925886154174805 0.9114531874656677
loss:  20.119277954101562 0.9004769325256348
loss:  19.981239318847656 0.8952769637107849
loss:  20.09686279296875 0.9033660888671875
loss:  19.821611404418945 0.894244909286499
loss:  20.49395751953125 0.9270580410957336
loss:  20.101207733154297 0.9195035696029663
loss:  20.068078994750977 0.8868122696876526
*******************Epoch 58 ****************** 1180 1.0
Validation Loss
*** pred loss:  26.338699340820312 pred acc: 0.5905796885490417
*** stop loss:  6.434710502624512 stop acc: 0.9257472157478333
*** template loss:  6.9870710372924805 template acc: tensor(0.1604, device='cuda:0')
*** label loss:  6.173545837402344 label acc: tensor(0.4119, device='cuda:0')
Train Loss
---> pred loss: 15.563386535644531 pred acc: 0.7447872340679169
---> stop loss: 2.7928659439086916 stop acc: 0.9694718778133392
---> template loss: 0.4696043968200684 tempalte acc: 0.9032240867614746
---> molecule label loss: 0.3050874710083008 molecule acc: 0.9233992576599122
---> kl loss: 0.9297770500183106
---> reconstruction loss: 19.130942249298098
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-59-with.npy
loss:  20.076457977294922 0.9102329015731812
loss:  19.943370819091797 0.9200429916381836
loss:  20.169282913208008 0.9368222951889038
loss:  19.775100708007812 0.9110865592956543
loss:  20.088987350463867 0.903942883014679
loss:  19.987062454223633 0.9139190912246704
loss:  19.889968872070312 0.9071824550628662
loss:  19.965959548950195 0.9356846213340759
loss:  20.24308967590332 0.9464805126190186
loss:  19.928668975830078 0.9431475400924683
loss:  20.187044143676758 0.932461678981781
loss:  19.638185501098633 0.9442424774169922
loss:  19.937610626220703 0.9266200661659241
loss:  19.942079544067383 0.9220847487449646
loss:  19.901653289794922 0.9425524473190308
loss:  19.783647537231445 0.9495856165885925
loss:  19.60133934020996 0.9160381555557251
loss:  19.328187942504883 0.9204367995262146
loss:  19.83038330078125 0.9189633131027222
loss:  19.65401840209961 0.9124589562416077
*******************Epoch 59 ****************** 1200 1.0
Validation Loss
*** pred loss:  26.259950637817383 pred acc: 0.5975241661071777
*** stop loss:  6.5879740715026855 stop acc: 0.925000011920929
*** template loss:  7.012894153594971 template acc: tensor(0.1569, device='cuda:0')
*** label loss:  6.110093593597412 label acc: tensor(0.3975, device='cuda:0')
Train Loss
---> pred loss: 15.453317260742187 pred acc: 0.7461108148097992
---> stop loss: 2.7597524642944338 stop acc: 0.9695371717214585
---> template loss: 0.4613812923431396 tempalte acc: 0.9067328453063965
---> molecule label loss: 0.2934556245803833 molecule acc: 0.9257308959960937
---> kl loss: 0.9256992340087891
---> reconstruction loss: 18.967905807495118
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-60-with.npy
loss:  19.872848510742188 0.899098813533783
loss:  20.065717697143555 0.889024555683136
loss:  19.85817527770996 0.8928006291389465
loss:  20.22222137451172 0.901881992816925
loss:  20.145856857299805 0.9134047627449036
loss:  20.163070678710938 0.9058652520179749
loss:  19.850549697875977 0.925157368183136
loss:  19.694305419921875 0.9218700528144836
loss:  19.847503662109375 0.9282753467559814
loss:  19.249675750732422 0.9121986627578735
loss:  19.824968338012695 0.8956009745597839
loss:  19.79947853088379 0.8908979892730713
loss:  19.90151596069336 0.8974379301071167
loss:  20.006181716918945 0.8787590265274048
loss:  19.529916763305664 0.8872511386871338
loss:  19.81619644165039 0.8854514956474304
loss:  19.62381935119629 0.9114327430725098
loss:  19.86977767944336 0.9270264506340027
loss:  19.67584991455078 0.9135482907295227
loss:  18.837141036987305 0.9885452389717102
*******************Epoch 60 ****************** 1220 1.0
Validation Loss
*** pred loss:  26.47701644897461 pred acc: 0.5892512202262878
*** stop loss:  6.7225518226623535 stop acc: 0.9261831045150757
*** template loss:  6.966851711273193 template acc: tensor(0.1572, device='cuda:0')
*** label loss:  6.141798496246338 label acc: tensor(0.4026, device='cuda:0')
Train Loss
---> pred loss: 15.350900268554687 pred acc: 0.7485850304365158
---> stop loss: 2.785953712463379 stop acc: 0.9693945348262787
---> template loss: 0.45397415161132815 tempalte acc: 0.9080768585205078
---> molecule label loss: 0.29363303184509276 molecule acc: 0.9257756233215332
---> kl loss: 0.9082763671875
---> reconstruction loss: 18.884461975097654
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-61-with.npy
loss:  19.982316970825195 0.905401349067688
loss:  19.772705078125 0.8805314302444458
loss:  19.720394134521484 0.8791357278823853
loss:  19.89453887939453 0.9044150710105896
loss:  19.878944396972656 0.9077271223068237
loss:  19.549762725830078 0.8850288391113281
loss:  19.81401824951172 0.8977317810058594
loss:  19.745018005371094 0.9315264821052551
loss:  19.885658264160156 0.9131618738174438
loss:  19.999088287353516 0.9154875874519348
loss:  19.591285705566406 0.8956933617591858
loss:  20.0632266998291 0.9087024927139282
loss:  19.61752700805664 0.9116826057434082
loss:  19.909759521484375 0.9046236872673035
loss:  19.59680938720703 0.9253870248794556
loss:  19.888792037963867 0.9335842132568359
loss:  19.560152053833008 0.9425114393234253
loss:  20.1005802154541 0.9202490448951721
loss:  19.69122314453125 0.9074678421020508
loss:  18.863309860229492 0.9152629971504211
*******************Epoch 61 ****************** 1240 1.0
Validation Loss
*** pred loss:  26.427242279052734 pred acc: 0.5963767766952515
*** stop loss:  7.143895626068115 stop acc: 0.9173724055290222
*** template loss:  6.9936676025390625 template acc: tensor(0.1523, device='cuda:0')
*** label loss:  6.177604675292969 label acc: tensor(0.3761, device='cuda:0')
Train Loss
---> pred loss: 15.332383728027343 pred acc: 0.747785609960556
---> stop loss: 2.7839693069458007 stop acc: 0.9693208336830139
---> template loss: 0.44045295715332033 tempalte acc: 0.9119443893432617
---> molecule label loss: 0.2901841402053833 molecule acc: 0.925666618347168
---> kl loss: 0.9092656135559082
---> reconstruction loss: 18.846988964080808
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-62-with.npy
loss:  20.115509033203125 0.9222882986068726
loss:  20.135574340820312 0.88198322057724
loss:  19.750852584838867 0.8923285603523254
loss:  20.111377716064453 0.8956419229507446
loss:  19.711315155029297 0.8714544177055359
loss:  20.03774642944336 0.8981188535690308
loss:  19.901918411254883 0.8735312819480896
loss:  19.719404220581055 0.8901998996734619
loss:  19.936002731323242 0.8857685923576355
loss:  19.68020248413086 0.8885760307312012
loss:  19.714975357055664 0.9009852409362793
loss:  19.416967391967773 0.9152207374572754
loss:  19.17473793029785 0.9424168467521667
loss:  19.577287673950195 0.9569860696792603
loss:  19.564157485961914 0.9413990378379822
loss:  19.274776458740234 0.9164767265319824
loss:  19.658048629760742 0.9001612663269043
loss:  19.4089298248291 0.8999148011207581
loss:  19.438634872436523 0.9197235703468323
loss:  20.27409553527832 0.9583286643028259
*******************Epoch 62 ****************** 1260 1.0
Validation Loss
*** pred loss:  26.286746978759766 pred acc: 0.5921497344970703
*** stop loss:  6.885736465454102 stop acc: 0.9235678911209106
*** template loss:  6.975178241729736 template acc: tensor(0.1555, device='cuda:0')
*** label loss:  6.276237964630127 label acc: tensor(0.4024, device='cuda:0')
Train Loss
---> pred loss: 15.263546752929688 pred acc: 0.7507652193307877
---> stop loss: 2.8684310913085938 stop acc: 0.9680508613586426
---> template loss: 0.415952730178833 tempalte acc: 0.9189857482910156
---> molecule label loss: 0.2746217489242554 molecule acc: 0.9308813095092774
---> kl loss: 0.9075752258300781
---> reconstruction loss: 18.822551727294922
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-63-with.npy
loss:  19.476655960083008 0.9099500179290771
loss:  19.442703247070312 0.9092229604721069
loss:  19.997953414916992 0.9086359739303589
loss:  19.529094696044922 0.8950006365776062
loss:  19.513885498046875 0.9284917116165161
loss:  19.46533203125 0.9079094529151917
loss:  19.637908935546875 0.8914464116096497
loss:  19.586158752441406 0.9150538444519043
loss:  19.74034309387207 0.9284128546714783
loss:  19.472665786743164 0.9236481189727783
loss:  19.238245010375977 0.9116151332855225
loss:  19.396644592285156 0.9275598526000977
loss:  19.56238555908203 0.9018654823303223
loss:  19.426374435424805 0.9112781882286072
loss:  19.044397354125977 0.8879290819168091
loss:  19.615238189697266 0.8884729146957397
loss:  19.279077529907227 0.898814857006073
loss:  19.222431182861328 0.8824118375778198
loss:  19.507678985595703 0.8780038356781006
loss:  18.583961486816406 0.8045313358306885
*******************Epoch 63 ****************** 1280 1.0
Validation Loss
*** pred loss:  26.512590408325195 pred acc: 0.5983695387840271
*** stop loss:  6.908200263977051 stop acc: 0.9241594076156616
*** template loss:  7.014360427856445 template acc: tensor(0.1502, device='cuda:0')
*** label loss:  6.116782188415527 label acc: tensor(0.3894, device='cuda:0')
Train Loss
---> pred loss: 15.140898132324219 pred acc: 0.7506549239158631
---> stop loss: 2.724658966064453 stop acc: 0.9699164181947708
---> template loss: 0.40816826820373536 tempalte acc: 0.9197135925292969
---> molecule label loss: 0.2627185106277466 molecule acc: 0.9342720031738281
---> kl loss: 0.9005126953125
---> reconstruction loss: 18.536444091796874
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-64-with.npy
loss:  19.071996688842773 0.8795323371887207
loss:  18.86287498474121 0.8682520389556885
loss:  19.74127197265625 0.9003419876098633
loss:  19.40249252319336 0.9175939559936523
loss:  19.31631851196289 0.9150725603103638
loss:  19.303970336914062 0.9275863170623779
loss:  19.470014572143555 0.9072920083999634
loss:  19.059911727905273 0.9183847308158875
loss:  19.321985244750977 0.9075121283531189
loss:  19.36880874633789 0.8910340070724487
loss:  18.874723434448242 0.9011663198471069
loss:  19.24839210510254 0.9191116690635681
loss:  19.587581634521484 0.8927761316299438
loss:  19.258512496948242 0.8800315856933594
loss:  19.41443634033203 0.8941443562507629
loss:  19.140926361083984 0.9087443351745605
loss:  19.345685958862305 0.8715304136276245
loss:  19.629606246948242 0.895778238773346
loss:  19.500734329223633 0.889623761177063
loss:  18.530515670776367 0.8086617588996887
*******************Epoch 64 ****************** 1300 1.0
Validation Loss
*** pred loss:  26.55038833618164 pred acc: 0.5984299182891846
*** stop loss:  6.706359386444092 stop acc: 0.9251556992530823
*** template loss:  7.014772415161133 template acc: tensor(0.1583, device='cuda:0')
*** label loss:  6.250704288482666 label acc: tensor(0.4087, device='cuda:0')
Train Loss
---> pred loss: 15.013871765136718 pred acc: 0.7537929356098175
---> stop loss: 2.7255880355834963 stop acc: 0.9698130995035171
---> template loss: 0.38909876346588135 tempalte acc: 0.9252264022827148
---> molecule label loss: 0.24926869869232177 molecule acc: 0.9374306678771973
---> kl loss: 0.8947085380554199
---> reconstruction loss: 18.377828693389894
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-65-with.npy
loss:  18.956647872924805 0.9039559960365295
loss:  19.16731834411621 0.8960261344909668
loss:  18.95014762878418 0.8891948461532593
loss:  19.503122329711914 0.910103440284729
loss:  18.97959327697754 0.9158666729927063
loss:  18.975826263427734 0.92851722240448
loss:  19.20813751220703 0.905154287815094
loss:  19.101459503173828 0.9187864661216736
loss:  19.11907386779785 0.8921869993209839
loss:  19.29646873474121 0.8998074531555176
loss:  19.191247940063477 0.8915578722953796
loss:  19.1276798248291 0.8700595498085022
loss:  19.494497299194336 0.892169713973999
loss:  19.052095413208008 0.8755953907966614
loss:  18.938186645507812 0.8682544231414795
loss:  18.66725730895996 0.9009636044502258
loss:  19.191186904907227 0.8815624117851257
loss:  19.128633499145508 0.8718858957290649
loss:  18.9394588470459 0.8907057642936707
loss:  18.74844741821289 0.8847895860671997
*******************Epoch 65 ****************** 1320 1.0
Validation Loss
*** pred loss:  26.343481063842773 pred acc: 0.5967994928359985
*** stop loss:  6.842742443084717 stop acc: 0.9234122633934021
*** template loss:  7.068165302276611 template acc: tensor(0.1534, device='cuda:0')
*** label loss:  6.290372371673584 label acc: tensor(0.3890, device='cuda:0')
Train Loss
---> pred loss: 14.954678344726563 pred acc: 0.7539970606565476
---> stop loss: 2.613901710510254 stop acc: 0.9713112473487854
---> template loss: 0.3817995309829712 tempalte acc: 0.927098560333252
---> molecule label loss: 0.2420881509780884 molecule acc: 0.939327621459961
---> kl loss: 0.8943572044372559
---> reconstruction loss: 18.19246835708618
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-66-with.npy
loss:  19.055286407470703 0.8962782025337219
loss:  19.103864669799805 0.8861272931098938
loss:  19.145658493041992 0.887793779373169
loss:  18.876441955566406 0.9122026562690735
loss:  18.85162353515625 0.8835518956184387
loss:  19.1539306640625 0.9036337733268738
loss:  19.358383178710938 0.8909351229667664
loss:  18.809568405151367 0.900095522403717
loss:  19.244657516479492 0.9336050748825073
loss:  19.056407928466797 0.9064782857894897
loss:  18.795501708984375 0.9213354587554932
loss:  19.1697940826416 0.9179747700691223
loss:  18.840394973754883 0.9104364514350891
loss:  19.082590103149414 0.9088274240493774
loss:  18.928150177001953 0.8714332580566406
loss:  18.627050399780273 0.8661903142929077
loss:  19.164127349853516 0.8798948526382446
loss:  19.130538940429688 0.9098671078681946
loss:  19.03916358947754 0.8924465179443359
loss:  20.028945922851562 0.9436905980110168
*******************Epoch 66 ****************** 1340 1.0
Validation Loss
*** pred loss:  26.900856018066406 pred acc: 0.5977053046226501
*** stop loss:  7.499868392944336 stop acc: 0.9202989339828491
*** template loss:  7.07487154006958 template acc: tensor(0.1523, device='cuda:0')
*** label loss:  6.33705472946167 label acc: tensor(0.4093, device='cuda:0')
Train Loss
---> pred loss: 14.85343017578125 pred acc: 0.7573859423398972
---> stop loss: 2.6941267013549806 stop acc: 0.9702534556388855
---> template loss: 0.375794792175293 tempalte acc: 0.9279369354248047
---> molecule label loss: 0.24861314296722412 molecule acc: 0.9368916511535644
---> kl loss: 0.9011399269104003
---> reconstruction loss: 18.171964931488038
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-67-with.npy
loss:  19.641904830932617 0.8986778855323792
loss:  19.319034576416016 0.9048374891281128
loss:  20.087705612182617 0.9393438696861267
loss:  19.591184616088867 0.9105029106140137
loss:  18.964637756347656 0.9001473784446716
loss:  19.768754959106445 0.9138868451118469
loss:  19.189531326293945 0.8932915925979614
loss:  19.14206314086914 0.881665050983429
loss:  18.996315002441406 0.8924309611320496
loss:  19.161170959472656 0.9004087448120117
loss:  19.249006271362305 0.8870928883552551
loss:  18.64161491394043 0.8623334169387817
loss:  19.487735748291016 0.9045416116714478
loss:  18.805952072143555 0.8949006199836731
loss:  19.104337692260742 0.8839942812919617
loss:  19.325422286987305 0.897631824016571
loss:  18.864105224609375 0.9040688276290894
loss:  19.344228744506836 0.8987165689468384
loss:  19.04102325439453 0.9037856459617615
loss:  18.853839874267578 0.9256091117858887
*******************Epoch 67 ****************** 1360 1.0
Validation Loss
*** pred loss:  26.74011993408203 pred acc: 0.6003019213676453
*** stop loss:  7.015446662902832 stop acc: 0.9239414930343628
*** template loss:  7.023632526397705 template acc: tensor(0.1516, device='cuda:0')
*** label loss:  6.325448513031006 label acc: tensor(0.4087, device='cuda:0')
Train Loss
---> pred loss: 14.877720642089844 pred acc: 0.7552512764930726
---> stop loss: 2.805927848815918 stop acc: 0.9687336981296539
---> template loss: 0.38223326206207275 tempalte acc: 0.926063346862793
---> molecule label loss: 0.2632046937942505 molecule acc: 0.9331842422485351
---> kl loss: 0.8998933792114258
---> reconstruction loss: 18.329084587097167
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-68-with.npy
loss:  18.91712188720703 0.8720490336418152
loss:  18.949565887451172 0.8852890133857727
loss:  18.650821685791016 0.8850924372673035
loss:  19.193029403686523 0.8808919191360474
loss:  19.08395767211914 0.8732102513313293
loss:  19.13873291015625 0.8956596255302429
loss:  19.059993743896484 0.8922571539878845
loss:  18.7926082611084 0.8987467288970947
loss:  18.9731388092041 0.9033194184303284
loss:  18.842422485351562 0.9114246964454651
loss:  19.23345947265625 0.9057413339614868
loss:  18.670164108276367 0.8953328132629395
loss:  18.680421829223633 0.913738489151001
loss:  18.60083770751953 0.8973644375801086
loss:  18.89303970336914 0.9063960313796997
loss:  18.74001121520996 0.8707636594772339
loss:  18.831554412841797 0.8714064955711365
loss:  18.377527236938477 0.8856015801429749
loss:  18.51003646850586 0.8766888976097107
loss:  18.998760223388672 0.8595391511917114
*******************Epoch 68 ****************** 1380 1.0
Validation Loss
*** pred loss:  27.001665115356445 pred acc: 0.5948067307472229
*** stop loss:  6.753396987915039 stop acc: 0.9247198104858398
*** template loss:  6.985222339630127 template acc: tensor(0.1625, device='cuda:0')
*** label loss:  6.229044437408447 label acc: tensor(0.3956, device='cuda:0')
Train Loss
---> pred loss: 14.71661834716797 pred acc: 0.7581914782524108
---> stop loss: 2.588807487487793 stop acc: 0.9716760993003846
---> template loss: 0.3911949634552002 tempalte acc: 0.9251302719116211
---> molecule label loss: 0.2712141752243042 molecule acc: 0.9300844192504882
---> kl loss: 0.8890255928039551
---> reconstruction loss: 17.967834758758546
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-69-with.npy
loss:  18.971391677856445 0.8746734857559204
loss:  18.7319393157959 0.8860026001930237
loss:  19.080581665039062 0.8914008736610413
loss:  18.846330642700195 0.8586026430130005
loss:  18.641315460205078 0.8772006034851074
loss:  18.49492073059082 0.8806743025779724
loss:  18.958526611328125 0.8635300397872925
loss:  18.89694595336914 0.872880220413208
loss:  18.550312042236328 0.8857513666152954
loss:  18.889253616333008 0.8695955872535706
loss:  18.754648208618164 0.8552982211112976
loss:  18.899354934692383 0.8728147745132446
loss:  18.779438018798828 0.8603882789611816
loss:  18.72633171081543 0.8657470941543579
loss:  18.573278427124023 0.8896311521530151
loss:  18.590923309326172 0.8541936874389648
loss:  18.70155143737793 0.8689561486244202
loss:  18.398155212402344 0.8675259947776794
loss:  18.851259231567383 0.8757777810096741
loss:  18.601806640625 0.7936887741088867
*******************Epoch 69 ****************** 1400 1.0
Validation Loss
*** pred loss:  26.86330795288086 pred acc: 0.5946255922317505
*** stop loss:  6.8128461837768555 stop acc: 0.9256849884986877
*** template loss:  7.066400051116943 template acc: tensor(0.1569, device='cuda:0')
*** label loss:  6.214023113250732 label acc: tensor(0.3817, device='cuda:0')
Train Loss
---> pred loss: 14.683500671386719 pred acc: 0.7597886919975281
---> stop loss: 2.525533676147461 stop acc: 0.9726775258779525
---> template loss: 0.3998000383377075 tempalte acc: 0.9223352432250976
---> molecule label loss: 0.26986238956451414 molecule acc: 0.9300525665283204
---> kl loss: 0.8682167053222656
---> reconstruction loss: 17.878694915771487
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-70-with.npy
loss:  18.43710708618164 0.8965594172477722
loss:  18.50905990600586 0.8986586332321167
loss:  18.536376953125 0.9014675617218018
loss:  18.74139404296875 0.9079451560974121
loss:  18.572208404541016 0.912908673286438
loss:  18.82723617553711 0.8888939619064331
loss:  18.5811767578125 0.9010453820228577
loss:  18.571929931640625 0.8931912183761597
loss:  18.46198272705078 0.8638167977333069
loss:  18.511714935302734 0.862783670425415
loss:  18.602176666259766 0.8615540266036987
loss:  18.339603424072266 0.85234135389328
loss:  18.819900512695312 0.8728509545326233
loss:  18.494312286376953 0.8566197156906128
loss:  18.35243034362793 0.8584806323051453
loss:  18.614171981811523 0.8694436550140381
loss:  18.598461151123047 0.8586416244506836
loss:  18.78685188293457 0.8701781034469604
loss:  18.76742172241211 0.86158686876297
loss:  19.347721099853516 0.7811927795410156
*******************Epoch 70 ****************** 1420 1.0
Validation Loss
*** pred loss:  26.881710052490234 pred acc: 0.5929951667785645
*** stop loss:  6.928099155426025 stop acc: 0.9249688982963562
*** template loss:  7.075127124786377 template acc: tensor(0.1541, device='cuda:0')
*** label loss:  6.273709774017334 label acc: tensor(0.3913, device='cuda:0')
Train Loss
---> pred loss: 14.597883605957032 pred acc: 0.7606665968894959
---> stop loss: 2.4922565460205077 stop acc: 0.9727243691682815
---> template loss: 0.39022562503814695 tempalte acc: 0.9246640205383301
---> molecule label loss: 0.26978905200958253 molecule acc: 0.9292760848999023
---> kl loss: 0.873508071899414
---> reconstruction loss: 17.750152206420896
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-71-with.npy
loss:  18.513586044311523 0.8584946990013123
loss:  18.20657730102539 0.886103630065918
loss:  18.533952713012695 0.9103066325187683
loss:  18.75635528564453 0.8779471516609192
loss:  18.45209503173828 0.8930177688598633
loss:  18.762855529785156 0.883404016494751
loss:  18.613304138183594 0.8848284482955933
loss:  18.84029197692871 0.8994107246398926
loss:  18.711448669433594 0.9016730189323425
loss:  18.61385726928711 0.890768826007843
loss:  18.095827102661133 0.8890132904052734
loss:  18.754722595214844 0.858352541923523
loss:  18.673309326171875 0.8750253915786743
loss:  18.61197280883789 0.8796907067298889
loss:  18.709115982055664 0.8620288372039795
loss:  18.205360412597656 0.8589622378349304
loss:  18.86422348022461 0.8716226816177368
loss:  18.175434112548828 0.85228431224823
loss:  18.438434600830078 0.8430711030960083
loss:  18.68827247619629 0.9024722576141357
*******************Epoch 71 ****************** 1440 1.0
Validation Loss
*** pred loss:  27.125219345092773 pred acc: 0.5935386419296265
*** stop loss:  6.864121913909912 stop acc: 0.926338791847229
*** template loss:  7.0439348220825195 template acc: tensor(0.1548, device='cuda:0')
*** label loss:  6.22590970993042 label acc: tensor(0.3975, device='cuda:0')
Train Loss
---> pred loss: 14.490184020996093 pred acc: 0.7621587574481964
---> stop loss: 2.5583871841430663 stop acc: 0.9717554450035095
---> template loss: 0.3732581615447998 tempalte acc: 0.9288647651672364
---> molecule label loss: 0.2602968215942383 molecule acc: 0.9330300331115723
---> kl loss: 0.8789239883422851
---> reconstruction loss: 17.68212490081787
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-72-with.npy
loss:  18.207056045532227 0.8577250242233276
loss:  18.315235137939453 0.863018810749054
loss:  18.249879837036133 0.8527961373329163
loss:  18.85327911376953 0.8606810569763184
loss:  18.55655860900879 0.8534356951713562
loss:  18.511993408203125 0.8373719453811646
loss:  18.454593658447266 0.8579418063163757
loss:  18.405269622802734 0.8652735948562622
loss:  18.35550880432129 0.8925025463104248
loss:  18.4360408782959 0.8536378741264343
loss:  18.28035545349121 0.8532949090003967
loss:  18.432565689086914 0.8657776117324829
loss:  18.29258918762207 0.880994439125061
loss:  18.333683013916016 0.8864175081253052
loss:  18.107498168945312 0.8768350481987
loss:  18.121004104614258 0.8852054476737976
loss:  18.38811492919922 0.8792943954467773
loss:  18.31096076965332 0.860579788684845
loss:  18.128660202026367 0.8641120195388794
loss:  18.354290008544922 0.9102960228919983
*******************Epoch 72 ****************** 1460 1.0
Validation Loss
*** pred loss:  26.990758895874023 pred acc: 0.5975241661071777
*** stop loss:  7.105160713195801 stop acc: 0.9242528080940247
*** template loss:  7.044098854064941 template acc: tensor(0.1604, device='cuda:0')
*** label loss:  6.250012397766113 label acc: tensor(0.3915, device='cuda:0')
Train Loss
---> pred loss: 14.437019348144531 pred acc: 0.7622749090194703
---> stop loss: 2.4661455154418945 stop acc: 0.9730413287878037
---> template loss: 0.3565181493759155 tempalte acc: 0.9336798667907715
---> molecule label loss: 0.22721464633941652 molecule acc: 0.9424360275268555
---> kl loss: 0.8678595542907714
---> reconstruction loss: 17.486898136138915
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-73-with.npy
loss:  18.191232681274414 0.8619231581687927
loss:  17.899410247802734 0.864701509475708
loss:  18.43879508972168 0.8620956540107727
loss:  18.375288009643555 0.8652909994125366
loss:  18.200132369995117 0.8449318408966064
loss:  18.31277084350586 0.858345627784729
loss:  18.377107620239258 0.846581220626831
loss:  17.956134796142578 0.8516574501991272
loss:  18.596458435058594 0.836132287979126
loss:  18.17477798461914 0.8336611986160278
loss:  18.51104736328125 0.8812389969825745
loss:  18.225915908813477 0.8596472144126892
loss:  18.316530227661133 0.8694460391998291
loss:  18.32415199279785 0.8883532285690308
loss:  18.298933029174805 0.8724319338798523
loss:  18.8594913482666 0.8842928409576416
loss:  18.29275894165039 0.8881345987319946
loss:  18.448476791381836 0.8910443782806396
loss:  18.126670837402344 0.903374195098877
loss:  18.523090362548828 0.8720284700393677
*******************Epoch 73 ****************** 1480 1.0
Validation Loss
*** pred loss:  27.041784286499023 pred acc: 0.59522944688797
*** stop loss:  7.109060764312744 stop acc: 0.9238792657852173
*** template loss:  7.030046463012695 template acc: tensor(0.1586, device='cuda:0')
*** label loss:  6.242055416107178 label acc: tensor(0.3964, device='cuda:0')
Train Loss
---> pred loss: 14.386892700195313 pred acc: 0.7626693218946456
---> stop loss: 2.5101261138916016 stop acc: 0.9721176236867904
---> template loss: 0.337451696395874 tempalte acc: 0.9379074096679687
---> molecule label loss: 0.22122137546539306 molecule acc: 0.9426124572753907
---> kl loss: 0.8667655944824219
---> reconstruction loss: 17.45569381713867
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-74-with.npy
loss:  18.110031127929688 0.876319408416748
loss:  18.059043884277344 0.8663972616195679
loss:  18.682910919189453 0.8727502822875977
loss:  18.692853927612305 0.8754019141197205
loss:  18.198074340820312 0.8575543165206909
loss:  18.459802627563477 0.8580883145332336
loss:  18.24327850341797 0.8862651586532593
loss:  18.187753677368164 0.8746817708015442
loss:  18.079742431640625 0.8777739405632019
loss:  18.244956970214844 0.8985048532485962
loss:  18.258377075195312 0.8836088180541992
loss:  18.104049682617188 0.8755031824111938
loss:  18.35614013671875 0.8862977027893066
loss:  18.15392303466797 0.8872460722923279
loss:  18.03404426574707 0.8727594017982483
loss:  18.23983383178711 0.8767442107200623
loss:  17.980527877807617 0.8916575312614441
loss:  17.987567901611328 0.8911988735198975
loss:  18.55437660217285 0.8765609860420227
loss:  17.8405818939209 0.8669151663780212
*******************Epoch 74 ****************** 1500 1.0
Validation Loss
*** pred loss:  27.248950958251953 pred acc: 0.5916666388511658
*** stop loss:  7.22222375869751 stop acc: 0.9215130805969238
*** template loss:  7.013137340545654 template acc: tensor(0.1565, device='cuda:0')
*** label loss:  6.342883110046387 label acc: tensor(0.4050, device='cuda:0')
Train Loss
---> pred loss: 14.309597778320313 pred acc: 0.7633172512054444
---> stop loss: 2.491074562072754 stop acc: 0.9725599080324173
---> template loss: 0.33456058502197267 tempalte acc: 0.9369741439819336
---> molecule label loss: 0.21055099964141846 molecule acc: 0.947883129119873
---> kl loss: 0.8776115417480469
---> reconstruction loss: 17.345783233642578
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-75-with.npy
loss:  17.840473175048828 0.8607917428016663
loss:  18.004915237426758 0.8654552102088928
loss:  18.143232345581055 0.8621514439582825
loss:  18.39702033996582 0.8697046637535095
loss:  18.0455322265625 0.8469212651252747
loss:  17.787166595458984 0.8585072755813599
loss:  18.445650100708008 0.8508483171463013
loss:  18.224102020263672 0.864489734172821
loss:  18.17263412475586 0.8454305529594421
loss:  18.042505264282227 0.8715387582778931
loss:  18.248796463012695 0.8542475700378418
loss:  17.818117141723633 0.8705875873565674
loss:  18.064550399780273 0.8709584474563599
loss:  18.151203155517578 0.8491694331169128
loss:  18.177993774414062 0.8830337524414062
loss:  18.22651481628418 0.8800594806671143
loss:  17.707752227783203 0.8724279403686523
loss:  18.515857696533203 0.897713840007782
loss:  18.117063522338867 0.8547627329826355
loss:  18.782718658447266 0.9252347350120544
*******************Epoch 75 ****************** 1520 1.0
Validation Loss
*** pred loss:  27.2459774017334 pred acc: 0.5971618294715881
*** stop loss:  7.152700424194336 stop acc: 0.9231942892074585
*** template loss:  7.028922080993652 template acc: tensor(0.1520, device='cuda:0')
*** label loss:  6.32762336730957 label acc: tensor(0.3990, device='cuda:0')
Train Loss
---> pred loss: 14.318666076660156 pred acc: 0.7647172540426255
---> stop loss: 2.4496450424194336 stop acc: 0.9730198383331299
---> template loss: 0.3129279375076294 tempalte acc: 0.9435938835144043
---> molecule label loss: 0.19674988985061645 molecule acc: 0.9513246536254882
---> kl loss: 0.8677016258239746
---> reconstruction loss: 17.277989292144774
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-76-with.npy
loss:  18.245603561401367 0.9039483070373535
loss:  17.96845245361328 0.9066701531410217
loss:  18.0678768157959 0.9061002135276794
loss:  18.276025772094727 0.8894122242927551
loss:  18.043703079223633 0.8861308097839355
loss:  18.0953426361084 0.8787798285484314
loss:  18.354658126831055 0.8806377053260803
loss:  18.13713264465332 0.8769078850746155
loss:  18.138896942138672 0.8709075450897217
loss:  18.042194366455078 0.8746874928474426
loss:  17.975236892700195 0.8696795701980591
loss:  18.149385452270508 0.8623629212379456
loss:  17.897241592407227 0.8652817606925964
loss:  18.48524284362793 0.854991614818573
loss:  18.10896110534668 0.8600596189498901
loss:  17.915964126586914 0.8443435430526733
loss:  18.034940719604492 0.8531246781349182
loss:  17.847034454345703 0.8506450057029724
loss:  17.962284088134766 0.8476194739341736
loss:  17.79115867614746 0.8890485167503357
*******************Epoch 76 ****************** 1540 1.0
Validation Loss
*** pred loss:  27.242233276367188 pred acc: 0.5938405394554138
*** stop loss:  7.125017166137695 stop acc: 0.924408495426178
*** template loss:  7.05255126953125 template acc: tensor(0.1527, device='cuda:0')
*** label loss:  6.440279006958008 label acc: tensor(0.4095, device='cuda:0')
Train Loss
---> pred loss: 14.235130310058594 pred acc: 0.7663011372089386
---> stop loss: 2.482366180419922 stop acc: 0.9729867428541183
---> template loss: 0.30112357139587403 tempalte acc: 0.9455982208251953
---> molecule label loss: 0.18467888832092286 molecule acc: 0.954581356048584
---> kl loss: 0.8735669136047364
---> reconstruction loss: 17.203300762176514
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-77-with.npy
loss:  17.880481719970703 0.8520906567573547
loss:  17.885515213012695 0.8397125005722046
loss:  18.078147888183594 0.8582829833030701
loss:  17.822322845458984 0.8737217783927917
loss:  18.0338077545166 0.868648111820221
loss:  17.595998764038086 0.8598694801330566
loss:  17.82451820373535 0.885173499584198
loss:  17.87525749206543 0.8863226771354675
loss:  18.1362247467041 0.8808228373527527
loss:  17.992473602294922 0.8525772094726562
loss:  17.855587005615234 0.8703389167785645
loss:  18.007720947265625 0.8618312478065491
loss:  17.672658920288086 0.8550356030464172
loss:  17.91318130493164 0.8649089336395264
loss:  17.5903377532959 0.8671396970748901
loss:  17.517990112304688 0.8608428239822388
loss:  17.853073120117188 0.8514147996902466
loss:  17.726425170898438 0.8728989362716675
loss:  17.803245544433594 0.8762974739074707
loss:  16.916868209838867 0.8090152740478516
*******************Epoch 77 ****************** 1560 1.0
Validation Loss
*** pred loss:  27.776336669921875 pred acc: 0.5908816456794739
*** stop loss:  7.122636318206787 stop acc: 0.9253113865852356
*** template loss:  7.032098770141602 template acc: tensor(0.1593, device='cuda:0')
*** label loss:  6.350703716278076 label acc: tensor(0.4037, device='cuda:0')
Train Loss
---> pred loss: 14.085713195800782 pred acc: 0.7670714050531388
---> stop loss: 2.3670894622802736 stop acc: 0.9741867125034332
---> template loss: 0.3012077808380127 tempalte acc: 0.9467445373535156
---> molecule label loss: 0.18273544311523438 molecule acc: 0.9548207283020019
---> kl loss: 0.8623472213745117
---> reconstruction loss: 16.93674793243408
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-78-with.npy
loss:  17.62286376953125 0.8444217443466187
loss:  18.068235397338867 0.8545385599136353
loss:  18.373868942260742 0.877082884311676
loss:  17.79172134399414 0.879664421081543
loss:  17.959592819213867 0.8714391589164734
loss:  17.974781036376953 0.8916918635368347
loss:  17.80304527282715 0.8993449807167053
loss:  17.85346221923828 0.8980675339698792
loss:  17.734119415283203 0.8830879926681519
loss:  17.6375732421875 0.8843252062797546
loss:  17.79888343811035 0.874172031879425
loss:  18.01825523376465 0.8673796653747559
loss:  17.64592742919922 0.8709031343460083
loss:  17.362478256225586 0.8622169494628906
loss:  17.492387771606445 0.880582869052887
loss:  17.91152572631836 0.860595703125
loss:  17.849895477294922 0.8372964859008789
loss:  18.098901748657227 0.854287326335907
loss:  17.774629592895508 0.8580037951469421
loss:  16.925369262695312 0.8253071308135986
*******************Epoch 78 ****************** 1580 1.0
Validation Loss
*** pred loss:  27.6981143951416 pred acc: 0.5884057879447937
*** stop loss:  7.305873870849609 stop acc: 0.9219489693641663
*** template loss:  7.094438552856445 template acc: tensor(0.1544, device='cuda:0')
*** label loss:  6.715519905090332 label acc: tensor(0.4114, device='cuda:0')
Train Loss
---> pred loss: 14.04674835205078 pred acc: 0.7682806551456451
---> stop loss: 2.3777517318725585 stop acc: 0.973703944683075
---> template loss: 0.30432829856872556 tempalte acc: 0.9463051795959473
---> molecule label loss: 0.1873262882232666 molecule acc: 0.9527948379516602
---> kl loss: 0.8687204360961914
---> reconstruction loss: 16.91615505218506
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-79-with.npy
loss:  17.619365692138672 0.8698686957359314
loss:  18.056604385375977 0.8658615350723267
loss:  17.720211029052734 0.8559442162513733
loss:  17.854278564453125 0.8528223037719727
loss:  17.513822555541992 0.8251215815544128
loss:  17.62660789489746 0.8259068727493286
loss:  17.594690322875977 0.8448954224586487
loss:  17.57892417907715 0.8332012891769409
loss:  17.99094581604004 0.8440672755241394
loss:  17.79433250427246 0.8483032584190369
loss:  17.53404998779297 0.8491098880767822
loss:  17.925493240356445 0.8393314480781555
loss:  17.53168487548828 0.8521193265914917
loss:  17.534170150756836 0.8663727045059204
loss:  17.4405517578125 0.8594517111778259
loss:  17.682004928588867 0.8630017042160034
loss:  17.853940963745117 0.8747597336769104
loss:  17.759950637817383 0.8709490299224854
loss:  17.99262046813965 0.8661367297172546
loss:  18.203533172607422 0.8263452053070068
*******************Epoch 79 ****************** 1600 1.0
Validation Loss
*** pred loss:  27.546607971191406 pred acc: 0.6011473536491394
*** stop loss:  7.268618583679199 stop acc: 0.9253736138343811
*** template loss:  7.072418212890625 template acc: tensor(0.1565, device='cuda:0')
*** label loss:  6.501758575439453 label acc: tensor(0.4095, device='cuda:0')
Train Loss
---> pred loss: 14.002561950683594 pred acc: 0.7686674922704697
---> stop loss: 2.3572872161865233 stop acc: 0.9741426855325699
---> template loss: 0.30078587532043455 tempalte acc: 0.9471750259399414
---> molecule label loss: 0.22807457447052001 molecule acc: 0.9384310722351075
---> kl loss: 0.851678466796875
---> reconstruction loss: 16.888710021972656
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-80-with.npy
loss:  17.678646087646484 0.8717182874679565
loss:  17.636289596557617 0.8474076986312866
loss:  17.50337791442871 0.8693593144416809
loss:  17.55498695373535 0.8677276968955994
loss:  17.824663162231445 0.8709406852722168
loss:  17.61515998840332 0.8837912082672119
loss:  17.479442596435547 0.8684568405151367
loss:  17.55860710144043 0.8658964037895203
loss:  17.57806396484375 0.8510695099830627
loss:  17.872787475585938 0.8389336466789246
loss:  17.42782974243164 0.8376842141151428
loss:  17.701068878173828 0.8390717506408691
loss:  17.6912841796875 0.8427394032478333
loss:  17.613435745239258 0.8416382074356079
loss:  17.378114700317383 0.844310998916626
loss:  17.322717666625977 0.8384414315223694
loss:  17.803821563720703 0.8463174104690552
loss:  17.979433059692383 0.8404704928398132
loss:  17.641807556152344 0.843867301940918
loss:  18.45978355407715 0.901893675327301
*******************Epoch 80 ****************** 1620 1.0
Validation Loss
*** pred loss:  27.792112350463867 pred acc: 0.5986714959144592
*** stop loss:  7.268263816833496 stop acc: 0.92303866147995
*** template loss:  7.082032203674316 template acc: tensor(0.1593, device='cuda:0')
*** label loss:  6.476253509521484 label acc: tensor(0.4099, device='cuda:0')
Train Loss
---> pred loss: 13.972805786132813 pred acc: 0.7697635978460312
---> stop loss: 2.336319923400879 stop acc: 0.9744287759065628
---> template loss: 0.3024705410003662 tempalte acc: 0.9465344429016114
---> molecule label loss: 0.19888190031051636 molecule acc: 0.9499789237976074
---> kl loss: 0.8555868148803711
---> reconstruction loss: 16.810479164123535
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-81-with.npy
loss:  17.576509475708008 0.868479311466217
loss:  17.527292251586914 0.8800637125968933
loss:  17.751914978027344 0.8682760000228882
loss:  17.652555465698242 0.8865931630134583
loss:  17.509302139282227 0.875853955745697
loss:  17.406681060791016 0.8706444501876831
loss:  17.596996307373047 0.8733304142951965
loss:  17.416866302490234 0.8442654013633728
loss:  17.740869522094727 0.8494297862052917
loss:  17.65976905822754 0.8634121417999268
loss:  17.45485496520996 0.8540199398994446
loss:  17.750864028930664 0.8710274696350098
loss:  17.565919876098633 0.858672022819519
loss:  17.029508590698242 0.8556951284408569
loss:  17.754390716552734 0.8518558740615845
loss:  17.65308380126953 0.8687533736228943
loss:  17.703706741333008 0.8615013957023621
loss:  17.453508377075195 0.8604307770729065
loss:  17.266511917114258 0.8624246716499329
loss:  16.754535675048828 0.9208627343177795
*******************Epoch 81 ****************** 1640 1.0
Validation Loss
*** pred loss:  27.891319274902344 pred acc: 0.592934787273407
*** stop loss:  7.383659839630127 stop acc: 0.9208281636238098
*** template loss:  7.098047256469727 template acc: tensor(0.1509, device='cuda:0')
*** label loss:  6.414689064025879 label acc: tensor(0.4086, device='cuda:0')
Train Loss
---> pred loss: 13.872686767578125 pred acc: 0.7705974638462066
---> stop loss: 2.3008886337280274 stop acc: 0.9750710129737854
---> template loss: 0.28807916641235354 tempalte acc: 0.950069808959961
---> molecule label loss: 0.18234875202178955 molecule acc: 0.9555088996887207
---> kl loss: 0.8672795295715332
---> reconstruction loss: 16.644004344940186
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-82-with.npy
loss:  17.205289840698242 0.8813605308532715
loss:  17.542329788208008 0.8923767805099487
loss:  17.535804748535156 0.8934096097946167
loss:  17.616323471069336 0.9265596866607666
loss:  17.541423797607422 0.9149556756019592
loss:  17.332897186279297 0.9030332565307617
loss:  17.608753204345703 0.9171566367149353
loss:  17.725833892822266 0.8937391638755798
loss:  17.39360237121582 0.9195652008056641
loss:  17.34650230407715 0.8973022699356079
loss:  17.369443893432617 0.8695536851882935
loss:  17.78656578063965 0.8618316054344177
loss:  17.81410789489746 0.8750902414321899
loss:  17.59141731262207 0.8636549711227417
loss:  17.436567306518555 0.8503125309944153
loss:  17.355443954467773 0.8643633723258972
loss:  17.433019638061523 0.8413483500480652
loss:  17.335662841796875 0.8549642562866211
loss:  17.40510368347168 0.8554006218910217
loss:  16.885051727294922 0.9182175993919373
*******************Epoch 82 ****************** 1660 1.0
Validation Loss
*** pred loss:  27.930522918701172 pred acc: 0.595108687877655
*** stop loss:  7.413965702056885 stop acc: 0.9228829741477966
*** template loss:  7.126458644866943 template acc: tensor(0.1541, device='cuda:0')
*** label loss:  6.354235649108887 label acc: tensor(0.3994, device='cuda:0')
Train Loss
---> pred loss: 13.792304992675781 pred acc: 0.7721589416265487
---> stop loss: 2.3236919403076173 stop acc: 0.9743477135896683
---> template loss: 0.2882058620452881 tempalte acc: 0.9498218536376953
---> molecule label loss: 0.17414480447769165 molecule acc: 0.9576156616210938
---> kl loss: 0.8847098350524902
---> reconstruction loss: 16.578344058990478
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-83-with.npy
loss:  17.16274642944336 0.8718496561050415
loss:  17.272584915161133 0.8832934498786926
loss:  17.320528030395508 0.8638777136802673
loss:  17.559682846069336 0.8698378801345825
loss:  17.136552810668945 0.8566278219223022
loss:  17.02812957763672 0.8418924808502197
loss:  17.336143493652344 0.8637691736221313
loss:  17.306262969970703 0.8395290374755859
loss:  17.213335037231445 0.8661840558052063
loss:  17.4719181060791 0.8680320978164673
loss:  17.06807518005371 0.8510045409202576
loss:  17.365009307861328 0.8340492248535156
loss:  17.677902221679688 0.8662057518959045
loss:  17.154863357543945 0.8304985165596008
loss:  17.380868911743164 0.8258328437805176
loss:  17.217144012451172 0.8271880745887756
loss:  17.212539672851562 0.8151626586914062
loss:  17.515058517456055 0.833650529384613
loss:  17.081050872802734 0.8284134864807129
loss:  17.769407272338867 0.86885005235672
*******************Epoch 83 ****************** 1680 1.0
Validation Loss
*** pred loss:  27.98401641845703 pred acc: 0.5944444537162781
*** stop loss:  7.357794284820557 stop acc: 0.9249688982963562
*** template loss:  7.101828575134277 template acc: tensor(0.1579, device='cuda:0')
*** label loss:  6.385470390319824 label acc: tensor(0.3915, device='cuda:0')
Train Loss
---> pred loss: 13.741384887695313 pred acc: 0.7732057750225068
---> stop loss: 2.2431055068969727 stop acc: 0.9758674770593643
---> template loss: 0.3004370927810669 tempalte acc: 0.9460289955139161
---> molecule label loss: 0.17727495431900026 molecule acc: 0.956900691986084
---> kl loss: 0.8502875328063965
---> reconstruction loss: 16.46220178604126
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-84-with.npy
loss:  17.449485778808594 0.8553995490074158
loss:  17.181108474731445 0.9017366766929626
loss:  17.2006778717041 0.8834953904151917
loss:  17.054580688476562 0.8632345795631409
loss:  17.467609405517578 0.8954020142555237
loss:  17.591087341308594 0.8821725845336914
loss:  17.337604522705078 0.8838101029396057
loss:  17.312679290771484 0.9061310887336731
loss:  17.29180145263672 0.877129077911377
loss:  17.34195899963379 0.8930299282073975
loss:  17.538347244262695 0.9099109172821045
loss:  17.45001983642578 0.8875945210456848
loss:  17.522558212280273 0.8896175026893616
loss:  17.45328712463379 0.8750829100608826
loss:  17.45362663269043 0.8974412083625793
loss:  17.326072692871094 0.847819983959198
loss:  17.52351951599121 0.8567034006118774
loss:  17.20374298095703 0.8393805027008057
loss:  17.71039390563965 0.8485885262489319
loss:  17.308183670043945 0.8268862962722778
*******************Epoch 84 ****************** 1700 1.0
Validation Loss
*** pred loss:  28.021921157836914 pred acc: 0.591304361820221
*** stop loss:  7.358591556549072 stop acc: 0.9221668839454651
*** template loss:  7.068435192108154 template acc: tensor(0.1537, device='cuda:0')
*** label loss:  6.388484954833984 label acc: tensor(0.3798, device='cuda:0')
Train Loss
---> pred loss: 13.738639831542969 pred acc: 0.7727344572544098
---> stop loss: 2.2746707916259767 stop acc: 0.9752221047878266
---> template loss: 0.3080010890960693 tempalte acc: 0.9441082000732421
---> molecule label loss: 0.18857871294021605 molecule acc: 0.9522968292236328
---> kl loss: 0.8760284423828125
---> reconstruction loss: 16.509889221191408
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-85-with.npy
loss:  16.872648239135742 0.846989095211029
loss:  17.40684700012207 0.8537513017654419
loss:  17.5382080078125 0.8421317338943481
loss:  17.524749755859375 0.8345251083374023
loss:  17.457956314086914 0.858296811580658
loss:  18.439449310302734 0.862163245677948
loss:  18.533681869506836 0.8376624584197998
loss:  20.092132568359375 0.8507348299026489
loss:  18.114946365356445 0.8401303291320801
loss:  18.935461044311523 0.8195207118988037
loss:  17.92995262145996 0.8094012141227722
loss:  17.766557693481445 0.7784814238548279
loss:  18.105884552001953 0.8022595643997192
loss:  17.812793731689453 0.8000249266624451
loss:  18.068504333496094 0.8133788704872131
loss:  18.251413345336914 0.8403146266937256
loss:  18.088159561157227 0.8526121377944946
loss:  18.090133666992188 0.8262296915054321
loss:  17.764320373535156 0.8254316449165344
loss:  18.11028480529785 0.7389521598815918
*******************Epoch 85 ****************** 1720 1.0
Validation Loss
*** pred loss:  28.001888275146484 pred acc: 0.5921497344970703
*** stop loss:  7.510462284088135 stop acc: 0.9228829741477966
*** template loss:  7.089241981506348 template acc: tensor(0.1428, device='cuda:0')
*** label loss:  6.447039604187012 label acc: tensor(0.3787, device='cuda:0')
Train Loss
---> pred loss: 13.656988525390625 pred acc: 0.7742618709802628
---> stop loss: 2.233071708679199 stop acc: 0.975760143995285
---> template loss: 0.4962637901306152 tempalte acc: 0.8986464500427246
---> molecule label loss: 0.8322330474853515 molecule acc: 0.7975221157073975
---> kl loss: 0.8266496658325195
---> reconstruction loss: 17.218551445007325
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-86-with.npy
loss:  17.73200035095215 0.8553613424301147
loss:  18.15071678161621 0.8609644174575806
loss:  17.987701416015625 0.8730564117431641
loss:  17.756900787353516 0.8603779673576355
loss:  18.1325740814209 0.8685356378555298
loss:  18.000133514404297 0.87076336145401
loss:  17.590892791748047 0.8444338440895081
loss:  17.85745620727539 0.8342330455780029
loss:  17.979162216186523 0.8399341702461243
loss:  17.9727840423584 0.8358463048934937
loss:  17.643590927124023 0.8407062292098999
loss:  18.0815486907959 0.8287387490272522
loss:  17.79587173461914 0.8266004920005798
loss:  17.552940368652344 0.8414747714996338
loss:  18.03398895263672 0.8492055535316467
loss:  17.603721618652344 0.8376514315605164
loss:  17.815265655517578 0.8508846759796143
loss:  17.509265899658203 0.8685352802276611
loss:  17.761716842651367 0.8447971940040588
loss:  16.76936149597168 0.8584915995597839
*******************Epoch 86 ****************** 1740 1.0
Validation Loss
*** pred loss:  28.106815338134766 pred acc: 0.5934178829193115
*** stop loss:  7.6612348556518555 stop acc: 0.9214197397232056
*** template loss:  7.016283988952637 template acc: tensor(0.1456, device='cuda:0')
*** label loss:  6.157251358032227 label acc: tensor(0.4037, device='cuda:0')
Train Loss
---> pred loss: 13.546054077148437 pred acc: 0.7757389605045318
---> stop loss: 2.204857063293457 stop acc: 0.9758375078439713
---> template loss: 0.6143734455108643 tempalte acc: 0.8653220176696778
---> molecule label loss: 0.5715639591217041 molecule acc: 0.8388439178466797
---> kl loss: 0.8495296478271485
---> reconstruction loss: 16.936850357055665
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-87-with.npy
loss:  17.306251525878906 0.8485813736915588
loss:  17.500703811645508 0.8646206855773926
loss:  17.421907424926758 0.8456718921661377
loss:  17.38178062438965 0.8434969186782837
loss:  17.75221061706543 0.8553006649017334
loss:  17.263402938842773 0.8404302000999451
loss:  17.22080421447754 0.8591861724853516
loss:  17.51425552368164 0.8645716905593872
loss:  17.075490951538086 0.8666424751281738
loss:  17.66841697692871 0.8596831560134888
loss:  17.09339141845703 0.8728346228599548
loss:  17.454483032226562 0.8518694043159485
loss:  17.506261825561523 0.8683777451515198
loss:  17.052228927612305 0.8616167306900024
loss:  17.289325714111328 0.871661901473999
loss:  17.406492233276367 0.857366681098938
loss:  17.642169952392578 0.8435857892036438
loss:  17.446916580200195 0.8462374806404114
loss:  17.042036056518555 0.8507961630821228
loss:  17.54522132873535 0.9038575887680054
*******************Epoch 87 ****************** 1760 1.0
Validation Loss
*** pred loss:  28.418437957763672 pred acc: 0.5914251208305359
*** stop loss:  8.067493438720703 stop acc: 0.9184932112693787
*** template loss:  7.0282769203186035 template acc: tensor(0.1597, device='cuda:0')
*** label loss:  6.199439525604248 label acc: tensor(0.4108, device='cuda:0')
Train Loss
---> pred loss: 13.512939453125 pred acc: 0.7760311186313629
---> stop loss: 2.2036651611328124 stop acc: 0.9760153084993363
---> template loss: 0.4558877944946289 tempalte acc: 0.904570484161377
---> molecule label loss: 0.34787654876708984 molecule acc: 0.902490234375
---> kl loss: 0.8588194847106934
---> reconstruction loss: 16.520369052886963
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-88-with.npy
loss:  17.651473999023438 0.839319109916687
loss:  17.502212524414062 0.8362523913383484
loss:  17.57834243774414 0.840601921081543
loss:  17.7405948638916 0.8388926386833191
loss:  17.276254653930664 0.8162064552307129
loss:  17.20661163330078 0.852621853351593
loss:  17.20591163635254 0.8385838270187378
loss:  17.45505714416504 0.849137008190155
loss:  17.3364315032959 0.8410927653312683
loss:  17.160255432128906 0.8564043045043945
loss:  17.31430435180664 0.8559556603431702
loss:  17.161697387695312 0.8560777902603149
loss:  17.1279296875 0.8498913645744324
loss:  17.395055770874023 0.8584113121032715
loss:  16.954681396484375 0.8507941365242004
loss:  17.326936721801758 0.8726767301559448
loss:  17.237133026123047 0.8694958090782166
loss:  17.174114227294922 0.8611834645271301
loss:  17.274015426635742 0.8419907689094543
loss:  16.524621963500977 0.9145802855491638
*******************Epoch 88 ****************** 1780 1.0
Validation Loss
*** pred loss:  28.315614700317383 pred acc: 0.5951690673828125
*** stop loss:  7.447364807128906 stop acc: 0.9231008887290955
*** template loss:  7.02736234664917 template acc: tensor(0.1541, device='cuda:0')
*** label loss:  6.191915988922119 label acc: tensor(0.4104, device='cuda:0')
Train Loss
---> pred loss: 13.489735412597657 pred acc: 0.776927974820137
---> stop loss: 2.2925127029418944 stop acc: 0.9746463984251023
---> template loss: 0.3772400379180908 tempalte acc: 0.9234980583190918
---> molecule label loss: 0.2686839818954468 molecule acc: 0.9253114700317383
---> kl loss: 0.8520084381103515
---> reconstruction loss: 16.42817039489746
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-89-with.npy
loss:  16.75324058532715 0.8472173810005188
loss:  16.848596572875977 0.8236081004142761
loss:  16.936376571655273 0.8553961515426636
loss:  17.226612091064453 0.8521251678466797
loss:  17.342029571533203 0.8385727405548096
loss:  17.08721160888672 0.8560113906860352
loss:  16.692337036132812 0.8480197191238403
loss:  16.940793991088867 0.841665506362915
loss:  17.437353134155273 0.8545987606048584
loss:  17.092506408691406 0.846622109413147
loss:  17.17306900024414 0.8674913644790649
loss:  17.124460220336914 0.8805193305015564
loss:  16.917354583740234 0.8554806709289551
loss:  17.10698890686035 0.8653162121772766
loss:  17.087926864624023 0.8559726476669312
loss:  16.912235260009766 0.850770115852356
loss:  16.854066848754883 0.86388099193573
loss:  16.91643714904785 0.8451401591300964
loss:  16.83249282836914 0.8512716293334961
loss:  16.83152198791504 0.828039824962616
*******************Epoch 89 ****************** 1800 1.0
Validation Loss
*** pred loss:  28.51653480529785 pred acc: 0.5954105854034424
*** stop loss:  7.694089889526367 stop acc: 0.9212640523910522
*** template loss:  7.0370612144470215 template acc: tensor(0.1572, device='cuda:0')
*** label loss:  6.2312397956848145 label acc: tensor(0.4110, device='cuda:0')
Train Loss
---> pred loss: 13.410459899902344 pred acc: 0.7778336882591248
---> stop loss: 2.1713655471801756 stop acc: 0.9762983113527298
---> template loss: 0.34375734329223634 tempalte acc: 0.9344911575317383
---> molecule label loss: 0.22871103286743164 molecule acc: 0.9380789756774902
---> kl loss: 0.8513859748840332
---> reconstruction loss: 16.154294872283938
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-90-with.npy
loss:  17.23976707458496 0.8423410654067993
loss:  16.516206741333008 0.8495089411735535
loss:  17.09628677368164 0.853474497795105
loss:  17.01624870300293 0.8589863777160645
loss:  17.17913246154785 0.8525704145431519
loss:  17.133302688598633 0.8643249273300171
loss:  16.73930549621582 0.8895251154899597
loss:  17.212831497192383 0.8666688203811646
loss:  16.794160842895508 0.8754563927650452
loss:  17.058731079101562 0.8799102306365967
loss:  16.720542907714844 0.8605433106422424
loss:  16.879411697387695 0.8428908586502075
loss:  16.921039581298828 0.855817973613739
loss:  16.874208450317383 0.8471947908401489
loss:  16.77953338623047 0.8614222407341003
loss:  17.006202697753906 0.8572227954864502
loss:  16.86638832092285 0.8572446703910828
loss:  16.901865005493164 0.821668803691864
loss:  16.728042602539062 0.8581828474998474
loss:  16.485610961914062 0.9403057098388672
*******************Epoch 90 ****************** 1820 1.0
Validation Loss
*** pred loss:  28.67931365966797 pred acc: 0.5855675935745239
*** stop loss:  7.723382949829102 stop acc: 0.9213574528694153
*** template loss:  7.048879146575928 template acc: tensor(0.1527, device='cuda:0')
*** label loss:  6.24213981628418 label acc: tensor(0.4142, device='cuda:0')
Train Loss
---> pred loss: 13.430517578125 pred acc: 0.7769864231348038
---> stop loss: 2.116695785522461 stop acc: 0.9768574893474579
---> template loss: 0.3075042486190796 tempalte acc: 0.9429048538208008
---> molecule label loss: 0.19096052646636963 molecule acc: 0.9499047279357911
---> kl loss: 0.8617630004882812
---> reconstruction loss: 16.045677185058594
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-91-with.npy
loss:  16.571386337280273 0.8494819402694702
loss:  16.772003173828125 0.8139275312423706
loss:  16.678529739379883 0.8201040029525757
loss:  16.827957153320312 0.8389072418212891
loss:  16.740549087524414 0.8281353712081909
loss:  16.6876277923584 0.8250473737716675
loss:  16.905445098876953 0.8235758543014526
loss:  16.516159057617188 0.816396951675415
loss:  16.8131046295166 0.8113150000572205
loss:  17.027610778808594 0.8322125673294067
loss:  16.973310470581055 0.8365477323532104
loss:  16.82222557067871 0.8346736431121826
loss:  16.862995147705078 0.8605202436447144
loss:  16.468544006347656 0.8497084379196167
loss:  16.470321655273438 0.8408582806587219
loss:  16.727079391479492 0.8435851335525513
loss:  16.76981544494629 0.8576830625534058
loss:  16.41921615600586 0.8328365087509155
loss:  16.8082218170166 0.8368668556213379
loss:  17.02846336364746 0.8562377691268921
*******************Epoch 91 ****************** 1840 1.0
Validation Loss
*** pred loss:  28.524328231811523 pred acc: 0.5919685959815979
*** stop loss:  7.832030773162842 stop acc: 0.919925332069397
*** template loss:  7.062867164611816 template acc: tensor(0.1600, device='cuda:0')
*** label loss:  6.259205341339111 label acc: tensor(0.4118, device='cuda:0')
Train Loss
---> pred loss: 13.373651123046875 pred acc: 0.7771524518728257
---> stop loss: 2.1016101837158203 stop acc: 0.9772621273994446
---> template loss: 0.2715611457824707 tempalte acc: 0.9512161254882813
---> molecule label loss: 0.1622746229171753 molecule acc: 0.9584849357604981
---> kl loss: 0.8354310989379883
---> reconstruction loss: 15.909097099304198
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-92-with.npy
loss:  16.704395294189453 0.8352813124656677
loss:  16.33648681640625 0.821175754070282
loss:  16.73119354248047 0.8148214817047119
loss:  16.586606979370117 0.8217288851737976
loss:  16.818099975585938 0.8187700510025024
loss:  16.752113342285156 0.8107007741928101
loss:  16.70966911315918 0.8223997950553894
loss:  17.061187744140625 0.8302295804023743
loss:  16.73359489440918 0.8368403315544128
loss:  16.544126510620117 0.8069426417350769
loss:  16.379562377929688 0.8086974620819092
loss:  16.569456100463867 0.8114464282989502
loss:  16.345722198486328 0.8145579695701599
loss:  16.63443946838379 0.8138974905014038
loss:  16.887094497680664 0.7993881106376648
loss:  16.130786895751953 0.8097963929176331
loss:  16.534305572509766 0.8075016736984253
loss:  16.53692626953125 0.8048235774040222
loss:  17.057132720947266 0.8087323904037476
loss:  18.14496421813965 0.7868392467498779
*******************Epoch 92 ****************** 1860 1.0
Validation Loss
*** pred loss:  28.50872230529785 pred acc: 0.594021737575531
*** stop loss:  7.712134838104248 stop acc: 0.9242528080940247
*** template loss:  7.108176231384277 template acc: tensor(0.1576, device='cuda:0')
*** label loss:  6.34374475479126 label acc: tensor(0.4181, device='cuda:0')
Train Loss
---> pred loss: 13.357136535644532 pred acc: 0.7784116268157959
---> stop loss: 2.1428089141845703 stop acc: 0.9767822742462158
---> template loss: 0.2506566047668457 tempalte acc: 0.9573036193847656
---> molecule label loss: 0.14506211280822753 molecule acc: 0.9638264656066895
---> kl loss: 0.8142285346984863
---> reconstruction loss: 15.89566526412964
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-93-with.npy
loss:  16.453786849975586 0.83674156665802
loss:  16.58492088317871 0.8446106314659119
loss:  16.491497039794922 0.8491314649581909
loss:  16.336503982543945 0.8256955742835999
loss:  16.904064178466797 0.8727312088012695
loss:  16.597951889038086 0.8551198244094849
loss:  16.69762420654297 0.86346834897995
loss:  16.8762149810791 0.8378309011459351
loss:  16.533414840698242 0.8726323246955872
loss:  16.43438720703125 0.8391449451446533
loss:  16.474241256713867 0.8386908769607544
loss:  16.621402740478516 0.8458388447761536
loss:  16.448583602905273 0.8298373818397522
loss:  16.32293128967285 0.8341797590255737
loss:  16.819168090820312 0.8320940136909485
loss:  16.662813186645508 0.8160657286643982
loss:  16.686695098876953 0.8187779188156128
loss:  16.457382202148438 0.8057458400726318
loss:  16.46144676208496 0.8193651437759399
loss:  17.588783264160156 0.7296174764633179
*******************Epoch 93 ****************** 1880 1.0
Validation Loss
*** pred loss:  28.763973236083984 pred acc: 0.5880434513092041
*** stop loss:  8.141475677490234 stop acc: 0.922073483467102
*** template loss:  7.0737504959106445 template acc: tensor(0.1537, device='cuda:0')
*** label loss:  6.271094799041748 label acc: tensor(0.4101, device='cuda:0')
Train Loss
---> pred loss: 13.303807067871094 pred acc: 0.7799040138721466
---> stop loss: 2.1110647201538084 stop acc: 0.9769917756319046
---> template loss: 0.23885245323181153 tempalte acc: 0.9603375434875489
---> molecule label loss: 0.1356018900871277 molecule acc: 0.9675614356994628
---> kl loss: 0.8333660125732422
---> reconstruction loss: 15.789326858520509
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-94-with.npy
loss:  16.61020851135254 0.800500750541687
loss:  16.42635726928711 0.8095226287841797
loss:  16.538677215576172 0.8439432382583618
loss:  17.151575088500977 0.8492071032524109
loss:  16.4654541015625 0.8334225416183472
loss:  16.917482376098633 0.8495864272117615
loss:  16.995363235473633 0.8553649187088013
loss:  16.334016799926758 0.8300156593322754
loss:  16.79615020751953 0.8350748419761658
loss:  16.630342483520508 0.8403977751731873
loss:  16.511232376098633 0.8249154090881348
loss:  16.799856185913086 0.8442153334617615
loss:  16.508586883544922 0.8229566216468811
loss:  16.66141700744629 0.8329290151596069
loss:  16.600261688232422 0.8329719305038452
loss:  16.477893829345703 0.8255792856216431
loss:  16.722740173339844 0.8327116370201111
loss:  16.640975952148438 0.8364662528038025
loss:  16.531389236450195 0.84885174036026
loss:  16.36290740966797 0.840735137462616
*******************Epoch 94 ****************** 1900 1.0
Validation Loss
*** pred loss:  28.68938636779785 pred acc: 0.5942632555961609
*** stop loss:  7.8650803565979 stop acc: 0.9221980571746826
*** template loss:  7.065840244293213 template acc: tensor(0.1618, device='cuda:0')
*** label loss:  6.380937099456787 label acc: tensor(0.4140, device='cuda:0')
Train Loss
---> pred loss: 13.230813598632812 pred acc: 0.7791427373886108
---> stop loss: 2.191229820251465 stop acc: 0.975868684053421
---> template loss: 0.23662230968475342 tempalte acc: 0.9599434852600097
---> molecule label loss: 0.1410093903541565 molecule acc: 0.9665329933166504
---> kl loss: 0.8344683647155762
---> reconstruction loss: 15.799679279327393
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-95-with.npy
loss:  16.358888626098633 0.8551937937736511
loss:  16.617862701416016 0.8345102071762085
loss:  16.58712387084961 0.8447668552398682
loss:  16.623626708984375 0.8173325657844543
loss:  16.570316314697266 0.8321208953857422
loss:  16.623308181762695 0.816304624080658
loss:  16.15867042541504 0.8061859607696533
loss:  16.700326919555664 0.821074903011322
loss:  16.587562561035156 0.830937385559082
loss:  16.433069229125977 0.8157592415809631
loss:  16.531356811523438 0.8185752034187317
loss:  16.528974533081055 0.8252885341644287
loss:  16.226091384887695 0.8237122893333435
loss:  16.0645694732666 0.8203015327453613
loss:  16.497642517089844 0.8194849491119385
loss:  16.58058738708496 0.7906254529953003
loss:  16.39073371887207 0.8152824640274048
loss:  16.83757209777832 0.8018000721931458
loss:  16.440330505371094 0.8000469207763672
loss:  16.637977600097656 0.7647590637207031
*******************Epoch 95 ****************** 1920 1.0
Validation Loss
*** pred loss:  29.450740814208984 pred acc: 0.595772922039032
*** stop loss:  7.961212158203125 stop acc: 0.9222602844238281
*** template loss:  7.145654678344727 template acc: tensor(0.1551, device='cuda:0')
*** label loss:  6.371469020843506 label acc: tensor(0.4125, device='cuda:0')
Train Loss
---> pred loss: 13.172125244140625 pred acc: 0.7804845750331879
---> stop loss: 2.1377386093139648 stop acc: 0.9766594707965851
---> template loss: 0.2319941282272339 tempalte acc: 0.962366771697998
---> molecule label loss: 0.14026799201965331 molecule acc: 0.9666428565979004
---> kl loss: 0.8177030563354493
---> reconstruction loss: 15.682127571105955
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-96-with.npy
loss:  16.662784576416016 0.8252264261245728
loss:  16.24517822265625 0.8273298144340515
loss:  16.685522079467773 0.8470203280448914
loss:  16.73714256286621 0.8326322436332703
loss:  16.695043563842773 0.8379148840904236
loss:  16.657773971557617 0.8297833204269409
loss:  16.42378044128418 0.8321011066436768
loss:  16.351686477661133 0.8190527558326721
loss:  16.624174118041992 0.8333075642585754
loss:  16.203014373779297 0.8367364406585693
loss:  16.806880950927734 0.8413037657737732
loss:  16.248279571533203 0.8278238773345947
loss:  16.403657913208008 0.8233710527420044
loss:  16.29604148864746 0.8091537952423096
loss:  16.245805740356445 0.8073456287384033
loss:  16.420242309570312 0.7988312244415283
loss:  16.527057647705078 0.811407208442688
loss:  16.37944793701172 0.8158180117607117
loss:  16.073501586914062 0.7863559722900391
loss:  16.54681968688965 0.8119210600852966
*******************Epoch 96 ****************** 1940 1.0
Validation Loss
*** pred loss:  29.024057388305664 pred acc: 0.5942632555961609
*** stop loss:  7.995945930480957 stop acc: 0.9205791354179382
*** template loss:  7.14735221862793 template acc: tensor(0.1643, device='cuda:0')
*** label loss:  6.301419258117676 label acc: tensor(0.4086, device='cuda:0')
Train Loss
---> pred loss: 13.21553955078125 pred acc: 0.779507777094841
---> stop loss: 2.0543228149414063 stop acc: 0.977616673707962
---> template loss: 0.23119511604309081 tempalte acc: 0.9612144470214844
---> molecule label loss: 0.1379122853279114 molecule acc: 0.9688652992248535
---> kl loss: 0.8227217674255372
---> reconstruction loss: 15.638972568511964
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-97-with.npy
loss:  16.022417068481445 0.808260440826416
loss:  16.14263916015625 0.8047158122062683
loss:  16.128400802612305 0.8088028430938721
loss:  16.508438110351562 0.8206757307052612
loss:  16.373971939086914 0.7906947731971741
loss:  16.238597869873047 0.7927364706993103
loss:  16.432565689086914 0.8145371079444885
loss:  16.566993713378906 0.804640531539917
loss:  16.201107025146484 0.8155443072319031
loss:  16.16875648498535 0.8272429704666138
loss:  16.340421676635742 0.8209745287895203
loss:  16.242244720458984 0.8235438466072083
loss:  16.49260139465332 0.8206000924110413
loss:  16.189544677734375 0.823906421661377
loss:  16.121789932250977 0.8255152702331543
loss:  16.082534790039062 0.8204153180122375
loss:  16.476211547851562 0.8189725279808044
loss:  16.35303497314453 0.845432460308075
loss:  16.450532913208008 0.8224802613258362
loss:  16.530534744262695 0.8262211680412292
*******************Epoch 97 ****************** 1960 1.0
Validation Loss
*** pred loss:  28.95276641845703 pred acc: 0.5919082164764404
*** stop loss:  8.013087272644043 stop acc: 0.9212640523910522
*** template loss:  7.13820219039917 template acc: tensor(0.1607, device='cuda:0')
*** label loss:  6.3757548332214355 label acc: tensor(0.4157, device='cuda:0')
Train Loss
---> pred loss: 13.107713317871093 pred acc: 0.7807834416627883
---> stop loss: 2.033883476257324 stop acc: 0.9780720174312592
---> template loss: 0.21706070899963378 tempalte acc: 0.9657814979553223
---> molecule label loss: 0.12771356105804443 molecule acc: 0.9706242561340332
---> kl loss: 0.8167956352233887
---> reconstruction loss: 15.486372089385984
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-98-with.npy
loss:  15.923172950744629 0.813159167766571
loss:  16.229705810546875 0.8062688112258911
loss:  16.249914169311523 0.8116719722747803
loss:  16.106586456298828 0.7776978611946106
loss:  16.261343002319336 0.8050382137298584
loss:  16.041257858276367 0.7863804697990417
loss:  16.37761116027832 0.797076404094696
loss:  16.534847259521484 0.7800590395927429
loss:  16.2796573638916 0.7876678109169006
loss:  16.072072982788086 0.7983811497688293
loss:  16.06829261779785 0.818591296672821
loss:  16.215538024902344 0.8168923854827881
loss:  15.943741798400879 0.825576901435852
loss:  16.02582550048828 0.8008823990821838
loss:  16.277606964111328 0.8034534454345703
loss:  16.228967666625977 0.8060604929924011
loss:  16.05780029296875 0.7994142174720764
loss:  16.171335220336914 0.8006196022033691
loss:  15.929018020629883 0.8255382180213928
loss:  15.607742309570312 0.8269718289375305
*******************Epoch 98 ****************** 1980 1.0
Validation Loss
*** pred loss:  29.55793571472168 pred acc: 0.5820048451423645
*** stop loss:  7.931552410125732 stop acc: 0.9227584600448608
*** template loss:  7.133320331573486 template acc: tensor(0.1625, device='cuda:0')
*** label loss:  6.390270709991455 label acc: tensor(0.4118, device='cuda:0')
Train Loss
---> pred loss: 12.955343627929688 pred acc: 0.7844557434320449
---> stop loss: 2.033249855041504 stop acc: 0.9779849290847779
---> template loss: 0.2106112003326416 tempalte acc: 0.9670143127441406
---> molecule label loss: 0.12652658224105834 molecule acc: 0.9709535598754883
---> kl loss: 0.8043701171875
---> reconstruction loss: 15.325732421875
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-99-with.npy
loss:  16.034181594848633 0.8109201192855835
loss:  15.76542854309082 0.8275691270828247
loss:  16.046890258789062 0.8275295495986938
loss:  16.283536911010742 0.8242084980010986
loss:  16.547542572021484 0.8223348259925842
loss:  16.117637634277344 0.8297553658485413
loss:  15.959542274475098 0.873428463935852
loss:  16.02826499938965 0.8686707019805908
loss:  15.987410545349121 0.8385409116744995
loss:  16.01697540283203 0.8408674597740173
loss:  16.15091323852539 0.8641484975814819
loss:  16.222497940063477 0.8640104532241821
loss:  16.12668228149414 0.8241822719573975
loss:  16.036327362060547 0.8501525521278381
loss:  16.015836715698242 0.8477667570114136
loss:  15.86811637878418 0.8416467308998108
loss:  16.127094268798828 0.8317362070083618
loss:  16.091459274291992 0.8270882368087769
loss:  15.958202362060547 0.8273037672042847
loss:  14.794157028198242 0.8192809820175171
*******************Epoch 99 ****************** 2000 1.0
Validation Loss
*** pred loss:  29.130462646484375 pred acc: 0.5911835432052612
*** stop loss:  7.964653015136719 stop acc: 0.9232565760612488
*** template loss:  7.153298854827881 template acc: tensor(0.1597, device='cuda:0')
*** label loss:  6.404390811920166 label acc: tensor(0.4104, device='cuda:0')
Train Loss
---> pred loss: 12.879779052734374 pred acc: 0.7837937980890274
---> stop loss: 1.97030029296875 stop acc: 0.9785587519407273
---> template loss: 0.20010223388671874 tempalte acc: 0.9697749137878418
---> molecule label loss: 0.1206969141960144 molecule acc: 0.9724669456481934
---> kl loss: 0.8380571365356445
---> reconstruction loss: 15.170878410339357
saving file:weights/hidden_size_300_latent_size_100_depth_2_beta_1.0_lr_0.001/bvae_iter-100-with.npy
