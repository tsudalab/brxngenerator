cuda is  True
loading data.....
size of reactant dic: 9766
size of template dic: 5567
size of fgm_trees: 20080
size of rxn_trees: 20080
size of fragment dic: 273
hidden size: 200 latent_size: 100 batch size: 1000 depth: 3
beta: 1.0 lr: 0.001
size of data pairs: 20080
trainng size: 19079
valid size: 1000
loss:  147.48251342773438 1.4688076972961426
loss:  141.2455596923828 1.980635404586792
loss:  134.24623107910156 3.4541432857513428
loss:  130.4224853515625 6.179827690124512
loss:  122.27432250976562 10.946218490600586
loss:  115.59813690185547 18.225570678710938
loss:  105.7229232788086 28.381271362304688
loss:  99.3897476196289 32.31342315673828
loss:  93.62712860107422 32.90837097167969
loss:  90.66022491455078 31.926048278808594
loss:  85.90263366699219 30.891786575317383
loss:  80.94723510742188 30.126232147216797
loss:  79.44904327392578 30.0008544921875
loss:  78.08879089355469 30.096832275390625
loss:  77.91798400878906 30.585445404052734
loss:  77.06303405761719 30.45124053955078
loss:  76.80193328857422 30.870309829711914
loss:  75.40196990966797 30.901153564453125
loss:  74.88772583007812 30.99258804321289
loss:  70.6784439086914 30.516132354736328
*******************Epoch 0 ****************** 20 0.00095
Validation Loss
*** pred loss:  42.27817916870117 pred acc: 0.34673911333084106
*** stop loss:  11.782923698425293 stop acc: 0.8298256993293762
*** template loss:  8.59515380859375 template acc: tensor(0.0281, device='cuda:0')
*** label loss:  6.5100250244140625 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 66.60787353515624 pred acc: 0.25619524388603165
---> stop loss: 16.718992614746092 stop acc: 0.7626473888754844
---> template loss: 7.822998809814453 tempalte acc: 0.01746799498796463
---> molecule label loss: 6.726673126220703 molecule acc: 0.3636336803436279
---> kl loss: 23.660845947265624
---> reconstruction loss: 97.86792136627197
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-1-with.npy
loss:  71.89362335205078 30.664775848388672
loss:  71.82037353515625 30.18479347229004
loss:  71.20227813720703 29.715045928955078
loss:  70.40210723876953 29.905128479003906
loss:  70.29415130615234 29.635683059692383
loss:  69.15451049804688 29.581235885620117
loss:  67.94222259521484 29.497360229492188
loss:  67.17301177978516 29.17322540283203
loss:  67.72396850585938 29.31119155883789
loss:  67.34547424316406 29.112422943115234
loss:  66.61942291259766 29.19613265991211
loss:  66.0079116821289 29.100666046142578
loss:  67.11711883544922 29.622297286987305
loss:  65.6189193725586 29.435487747192383
loss:  64.7057876586914 29.637104034423828
loss:  63.9221305847168 30.15877914428711
loss:  63.77124786376953 30.225786209106445
loss:  62.816078186035156 30.42711639404297
loss:  63.259010314941406 30.54911994934082
loss:  64.81269073486328 31.74053382873535
*******************Epoch 1 ****************** 40 0.0019500000000000001
Validation Loss
*** pred loss:  36.75804138183594 pred acc: 0.3925120532512665
*** stop loss:  9.840446472167969 stop acc: 0.8605542182922363
*** template loss:  8.500407218933105 template acc: tensor(0.0426, device='cuda:0')
*** label loss:  6.340414524078369 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 43.468316650390626 pred acc: 0.34333230555057526
---> stop loss: 10.807342529296875 stop acc: 0.8690548866987229
---> template loss: 7.250665283203125 tempalte acc: 0.03858254849910736
---> molecule label loss: 5.609695816040039 molecule acc: 0.3831813097000122
---> kl loss: 29.84369812011719
---> reconstruction loss: 67.12190732772828
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-2-with.npy
loss:  62.37855911254883 30.611331939697266
loss:  62.215877532958984 30.23240852355957
loss:  60.93534851074219 30.746904373168945
loss:  60.93807601928711 30.5235595703125
loss:  60.967750549316406 30.825626373291016
loss:  60.79629898071289 31.15575408935547
loss:  60.18643569946289 31.335968017578125
loss:  59.61060333251953 31.46754264831543
loss:  59.139652252197266 31.700328826904297
loss:  58.866783142089844 32.510528564453125
loss:  57.418766021728516 32.719112396240234
loss:  58.50328063964844 32.94129943847656
loss:  57.2750129699707 33.1031608581543
loss:  57.94807434082031 33.911224365234375
loss:  56.97523498535156 34.05195617675781
loss:  57.125125885009766 34.38683319091797
loss:  56.43844985961914 34.40399932861328
loss:  56.62794494628906 35.302650451660156
loss:  55.88908004760742 34.98744201660156
loss:  55.810447692871094 35.904605865478516
*******************Epoch 2 ****************** 60 0.00295
Validation Loss
*** pred loss:  33.12782669067383 pred acc: 0.45615941286087036
*** stop loss:  8.249476432800293 stop acc: 0.8876712918281555
*** template loss:  8.351000785827637 template acc: tensor(0.0594, device='cuda:0')
*** label loss:  6.2576680183410645 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 37.7741455078125 pred acc: 0.41777504831552503
---> stop loss: 8.768387603759766 stop acc: 0.8959827214479447
---> template loss: 6.682006072998047 tempalte acc: 0.06757500767707825
---> molecule label loss: 5.496517944335937 molecule acc: 0.3820692777633667
---> kl loss: 32.64111328125
---> reconstruction loss: 58.70604636230469
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-3-with.npy
loss:  54.967220306396484 35.72980499267578
loss:  55.55446243286133 35.89521026611328
loss:  55.275062561035156 35.027870178222656
loss:  54.79806900024414 36.068504333496094
loss:  53.79867172241211 35.499088287353516
loss:  54.327598571777344 36.27873992919922
loss:  53.955623626708984 36.119407653808594
loss:  53.841163635253906 35.988407135009766
loss:  53.48249816894531 36.53611755371094
loss:  53.501441955566406 37.07899475097656
loss:  52.24415969848633 37.13408279418945
loss:  51.7234001159668 36.52548599243164
loss:  52.04026794433594 36.809661865234375
loss:  51.1738395690918 37.67909622192383
loss:  51.15913009643555 38.39202117919922
loss:  50.97195053100586 37.58129119873047
loss:  51.10625076293945 37.19792175292969
loss:  50.56166076660156 37.744476318359375
loss:  51.128700256347656 37.524417877197266
loss:  49.97328186035156 37.358917236328125
*******************Epoch 3 ****************** 80 0.00395
Validation Loss
*** pred loss:  30.471982955932617 pred acc: 0.5001207590103149
*** stop loss:  7.702064037322998 stop acc: 0.8895081281661987
*** template loss:  8.220142364501953 template acc: tensor(0.0735, device='cuda:0')
*** label loss:  6.138364315032959 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 33.746463012695315 pred acc: 0.47692499607801436
---> stop loss: 7.610372924804688 stop acc: 0.9092524081468583
---> template loss: 6.004853439331055 tempalte acc: 0.11825670003890991
---> molecule label loss: 5.289757919311524 molecule acc: 0.38321986198425295
---> kl loss: 36.7084716796875
---> reconstruction loss: 52.634225169677734
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-4-with.npy
loss:  49.84467315673828 37.43843078613281
loss:  49.9163932800293 37.210693359375
loss:  49.446197509765625 36.515968322753906
loss:  49.15914535522461 37.065086364746094
loss:  49.05921936035156 37.020103454589844
loss:  49.09353256225586 37.27351760864258
loss:  49.40023422241211 37.4578742980957
loss:  49.019134521484375 37.308448791503906
loss:  48.97785186767578 37.450103759765625
loss:  48.33203125 38.174835205078125
loss:  48.7848014831543 37.966556549072266
loss:  48.36839294433594 37.30486297607422
loss:  48.16400909423828 37.16899108886719
loss:  47.17460632324219 36.99922561645508
loss:  47.60017013549805 36.26951599121094
loss:  47.47626876831055 36.374961853027344
loss:  46.85652160644531 36.611671447753906
loss:  46.97975540161133 36.82946014404297
loss:  46.956932067871094 37.402610778808594
loss:  46.74378204345703 36.283905029296875
*******************Epoch 4 ****************** 100 0.0049499999999999995
Validation Loss
*** pred loss:  28.72489356994629 pred acc: 0.535990297794342
*** stop loss:  6.9674859046936035 stop acc: 0.9029576778411865
*** template loss:  8.051008224487305 template acc: tensor(0.0883, device='cuda:0')
*** label loss:  6.084454536437988 label acc: tensor(0.3472, device='cuda:0')
Train Loss
---> pred loss: 30.903054809570314 pred acc: 0.5209072411060334
---> stop loss: 6.918414306640625 stop acc: 0.9178295195102691
---> template loss: 5.36706771850586 tempalte acc: 0.16678656339645387
---> molecule label loss: 5.01314697265625 molecule acc: 0.3831794261932373
---> kl loss: 37.10634155273438
---> reconstruction loss: 48.18400244232178
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-5-with.npy
loss:  45.85343933105469 36.30640411376953
loss:  45.63032531738281 36.97808837890625
loss:  45.876224517822266 36.8547477722168
loss:  45.72864532470703 36.907257080078125
loss:  45.579593658447266 37.36536407470703
loss:  45.710758209228516 36.571773529052734
loss:  45.533790588378906 36.864646911621094
loss:  45.43719482421875 37.677642822265625
loss:  45.234535217285156 37.07896423339844
loss:  44.845680236816406 36.97954559326172
loss:  45.22941970825195 37.78107452392578
loss:  44.754852294921875 37.22100830078125
loss:  44.53254699707031 36.85124969482422
loss:  44.84779357910156 36.681793212890625
loss:  43.92644119262695 36.38728713989258
loss:  44.16441345214844 37.03811264038086
loss:  43.534767150878906 36.712158203125
loss:  43.97089767456055 36.3084716796875
loss:  43.77065658569336 37.147674560546875
loss:  44.922828674316406 38.51754379272461
*******************Epoch 5 ****************** 120 0.0059499999999999996
Validation Loss
*** pred loss:  27.216651916503906 pred acc: 0.5589975714683533
*** stop loss:  7.346737384796143 stop acc: 0.8950809836387634
*** template loss:  7.880052089691162 template acc: tensor(0.1020, device='cuda:0')
*** label loss:  6.060739040374756 label acc: tensor(0.3494, device='cuda:0')
Train Loss
---> pred loss: 28.933978271484374 pred acc: 0.5606584817171096
---> stop loss: 6.410433197021485 stop acc: 0.9246767163276672
---> template loss: 4.715073776245117 tempalte acc: 0.22402877807617189
---> molecule label loss: 4.69207992553711 molecule acc: 0.3869903326034546
---> kl loss: 37.011538696289065
---> reconstruction loss: 44.734020236358646
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-6-with.npy
loss:  43.995784759521484 37.41510772705078
loss:  43.846683502197266 36.73759078979492
loss:  42.69590377807617 37.59233093261719
loss:  42.300559997558594 38.30314636230469
loss:  43.02335739135742 38.0198974609375
loss:  42.31780242919922 38.19982147216797
loss:  42.1491813659668 38.33625793457031
loss:  42.26716613769531 38.467430114746094
loss:  42.05788040161133 37.86354064941406
loss:  42.87821578979492 38.384178161621094
loss:  41.95537567138672 37.76466369628906
loss:  41.87570571899414 37.5555534362793
loss:  42.0317268371582 38.2559814453125
loss:  41.62687683105469 38.25066375732422
loss:  42.127220153808594 38.13328552246094
loss:  42.10358428955078 38.590003967285156
loss:  41.789093017578125 38.67097854614258
loss:  41.32193374633789 37.881561279296875
loss:  40.98992156982422 38.81678009033203
loss:  40.209651947021484 38.47877883911133
*******************Epoch 6 ****************** 140 0.00695
Validation Loss
*** pred loss:  26.129119873046875 pred acc: 0.5730072259902954
*** stop loss:  6.390391826629639 stop acc: 0.9137609601020813
*** template loss:  7.663522720336914 template acc: tensor(0.1175, device='cuda:0')
*** label loss:  6.058787822723389 label acc: tensor(0.3479, device='cuda:0')
Train Loss
---> pred loss: 27.248675537109374 pred acc: 0.5796083986759186
---> stop loss: 6.115620422363281 stop acc: 0.927907058596611
---> template loss: 4.156047058105469 tempalte acc: 0.28701460361480713
---> molecule label loss: 4.411149597167968 molecule acc: 0.39140944480895995
---> kl loss: 38.08587646484375
---> reconstruction loss: 41.91348614196777
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-7-with.npy
loss:  40.73271179199219 39.048492431640625
loss:  40.33810043334961 38.94064712524414
loss:  40.345760345458984 39.15245819091797
loss:  40.09537124633789 39.105533599853516
loss:  40.35298156738281 39.46822738647461
loss:  40.51646041870117 39.52632141113281
loss:  40.201622009277344 39.26934051513672
loss:  40.75057601928711 39.55152130126953
loss:  40.25701904296875 39.53874206542969
loss:  39.748165130615234 38.96131134033203
loss:  40.014190673828125 38.80931091308594
loss:  39.98878860473633 39.50092315673828
loss:  39.829689025878906 39.292022705078125
loss:  39.584110260009766 39.4680061340332
loss:  39.423648834228516 39.26982116699219
loss:  39.5247688293457 39.41830062866211
loss:  39.13507080078125 39.94305419921875
loss:  39.73826217651367 40.057716369628906
loss:  39.273658752441406 40.58062744140625
loss:  37.79488754272461 38.72343444824219
*******************Epoch 7 ****************** 160 0.00795
Validation Loss
*** pred loss:  25.139949798583984 pred acc: 0.5948671102523804
*** stop loss:  6.095958709716797 stop acc: 0.9163761138916016
*** template loss:  7.544588565826416 template acc: tensor(0.1245, device='cuda:0')
*** label loss:  6.029466152191162 label acc: tensor(0.3492, device='cuda:0')
Train Loss
---> pred loss: 25.932012939453124 pred acc: 0.600241756439209
---> stop loss: 5.8162384033203125 stop acc: 0.931340092420578
---> template loss: 3.687551498413086 tempalte acc: 0.3454369068145752
---> molecule label loss: 4.152066040039062 molecule acc: 0.3982566833496094
---> kl loss: 39.381289672851565
---> reconstruction loss: 39.56921244827271
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-8-with.npy
loss:  38.59421920776367 39.92177200317383
loss:  39.09440231323242 40.38546371459961
loss:  38.51123809814453 40.96044921875
loss:  38.743431091308594 39.99505615234375
loss:  38.041351318359375 40.292396545410156
loss:  38.44231414794922 40.54719543457031
loss:  38.27175521850586 40.66967010498047
loss:  37.79886245727539 41.01905059814453
loss:  37.65145492553711 40.52638244628906
loss:  37.69758224487305 40.78458023071289
loss:  37.793846130371094 41.23102569580078
loss:  37.93513488769531 41.0931396484375
loss:  38.13493728637695 41.07590866088867
loss:  37.94413757324219 40.889320373535156
loss:  37.92403793334961 41.52719497680664
loss:  37.53324508666992 41.13848114013672
loss:  37.57229232788086 41.36042785644531
loss:  37.45447540283203 41.562705993652344
loss:  37.32831954956055 41.265018463134766
loss:  40.44190216064453 40.529720306396484
*******************Epoch 8 ****************** 180 0.00895
Validation Loss
*** pred loss:  24.279224395751953 pred acc: 0.6106883883476257
*** stop loss:  6.5228962898254395 stop acc: 0.9082815051078796
*** template loss:  7.480345726013184 template acc: tensor(0.1396, device='cuda:0')
*** label loss:  6.030714988708496 label acc: tensor(0.3485, device='cuda:0')
Train Loss
---> pred loss: 25.01122589111328 pred acc: 0.6153580546379089
---> stop loss: 5.635452651977539 stop acc: 0.9338531851768493
---> template loss: 3.278017044067383 tempalte acc: 0.39976260662078855
---> molecule label loss: 3.8745494842529298 molecule acc: 0.4132078170776367
---> kl loss: 40.838748168945315
---> reconstruction loss: 37.77993998123169
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-9-with.npy
loss:  37.105560302734375 41.58540344238281
loss:  36.73564910888672 41.61258316040039
loss:  36.77864456176758 41.29846954345703
loss:  37.42049789428711 41.64967727661133
loss:  37.120296478271484 41.70726013183594
loss:  37.23377227783203 41.4642448425293
loss:  36.46980667114258 41.72739028930664
loss:  36.68363952636719 41.692909240722656
loss:  36.40094757080078 41.53191375732422
loss:  36.32176208496094 41.305137634277344
loss:  36.84015655517578 42.292747497558594
loss:  35.98442840576172 42.17510986328125
loss:  35.98427963256836 41.68772888183594
loss:  35.45418167114258 41.963356018066406
loss:  36.350460052490234 41.91307830810547
loss:  36.655311584472656 41.88975524902344
loss:  35.86845779418945 42.162445068359375
loss:  35.174049377441406 41.783477783203125
loss:  35.81305694580078 42.16523742675781
loss:  37.90365219116211 40.9471549987793
*******************Epoch 9 ****************** 200 0.00995
Validation Loss
*** pred loss:  23.768138885498047 pred acc: 0.6217995285987854
*** stop loss:  6.233043193817139 stop acc: 0.9141033887863159
*** template loss:  7.334469318389893 template acc: tensor(0.1512, device='cuda:0')
*** label loss:  6.008645057678223 label acc: tensor(0.3504, device='cuda:0')
Train Loss
---> pred loss: 24.050718688964842 pred acc: 0.6282676994800568
---> stop loss: 5.441127014160156 stop acc: 0.9360242366790772
---> template loss: 2.9691694259643553 tempalte acc: 0.4438908100128174
---> molecule label loss: 3.6585163116455077 molecule acc: 0.4233048915863037
---> kl loss: 41.72775573730469
---> reconstruction loss: 36.09974413314819
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-10-with.npy
loss:  35.3815803527832 41.46028137207031
loss:  35.58790969848633 42.14378356933594
loss:  35.33720779418945 41.7150993347168
loss:  35.44276809692383 42.17989730834961
loss:  34.662017822265625 42.53871154785156
loss:  35.297630310058594 42.25638961791992
loss:  34.97279739379883 42.26241683959961
loss:  34.69243621826172 41.96942138671875
loss:  35.386905670166016 42.279632568359375
loss:  35.02423095703125 42.388694763183594
loss:  34.806251525878906 42.19328308105469
loss:  34.63545608520508 42.462459564208984
loss:  35.241275787353516 42.69305419921875
loss:  34.72472381591797 42.78180694580078
loss:  34.81277847290039 42.6927490234375
loss:  35.006107330322266 42.749908447265625
loss:  34.2160530090332 42.644493103027344
loss:  34.70915985107422 42.55730438232422
loss:  34.511688232421875 42.003684997558594
loss:  34.81215286254883 43.052452087402344
*******************Epoch 10 ****************** 220 0.01095
Validation Loss
*** pred loss:  23.305034637451172 pred acc: 0.6254227161407471
*** stop loss:  5.725265979766846 stop acc: 0.9218244552612305
*** template loss:  7.196399211883545 template acc: tensor(0.1636, device='cuda:0')
*** label loss:  5.985479354858398 label acc: tensor(0.3485, device='cuda:0')
Train Loss
---> pred loss: 23.18173828125 pred acc: 0.6392218500375748
---> stop loss: 5.217474746704101 stop acc: 0.9396996021270752
---> template loss: 2.6790950775146483 tempalte acc: 0.48851923942565917
---> molecule label loss: 3.4410400390625 molecule acc: 0.4390730381011963
---> kl loss: 42.35127258300781
---> reconstruction loss: 34.49930898513794
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-11-with.npy
loss:  34.35837936401367 42.527198791503906
loss:  34.3166389465332 42.79278564453125
loss:  33.33729934692383 43.02753448486328
loss:  33.86228942871094 42.836463928222656
loss:  33.847930908203125 42.64203643798828
loss:  33.879058837890625 42.63832473754883
loss:  33.54249572753906 42.25468444824219
loss:  33.67021942138672 42.605560302734375
loss:  33.65267562866211 42.68208312988281
loss:  33.684326171875 42.78862762451172
loss:  33.153839111328125 42.3577995300293
loss:  33.29225158691406 42.720542907714844
loss:  33.41600799560547 42.741920471191406
loss:  33.625545501708984 43.008487701416016
loss:  33.426422119140625 42.80377960205078
loss:  33.492889404296875 42.655967712402344
loss:  33.288482666015625 42.72664260864258
loss:  33.76616287231445 42.79608154296875
loss:  33.34988784790039 42.50439453125
loss:  32.85131072998047 41.956661224365234
*******************Epoch 11 ****************** 240 0.01195
Validation Loss
*** pred loss:  22.735200881958008 pred acc: 0.637077271938324
*** stop loss:  5.602625370025635 stop acc: 0.9242528080940247
*** template loss:  7.133516788482666 template acc: tensor(0.1685, device='cuda:0')
*** label loss:  5.989489555358887 label acc: tensor(0.3515, device='cuda:0')
Train Loss
---> pred loss: 22.399488830566405 pred acc: 0.6522889494895935
---> stop loss: 4.988354873657227 stop acc: 0.9419592559337616
---> template loss: 2.461671257019043 tempalte acc: 0.5219541549682617
---> molecule label loss: 3.2517601013183595 molecule acc: 0.4537031650543213
---> kl loss: 42.653378295898435
---> reconstruction loss: 33.08100257858276
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-12-with.npy
loss:  33.015724182128906 42.804847717285156
loss:  32.465667724609375 42.5955924987793
loss:  33.17013931274414 42.74308776855469
loss:  32.513545989990234 42.755767822265625
loss:  32.63507843017578 43.02347946166992
loss:  32.80900955200195 43.194976806640625
loss:  32.769996643066406 42.84169387817383
loss:  32.79014587402344 43.08708190917969
loss:  32.280887603759766 43.12012481689453
loss:  33.02714920043945 43.35917282104492
loss:  32.09124755859375 43.10259246826172
loss:  32.868953704833984 43.06009292602539
loss:  32.99041748046875 43.14310836791992
loss:  32.51283645629883 43.223777770996094
loss:  32.42753219604492 43.18524932861328
loss:  32.07918930053711 43.09783172607422
loss:  32.266998291015625 42.73696517944336
loss:  31.509458541870117 43.080360412597656
loss:  32.01091384887695 43.31297302246094
loss:  30.766246795654297 42.86914825439453
*******************Epoch 12 ****************** 260 0.01295
Validation Loss
*** pred loss:  22.339845657348633 pred acc: 0.639794647693634
*** stop loss:  5.690773010253906 stop acc: 0.924408495426178
*** template loss:  7.080925464630127 template acc: tensor(0.1748, device='cuda:0')
*** label loss:  5.963135242462158 label acc: tensor(0.3539, device='cuda:0')
Train Loss
---> pred loss: 21.661317443847658 pred acc: 0.661504653096199
---> stop loss: 4.843770599365234 stop acc: 0.9441782802343368
---> template loss: 2.299055480957031 tempalte acc: 0.5482868671417236
---> molecule label loss: 3.109248161315918 molecule acc: 0.4663981914520264
---> kl loss: 43.01689453125
---> reconstruction loss: 31.892986147460935
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-13-with.npy
loss:  31.977113723754883 43.12791061401367
loss:  32.57645797729492 43.59684753417969
loss:  31.80844497680664 43.230438232421875
loss:  31.175113677978516 43.3358154296875
loss:  31.70705223083496 43.53973388671875
loss:  31.29759407043457 43.490875244140625
loss:  31.548059463500977 44.04667663574219
loss:  31.126008987426758 43.21147918701172
loss:  31.85370445251465 43.532676696777344
loss:  30.916868209838867 43.56599044799805
loss:  31.830150604248047 43.32501220703125
loss:  31.359628677368164 43.24898910522461
loss:  31.682300567626953 43.29850769042969
loss:  31.311410903930664 43.84600067138672
loss:  31.443126678466797 43.849266052246094
loss:  30.94474220275879 43.92192840576172
loss:  31.605066299438477 43.59313201904297
loss:  31.328262329101562 43.62334442138672
loss:  30.79827117919922 43.62505340576172
loss:  30.639421463012695 42.899169921875
*******************Epoch 13 ****************** 280 0.01395
Validation Loss
*** pred loss:  21.807531356811523 pred acc: 0.6519927382469177
*** stop loss:  5.520811557769775 stop acc: 0.9257161021232605
*** template loss:  7.056487560272217 template acc: tensor(0.1854, device='cuda:0')
*** label loss:  5.989186763763428 label acc: tensor(0.3554, device='cuda:0')
Train Loss
---> pred loss: 21.022665405273436 pred acc: 0.6699526339769364
---> stop loss: 4.7795055389404295 stop acc: 0.9446615070104599
---> template loss: 2.1259593963623047 tempalte acc: 0.5761735439300537
---> molecule label loss: 2.9321962356567384 molecule acc: 0.485977840423584
---> kl loss: 43.495443725585936
---> reconstruction loss: 30.83967410690308
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-14-with.npy
loss:  30.370361328125 43.708412170410156
loss:  31.08789825439453 43.50904846191406
loss:  31.085086822509766 43.814945220947266
loss:  30.907711029052734 43.975685119628906
loss:  30.44518280029297 43.3248176574707
loss:  30.55754852294922 43.68646240234375
loss:  31.094141006469727 43.65576934814453
loss:  30.81179428100586 43.34950256347656
loss:  30.591493606567383 43.20824432373047
loss:  30.54139518737793 43.33003234863281
loss:  30.114887237548828 43.30171203613281
loss:  30.381784439086914 43.39360046386719
loss:  30.517423629760742 43.62260437011719
loss:  30.37848663330078 43.62330627441406
loss:  30.17022132873535 43.290374755859375
loss:  30.728240966796875 43.875213623046875
loss:  30.061969757080078 43.89679718017578
loss:  29.659677505493164 43.48808288574219
loss:  30.182222366333008 43.69150924682617
loss:  30.87464141845703 43.82588195800781
*******************Epoch 14 ****************** 300 0.014950000000000001
Validation Loss
*** pred loss:  21.625619888305664 pred acc: 0.6526569724082947
*** stop loss:  5.504331111907959 stop acc: 0.9266812205314636
*** template loss:  6.9386677742004395 template acc: tensor(0.1864, device='cuda:0')
*** label loss:  5.994583606719971 label acc: tensor(0.3551, device='cuda:0')
Train Loss
---> pred loss: 20.474481201171876 pred acc: 0.6792444705963134
---> stop loss: 4.699135589599609 stop acc: 0.9456118464469909
---> template loss: 1.9504444122314453 tempalte acc: 0.6047760963439941
---> molecule label loss: 2.773243713378906 molecule acc: 0.5002078533172607
---> kl loss: 43.57859802246094
---> reconstruction loss: 29.876609700775145
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-15-with.npy
loss:  29.799644470214844 43.41450500488281
loss:  29.864652633666992 43.50912094116211
loss:  29.817724227905273 43.472721099853516
loss:  30.632041931152344 43.6279296875
loss:  29.635292053222656 43.582763671875
loss:  30.14643096923828 43.870670318603516
loss:  29.834903717041016 43.71873474121094
loss:  29.69354820251465 43.868370056152344
loss:  29.968732833862305 43.55220031738281
loss:  29.88371467590332 43.828887939453125
loss:  30.004833221435547 43.64855194091797
loss:  29.531017303466797 43.58570098876953
loss:  29.35724449157715 43.89025115966797
loss:  29.602014541625977 43.79986572265625
loss:  30.041561126708984 43.68901062011719
loss:  29.618175506591797 43.80633544921875
loss:  29.42214584350586 43.57604217529297
loss:  28.969316482543945 43.759681701660156
loss:  29.20183753967285 43.39241409301758
loss:  28.53411102294922 42.39006805419922
*******************Epoch 15 ****************** 320 0.01595
Validation Loss
*** pred loss:  21.141849517822266 pred acc: 0.6641303896903992
*** stop loss:  5.2364325523376465 stop acc: 0.9307908415794373
*** template loss:  6.8738203048706055 template acc: tensor(0.2037, device='cuda:0')
*** label loss:  5.928475379943848 label acc: tensor(0.3590, device='cuda:0')
Train Loss
---> pred loss: 19.947956848144532 pred acc: 0.6852081328630447
---> stop loss: 4.574832153320313 stop acc: 0.9472713261842728
---> template loss: 1.812592124938965 tempalte acc: 0.6331668853759765
---> molecule label loss: 2.667890930175781 molecule acc: 0.5110598087310791
---> kl loss: 43.59919738769531
---> reconstruction loss: 28.982537747955323
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-16-with.npy
loss:  28.65291404724121 43.23735046386719
loss:  29.057960510253906 43.55401611328125
loss:  29.65716552734375 43.82228088378906
loss:  28.7275390625 43.42816925048828
loss:  29.213077545166016 43.32684326171875
loss:  28.887231826782227 43.359981536865234
loss:  28.903791427612305 43.34382629394531
loss:  28.880020141601562 43.16315841674805
loss:  29.23768424987793 43.186187744140625
loss:  28.490400314331055 43.44712829589844
loss:  28.74669075012207 43.298343658447266
loss:  28.646556854248047 43.717430114746094
loss:  28.905439376831055 43.70124053955078
loss:  29.132793426513672 43.292572021484375
loss:  28.588268280029297 43.17686462402344
loss:  28.91541290283203 43.66179656982422
loss:  27.853187561035156 43.32305145263672
loss:  28.95716667175293 43.261695861816406
loss:  28.476835250854492 43.547157287597656
loss:  29.901966094970703 42.62294387817383
*******************Epoch 16 ****************** 340 0.01695
Validation Loss
*** pred loss:  21.154922485351562 pred acc: 0.6579710245132446
*** stop loss:  5.54640531539917 stop acc: 0.9242839813232422
*** template loss:  6.852487087249756 template acc: tensor(0.2068, device='cuda:0')
*** label loss:  6.0121049880981445 label acc: tensor(0.3588, device='cuda:0')
Train Loss
---> pred loss: 19.500440979003905 pred acc: 0.6939243167638779
---> stop loss: 4.406858444213867 stop acc: 0.9497125655412674
---> template loss: 1.721256637573242 tempalte acc: 0.6450727462768555
---> molecule label loss: 2.5484899520874023 molecule acc: 0.5280701637268066
---> kl loss: 43.373599243164065
---> reconstruction loss: 28.15641905532837
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-17-with.npy
loss:  28.69182586669922 43.154178619384766
loss:  28.50958824157715 43.646419525146484
loss:  29.012826919555664 43.18341064453125
loss:  28.41671371459961 43.41509246826172
loss:  28.523582458496094 43.58882141113281
loss:  28.210973739624023 43.85499572753906
loss:  28.603450775146484 43.242950439453125
loss:  28.894765853881836 43.47398376464844
loss:  27.944637298583984 43.44251251220703
loss:  28.344547271728516 43.666358947753906
loss:  28.04924201965332 43.08735656738281
loss:  28.570171356201172 43.572540283203125
loss:  28.134878158569336 43.60520935058594
loss:  28.24325180053711 43.285221099853516
loss:  28.039098739624023 43.52051544189453
loss:  28.122093200683594 43.766685485839844
loss:  28.050220489501953 43.251041412353516
loss:  27.368587493896484 43.464237213134766
loss:  28.22723960876465 43.514530181884766
loss:  26.461145401000977 44.03985595703125
*******************Epoch 17 ****************** 360 0.01795
Validation Loss
*** pred loss:  20.777738571166992 pred acc: 0.6678140163421631
*** stop loss:  5.284499168395996 stop acc: 0.9293586611747742
*** template loss:  6.837776184082031 template acc: tensor(0.2023, device='cuda:0')
*** label loss:  5.957949638366699 label acc: tensor(0.3616, device='cuda:0')
Train Loss
---> pred loss: 19.101629638671874 pred acc: 0.6981380909681321
---> stop loss: 4.325784301757812 stop acc: 0.9501266986131668
---> template loss: 1.6173147201538085 tempalte acc: 0.6627931594848633
---> molecule label loss: 2.4162271499633787 molecule acc: 0.5428232669830322
---> kl loss: 43.4887939453125
---> reconstruction loss: 27.440317310791016
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-18-with.npy
loss:  27.628124237060547 43.60152816772461
loss:  27.408964157104492 43.361610412597656
loss:  27.63404655456543 43.16987609863281
loss:  27.656414031982422 42.941368103027344
loss:  27.50274085998535 43.08301544189453
loss:  27.85287857055664 43.1319580078125
loss:  27.603376388549805 43.01335906982422
loss:  27.935991287231445 43.282657623291016
loss:  27.948184967041016 43.199947357177734
loss:  27.514249801635742 42.94381332397461
loss:  27.351696014404297 43.086307525634766
loss:  27.489585876464844 43.114158630371094
loss:  27.606740951538086 43.179351806640625
loss:  27.407442092895508 43.401039123535156
loss:  27.563199996948242 43.12358856201172
loss:  27.706348419189453 43.100975036621094
loss:  27.314146041870117 43.280982971191406
loss:  27.349143981933594 42.91149139404297
loss:  27.02231216430664 43.29061508178711
loss:  26.605802536010742 43.8505859375
*******************Epoch 18 ****************** 380 0.01895
Validation Loss
*** pred loss:  20.59119415283203 pred acc: 0.6667270064353943
*** stop loss:  5.117738723754883 stop acc: 0.933343768119812
*** template loss:  6.760066509246826 template acc: tensor(0.2170, device='cuda:0')
*** label loss:  5.966144561767578 label acc: tensor(0.3624, device='cuda:0')
Train Loss
---> pred loss: 18.609536743164064 pred acc: 0.7049991667270661
---> stop loss: 4.266854858398437 stop acc: 0.9512828022241593
---> template loss: 1.5249204635620117 tempalte acc: 0.6814419746398925
---> molecule label loss: 2.3055656433105467 molecule acc: 0.5588942050933838
---> kl loss: 43.203408813476564
---> reconstruction loss: 26.686364372711182
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-19-with.npy
loss:  27.309762954711914 43.04154968261719
loss:  26.722904205322266 43.150413513183594
loss:  27.239919662475586 43.3089714050293
loss:  27.304685592651367 43.319271087646484
loss:  26.620014190673828 43.13636779785156
loss:  26.774751663208008 43.52238845825195
loss:  26.972572326660156 43.35661315917969
loss:  26.713136672973633 43.18760681152344
loss:  27.030872344970703 43.23507308959961
loss:  27.19582176208496 43.45394515991211
loss:  27.31470489501953 43.207069396972656
loss:  27.13730812072754 43.04435348510742
loss:  26.7557315826416 43.246116638183594
loss:  26.437692642211914 43.22259521484375
loss:  26.490432739257812 43.1513671875
loss:  26.937297821044922 42.866363525390625
loss:  26.882402420043945 43.18575668334961
loss:  26.418336868286133 43.14276123046875
loss:  26.215782165527344 43.109962463378906
loss:  26.488447189331055 43.660404205322266
*******************Epoch 19 ****************** 400 0.019950000000000002
Validation Loss
*** pred loss:  20.15652084350586 pred acc: 0.6715579628944397
*** stop loss:  5.050012588500977 stop acc: 0.933935284614563
*** template loss:  6.6976518630981445 template acc: tensor(0.2336, device='cuda:0')
*** label loss:  5.986503601074219 label acc: tensor(0.3611, device='cuda:0')
Train Loss
---> pred loss: 18.241758728027342 pred acc: 0.7117925226688385
---> stop loss: 4.10510368347168 stop acc: 0.9533196955919265
---> template loss: 1.4419848442077636 tempalte acc: 0.6967707633972168
---> molecule label loss: 2.2174301147460938 molecule acc: 0.5714974403381348
---> kl loss: 43.227447509765625
---> reconstruction loss: 25.9857386428833
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-20-with.npy
loss:  68.61494445800781 42.8053092956543
loss:  66.21826171875 40.764400482177734
loss:  63.317726135253906 37.51287078857422
loss:  60.783485412597656 34.06182098388672
loss:  57.65509796142578 30.846755981445312
loss:  56.091278076171875 28.640316009521484
loss:  54.186988830566406 26.6807918548584
loss:  52.716331481933594 24.973262786865234
loss:  51.04365539550781 23.159536361694336
loss:  50.208229064941406 21.560516357421875
loss:  49.839324951171875 19.95433807373047
loss:  48.52638244628906 18.27245330810547
loss:  48.44061279296875 16.706979751586914
loss:  48.11488723754883 14.8444185256958
loss:  45.994384765625 13.59178638458252
loss:  43.758636474609375 11.867985725402832
loss:  44.522605895996094 10.849626541137695
loss:  43.282203674316406 9.290985107421875
loss:  41.41780090332031 8.26649284362793
loss:  40.293941497802734 6.821497917175293
*******************Epoch 20 ****************** 420 1.0
Validation Loss
*** pred loss:  24.50613021850586 pred acc: 0.594685971736908
*** stop loss:  5.832780838012695 stop acc: 0.9237546920776367
*** template loss:  7.545498847961426 template acc: tensor(0.0570, device='cuda:0')
*** label loss:  5.814401626586914 label acc: tensor(0.3507, device='cuda:0')
Train Loss
---> pred loss: 19.24524383544922 pred acc: 0.6919217348098755
---> stop loss: 4.807427215576172 stop acc: 0.9439768671989441
---> template loss: 2.82171573638916 tempalte acc: 0.4531380653381348
---> molecule label loss: 2.8033451080322265 molecule acc: 0.4761159896850586
---> kl loss: 22.0736083984375
---> reconstruction loss: 29.677722167968753
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-21-with.npy
loss:  39.95696258544922 6.536916732788086
loss:  40.20024108886719 5.996049880981445
loss:  39.168365478515625 5.19740629196167
loss:  39.409053802490234 4.864105701446533
loss:  38.85358810424805 4.5326714515686035
loss:  38.79560470581055 4.183039665222168
loss:  38.76713562011719 4.204926490783691
loss:  38.09750747680664 3.8803353309631348
loss:  38.3553581237793 3.5595054626464844
loss:  37.5885009765625 3.4666099548339844
loss:  36.934043884277344 3.431819200515747
loss:  37.056251525878906 3.2250685691833496
loss:  36.99462127685547 3.1172525882720947
loss:  36.827510833740234 3.1902883052825928
loss:  36.46128845214844 3.117563247680664
loss:  36.708499908447266 3.0557687282562256
loss:  36.381614685058594 3.00222110748291
loss:  36.86832046508789 3.047943592071533
loss:  36.566158294677734 3.0255377292633057
loss:  36.954307556152344 2.835092306137085
*******************Epoch 21 ****************** 440 1.0
Validation Loss
*** pred loss:  24.457637786865234 pred acc: 0.5945048332214355
*** stop loss:  5.7250518798828125 stop acc: 0.9230697751045227
*** template loss:  7.525116443634033 template acc: tensor(0.0711, device='cuda:0')
*** label loss:  5.894913673400879 label acc: tensor(0.3549, device='cuda:0')
Train Loss
---> pred loss: 22.640522766113282 pred acc: 0.6372393041849136
---> stop loss: 4.952900695800781 stop acc: 0.9411199033260346
---> template loss: 3.4759185791015623 tempalte acc: 0.34844093322753905
---> molecule label loss: 2.9043994903564454 molecule acc: 0.46959896087646485
---> kl loss: 3.873505783081055
---> reconstruction loss: 33.973738479614255
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-22-with.npy
loss:  35.74684143066406 2.778251886367798
loss:  35.5015983581543 2.773125648498535
loss:  35.80044174194336 2.7598612308502197
loss:  34.962284088134766 2.7098190784454346
loss:  35.55897521972656 2.7748827934265137
loss:  34.95456314086914 2.6426913738250732
loss:  35.51150131225586 2.6561477184295654
loss:  35.19789123535156 2.6595664024353027
loss:  35.23240280151367 2.7327771186828613
loss:  35.1082649230957 2.6413142681121826
loss:  35.32998275756836 2.7524712085723877
loss:  34.845916748046875 2.7095894813537598
loss:  35.3331184387207 2.583048105239868
loss:  34.56282424926758 2.6672329902648926
loss:  34.57286071777344 2.5117435455322266
loss:  34.58941650390625 2.5423810482025146
loss:  35.34605407714844 2.6000123023986816
loss:  34.511322021484375 2.5582199096679688
loss:  34.61783218383789 2.5773167610168457
loss:  33.191749572753906 2.40107798576355
*******************Epoch 22 ****************** 460 1.0
Validation Loss
*** pred loss:  24.37136459350586 pred acc: 0.5983091592788696
*** stop loss:  5.892946720123291 stop acc: 0.921201765537262
*** template loss:  7.409361362457275 template acc: tensor(0.0869, device='cuda:0')
*** label loss:  5.8772382736206055 label acc: tensor(0.3543, device='cuda:0')
Train Loss
---> pred loss: 22.15977783203125 pred acc: 0.6436302065849304
---> stop loss: 4.721547317504883 stop acc: 0.9441623479127884
---> template loss: 2.938910484313965 tempalte acc: 0.42693371772766114
---> molecule label loss: 2.5519784927368163 molecule acc: 0.512219762802124
---> kl loss: 2.651576614379883
---> reconstruction loss: 32.37221794128418
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-23-with.npy
loss:  34.080284118652344 2.4181582927703857
loss:  34.474998474121094 2.548379898071289
loss:  34.077457427978516 2.4521431922912598
loss:  34.4814453125 2.419572353363037
loss:  34.25266647338867 2.3835363388061523
loss:  33.95913314819336 2.41414737701416
loss:  34.22492980957031 2.5043351650238037
loss:  33.92826843261719 2.332428455352783
loss:  33.91050338745117 2.308882713317871
loss:  33.90279769897461 2.288597583770752
loss:  34.37036895751953 2.3379080295562744
loss:  33.79729461669922 2.3749701976776123
loss:  33.56974411010742 2.3385536670684814
loss:  33.608604431152344 2.377563238143921
loss:  34.211524963378906 2.329132318496704
loss:  33.88574981689453 2.259868860244751
loss:  34.08506393432617 2.3171682357788086
loss:  33.75703811645508 2.2362000942230225
loss:  33.633174896240234 2.250666856765747
loss:  32.46867752075195 2.018599271774292
*******************Epoch 23 ****************** 480 1.0
Validation Loss
*** pred loss:  24.478166580200195 pred acc: 0.5967391133308411
*** stop loss:  5.713383674621582 stop acc: 0.9230074882507324
*** template loss:  7.33098030090332 template acc: tensor(0.0985, device='cuda:0')
*** label loss:  5.909499645233154 label acc: tensor(0.3537, device='cuda:0')
Train Loss
---> pred loss: 21.915892028808592 pred acc: 0.6476799666881561
---> stop loss: 4.633001708984375 stop acc: 0.9456201225519181
---> template loss: 2.6637126922607424 tempalte acc: 0.47172865867614744
---> molecule label loss: 2.375836944580078 molecule acc: 0.5362675189971924
---> kl loss: 2.345540428161621
---> reconstruction loss: 31.58844699859619
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-24-with.npy
loss:  33.406044006347656 2.2121047973632812
loss:  33.27663040161133 2.211556911468506
loss:  33.79624938964844 2.330223321914673
loss:  33.77406311035156 2.30869197845459
loss:  33.35219192504883 2.25927472114563
loss:  33.405738830566406 2.2090625762939453
loss:  33.630836486816406 2.2329843044281006
loss:  33.39911651611328 2.162811279296875
loss:  33.5584602355957 2.115536689758301
loss:  33.03693389892578 2.1597306728363037
loss:  32.81722640991211 2.1388397216796875
loss:  33.74878692626953 2.1627306938171387
loss:  33.20918655395508 2.152632236480713
loss:  33.404869079589844 2.1645917892456055
loss:  33.424964904785156 2.0994346141815186
loss:  33.12983322143555 2.11541485786438
loss:  32.94989776611328 2.0171456336975098
loss:  33.135684967041016 2.1199135780334473
loss:  32.97933578491211 2.039217233657837
loss:  33.148101806640625 2.0763092041015625
*******************Epoch 24 ****************** 500 1.0
Validation Loss
*** pred loss:  24.444028854370117 pred acc: 0.5933574438095093
*** stop loss:  5.9412922859191895 stop acc: 0.9208281636238098
*** template loss:  7.3319993019104 template acc: tensor(0.1055, device='cuda:0')
*** label loss:  5.914787769317627 label acc: tensor(0.3607, device='cuda:0')
Train Loss
---> pred loss: 21.816244506835936 pred acc: 0.6486426293849945
---> stop loss: 4.5937652587890625 stop acc: 0.9459548562765121
---> template loss: 2.5000179290771483 tempalte acc: 0.4969182968139648
---> molecule label loss: 2.254768180847168 molecule acc: 0.555267333984375
---> kl loss: 2.1644105911254883
---> reconstruction loss: 31.164794731140134
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-25-with.npy
loss:  32.751792907714844 2.039947032928467
loss:  33.01963424682617 2.0545053482055664
loss:  32.928409576416016 2.0412397384643555
loss:  32.730987548828125 2.0168545246124268
loss:  33.25212860107422 1.9973812103271484
loss:  32.86921310424805 2.0081655979156494
loss:  32.64033508300781 2.0655391216278076
loss:  32.597938537597656 2.043030261993408
loss:  32.63721466064453 2.0449891090393066
loss:  32.735897064208984 2.0749728679656982
loss:  32.6749267578125 2.007841110229492
loss:  32.59125900268555 2.02929425239563
loss:  32.33610534667969 1.9826833009719849
loss:  32.42918395996094 1.9124125242233276
loss:  32.61069869995117 1.9954277276992798
loss:  32.3238525390625 1.8581995964050293
loss:  32.240638732910156 1.9111785888671875
loss:  32.80895233154297 1.9106767177581787
loss:  33.0284538269043 1.9349141120910645
loss:  33.7764892578125 1.8004493713378906
*******************Epoch 25 ****************** 520 1.0
Validation Loss
*** pred loss:  24.547832489013672 pred acc: 0.5946255922317505
*** stop loss:  5.876433372497559 stop acc: 0.9209215641021729
*** template loss:  7.2728729248046875 template acc: tensor(0.1031, device='cuda:0')
*** label loss:  5.920795917510986 label acc: tensor(0.3656, device='cuda:0')
Train Loss
---> pred loss: 21.723605346679687 pred acc: 0.6510415315628052
---> stop loss: 4.549516296386718 stop acc: 0.9466189026832581
---> template loss: 2.3519817352294923 tempalte acc: 0.522706937789917
---> molecule label loss: 2.1376163482666017 molecule acc: 0.5749496936798095
---> kl loss: 1.986484909057617
---> reconstruction loss: 30.76271858215332
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-26-with.npy
loss:  32.31758499145508 1.9176247119903564
loss:  32.15670394897461 1.9207624197006226
loss:  32.27284622192383 1.8907480239868164
loss:  31.955724716186523 1.9094088077545166
loss:  32.40966033935547 1.928001046180725
loss:  32.32398223876953 1.8943774700164795
loss:  32.60072326660156 1.9208451509475708
loss:  31.86232566833496 1.8698318004608154
loss:  32.554229736328125 1.8528720140457153
loss:  32.08162307739258 1.803463101387024
loss:  32.66567611694336 1.8333840370178223
loss:  32.545963287353516 1.8332085609436035
loss:  32.36930465698242 1.8722295761108398
loss:  32.208003997802734 1.8868530988693237
loss:  32.64971160888672 1.9186584949493408
loss:  31.771238327026367 1.84107506275177
loss:  31.931297302246094 1.8576273918151855
loss:  32.08222198486328 1.8734560012817383
loss:  31.84708023071289 1.831955909729004
loss:  32.48701858520508 1.732430100440979
*******************Epoch 26 ****************** 540 1.0
Validation Loss
*** pred loss:  24.484601974487305 pred acc: 0.5922704935073853
*** stop loss:  5.827085018157959 stop acc: 0.9232565760612488
*** template loss:  7.259725093841553 template acc: tensor(0.1126, device='cuda:0')
*** label loss:  5.914762496948242 label acc: tensor(0.3599, device='cuda:0')
Train Loss
---> pred loss: 21.570867919921874 pred acc: 0.652383542060852
---> stop loss: 4.50256233215332 stop acc: 0.9476357132196427
---> template loss: 2.259866142272949 tempalte acc: 0.5400393009185791
---> molecule label loss: 2.0519107818603515 molecule acc: 0.5865684509277344
---> kl loss: 1.8694406509399415
---> reconstruction loss: 30.38520412445068
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-27-with.npy
loss:  31.684152603149414 1.7975494861602783
loss:  31.900360107421875 1.8486549854278564
loss:  31.85456085205078 1.8267368078231812
loss:  32.787200927734375 1.8941532373428345
loss:  31.822063446044922 1.7889904975891113
loss:  32.230342864990234 1.8865196704864502
loss:  31.790138244628906 1.8319960832595825
loss:  31.703794479370117 1.8557610511779785
loss:  31.577985763549805 1.785497784614563
loss:  31.815933227539062 1.7701561450958252
loss:  31.746376037597656 1.7768727540969849
loss:  31.991662979125977 1.7765552997589111
loss:  31.084871292114258 1.6902518272399902
loss:  31.8099308013916 1.7374857664108276
loss:  32.15355682373047 1.7282863855361938
loss:  31.65984344482422 1.7324527502059937
loss:  31.828960418701172 1.7458382844924927
loss:  31.35821533203125 1.7200708389282227
loss:  31.660871505737305 1.737349271774292
loss:  33.33195877075195 1.770323634147644
*******************Epoch 27 ****************** 560 1.0
Validation Loss
*** pred loss:  24.424646377563477 pred acc: 0.5955314040184021
*** stop loss:  5.832344055175781 stop acc: 0.9243462085723877
*** template loss:  7.292410850524902 template acc: tensor(0.1090, device='cuda:0')
*** label loss:  5.9197211265563965 label acc: tensor(0.3586, device='cuda:0')
Train Loss
---> pred loss: 21.501828002929688 pred acc: 0.6545082330703735
---> stop loss: 4.47156867980957 stop acc: 0.9476675361394882
---> template loss: 2.1610313415527345 tempalte acc: 0.5550098896026612
---> molecule label loss: 1.9701360702514648 molecule acc: 0.6011925220489502
---> kl loss: 1.7850753784179687
---> reconstruction loss: 30.104563903808593
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-28-with.npy
loss:  32.01756286621094 1.750267505645752
loss:  31.4532470703125 1.7345272302627563
loss:  31.260570526123047 1.712410569190979
loss:  31.826480865478516 1.6986926794052124
loss:  31.529150009155273 1.6945794820785522
loss:  31.697147369384766 1.7216213941574097
loss:  31.797077178955078 1.686563491821289
loss:  31.506427764892578 1.6755727529525757
loss:  31.33157730102539 1.732726812362671
loss:  30.935306549072266 1.6233594417572021
loss:  31.4219913482666 1.7191510200500488
loss:  31.08936882019043 1.6213382482528687
loss:  31.688814163208008 1.673798680305481
loss:  31.46886444091797 1.6823769807815552
loss:  31.388912200927734 1.647915005683899
loss:  31.37714385986328 1.6331802606582642
loss:  31.350528717041016 1.6480664014816284
loss:  31.542387008666992 1.6413251161575317
loss:  31.343225479125977 1.630637526512146
loss:  32.14697265625 1.7430245876312256
*******************Epoch 28 ****************** 580 1.0
Validation Loss
*** pred loss:  24.65350341796875 pred acc: 0.5907004475593567
*** stop loss:  6.133047103881836 stop acc: 0.9184309244155884
*** template loss:  7.2651872634887695 template acc: tensor(0.1126, device='cuda:0')
*** label loss:  5.916902542114258 label acc: tensor(0.3654, device='cuda:0')
Train Loss
---> pred loss: 21.336257934570312 pred acc: 0.6563169062137604
---> stop loss: 4.4885398864746096 stop acc: 0.9476260364055633
---> template loss: 2.0876041412353517 tempalte acc: 0.5677215576171875
---> molecule label loss: 1.9126781463623046 molecule acc: 0.609913444519043
---> kl loss: 1.6835567474365234
---> reconstruction loss: 29.82507667541504
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-29-with.npy
loss:  30.726116180419922 1.639650821685791
loss:  31.36446762084961 1.6808300018310547
loss:  31.119707107543945 1.6330398321151733
loss:  31.264934539794922 1.6629736423492432
loss:  30.919742584228516 1.64808189868927
loss:  31.076412200927734 1.6294463872909546
loss:  31.06272315979004 1.6381381750106812
loss:  31.180498123168945 1.639028549194336
loss:  31.234691619873047 1.6236302852630615
loss:  30.822750091552734 1.6076710224151611
loss:  31.555395126342773 1.606771469116211
loss:  30.667959213256836 1.5756317377090454
loss:  30.69159507751465 1.5470305681228638
loss:  31.031145095825195 1.6013484001159668
loss:  30.80957794189453 1.5348676443099976
loss:  30.626569747924805 1.5162715911865234
loss:  30.733808517456055 1.5389041900634766
loss:  31.123971939086914 1.601574420928955
loss:  30.93508529663086 1.594963788986206
loss:  29.448640823364258 1.5404554605484009
*******************Epoch 29 ****************** 600 1.0
Validation Loss
*** pred loss:  24.750709533691406 pred acc: 0.588164210319519
*** stop loss:  5.8922858238220215 stop acc: 0.92391037940979
*** template loss:  7.258513450622559 template acc: tensor(0.1168, device='cuda:0')
*** label loss:  5.9277262687683105 label acc: tensor(0.3695, device='cuda:0')
Train Loss
---> pred loss: 21.144737243652344 pred acc: 0.6593060910701751
---> stop loss: 4.3987274169921875 stop acc: 0.9483917415142059
---> template loss: 1.974696159362793 tempalte acc: 0.5890705585479736
---> molecule label loss: 1.7986131668090821 molecule acc: 0.6308095932006836
---> kl loss: 1.6030155181884767
---> reconstruction loss: 29.31677207946777
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-30-with.npy
loss:  30.2294921875 1.5667496919631958
loss:  30.28534507751465 1.5653202533721924
loss:  30.92081069946289 1.5825408697128296
loss:  30.947298049926758 1.5771228075027466
loss:  31.198598861694336 1.6079388856887817
loss:  31.163917541503906 1.6172605752944946
loss:  30.50798797607422 1.5467497110366821
loss:  30.38610076904297 1.5712634325027466
loss:  30.575077056884766 1.577351689338684
loss:  30.294769287109375 1.5642198324203491
loss:  30.375320434570312 1.505625605583191
loss:  30.307737350463867 1.477064609527588
loss:  30.278385162353516 1.5286067724227905
loss:  30.355295181274414 1.4628292322158813
loss:  29.956857681274414 1.5122884511947632
loss:  30.334386825561523 1.4987891912460327
loss:  30.108869552612305 1.466041088104248
loss:  30.984899520874023 1.5115495920181274
loss:  31.055700302124023 1.497534990310669
loss:  32.871734619140625 1.5935616493225098
*******************Epoch 30 ****************** 620 1.0
Validation Loss
*** pred loss:  24.683696746826172 pred acc: 0.5886473059654236
*** stop loss:  5.978967666625977 stop acc: 0.9216064810752869
*** template loss:  7.232086658477783 template acc: tensor(0.1196, device='cuda:0')
*** label loss:  5.965132236480713 label acc: tensor(0.3646, device='cuda:0')
Train Loss
---> pred loss: 21.112467956542968 pred acc: 0.6611169308423996
---> stop loss: 4.348493576049805 stop acc: 0.9496885627508164
---> template loss: 1.9094623565673827 tempalte acc: 0.6014148235321045
---> molecule label loss: 1.7449874877929688 molecule acc: 0.6427427291870117
---> kl loss: 1.5415204048156739
---> reconstruction loss: 29.1154070854187
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-31-with.npy
loss:  30.141845703125 1.527327537536621
loss:  29.875062942504883 1.531409740447998
loss:  30.169254302978516 1.5240790843963623
loss:  30.904239654541016 1.5472736358642578
loss:  30.41946792602539 1.5517770051956177
loss:  29.949630737304688 1.5429940223693848
loss:  30.441001892089844 1.5238538980484009
loss:  30.11574363708496 1.4865857362747192
loss:  30.117938995361328 1.5079478025436401
loss:  30.131792068481445 1.445375680923462
loss:  30.39848518371582 1.4889737367630005
loss:  30.492923736572266 1.4976764917373657
loss:  29.99908447265625 1.423753023147583
loss:  30.663448333740234 1.489664077758789
loss:  30.257020950317383 1.4793293476104736
loss:  30.304908752441406 1.4754881858825684
loss:  30.04560661315918 1.4961299896240234
loss:  29.89344024658203 1.4942246675491333
loss:  30.142704010009766 1.471573829650879
loss:  29.98625373840332 1.4246197938919067
*******************Epoch 31 ****************** 640 1.0
Validation Loss
*** pred loss:  24.716766357421875 pred acc: 0.5911231637001038
*** stop loss:  5.767429828643799 stop acc: 0.9260585904121399
*** template loss:  7.2479658126831055 template acc: tensor(0.1175, device='cuda:0')
*** label loss:  5.976345539093018 label acc: tensor(0.3688, device='cuda:0')
Train Loss
---> pred loss: 20.938478088378908 pred acc: 0.6622080862522125
---> stop loss: 4.275010299682617 stop acc: 0.9506087750196457
---> template loss: 1.8345354080200196 tempalte acc: 0.6153585910797119
---> molecule label loss: 1.6779655456542968 molecule acc: 0.6539267063140869
---> kl loss: 1.49650297164917
---> reconstruction loss: 28.725988483428953
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-32-with.npy
loss:  29.557899475097656 1.4627106189727783
loss:  30.161863327026367 1.4766857624053955
loss:  30.05625343322754 1.4138659238815308
loss:  29.750919342041016 1.4029629230499268
loss:  29.43916130065918 1.3990821838378906
loss:  29.95819664001465 1.4452054500579834
loss:  29.91558265686035 1.4362813234329224
loss:  29.80718231201172 1.4498662948608398
loss:  29.798259735107422 1.43325936794281
loss:  29.92401885986328 1.4186288118362427
loss:  29.9915828704834 1.4138123989105225
loss:  29.94104766845703 1.4518966674804688
loss:  29.79034423828125 1.4213578701019287
loss:  29.902589797973633 1.4442662000656128
loss:  29.970867156982422 1.3971980810165405
loss:  29.796802520751953 1.3871315717697144
loss:  30.108121871948242 1.4590260982513428
loss:  30.19275665283203 1.4410350322723389
loss:  30.083703994750977 1.4204684495925903
loss:  29.884845733642578 1.4904167652130127
*******************Epoch 32 ****************** 660 1.0
Validation Loss
*** pred loss:  24.515403747558594 pred acc: 0.5902777910232544
*** stop loss:  5.705464839935303 stop acc: 0.9257161021232605
*** template loss:  7.265994071960449 template acc: tensor(0.1235, device='cuda:0')
*** label loss:  6.0215582847595215 label acc: tensor(0.3731, device='cuda:0')
Train Loss
---> pred loss: 20.80279083251953 pred acc: 0.6645319312810898
---> stop loss: 4.252762985229492 stop acc: 0.9508826702833175
---> template loss: 1.7908071517944335 tempalte acc: 0.6220707416534423
---> molecule label loss: 1.621981430053711 molecule acc: 0.6645159721374512
---> kl loss: 1.4332578659057618
---> reconstruction loss: 28.468338203430175
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-33-with.npy
loss:  28.72837257385254 1.4177619218826294
loss:  29.7164363861084 1.413117527961731
loss:  29.561931610107422 1.439379096031189
loss:  29.73632049560547 1.4411269426345825
loss:  29.86690330505371 1.4472371339797974
loss:  29.374372482299805 1.3986672163009644
loss:  29.73747444152832 1.4078106880187988
loss:  29.942996978759766 1.3828792572021484
loss:  29.67486572265625 1.3621253967285156
loss:  29.1957950592041 1.3522861003875732
loss:  28.968671798706055 1.3338326215744019
loss:  29.739482879638672 1.3723101615905762
loss:  30.086816787719727 1.3904703855514526
loss:  29.361164093017578 1.3509984016418457
loss:  29.651473999023438 1.3688117265701294
loss:  29.12649154663086 1.3436951637268066
loss:  29.386465072631836 1.392017126083374
loss:  29.601511001586914 1.3624956607818604
loss:  29.52334976196289 1.3566482067108154
loss:  28.105825424194336 1.3062516450881958
*******************Epoch 33 ****************** 680 1.0
Validation Loss
*** pred loss:  24.60915184020996 pred acc: 0.5922101140022278
*** stop loss:  6.373410224914551 stop acc: 0.9189913272857666
*** template loss:  7.206882476806641 template acc: tensor(0.1263, device='cuda:0')
*** label loss:  5.9357733726501465 label acc: tensor(0.3703, device='cuda:0')
Train Loss
---> pred loss: 20.61851806640625 pred acc: 0.6670690089464187
---> stop loss: 4.1918586730957035 stop acc: 0.9515849977731705
---> template loss: 1.7127185821533204 tempalte acc: 0.6363032817840576
---> molecule label loss: 1.5492443084716796 molecule acc: 0.6755956172943115
---> kl loss: 1.3819960594177245
---> reconstruction loss: 28.072343540191653
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-34-with.npy
loss:  29.517898559570312 1.376946210861206
loss:  29.408971786499023 1.3630837202072144
loss:  29.33167266845703 1.38631272315979
loss:  29.39458465576172 1.3391387462615967
loss:  29.320568084716797 1.3357847929000854
loss:  29.166337966918945 1.3971056938171387
loss:  29.455480575561523 1.3655768632888794
loss:  29.115795135498047 1.3347764015197754
loss:  29.183969497680664 1.368593692779541
loss:  29.010419845581055 1.3658276796340942
loss:  29.382022857666016 1.3901373147964478
loss:  28.907209396362305 1.3047325611114502
loss:  29.398658752441406 1.343554973602295
loss:  29.212818145751953 1.3543634414672852
loss:  29.30845832824707 1.3231241703033447
loss:  29.27834129333496 1.3422106504440308
loss:  28.828981399536133 1.321306824684143
loss:  29.63407325744629 1.359122395515442
loss:  29.232847213745117 1.3485182523727417
loss:  29.050779342651367 1.2542248964309692
*******************Epoch 34 ****************** 700 1.0
Validation Loss
*** pred loss:  24.91023826599121 pred acc: 0.5868357419967651
*** stop loss:  5.808391094207764 stop acc: 0.9254670143127441
*** template loss:  7.288129806518555 template acc: tensor(0.1228, device='cuda:0')
*** label loss:  5.954959869384766 label acc: tensor(0.3697, device='cuda:0')
Train Loss
---> pred loss: 20.583677673339842 pred acc: 0.6675513029098511
---> stop loss: 4.168704605102539 stop acc: 0.9517674088478089
---> template loss: 1.6667669296264649 tempalte acc: 0.6439907073974609
---> molecule label loss: 1.4891241073608399 molecule acc: 0.6871596813201905
---> kl loss: 1.3487221717834472
---> reconstruction loss: 27.908272457122802
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-35-with.npy
loss:  29.07097816467285 1.30074143409729
loss:  28.834762573242188 1.2961379289627075
loss:  28.997257232666016 1.3075748682022095
loss:  29.019290924072266 1.3445186614990234
loss:  28.62731170654297 1.3196306228637695
loss:  29.097591400146484 1.3265646696090698
loss:  28.95014190673828 1.3433729410171509
loss:  28.834941864013672 1.3873395919799805
loss:  28.597370147705078 1.3522909879684448
loss:  29.459102630615234 1.3395318984985352
loss:  28.799562454223633 1.345680832862854
loss:  28.959768295288086 1.307318091392517
loss:  28.821901321411133 1.2996240854263306
loss:  29.161666870117188 1.284538984298706
loss:  28.417566299438477 1.302064299583435
loss:  29.355224609375 1.3217151165008545
loss:  28.932262420654297 1.28880774974823
loss:  29.18865203857422 1.317828893661499
loss:  28.627729415893555 1.2629421949386597
loss:  28.442886352539062 1.246417760848999
*******************Epoch 35 ****************** 720 1.0
Validation Loss
*** pred loss:  25.066566467285156 pred acc: 0.5825483202934265
*** stop loss:  5.785395622253418 stop acc: 0.9250311851501465
*** template loss:  7.231308937072754 template acc: tensor(0.1263, device='cuda:0')
*** label loss:  6.0459465980529785 label acc: tensor(0.3772, device='cuda:0')
Train Loss
---> pred loss: 20.43773651123047 pred acc: 0.6700404107570648
---> stop loss: 4.115145492553711 stop acc: 0.9526222020387649
---> template loss: 1.6126165390014648 tempalte acc: 0.6573013305664063
---> molecule label loss: 1.4295670509338378 molecule acc: 0.6977797031402588
---> kl loss: 1.314731979370117
---> reconstruction loss: 27.595064163208008
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-36-with.npy
loss:  28.682369232177734 1.271541953086853
loss:  28.53429412841797 1.2493287324905396
loss:  28.226016998291016 1.2379584312438965
loss:  28.731855392456055 1.2577929496765137
loss:  28.86171531677246 1.2966910600662231
loss:  28.808698654174805 1.3077865839004517
loss:  28.21255111694336 1.294169306755066
loss:  28.83881187438965 1.2883049249649048
loss:  28.399078369140625 1.2526429891586304
loss:  28.495582580566406 1.2348403930664062
loss:  28.986726760864258 1.257245421409607
loss:  29.025348663330078 1.2497767210006714
loss:  28.51137351989746 1.2542147636413574
loss:  28.554401397705078 1.2212122678756714
loss:  28.257627487182617 1.2626723051071167
loss:  28.733562469482422 1.2304699420928955
loss:  28.650676727294922 1.2842400074005127
loss:  28.601329803466797 1.3022770881652832
loss:  28.296232223510742 1.2534152269363403
loss:  28.119600296020508 1.3057793378829956
*******************Epoch 36 ****************** 740 1.0
Validation Loss
*** pred loss:  24.882822036743164 pred acc: 0.5861110687255859
*** stop loss:  6.239991664886475 stop acc: 0.9207659363746643
*** template loss:  7.248023509979248 template acc: tensor(0.1287, device='cuda:0')
*** label loss:  5.998415946960449 label acc: tensor(0.3710, device='cuda:0')
Train Loss
---> pred loss: 20.296221923828124 pred acc: 0.6729317605495453
---> stop loss: 4.104204559326172 stop acc: 0.9525217086076736
---> template loss: 1.5428780555725097 tempalte acc: 0.6675574779510498
---> molecule label loss: 1.3674704551696777 molecule acc: 0.7077933311462402
---> kl loss: 1.2656180381774902
---> reconstruction loss: 27.310776615142824
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-37-with.npy
loss:  28.197973251342773 1.2608100175857544
loss:  28.667673110961914 1.2702547311782837
loss:  28.21417808532715 1.271227478981018
loss:  28.316320419311523 1.25418221950531
loss:  28.63241958618164 1.2777020931243896
loss:  28.964658737182617 1.2723311185836792
loss:  28.31484603881836 1.2637218236923218
loss:  28.756078720092773 1.2488839626312256
loss:  27.990514755249023 1.2124768495559692
loss:  28.85910415649414 1.2610530853271484
loss:  28.297956466674805 1.2328095436096191
loss:  28.455495834350586 1.2448889017105103
loss:  28.40135383605957 1.2412188053131104
loss:  28.386672973632812 1.2171812057495117
loss:  28.460222244262695 1.2639515399932861
loss:  27.62808609008789 1.225942611694336
loss:  28.19009017944336 1.230932354927063
loss:  28.022794723510742 1.2237693071365356
loss:  28.28152847290039 1.208096981048584
loss:  27.449872970581055 1.1328164339065552
*******************Epoch 37 ****************** 760 1.0
Validation Loss
*** pred loss:  25.12715721130371 pred acc: 0.5804951786994934
*** stop loss:  5.960975646972656 stop acc: 0.9222914576530457
*** template loss:  7.215954780578613 template acc: tensor(0.1319, device='cuda:0')
*** label loss:  6.0284037590026855 label acc: tensor(0.3735, device='cuda:0')
Train Loss
---> pred loss: 20.132472229003906 pred acc: 0.6746512740850449
---> stop loss: 4.131243896484375 stop acc: 0.9522971004247666
---> template loss: 1.5060786247253417 tempalte acc: 0.6752649784088135
---> molecule label loss: 1.3138848304748536 molecule acc: 0.719083023071289
---> kl loss: 1.2407127380371095
---> reconstruction loss: 27.083683013916016
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-38-with.npy
loss:  27.890331268310547 1.229134202003479
loss:  28.531002044677734 1.243921160697937
loss:  28.117525100708008 1.2544186115264893
loss:  28.25780487060547 1.2324116230010986
loss:  28.25535774230957 1.237165093421936
loss:  28.085205078125 1.2319221496582031
loss:  28.0591983795166 1.2393289804458618
loss:  28.14511489868164 1.2388029098510742
loss:  28.388307571411133 1.2369301319122314
loss:  28.040054321289062 1.2383784055709839
loss:  27.940383911132812 1.2231779098510742
loss:  27.92022705078125 1.181804895401001
loss:  28.181549072265625 1.2087624073028564
loss:  27.94474983215332 1.2059378623962402
loss:  28.292940139770508 1.2092143297195435
loss:  28.126678466796875 1.184992790222168
loss:  28.128267288208008 1.2121977806091309
loss:  28.029760360717773 1.142049789428711
loss:  28.133373260498047 1.2132450342178345
loss:  27.441308975219727 1.0380123853683472
*******************Epoch 38 ****************** 780 1.0
Validation Loss
*** pred loss:  25.107433319091797 pred acc: 0.583816409111023
*** stop loss:  5.781244277954102 stop acc: 0.9278643131256104
*** template loss:  7.249053955078125 template acc: tensor(0.1235, device='cuda:0')
*** label loss:  6.0257086753845215 label acc: tensor(0.3808, device='cuda:0')
Train Loss
---> pred loss: 20.076596069335938 pred acc: 0.6752096354961395
---> stop loss: 4.0530250549316404 stop acc: 0.9531961530447006
---> template loss: 1.4733165740966796 tempalte acc: 0.6832663536071777
---> molecule label loss: 1.2824275016784668 molecule acc: 0.7240221977233887
---> kl loss: 1.2100903511047363
---> reconstruction loss: 26.885365581512453
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-39-with.npy
loss:  28.286727905273438 1.1979179382324219
loss:  27.51872444152832 1.198752999305725
loss:  27.693252563476562 1.1909199953079224
loss:  27.891271591186523 1.1958738565444946
loss:  28.03071403503418 1.1851966381072998
loss:  27.759939193725586 1.207113265991211
loss:  27.643766403198242 1.1988892555236816
loss:  27.920034408569336 1.2218374013900757
loss:  27.204984664916992 1.1813362836837769
loss:  28.30648422241211 1.2093780040740967
loss:  27.815210342407227 1.201462984085083
loss:  28.107439041137695 1.1698888540267944
loss:  28.099491119384766 1.1900458335876465
loss:  27.552635192871094 1.1552890539169312
loss:  27.616436004638672 1.1896216869354248
loss:  27.680513381958008 1.1899276971817017
loss:  27.767316818237305 1.170570969581604
loss:  28.018552780151367 1.1579581499099731
loss:  28.02865219116211 1.2142480611801147
loss:  27.691160202026367 1.0495548248291016
*******************Epoch 39 ****************** 800 1.0
Validation Loss
*** pred loss:  25.033138275146484 pred acc: 0.5890700221061707
*** stop loss:  5.804117679595947 stop acc: 0.9265567064285278
*** template loss:  7.256258010864258 template acc: tensor(0.1294, device='cuda:0')
*** label loss:  6.045481204986572 label acc: tensor(0.3766, device='cuda:0')
Train Loss
---> pred loss: 19.980850219726562 pred acc: 0.6767749398946762
---> stop loss: 3.9856845855712892 stop acc: 0.9538973569869995
---> template loss: 1.4299951553344727 tempalte acc: 0.6892584800720215
---> molecule label loss: 1.2513443946838378 molecule acc: 0.7299938201904297
---> kl loss: 1.1837891578674316
---> reconstruction loss: 26.64787588119507
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-40-with.npy
loss:  27.3408145904541 1.1378642320632935
loss:  27.369142532348633 1.1948572397232056
loss:  27.45774269104004 1.1805779933929443
loss:  27.797258377075195 1.216729998588562
loss:  27.950389862060547 1.181020975112915
loss:  27.646703720092773 1.1781582832336426
loss:  27.34600830078125 1.1430933475494385
loss:  27.754182815551758 1.1704145669937134
loss:  27.732513427734375 1.1360530853271484
loss:  27.637432098388672 1.176186203956604
loss:  27.116666793823242 1.20374596118927
loss:  27.676862716674805 1.165510892868042
loss:  27.48650360107422 1.1685339212417603
loss:  27.519031524658203 1.1617034673690796
loss:  27.34286117553711 1.1417427062988281
loss:  27.734148025512695 1.1747841835021973
loss:  27.268814086914062 1.1561731100082397
loss:  28.175334930419922 1.1581363677978516
loss:  27.80862045288086 1.1679518222808838
loss:  28.455322265625 1.1032814979553223
*******************Epoch 40 ****************** 820 1.0
Validation Loss
*** pred loss:  25.084754943847656 pred acc: 0.5893115997314453
*** stop loss:  6.287448406219482 stop acc: 0.9205479621887207
*** template loss:  7.265174388885498 template acc: tensor(0.1312, device='cuda:0')
*** label loss:  6.1032609939575195 label acc: tensor(0.3838, device='cuda:0')
Train Loss
---> pred loss: 19.92597351074219 pred acc: 0.6792573630809784
---> stop loss: 3.917941665649414 stop acc: 0.9554684638977051
---> template loss: 1.4127927780151368 tempalte acc: 0.6933215141296387
---> molecule label loss: 1.208284568786621 molecule acc: 0.7367426872253418
---> kl loss: 1.1658260345458984
---> reconstruction loss: 26.464990615844727
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-41-with.npy
loss:  27.36324119567871 1.1603567600250244
loss:  27.719161987304688 1.1646265983581543
loss:  27.162614822387695 1.1571751832962036
loss:  27.593158721923828 1.2008545398712158
loss:  28.42496681213379 1.1655631065368652
loss:  27.580102920532227 1.1396186351776123
loss:  27.168350219726562 1.155551791191101
loss:  27.363370895385742 1.1391128301620483
loss:  27.214136123657227 1.1492418050765991
loss:  27.07489013671875 1.127407431602478
loss:  27.20131492614746 1.1006073951721191
loss:  27.515056610107422 1.154427409172058
loss:  27.15970230102539 1.1220011711120605
loss:  27.113372802734375 1.154932975769043
loss:  27.210506439208984 1.1359028816223145
loss:  27.434770584106445 1.157682180404663
loss:  27.43250274658203 1.1500301361083984
loss:  27.286592483520508 1.1360046863555908
loss:  26.865253448486328 1.1604626178741455
loss:  24.956005096435547 1.0524109601974487
*******************Epoch 41 ****************** 840 1.0
Validation Loss
*** pred loss:  25.159494400024414 pred acc: 0.5885265469551086
*** stop loss:  5.811392784118652 stop acc: 0.9279265403747559
*** template loss:  7.2823486328125 template acc: tensor(0.1277, device='cuda:0')
*** label loss:  6.15431022644043 label acc: tensor(0.3857, device='cuda:0')
Train Loss
---> pred loss: 19.67613830566406 pred acc: 0.6816848397254944
---> stop loss: 3.904677963256836 stop acc: 0.9548688679933548
---> template loss: 1.3573863983154297 tempalte acc: 0.7068448066711426
---> molecule label loss: 1.1595537185668945 molecule acc: 0.7463817119598388
---> kl loss: 1.144198513031006
---> reconstruction loss: 26.09775400161743
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-42-with.npy
loss:  27.300233840942383 1.1461536884307861
loss:  27.019216537475586 1.1544898748397827
loss:  27.209976196289062 1.1476060152053833
loss:  26.936250686645508 1.1188838481903076
loss:  26.909324645996094 1.1328362226486206
loss:  27.15146827697754 1.1446170806884766
loss:  27.045900344848633 1.0886248350143433
loss:  27.25142478942871 1.1503996849060059
loss:  27.362571716308594 1.1444798707962036
loss:  27.359060287475586 1.096166968345642
loss:  27.237363815307617 1.1271456480026245
loss:  27.337121963500977 1.1291296482086182
loss:  27.014184951782227 1.133508563041687
loss:  27.256040573120117 1.1137714385986328
loss:  27.177677154541016 1.12953519821167
loss:  27.34065055847168 1.1101270914077759
loss:  27.080642700195312 1.1183258295059204
loss:  26.83380699157715 1.1224278211593628
loss:  26.751575469970703 1.110081434249878
loss:  25.607412338256836 1.0070174932479858
*******************Epoch 42 ****************** 860 1.0
Validation Loss
*** pred loss:  25.13117027282715 pred acc: 0.586533784866333
*** stop loss:  5.883082389831543 stop acc: 0.9257472157478333
*** template loss:  7.273357391357422 template acc: tensor(0.1326, device='cuda:0')
*** label loss:  6.0224528312683105 label acc: tensor(0.3819, device='cuda:0')
Train Loss
---> pred loss: 19.58599090576172 pred acc: 0.6827581197023391
---> stop loss: 3.9128662109375 stop acc: 0.9551121652126312
---> template loss: 1.3170889854431151 tempalte acc: 0.712674331665039
---> molecule label loss: 1.1218819618225098 molecule acc: 0.7519444465637207
---> kl loss: 1.1212662696838378
---> reconstruction loss: 25.937831020355226
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-43-with.npy
loss:  27.019088745117188 1.1063296794891357
loss:  26.918142318725586 1.1051546335220337
loss:  26.708911895751953 1.1260275840759277
loss:  26.491249084472656 1.1127814054489136
loss:  26.85624885559082 1.094032645225525
loss:  26.71688461303711 1.0940780639648438
loss:  26.943073272705078 1.1480283737182617
loss:  26.732776641845703 1.111313819885254
loss:  26.9033203125 1.1175086498260498
loss:  27.02640724182129 1.0927493572235107
loss:  26.868316650390625 1.081176519393921
loss:  26.641611099243164 1.06712806224823
loss:  27.056997299194336 1.057134747505188
loss:  27.096059799194336 1.0738955736160278
loss:  26.831968307495117 1.082703709602356
loss:  26.92820930480957 1.0853890180587769
loss:  26.768577575683594 1.0512081384658813
loss:  26.288965225219727 1.037678599357605
loss:  26.771759033203125 1.0696686506271362
loss:  26.152318954467773 1.1233229637145996
*******************Epoch 43 ****************** 880 1.0
Validation Loss
*** pred loss:  25.06552505493164 pred acc: 0.5890700221061707
*** stop loss:  5.952239513397217 stop acc: 0.9258095026016235
*** template loss:  7.280811786651611 template acc: tensor(0.1312, device='cuda:0')
*** label loss:  6.0017619132995605 label acc: tensor(0.3804, device='cuda:0')
Train Loss
---> pred loss: 19.512498474121095 pred acc: 0.6849549263715744
---> stop loss: 3.831399917602539 stop acc: 0.9560018330812454
---> template loss: 1.2796759605407715 tempalte acc: 0.7211262226104737
---> molecule label loss: 1.0706034660339356 molecule acc: 0.7620325088500977
---> kl loss: 1.0918655395507812
---> reconstruction loss: 25.694181823730467
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-44-with.npy
loss:  26.343154907226562 1.108224630355835
loss:  26.922090530395508 1.1310564279556274
loss:  26.26096534729004 1.1055693626403809
loss:  26.488405227661133 1.1043044328689575
loss:  26.561809539794922 1.0890324115753174
loss:  26.881147384643555 1.083994746208191
loss:  26.73416519165039 1.0941776037216187
loss:  27.081037521362305 1.13163161277771
loss:  26.34842872619629 1.119651436805725
loss:  26.593477249145508 1.0980020761489868
loss:  27.199249267578125 1.1190282106399536
loss:  27.00079345703125 1.0388811826705933
loss:  26.897205352783203 1.0377881526947021
loss:  26.794321060180664 1.073692798614502
loss:  26.8606014251709 1.070495367050171
loss:  26.281173706054688 1.0730568170547485
loss:  26.902156829833984 1.0904583930969238
loss:  26.569067001342773 1.0538346767425537
loss:  26.57710075378418 1.0705209970474243
loss:  26.095003128051758 0.964533269405365
*******************Epoch 44 ****************** 900 1.0
Validation Loss
*** pred loss:  25.24424171447754 pred acc: 0.5877415537834167
*** stop loss:  6.245142936706543 stop acc: 0.9225093722343445
*** template loss:  7.301120758056641 template acc: tensor(0.1337, device='cuda:0')
*** label loss:  6.051787376403809 label acc: tensor(0.3787, device='cuda:0')
Train Loss
---> pred loss: 19.442376708984376 pred acc: 0.6836899101734162
---> stop loss: 3.86697998046875 stop acc: 0.9551039904356002
---> template loss: 1.2485435485839844 tempalte acc: 0.7252791404724122
---> molecule label loss: 1.0287689208984374 molecule acc: 0.7714009761810303
---> kl loss: 1.0828967094421387
---> reconstruction loss: 25.586671161651612
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-45-with.npy
loss:  26.668588638305664 1.1059818267822266
loss:  26.46782684326172 1.0494626760482788
loss:  26.672657012939453 1.0722984075546265
loss:  26.617090225219727 1.0918636322021484
loss:  26.611642837524414 1.0589357614517212
loss:  26.571189880371094 1.0661240816116333
loss:  26.385406494140625 1.067978858947754
loss:  26.597747802734375 1.0513054132461548
loss:  26.80574607849121 1.0660476684570312
loss:  26.42070960998535 1.063962697982788
loss:  26.215139389038086 1.0682618618011475
loss:  26.664770126342773 1.0349262952804565
loss:  26.67864418029785 1.0819772481918335
loss:  26.537145614624023 1.0362557172775269
loss:  26.1451358795166 1.045178771018982
loss:  26.880168914794922 1.0708491802215576
loss:  26.159671783447266 1.0675578117370605
loss:  26.54473114013672 1.085536003112793
loss:  26.306673049926758 1.0741770267486572
loss:  28.416866302490234 1.0478078126907349
*******************Epoch 45 ****************** 920 1.0
Validation Loss
*** pred loss:  25.332231521606445 pred acc: 0.5811594128608704
*** stop loss:  6.123378276824951 stop acc: 0.923132061958313
*** template loss:  7.277655601501465 template acc: tensor(0.1337, device='cuda:0')
*** label loss:  6.025039196014404 label acc: tensor(0.3736, device='cuda:0')
Train Loss
---> pred loss: 19.421075439453126 pred acc: 0.6866095781326294
---> stop loss: 3.8601757049560548 stop acc: 0.9558198750019073
---> template loss: 1.2469563484191895 tempalte acc: 0.7255022048950195
---> molecule label loss: 1.0248435974121093 molecule acc: 0.7719553947448731
---> kl loss: 1.0653244972229003
---> reconstruction loss: 25.553050136566164
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-46-with.npy
loss:  26.10610580444336 1.0555403232574463
loss:  26.602813720703125 1.045999526977539
loss:  26.493690490722656 1.0296088457107544
loss:  26.96595573425293 1.059108853340149
loss:  26.534940719604492 1.056944489479065
loss:  26.396930694580078 1.0305263996124268
loss:  26.471176147460938 1.044726848602295
loss:  27.14369773864746 1.088133692741394
loss:  26.440271377563477 1.082960844039917
loss:  26.6406192779541 1.0739580392837524
loss:  26.643482208251953 1.0562784671783447
loss:  27.184110641479492 1.0905935764312744
loss:  26.605911254882812 1.0247999429702759
loss:  26.414955139160156 1.0560368299484253
loss:  26.67266845703125 1.072631597518921
loss:  26.487213134765625 1.0303161144256592
loss:  26.416540145874023 1.055854082107544
loss:  26.384624481201172 1.065000295639038
loss:  26.50741195678711 1.0627031326293945
loss:  27.13569450378418 1.0342121124267578
*******************Epoch 46 ****************** 940 1.0
Validation Loss
*** pred loss:  25.044239044189453 pred acc: 0.5902173519134521
*** stop loss:  6.441167831420898 stop acc: 0.9201432466506958
*** template loss:  7.300302982330322 template acc: tensor(0.1245, device='cuda:0')
*** label loss:  6.181533336639404 label acc: tensor(0.3830, device='cuda:0')
Train Loss
---> pred loss: 19.3184326171875 pred acc: 0.6875844210386276
---> stop loss: 3.8027008056640623 stop acc: 0.9562663644552231
---> template loss: 1.3160218238830566 tempalte acc: 0.7067562103271484
---> molecule label loss: 1.1194907188415528 molecule acc: 0.7482879638671875
---> kl loss: 1.0557967185974122
---> reconstruction loss: 25.55664529800415
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-47-with.npy
loss:  27.099712371826172 1.0754331350326538
loss:  26.538583755493164 1.0702660083770752
loss:  26.639135360717773 1.0471113920211792
loss:  26.792387008666992 1.0855882167816162
loss:  26.662200927734375 1.0264501571655273
loss:  26.88119888305664 1.0733829736709595
loss:  26.558645248413086 1.0213679075241089
loss:  26.59096908569336 1.0296401977539062
loss:  26.224437713623047 1.010913610458374
loss:  26.04290199279785 1.031256079673767
loss:  26.61284637451172 1.0328333377838135
loss:  25.902929306030273 1.0104522705078125
loss:  25.99261474609375 1.0277605056762695
loss:  26.13249969482422 1.0644837617874146
loss:  26.50175666809082 1.0516992807388306
loss:  26.403268814086914 1.0283833742141724
loss:  26.322479248046875 1.0170824527740479
loss:  25.994449615478516 1.0117255449295044
loss:  25.793825149536133 1.0400182008743286
loss:  25.57469940185547 1.0117168426513672
*******************Epoch 47 ****************** 960 1.0
Validation Loss
*** pred loss:  25.253698348999023 pred acc: 0.5829105973243713
*** stop loss:  5.899346351623535 stop acc: 0.9267746210098267
*** template loss:  7.208411693572998 template acc: tensor(0.1435, device='cuda:0')
*** label loss:  5.984127998352051 label acc: tensor(0.3778, device='cuda:0')
Train Loss
---> pred loss: 19.183686828613283 pred acc: 0.69049012362957
---> stop loss: 3.800567626953125 stop acc: 0.9563931941986084
---> template loss: 1.2745858192443849 tempalte acc: 0.717425012588501
---> molecule label loss: 1.0658576011657714 molecule acc: 0.7569904327392578
---> kl loss: 1.0383782386779785
---> reconstruction loss: 25.324698543548585
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-48-with.npy
loss:  26.15467643737793 1.0026755332946777
loss:  26.181421279907227 0.9787523150444031
loss:  25.973623275756836 1.0279062986373901
loss:  26.097023010253906 0.9954420924186707
loss:  25.694042205810547 0.9792708158493042
loss:  26.170665740966797 1.0167845487594604
loss:  26.02037811279297 0.9952771663665771
loss:  25.960479736328125 0.9804800152778625
loss:  26.29950523376465 1.04014253616333
loss:  25.770036697387695 1.058251976966858
loss:  25.461219787597656 1.0093798637390137
loss:  26.15367317199707 0.9851995706558228
loss:  26.286706924438477 1.0210931301116943
loss:  25.555089950561523 1.0081439018249512
loss:  25.80976104736328 1.0095281600952148
loss:  26.257244110107422 1.0329116582870483
loss:  25.903390884399414 1.0286527872085571
loss:  25.5870304107666 1.0073305368423462
loss:  25.722721099853516 0.9960317611694336
loss:  26.107738494873047 1.051512360572815
*******************Epoch 48 ****************** 980 1.0
Validation Loss
*** pred loss:  25.07383155822754 pred acc: 0.5888888835906982
*** stop loss:  6.053503513336182 stop acc: 0.9252179861068726
*** template loss:  7.27570104598999 template acc: tensor(0.1375, device='cuda:0')
*** label loss:  6.058185577392578 label acc: tensor(0.3774, device='cuda:0')
Train Loss
---> pred loss: 19.09386444091797 pred acc: 0.6917525231838226
---> stop loss: 3.7261516571044924 stop acc: 0.9577411949634552
---> template loss: 1.1671451568603515 tempalte acc: 0.7412492275238037
---> molecule label loss: 0.9599221229553223 molecule acc: 0.7806414127349853
---> kl loss: 1.0112383842468262
---> reconstruction loss: 24.947083759307862
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-49-with.npy
loss:  25.500761032104492 0.9765087366104126
loss:  25.981239318847656 1.016714334487915
loss:  26.298643112182617 1.0148403644561768
loss:  25.569799423217773 1.0047053098678589
loss:  26.295066833496094 1.042190670967102
loss:  26.216232299804688 1.0232477188110352
loss:  26.16301155090332 0.9859029054641724
loss:  26.13434600830078 1.000086784362793
loss:  25.69767189025879 0.9857293963432312
loss:  26.117481231689453 1.0113506317138672
loss:  26.106853485107422 1.006752371788025
loss:  25.56800651550293 0.9963364005088806
loss:  26.11466407775879 0.9989699125289917
loss:  25.756319046020508 0.9669954180717468
loss:  25.736194610595703 1.0213438272476196
loss:  25.466590881347656 0.9756149649620056
loss:  25.696720123291016 1.002166509628296
loss:  25.659391403198242 0.9690791368484497
loss:  25.942602157592773 0.9882484674453735
loss:  26.165618896484375 0.9106920957565308
*******************Epoch 49 ****************** 1000 1.0
Validation Loss
*** pred loss:  25.211257934570312 pred acc: 0.5901569724082947
*** stop loss:  5.8471293449401855 stop acc: 0.9270859360694885
*** template loss:  7.256216526031494 template acc: tensor(0.1340, device='cuda:0')
*** label loss:  6.090386390686035 label acc: tensor(0.3802, device='cuda:0')
Train Loss
---> pred loss: 19.014181518554686 pred acc: 0.6931403428316116
---> stop loss: 3.7607471466064455 stop acc: 0.9572758555412293
---> template loss: 1.1799715042114258 tempalte acc: 0.7394381523132324
---> molecule label loss: 0.9595883369445801 molecule acc: 0.7805534362792969
---> kl loss: 0.9948738098144532
---> reconstruction loss: 24.914482879638673
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-50-with.npy
loss:  25.48373031616211 0.9873494505882263
loss:  25.863048553466797 0.9851768016815186
loss:  25.494306564331055 0.9826605319976807
loss:  25.712329864501953 1.0034518241882324
loss:  25.711462020874023 0.9910998940467834
loss:  25.789043426513672 1.0079542398452759
loss:  25.578628540039062 0.9939571619033813
loss:  25.71555519104004 0.9975956082344055
loss:  25.33672523498535 0.9781399965286255
loss:  25.358787536621094 0.9702361822128296
loss:  25.24561882019043 0.9516386389732361
loss:  25.480968475341797 0.9684483408927917
loss:  25.94379425048828 0.9322431087493896
loss:  25.343839645385742 0.9585442543029785
loss:  25.421184539794922 0.9536033272743225
loss:  25.27016258239746 0.9807800054550171
loss:  25.568387985229492 0.9425255656242371
loss:  25.350061416625977 1.0032163858413696
loss:  25.42378807067871 0.9925612211227417
loss:  25.856761932373047 0.9607576131820679
*******************Epoch 50 ****************** 1020 1.0
Validation Loss
*** pred loss:  25.35945701599121 pred acc: 0.5829105973243713
*** stop loss:  5.971107482910156 stop acc: 0.9258717894554138
*** template loss:  7.279721736907959 template acc: tensor(0.1400, device='cuda:0')
*** label loss:  6.079225540161133 label acc: tensor(0.3868, device='cuda:0')
Train Loss
---> pred loss: 18.890089416503905 pred acc: 0.6949377626180648
---> stop loss: 3.6586288452148437 stop acc: 0.9583684653043747
---> template loss: 1.1223194122314453 tempalte acc: 0.7510181427001953
---> molecule label loss: 0.8992751121520997 molecule acc: 0.7924309253692627
---> kl loss: 0.9770970344543457
---> reconstruction loss: 24.570312023162842
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-51-with.npy
loss:  25.24368667602539 0.9599857926368713
loss:  25.3358154296875 0.9515920877456665
loss:  25.362483978271484 0.971638560295105
loss:  25.747140884399414 0.9683787822723389
loss:  25.103229522705078 0.9745054244995117
loss:  25.324975967407227 0.9366817474365234
loss:  25.448148727416992 0.9728624820709229
loss:  25.39963150024414 0.9795195460319519
loss:  25.488037109375 0.9923328161239624
loss:  24.977752685546875 0.9933943152427673
loss:  25.330974578857422 0.9989396929740906
loss:  25.62637710571289 0.9847143292427063
loss:  25.54709243774414 0.9871531128883362
loss:  25.305355072021484 0.977486789226532
loss:  25.940597534179688 0.9676389098167419
loss:  25.574462890625 0.9828975200653076
loss:  25.37309455871582 0.9428565502166748
loss:  25.259376525878906 0.928283154964447
loss:  24.850849151611328 0.9329153895378113
loss:  24.730497360229492 1.054207682609558
*******************Epoch 51 ****************** 1040 1.0
Validation Loss
*** pred loss:  25.217796325683594 pred acc: 0.5830917954444885
*** stop loss:  6.399827480316162 stop acc: 0.9224159717559814
*** template loss:  7.253822326660156 template acc: tensor(0.1389, device='cuda:0')
*** label loss:  6.019177436828613 label acc: tensor(0.3751, device='cuda:0')
Train Loss
---> pred loss: 18.80384521484375 pred acc: 0.6961850672960281
---> stop loss: 3.6422283172607424 stop acc: 0.9585324257612229
---> template loss: 1.0822696685791016 tempalte acc: 0.7602812767028808
---> molecule label loss: 0.8472368240356445 molecule acc: 0.8040353775024414
---> kl loss: 0.9728991508483886
---> reconstruction loss: 24.37557954788208
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-52-with.npy
loss:  25.21642303466797 0.9452213644981384
loss:  25.016366958618164 0.9624559283256531
loss:  25.493576049804688 0.9680994153022766
loss:  25.733484268188477 0.980597198009491
loss:  25.065954208374023 0.936357319355011
loss:  25.71959114074707 0.9927324056625366
loss:  25.58452606201172 0.9938628673553467
loss:  25.525188446044922 1.0003076791763306
loss:  25.202938079833984 0.9713394045829773
loss:  24.885969161987305 0.9677694439888
loss:  25.213979721069336 0.9612307548522949
loss:  25.003969192504883 0.9545176029205322
loss:  25.122098922729492 0.9868049025535583
loss:  25.09796714782715 0.966805100440979
loss:  25.093448638916016 0.9660822153091431
loss:  25.17045021057129 0.9358822703361511
loss:  25.085351943969727 0.9203019142150879
loss:  25.57830238342285 0.9313839077949524
loss:  25.326066970825195 0.9151609539985657
loss:  25.36376953125 0.9295735359191895
*******************Epoch 52 ****************** 1060 1.0
Validation Loss
*** pred loss:  25.225004196166992 pred acc: 0.5905193090438843
*** stop loss:  5.91904354095459 stop acc: 0.9264633059501648
*** template loss:  7.248990058898926 template acc: tensor(0.1442, device='cuda:0')
*** label loss:  6.084373950958252 label acc: tensor(0.3877, device='cuda:0')
Train Loss
---> pred loss: 18.765283203125 pred acc: 0.6960639715194702
---> stop loss: 3.689569091796875 stop acc: 0.9578549951314926
---> template loss: 1.04988431930542 tempalte acc: 0.7648104667663574
---> molecule label loss: 0.8109099388122558 molecule acc: 0.81126708984375
---> kl loss: 0.9593242645263672
---> reconstruction loss: 24.315648269653323
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-53-with.npy
loss:  24.750913619995117 0.9327941536903381
loss:  24.74562644958496 0.9089120626449585
loss:  25.20722198486328 0.9196347594261169
loss:  24.794286727905273 0.9222752451896667
loss:  24.903148651123047 0.9442392587661743
loss:  25.1166934967041 0.9492889642715454
loss:  24.695106506347656 0.9199290871620178
loss:  24.620019912719727 0.9158847332000732
loss:  25.072975158691406 0.9360584616661072
loss:  25.291725158691406 0.9293847680091858
loss:  24.802927017211914 0.9103439450263977
loss:  24.82559585571289 0.9649630784988403
loss:  25.279560089111328 0.9277006387710571
loss:  25.455097198486328 0.947946310043335
loss:  25.444351196289062 0.9539759159088135
loss:  26.174928665161133 0.9750068783760071
loss:  25.472318649291992 0.9477556943893433
loss:  25.822998046875 0.9527061581611633
loss:  25.74595832824707 0.9661345481872559
loss:  25.91480255126953 1.023419976234436
*******************Epoch 53 ****************** 1080 1.0
Validation Loss
*** pred loss:  25.483020782470703 pred acc: 0.5873792171478271
*** stop loss:  5.952827453613281 stop acc: 0.9259963035583496
*** template loss:  7.43305778503418 template acc: tensor(0.1199, device='cuda:0')
*** label loss:  6.090182781219482 label acc: tensor(0.3624, device='cuda:0')
Train Loss
---> pred loss: 18.669230651855468 pred acc: 0.6982430726289749
---> stop loss: 3.5920345306396486 stop acc: 0.959269541501999
---> template loss: 1.117339515686035 tempalte acc: 0.7495813369750977
---> molecule label loss: 0.8857895851135253 molecule acc: 0.7928679943084717
---> kl loss: 0.9424178123474121
---> reconstruction loss: 24.264395236968994
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-54-with.npy
loss:  25.401296615600586 0.9634300470352173
loss:  25.829208374023438 0.9620721340179443
loss:  25.75459098815918 0.927378237247467
loss:  25.986751556396484 0.9491189122200012
loss:  25.988279342651367 0.9342472553253174
loss:  26.55477523803711 0.9223470091819763
loss:  25.7546443939209 0.948309063911438
loss:  25.483062744140625 0.963126003742218
loss:  25.913454055786133 0.9778811931610107
loss:  25.609525680541992 0.9530024528503418
loss:  25.51263427734375 0.9380009174346924
loss:  26.000001907348633 0.9280785322189331
loss:  25.11741065979004 0.9225931763648987
loss:  25.04370880126953 0.9339020252227783
loss:  25.434558868408203 0.9314958453178406
loss:  24.806903839111328 0.9270488619804382
loss:  25.488136291503906 0.9271647334098816
loss:  24.91576385498047 0.9001834392547607
loss:  24.929529190063477 0.9207983613014221
loss:  26.071020126342773 0.9455226063728333
*******************Epoch 54 ****************** 1100 1.0
Validation Loss
*** pred loss:  25.31136703491211 pred acc: 0.5850241184234619
*** stop loss:  5.953012466430664 stop acc: 0.9273350238800049
*** template loss:  7.308133602142334 template acc: tensor(0.1266, device='cuda:0')
*** label loss:  5.971861362457275 label acc: tensor(0.3740, device='cuda:0')
Train Loss
---> pred loss: 18.64894256591797 pred acc: 0.6988028436899185
---> stop loss: 3.616985321044922 stop acc: 0.9586535125970841
---> template loss: 1.3208422660827637 tempalte acc: 0.7036036491394043
---> molecule label loss: 1.054206657409668 molecule acc: 0.748256778717041
---> kl loss: 0.9387849807739258
---> reconstruction loss: 24.640977287292483
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-55-with.npy
loss:  24.80337905883789 0.9154460430145264
loss:  24.80545997619629 0.9248245358467102
loss:  25.16495704650879 0.9662643074989319
loss:  25.383377075195312 0.9546294212341309
loss:  24.7010498046875 0.9334368705749512
loss:  25.322004318237305 0.9334742426872253
loss:  25.005590438842773 0.9581709504127502
loss:  25.132307052612305 0.954777181148529
loss:  24.740623474121094 0.9178135395050049
loss:  25.03519058227539 0.9349220395088196
loss:  24.773622512817383 0.9155977368354797
loss:  25.43799591064453 0.9279392957687378
loss:  24.724288940429688 0.9422388076782227
loss:  25.125099182128906 0.902108371257782
loss:  25.445865631103516 0.8790931701660156
loss:  24.91767692565918 0.9062746167182922
loss:  24.53435516357422 0.9119605422019958
loss:  24.802553176879883 0.9145367741584778
loss:  24.970373153686523 0.9205911755561829
loss:  24.389928817749023 0.8606663942337036
*******************Epoch 55 ****************** 1120 1.0
Validation Loss
*** pred loss:  25.276294708251953 pred acc: 0.5890700221061707
*** stop loss:  5.987890720367432 stop acc: 0.9272105097770691
*** template loss:  7.291783332824707 template acc: tensor(0.1407, device='cuda:0')
*** label loss:  6.016864776611328 label acc: tensor(0.3810, device='cuda:0')
Train Loss
---> pred loss: 18.48577423095703 pred acc: 0.7002811878919601
---> stop loss: 3.526647186279297 stop acc: 0.9601351350545884
---> template loss: 1.1448728561401367 tempalte acc: 0.742564344406128
---> molecule label loss: 0.8797497749328613 molecule acc: 0.7917881488800049
---> kl loss: 0.9237382888793946
---> reconstruction loss: 24.037045097351072
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-56-with.npy
loss:  24.6181640625 0.929293692111969
loss:  24.43490219116211 0.9023005962371826
loss:  24.99823760986328 0.9366399049758911
loss:  24.232892990112305 0.9263734221458435
loss:  24.82834815979004 0.9143801331520081
loss:  25.170042037963867 0.9358211159706116
loss:  24.66572380065918 0.9166998267173767
loss:  24.292198181152344 0.8860417604446411
loss:  24.425058364868164 0.8955808281898499
loss:  24.57720947265625 0.9197081923484802
loss:  24.801006317138672 0.8623590469360352
loss:  24.717300415039062 0.9232576489448547
loss:  24.104032516479492 0.8836197257041931
loss:  24.34690284729004 0.8760402202606201
loss:  24.90009880065918 0.8954644203186035
loss:  25.044252395629883 0.8740091919898987
loss:  24.685400009155273 0.8693803548812866
loss:  24.98070526123047 0.8926116228103638
loss:  24.899385452270508 0.9072055816650391
loss:  24.784412384033203 0.9369335770606995
*******************Epoch 56 ****************** 1140 1.0
Validation Loss
*** pred loss:  25.238954544067383 pred acc: 0.5861715078353882
*** stop loss:  6.234676361083984 stop acc: 0.9229452610015869
*** template loss:  7.261370658874512 template acc: tensor(0.1435, device='cuda:0')
*** label loss:  6.076842308044434 label acc: tensor(0.3883, device='cuda:0')
Train Loss
---> pred loss: 18.427752685546874 pred acc: 0.7024579644203186
---> stop loss: 3.4875545501708984 stop acc: 0.9604684263467789
---> template loss: 1.0576992988586427 tempalte acc: 0.7610169887542725
---> molecule label loss: 0.798119068145752 molecule acc: 0.8100876808166504
---> kl loss: 0.9041860580444336
---> reconstruction loss: 23.77112827301025
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-57-with.npy
loss:  24.358327865600586 0.8573823571205139
loss:  24.627809524536133 0.8709774017333984
loss:  24.46661376953125 0.8924968242645264
loss:  24.37254524230957 0.8728061318397522
loss:  24.586042404174805 0.8593529462814331
loss:  24.53277587890625 0.8666117191314697
loss:  24.619733810424805 0.8794223070144653
loss:  24.581789016723633 0.8767927885055542
loss:  24.217662811279297 0.8685520887374878
loss:  24.67139434814453 0.8924565315246582
loss:  24.221914291381836 0.8859920501708984
loss:  24.43204689025879 0.8875067830085754
loss:  24.722339630126953 0.8867147564888
loss:  24.625118255615234 0.8733632564544678
loss:  24.37442398071289 0.9026606678962708
loss:  24.546894073486328 0.9067728519439697
loss:  24.604400634765625 0.8880921006202698
loss:  24.65922737121582 0.87955641746521
loss:  24.598134994506836 0.9184790849685669
loss:  23.17230796813965 0.8756657242774963
*******************Epoch 57 ****************** 1160 1.0
Validation Loss
*** pred loss:  25.341327667236328 pred acc: 0.5890096426010132
*** stop loss:  6.005360126495361 stop acc: 0.9259963035583496
*** template loss:  7.260467052459717 template acc: tensor(0.1442, device='cuda:0')
*** label loss:  6.118414402008057 label acc: tensor(0.3875, device='cuda:0')
Train Loss
---> pred loss: 18.305271911621094 pred acc: 0.7029605656862259
---> stop loss: 3.516520690917969 stop acc: 0.9598374933004379
---> template loss: 1.0026971817016601 tempalte acc: 0.7744418144226074
---> molecule label loss: 0.7430028915405273 molecule acc: 0.8236771583557129
---> kl loss: 0.882082748413086
---> reconstruction loss: 23.567494583129882
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-58-with.npy
loss:  24.404584884643555 0.8952213525772095
loss:  24.003299713134766 0.8997263312339783
loss:  24.438188552856445 0.9066639542579651
loss:  24.310009002685547 0.8902607560157776
loss:  23.855497360229492 0.8759257197380066
loss:  24.6769962310791 0.907845675945282
loss:  23.872337341308594 0.8754017353057861
loss:  24.30533790588379 0.8815328478813171
loss:  24.19615364074707 0.8823065161705017
loss:  24.09868049621582 0.9042279720306396
loss:  24.653045654296875 0.8939090371131897
loss:  24.652177810668945 0.8898144960403442
loss:  24.686756134033203 0.8897508382797241
loss:  24.091646194458008 0.8894577026367188
loss:  24.677928924560547 0.8973119854927063
loss:  23.750446319580078 0.877485454082489
loss:  24.091209411621094 0.9096920490264893
loss:  24.33808135986328 0.9025927782058716
loss:  24.55487060546875 0.8780004382133484
loss:  23.945505142211914 0.9298660159111023
*******************Epoch 58 ****************** 1180 1.0
Validation Loss
*** pred loss:  25.177566528320312 pred acc: 0.5916062593460083
*** stop loss:  6.214704513549805 stop acc: 0.9230697751045227
*** template loss:  7.295418739318848 template acc: tensor(0.1428, device='cuda:0')
*** label loss:  6.122542858123779 label acc: tensor(0.3860, device='cuda:0')
Train Loss
---> pred loss: 18.250167846679688 pred acc: 0.7052945107221603
---> stop loss: 3.469777297973633 stop acc: 0.9608769297599793
---> template loss: 0.9557710647583008 tempalte acc: 0.7846186637878418
---> molecule label loss: 0.7105740547180176 molecule acc: 0.8319046974182129
---> kl loss: 0.8938496589660645
---> reconstruction loss: 23.386289501190184
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-59-with.npy
loss:  24.49816131591797 0.8956168293952942
loss:  24.46487808227539 0.8669618964195251
loss:  24.02519989013672 0.8501143455505371
loss:  24.072751998901367 0.8659905195236206
loss:  24.44123649597168 0.8696233630180359
loss:  24.519163131713867 0.8833664059638977
loss:  24.491823196411133 0.8704685568809509
loss:  23.659244537353516 0.8831143975257874
loss:  24.524738311767578 0.8771176338195801
loss:  24.538490295410156 0.885845959186554
loss:  23.98026466369629 0.880709707736969
loss:  24.207141876220703 0.8927785754203796
loss:  24.3198184967041 0.906421422958374
loss:  24.0712890625 0.8780244588851929
loss:  24.00105094909668 0.8711517453193665
loss:  23.525596618652344 0.8635141849517822
loss:  24.11115264892578 0.8485559821128845
loss:  24.66200828552246 0.8586030006408691
loss:  24.01957130432129 0.851108193397522
loss:  24.443620681762695 0.9272679090499878
*******************Epoch 59 ****************** 1200 1.0
Validation Loss
*** pred loss:  25.446367263793945 pred acc: 0.5888285040855408
*** stop loss:  6.0618205070495605 stop acc: 0.9268680214881897
*** template loss:  7.296932697296143 template acc: tensor(0.1400, device='cuda:0')
*** label loss:  6.098867893218994 label acc: tensor(0.3866, device='cuda:0')
Train Loss
---> pred loss: 18.242533874511718 pred acc: 0.7051459610462188
---> stop loss: 3.4816616058349608 stop acc: 0.9605857819318772
---> template loss: 0.9411711692810059 tempalte acc: 0.7894577980041504
---> molecule label loss: 0.6871747493743896 molecule acc: 0.8351651191711426
---> kl loss: 0.8763176918029785
---> reconstruction loss: 23.352542781829836
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-60-with.npy
loss:  23.80801773071289 0.8561550974845886
loss:  24.413562774658203 0.8576940298080444
loss:  23.97164535522461 0.8385515213012695
loss:  24.003318786621094 0.8332164287567139
loss:  23.561893463134766 0.8575726747512817
loss:  24.089935302734375 0.857938289642334
loss:  23.629108428955078 0.8807528018951416
loss:  23.877017974853516 0.8605847954750061
loss:  23.96558380126953 0.8832350373268127
loss:  24.254961013793945 0.8739163875579834
loss:  24.158065795898438 0.8717824816703796
loss:  24.01289176940918 0.8766785264015198
loss:  24.072254180908203 0.8774576187133789
loss:  24.099218368530273 0.875095009803772
loss:  23.972671508789062 0.8617695569992065
loss:  23.77473258972168 0.8671032786369324
loss:  23.51886558532715 0.8552520871162415
loss:  23.908397674560547 0.8673062920570374
loss:  24.089723587036133 0.847578227519989
loss:  25.91604995727539 0.823448657989502
*******************Epoch 60 ****************** 1220 1.0
Validation Loss
*** pred loss:  25.318695068359375 pred acc: 0.5882850289344788
*** stop loss:  5.981910228729248 stop acc: 0.9275841116905212
*** template loss:  7.3112263679504395 template acc: tensor(0.1435, device='cuda:0')
*** label loss:  6.118427276611328 label acc: tensor(0.3714, device='cuda:0')
Train Loss
---> pred loss: 18.214657592773438 pred acc: 0.7058649361133575
---> stop loss: 3.392381286621094 stop acc: 0.9617877155542374
---> template loss: 0.9168728828430176 tempalte acc: 0.7947585582733154
---> molecule label loss: 0.6698288440704345 molecule acc: 0.840218448638916
---> kl loss: 0.8611544609069824
---> reconstruction loss: 23.193739032745363
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-61-with.npy
loss:  23.606849670410156 0.8677225112915039
loss:  24.025318145751953 0.8479161858558655
loss:  24.06905746459961 0.8617377281188965
loss:  23.770158767700195 0.8687794804573059
loss:  23.82125473022461 0.9004864692687988
loss:  24.39590835571289 0.8852620124816895
loss:  23.81358528137207 0.8630019426345825
loss:  24.167264938354492 0.8650436401367188
loss:  23.816617965698242 0.8676663637161255
loss:  24.171165466308594 0.8398866653442383
loss:  23.934694290161133 0.8546743988990784
loss:  24.211462020874023 0.8450019359588623
loss:  23.38932991027832 0.85781329870224
loss:  24.033170700073242 0.8416023850440979
loss:  23.624832153320312 0.8525698184967041
loss:  23.533252716064453 0.8563688397407532
loss:  23.663959503173828 0.8455281257629395
loss:  23.50934410095215 0.8403308987617493
loss:  23.527738571166992 0.8466890454292297
loss:  24.651538848876953 0.7769923210144043
*******************Epoch 61 ****************** 1240 1.0
Validation Loss
*** pred loss:  25.55362892150879 pred acc: 0.58423912525177
*** stop loss:  6.019801616668701 stop acc: 0.9280199408531189
*** template loss:  7.3255205154418945 template acc: tensor(0.1467, device='cuda:0')
*** label loss:  6.206380844116211 label acc: tensor(0.3960, device='cuda:0')
Train Loss
---> pred loss: 18.082427978515625 pred acc: 0.707473772764206
---> stop loss: 3.404145050048828 stop acc: 0.9618992060422897
---> template loss: 0.8872217178344727 tempalte acc: 0.7993447780609131
---> molecule label loss: 0.6587776184082031 molecule acc: 0.8421477317810059
---> kl loss: 0.8542536735534668
---> reconstruction loss: 23.032571887969972
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-62-with.npy
loss:  23.716693878173828 0.8540505766868591
loss:  23.434959411621094 0.8519732356071472
loss:  24.14659881591797 0.8439707159996033
loss:  23.052167892456055 0.8624548316001892
loss:  23.722225189208984 0.8318189978599548
loss:  23.93514633178711 0.8561729192733765
loss:  23.591896057128906 0.8483105301856995
loss:  23.795469284057617 0.8614659309387207
loss:  24.207679748535156 0.8287929892539978
loss:  23.87361717224121 0.8562034964561462
loss:  23.903614044189453 0.8214846849441528
loss:  23.741559982299805 0.8383345603942871
loss:  23.866458892822266 0.8437128067016602
loss:  23.459793090820312 0.8445212841033936
loss:  23.35759925842285 0.8294678330421448
loss:  24.550077438354492 0.8523662686347961
loss:  23.907424926757812 0.8480075597763062
loss:  23.9726619720459 0.8492491245269775
loss:  23.5611515045166 0.8573957085609436
loss:  22.71391487121582 0.8753129243850708
*******************Epoch 62 ****************** 1260 1.0
Validation Loss
*** pred loss:  25.364484786987305 pred acc: 0.5871376395225525
*** stop loss:  6.005733013153076 stop acc: 0.928300142288208
*** template loss:  7.325243949890137 template acc: tensor(0.1467, device='cuda:0')
*** label loss:  6.1941962242126465 label acc: tensor(0.3898, device='cuda:0')
Train Loss
---> pred loss: 18.004881286621092 pred acc: 0.7072530120611191
---> stop loss: 3.3848190307617188 stop acc: 0.9617829352617264
---> template loss: 0.8628622055053711 tempalte acc: 0.8057761192321777
---> molecule label loss: 0.6252218723297119 molecule acc: 0.8493188858032227
---> kl loss: 0.8477533340454102
---> reconstruction loss: 22.87778377532959
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-63-with.npy
loss:  23.21837043762207 0.8581047058105469
loss:  23.22044563293457 0.8902471661567688
loss:  23.570589065551758 0.8667504787445068
loss:  23.22359848022461 0.8569349646568298
loss:  23.42230224609375 0.8713908195495605
loss:  23.599224090576172 0.8505191206932068
loss:  23.763267517089844 0.8434536457061768
loss:  23.432504653930664 0.8418387174606323
loss:  23.450763702392578 0.8738741874694824
loss:  23.535268783569336 0.8681447505950928
loss:  23.517648696899414 0.866772472858429
loss:  23.594614028930664 0.8496613502502441
loss:  23.550323486328125 0.8767473697662354
loss:  23.561050415039062 0.8644190430641174
loss:  23.887601852416992 0.8700510263442993
loss:  23.3052978515625 0.8529627323150635
loss:  23.597686767578125 0.826772928237915
loss:  23.817384719848633 0.8099077343940735
loss:  24.07992172241211 0.8131617307662964
loss:  24.258346557617188 0.9206686019897461
*******************Epoch 63 ****************** 1280 1.0
Validation Loss
*** pred loss:  25.674537658691406 pred acc: 0.5856884121894836
*** stop loss:  6.335110187530518 stop acc: 0.9253736138343811
*** template loss:  7.34005069732666 template acc: tensor(0.1435, device='cuda:0')
*** label loss:  6.189030647277832 label acc: tensor(0.3887, device='cuda:0')
Train Loss
---> pred loss: 17.91951141357422 pred acc: 0.7114744812250138
---> stop loss: 3.345131683349609 stop acc: 0.9627765357494354
---> template loss: 0.8574753761291504 tempalte acc: 0.808928394317627
---> molecule label loss: 0.5995723724365234 molecule acc: 0.8555560111999512
---> kl loss: 0.8586191177368164
---> reconstruction loss: 22.721690940856934
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-64-with.npy
loss:  23.17037582397461 0.8082529902458191
loss:  24.10548210144043 0.8306791186332703
loss:  23.57293701171875 0.8422865867614746
loss:  23.51795768737793 0.8505262732505798
loss:  22.887409210205078 0.8077285289764404
loss:  23.22044563293457 0.8328772187232971
loss:  23.373647689819336 0.8276602625846863
loss:  23.52180290222168 0.8275886178016663
loss:  23.432395935058594 0.8129898309707642
loss:  23.780702590942383 0.8507992625236511
loss:  23.71480369567871 0.8570401668548584
loss:  23.207746505737305 0.8084971308708191
loss:  23.18243980407715 0.8387884497642517
loss:  23.581058502197266 0.8354367017745972
loss:  23.640541076660156 0.8337157368659973
loss:  23.330568313598633 0.8360075950622559
loss:  23.753463745117188 0.8285747766494751
loss:  23.529722213745117 0.8295180201530457
loss:  23.312658309936523 0.8813884854316711
loss:  22.88715934753418 0.8219941854476929
*******************Epoch 64 ****************** 1300 1.0
Validation Loss
*** pred loss:  25.692747116088867 pred acc: 0.585446834564209
*** stop loss:  6.095576763153076 stop acc: 0.9274907112121582
*** template loss:  7.337130069732666 template acc: tensor(0.1456, device='cuda:0')
*** label loss:  6.135703086853027 label acc: tensor(0.3736, device='cuda:0')
Train Loss
---> pred loss: 17.83905792236328 pred acc: 0.7112508982419967
---> stop loss: 3.327142333984375 stop acc: 0.9623706996440887
---> template loss: 0.840579891204834 tempalte acc: 0.8107170104980469
---> molecule label loss: 0.5962700366973877 molecule acc: 0.8558509826660157
---> kl loss: 0.8331175804138183
---> reconstruction loss: 22.60304727554321
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-65-with.npy
loss:  23.87436866760254 0.8511046171188354
loss:  23.686527252197266 0.8644421100616455
loss:  23.739404678344727 0.8437435626983643
loss:  23.487022399902344 0.8457056283950806
loss:  23.303260803222656 0.8338039517402649
loss:  23.06596565246582 0.818777859210968
loss:  23.46169090270996 0.829071044921875
loss:  23.796205520629883 0.8186103701591492
loss:  23.05014419555664 0.8254197239875793
loss:  23.470590591430664 0.8150607347488403
loss:  22.79839324951172 0.8071621060371399
loss:  23.172462463378906 0.8070387840270996
loss:  23.457048416137695 0.7980480790138245
loss:  22.986867904663086 0.8151945471763611
loss:  23.173372268676758 0.7977663278579712
loss:  23.249582290649414 0.8145176768302917
loss:  23.378944396972656 0.7895771861076355
loss:  23.461021423339844 0.7916923761367798
loss:  23.01141357421875 0.7974829077720642
loss:  22.7979793548584 0.7928788065910339
*******************Epoch 65 ****************** 1320 1.0
Validation Loss
*** pred loss:  25.625024795532227 pred acc: 0.5851449370384216
*** stop loss:  6.267029762268066 stop acc: 0.9262765049934387
*** template loss:  7.302456855773926 template acc: tensor(0.1435, device='cuda:0')
*** label loss:  6.1042962074279785 label acc: tensor(0.3787, device='cuda:0')
Train Loss
---> pred loss: 17.765715026855467 pred acc: 0.7116767674684524
---> stop loss: 3.313447952270508 stop acc: 0.9625518381595611
---> template loss: 0.8375460624694824 tempalte acc: 0.8113958358764648
---> molecule label loss: 0.5865493774414062 molecule acc: 0.8554080963134766
---> kl loss: 0.8178549766540527
---> reconstruction loss: 22.503258609771727
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-66-with.npy
loss:  22.954132080078125 0.7915998697280884
loss:  23.462182998657227 0.797927737236023
loss:  23.37372398376465 0.8416831493377686
loss:  23.55460548400879 0.8282186388969421
loss:  23.348203659057617 0.8346478343009949
loss:  23.196367263793945 0.8449423313140869
loss:  23.199174880981445 0.8410347700119019
loss:  23.204299926757812 0.8556321263313293
loss:  23.113073348999023 0.8244137167930603
loss:  23.192790985107422 0.8261783123016357
loss:  22.95905113220215 0.8454265594482422
loss:  23.69077491760254 0.8551483154296875
loss:  22.69429588317871 0.8429028987884521
loss:  23.107677459716797 0.8414581418037415
loss:  23.30501937866211 0.7874128222465515
loss:  22.901416778564453 0.8129932284355164
loss:  23.02391242980957 0.8276835680007935
loss:  23.058143615722656 0.7857529520988464
loss:  23.055339813232422 0.7856809496879578
loss:  23.819660186767578 0.8648505210876465
*******************Epoch 66 ****************** 1340 1.0
Validation Loss
*** pred loss:  25.814674377441406 pred acc: 0.5870168805122375
*** stop loss:  6.319045543670654 stop acc: 0.9255293011665344
*** template loss:  7.322671890258789 template acc: tensor(0.1446, device='cuda:0')
*** label loss:  6.247757911682129 label acc: tensor(0.3930, device='cuda:0')
Train Loss
---> pred loss: 17.74968719482422 pred acc: 0.7137163311243058
---> stop loss: 3.264369583129883 stop acc: 0.9634745359420777
---> template loss: 0.7973892688751221 tempalte acc: 0.8220786094665528
---> molecule label loss: 0.5724660396575928 molecule acc: 0.8583759307861328
---> kl loss: 0.8267794609069824
---> reconstruction loss: 22.383913898468016
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-67-with.npy
loss:  22.871826171875 0.8198769092559814
loss:  23.2696533203125 0.8439388275146484
loss:  23.089906692504883 0.8559984564781189
loss:  23.33225440979004 0.7931723594665527
loss:  23.49300765991211 0.8131304979324341
loss:  22.914722442626953 0.808729887008667
loss:  22.89149284362793 0.823107898235321
loss:  23.14559555053711 0.813808798789978
loss:  22.97933006286621 0.824413001537323
loss:  23.51310157775879 0.8157786726951599
loss:  23.22772789001465 0.8229004144668579
loss:  23.315811157226562 0.8199390769004822
loss:  23.089115142822266 0.8146066665649414
loss:  22.758323669433594 0.796981930732727
loss:  22.700563430786133 0.7989347577095032
loss:  23.034156799316406 0.7966888546943665
loss:  23.100345611572266 0.7999091148376465
loss:  23.177553176879883 0.8144810199737549
loss:  22.940086364746094 0.7922311425209045
loss:  23.634511947631836 0.8000864386558533
*******************Epoch 67 ****************** 1360 1.0
Validation Loss
*** pred loss:  25.743471145629883 pred acc: 0.5855675935745239
*** stop loss:  6.180762767791748 stop acc: 0.9261831045150757
*** template loss:  7.327455997467041 template acc: tensor(0.1446, device='cuda:0')
*** label loss:  6.177077293395996 label acc: tensor(0.3907, device='cuda:0')
Train Loss
---> pred loss: 17.660603332519532 pred acc: 0.7142673611640931
---> stop loss: 3.3176830291748045 stop acc: 0.9627542316913604
---> template loss: 0.7882148742675781 tempalte acc: 0.8244093894958496
---> molecule label loss: 0.5440175533294678 molecule acc: 0.867159366607666
---> kl loss: 0.8134357452392578
---> reconstruction loss: 22.31051902770996
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-68-with.npy
loss:  23.31580352783203 0.8136701583862305
loss:  22.798908233642578 0.8048286437988281
loss:  22.759838104248047 0.7892698049545288
loss:  22.90869140625 0.826229989528656
loss:  23.02653694152832 0.832096517086029
loss:  22.918575286865234 0.7985419034957886
loss:  22.96660614013672 0.8250473737716675
loss:  22.772356033325195 0.822420060634613
loss:  22.91139030456543 0.8376553654670715
loss:  23.498828887939453 0.8417866230010986
loss:  22.785106658935547 0.8438894748687744
loss:  22.82402801513672 0.7980607748031616
loss:  22.956262588500977 0.8194226026535034
loss:  22.748981475830078 0.819606602191925
loss:  23.244346618652344 0.8127004504203796
loss:  22.907304763793945 0.8181436657905579
loss:  23.01639747619629 0.8138111233711243
loss:  23.037235260009766 0.8140148520469666
loss:  23.14117431640625 0.7984087467193604
loss:  23.079526901245117 0.7676903009414673
*******************Epoch 68 ****************** 1380 1.0
Validation Loss
*** pred loss:  25.50258445739746 pred acc: 0.588164210319519
*** stop loss:  6.596053123474121 stop acc: 0.9223225712776184
*** template loss:  7.366473197937012 template acc: tensor(0.1467, device='cuda:0')
*** label loss:  6.257203102111816 label acc: tensor(0.3842, device='cuda:0')
Train Loss
---> pred loss: 17.585476684570313 pred acc: 0.7157624423503876
---> stop loss: 3.316991424560547 stop acc: 0.9627579480409623
---> template loss: 0.7535340309143066 tempalte acc: 0.8339834213256836
---> molecule label loss: 0.5100292205810547 molecule acc: 0.8739215850830078
---> kl loss: 0.8148647308349609
---> reconstruction loss: 22.166031265258788
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-69-with.npy
loss:  22.806411743164062 0.7940906882286072
loss:  22.596393585205078 0.8129385709762573
loss:  23.192785263061523 0.8009766936302185
loss:  22.97454261779785 0.8077641129493713
loss:  23.008024215698242 0.7936108112335205
loss:  23.090787887573242 0.8060811758041382
loss:  23.421852111816406 0.7918398976325989
loss:  23.323177337646484 0.7918443083763123
loss:  22.626209259033203 0.8006452918052673
loss:  23.279752731323242 0.8189290761947632
loss:  22.912118911743164 0.7933529019355774
loss:  22.392669677734375 0.7725003957748413
loss:  22.793472290039062 0.8052748441696167
loss:  22.885700225830078 0.7953534722328186
loss:  22.719823837280273 0.8178939819335938
loss:  22.60725975036621 0.7933388352394104
loss:  22.933876037597656 0.8034118413925171
loss:  22.55556869506836 0.7723697423934937
loss:  22.790170669555664 0.8040350079536438
loss:  23.446374893188477 0.7414776682853699
*******************Epoch 69 ****************** 1400 1.0
Validation Loss
*** pred loss:  25.559328079223633 pred acc: 0.588707685470581
*** stop loss:  6.058622360229492 stop acc: 0.9273039102554321
*** template loss:  7.408740520477295 template acc: tensor(0.1509, device='cuda:0')
*** label loss:  6.3534135818481445 label acc: tensor(0.3928, device='cuda:0')
Train Loss
---> pred loss: 17.551963806152344 pred acc: 0.7150138676166534
---> stop loss: 3.278879165649414 stop acc: 0.9631446093320847
---> template loss: 0.7631638526916504 tempalte acc: 0.8314951896667481
---> molecule label loss: 0.527956199645996 molecule acc: 0.8691250801086425
---> kl loss: 0.7958864688873291
---> reconstruction loss: 22.121963262557983
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-70-with.npy
loss:  22.794898986816406 0.823759138584137
loss:  22.34175682067871 0.8065837025642395
loss:  22.578746795654297 0.8337871432304382
loss:  23.034822463989258 0.8330367207527161
loss:  22.867881774902344 0.8237617611885071
loss:  22.62281036376953 0.8065789341926575
loss:  22.718334197998047 0.8022654056549072
loss:  22.781938552856445 0.8193696737289429
loss:  22.8533992767334 0.7979666590690613
loss:  22.512371063232422 0.7802006006240845
loss:  22.92519187927246 0.7949758768081665
loss:  22.73079490661621 0.7834656834602356
loss:  22.329879760742188 0.7734643220901489
loss:  22.403717041015625 0.7780304551124573
loss:  22.90077018737793 0.7763017416000366
loss:  22.494943618774414 0.7828022837638855
loss:  22.886322021484375 0.7928044199943542
loss:  22.471023559570312 0.7638988494873047
loss:  22.824081420898438 0.781383752822876
loss:  23.55665397644043 0.7930763363838196
*******************Epoch 70 ****************** 1420 1.0
Validation Loss
*** pred loss:  25.793546676635742 pred acc: 0.5861715078353882
*** stop loss:  6.2275238037109375 stop acc: 0.9262142181396484
*** template loss:  7.35753059387207 template acc: tensor(0.1498, device='cuda:0')
*** label loss:  6.385523796081543 label acc: tensor(0.3960, device='cuda:0')
Train Loss
---> pred loss: 17.45935821533203 pred acc: 0.7170838475227356
---> stop loss: 3.203019714355469 stop acc: 0.9640283048152923
---> template loss: 0.7524688243865967 tempalte acc: 0.8330191612243653
---> molecule label loss: 0.5192914962768554 molecule acc: 0.8705463409423828
---> kl loss: 0.7973756790161133
---> reconstruction loss: 21.934139823913576
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-71-with.npy
loss:  22.415889739990234 0.7886622548103333
loss:  22.26648712158203 0.7986297607421875
loss:  23.155479431152344 0.8230631351470947
loss:  22.57411766052246 0.8144133687019348
loss:  22.21761131286621 0.7930992245674133
loss:  22.99991226196289 0.8176118731498718
loss:  22.814544677734375 0.836969256401062
loss:  22.724323272705078 0.8257396817207336
loss:  22.59964370727539 0.8448807597160339
loss:  22.996305465698242 0.818958580493927
loss:  22.66702651977539 0.8049964904785156
loss:  22.61508560180664 0.7885997295379639
loss:  22.43523597717285 0.8146116137504578
loss:  22.786882400512695 0.802738606929779
loss:  23.426698684692383 0.807113528251648
loss:  22.43221664428711 0.802042543888092
loss:  22.520910263061523 0.7882848978042603
loss:  22.282604217529297 0.811924934387207
loss:  22.14043617248535 0.7850968241691589
loss:  23.507360458374023 0.8130619525909424
*******************Epoch 71 ****************** 1440 1.0
Validation Loss
*** pred loss:  25.65700340270996 pred acc: 0.5897946953773499
*** stop loss:  6.185431957244873 stop acc: 0.92693030834198
*** template loss:  7.411184787750244 template acc: tensor(0.1428, device='cuda:0')
*** label loss:  6.384925365447998 label acc: tensor(0.3926, device='cuda:0')
Train Loss
---> pred loss: 17.354226684570314 pred acc: 0.7190226793289185
---> stop loss: 3.236685562133789 stop acc: 0.9635777592658996
---> template loss: 0.7611835956573486 tempalte acc: 0.8280925750732422
---> molecule label loss: 0.517814826965332 molecule acc: 0.8703600883483886
---> kl loss: 0.8090250015258789
---> reconstruction loss: 21.86991329193115
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-72-with.npy
loss:  22.214136123657227 0.8005472421646118
loss:  22.614036560058594 0.8232967257499695
loss:  22.725269317626953 0.8243178129196167
loss:  22.8818416595459 0.8113138675689697
loss:  22.671676635742188 0.8141511678695679
loss:  22.408905029296875 0.8141016364097595
loss:  22.78556251525879 0.7971383929252625
loss:  22.76891326904297 0.804041862487793
loss:  22.366912841796875 0.8070638179779053
loss:  22.11040687561035 0.7904283404350281
loss:  23.152280807495117 0.8001976609230042
loss:  22.432615280151367 0.8025453686714172
loss:  22.525598526000977 0.8032573461532593
loss:  22.746232986450195 0.7915356755256653
loss:  22.686431884765625 0.8019633293151855
loss:  22.601747512817383 0.7680248618125916
loss:  22.355152130126953 0.7690367698669434
loss:  22.41865348815918 0.7756315469741821
loss:  22.251758575439453 0.8102627396583557
loss:  23.497764587402344 0.7697915434837341
*******************Epoch 72 ****************** 1460 1.0
Validation Loss
*** pred loss:  25.74298667907715 pred acc: 0.5861715078353882
*** stop loss:  6.1313157081604 stop acc: 0.9275841116905212
*** template loss:  7.399866580963135 template acc: tensor(0.1484, device='cuda:0')
*** label loss:  6.414320468902588 label acc: tensor(0.3947, device='cuda:0')
Train Loss
---> pred loss: 17.329815673828126 pred acc: 0.7186185836791992
---> stop loss: 3.2131237030029296 stop acc: 0.9638554662466049
---> template loss: 0.7575865268707276 tempalte acc: 0.8305500030517579
---> molecule label loss: 0.5113379001617432 molecule acc: 0.8708146095275879
---> kl loss: 0.7989323616027832
---> reconstruction loss: 21.81186475753784
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-73-with.npy
loss:  22.356285095214844 0.8167113065719604
loss:  22.816354751586914 0.7907199263572693
loss:  22.85715675354004 0.8203088641166687
loss:  22.52957534790039 0.7951375842094421
loss:  22.36780548095703 0.8091478943824768
loss:  22.497774124145508 0.7982596755027771
loss:  22.60943031311035 0.8055588006973267
loss:  22.43384552001953 0.7862234711647034
loss:  22.365163803100586 0.792799174785614
loss:  22.419851303100586 0.7417423129081726
loss:  22.091764450073242 0.7759518623352051
loss:  22.412424087524414 0.7749121189117432
loss:  22.54345703125 0.791628897190094
loss:  22.17364501953125 0.7862399220466614
loss:  22.848861694335938 0.7957196235656738
loss:  22.85861587524414 0.7819894552230835
loss:  23.319921493530273 0.7720810174942017
loss:  23.91211700439453 0.755902111530304
loss:  23.428621292114258 0.7596812844276428
loss:  24.723880767822266 0.7332584261894226
*******************Epoch 73 ****************** 1480 1.0
Validation Loss
*** pred loss:  25.805465698242188 pred acc: 0.5840579271316528
*** stop loss:  6.323594093322754 stop acc: 0.9254670143127441
*** template loss:  7.841779708862305 template acc: tensor(0.1161, device='cuda:0')
*** label loss:  6.299013137817383 label acc: tensor(0.3365, device='cuda:0')
Train Loss
---> pred loss: 17.25281677246094 pred acc: 0.7203564345836639
---> stop loss: 3.1578798294067383 stop acc: 0.9644554615020752
---> template loss: 0.9738771438598632 tempalte acc: 0.7880025863647461
---> molecule label loss: 0.6095555305480957 molecule acc: 0.8464137077331543
---> kl loss: 0.7841987133026123
---> reconstruction loss: 21.994126176834108
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-74-with.npy
loss:  23.783973693847656 0.7671657204627991
loss:  23.970840454101562 0.7766042947769165
loss:  23.94146728515625 0.7672850489616394
loss:  23.642887115478516 0.7588381767272949
loss:  24.04720687866211 0.765930712223053
loss:  23.738494873046875 0.7793080806732178
loss:  23.8620548248291 0.7664819359779358
loss:  23.639545440673828 0.8051859140396118
loss:  23.397096633911133 0.7977390885353088
loss:  23.88208770751953 0.8233916163444519
loss:  23.282028198242188 0.7814812660217285
loss:  23.280317306518555 0.7822862863540649
loss:  23.797422409057617 0.8013148903846741
loss:  22.974637985229492 0.7768868207931519
loss:  23.287124633789062 0.8043310046195984
loss:  23.40987777709961 0.7892763614654541
loss:  23.084270477294922 0.7976148724555969
loss:  23.580347061157227 0.8036991953849792
loss:  23.291641235351562 0.7900819778442383
loss:  23.849464416503906 0.8689817190170288
*******************Epoch 74 ****************** 1500 1.0
Validation Loss
*** pred loss:  25.714460372924805 pred acc: 0.5912439227104187
*** stop loss:  6.176229476928711 stop acc: 0.9266189336776733
*** template loss:  7.426794528961182 template acc: tensor(0.1214, device='cuda:0')
*** label loss:  6.254499435424805 label acc: tensor(0.3838, device='cuda:0')
Train Loss
---> pred loss: 17.24236297607422 pred acc: 0.7188734263181686
---> stop loss: 3.150605583190918 stop acc: 0.964516106247902
---> template loss: 1.3951732635498046 tempalte acc: 0.6850085735321045
---> molecule label loss: 1.0088051795959472 molecule acc: 0.7401578903198243
---> kl loss: 0.7901942729949951
---> reconstruction loss: 22.796944093704223
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-75-with.npy
loss:  22.95846939086914 0.7960586547851562
loss:  22.912914276123047 0.7870340347290039
loss:  22.993024826049805 0.7808479070663452
loss:  23.023818969726562 0.78091961145401
loss:  22.961997985839844 0.7953084707260132
loss:  22.898223876953125 0.8042798638343811
loss:  22.722618103027344 0.8169682025909424
loss:  22.743101119995117 0.7844059467315674
loss:  22.778141021728516 0.780609130859375
loss:  22.518590927124023 0.8027512431144714
loss:  22.557109832763672 0.7839020490646362
loss:  22.545757293701172 0.816536009311676
loss:  22.888320922851562 0.7688189148902893
loss:  22.13115692138672 0.7637158632278442
loss:  22.593021392822266 0.8043117523193359
loss:  23.001232147216797 0.7882964015007019
loss:  22.763465881347656 0.7668803930282593
loss:  22.199068069458008 0.7837924957275391
loss:  22.75693130493164 0.7782410979270935
loss:  23.31693458557129 0.775316059589386
*******************Epoch 75 ****************** 1520 1.0
Validation Loss
*** pred loss:  25.91605567932129 pred acc: 0.584782600402832
*** stop loss:  6.230811595916748 stop acc: 0.9252179861068726
*** template loss:  7.382528781890869 template acc: tensor(0.1407, device='cuda:0')
*** label loss:  6.145364284515381 label acc: tensor(0.3935, device='cuda:0')
Train Loss
---> pred loss: 17.170179748535155 pred acc: 0.7219716072082519
---> stop loss: 3.148724365234375 stop acc: 0.9646400600671768
---> template loss: 1.011673641204834 tempalte acc: 0.765893030166626
---> molecule label loss: 0.6446672439575195 molecule acc: 0.8337157249450684
---> kl loss: 0.7879496574401855
---> reconstruction loss: 21.975243091583252
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-76-with.npy
loss:  21.876548767089844 0.7884398102760315
loss:  22.30921745300293 0.8053215146064758
loss:  22.170522689819336 0.7793914079666138
loss:  22.432771682739258 0.7726916670799255
loss:  22.490020751953125 0.7778792977333069
loss:  22.607852935791016 0.7964711785316467
loss:  22.15528678894043 0.7791218757629395
loss:  22.606033325195312 0.7569863796234131
loss:  22.369491577148438 0.7508693933486938
loss:  22.577775955200195 0.7486591339111328
loss:  22.091007232666016 0.7699481248855591
loss:  22.285390853881836 0.7454754710197449
loss:  22.45338249206543 0.7433923482894897
loss:  21.797035217285156 0.745986819267273
loss:  22.459028244018555 0.7508604526519775
loss:  22.675161361694336 0.7749532461166382
loss:  22.328125 0.7697635889053345
loss:  22.234092712402344 0.761776864528656
loss:  21.908960342407227 0.7511325478553772
loss:  21.134471893310547 0.7516546249389648
*******************Epoch 76 ****************** 1540 1.0
Validation Loss
*** pred loss:  25.84044647216797 pred acc: 0.5891907811164856
*** stop loss:  6.2122392654418945 stop acc: 0.9261519908905029
*** template loss:  7.438353538513184 template acc: tensor(0.1393, device='cuda:0')
*** label loss:  6.207603931427002 label acc: tensor(0.4016, device='cuda:0')
Train Loss
---> pred loss: 17.051141357421876 pred acc: 0.7227539390325546
---> stop loss: 3.066902732849121 stop acc: 0.9657953292131424
---> template loss: 0.847709846496582 tempalte acc: 0.8044722557067872
---> molecule label loss: 0.5163167953491211 molecule acc: 0.8683245658874512
---> kl loss: 0.7660387992858887
---> reconstruction loss: 21.482069110870363
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-77-with.npy
loss:  21.526264190673828 0.789241373538971
loss:  22.257667541503906 0.7677618265151978
loss:  22.409685134887695 0.7575615644454956
loss:  21.722192764282227 0.766340970993042
loss:  21.938690185546875 0.7649927139282227
loss:  22.330020904541016 0.7892770767211914
loss:  22.349180221557617 0.7658856511116028
loss:  21.887451171875 0.7684981822967529
loss:  21.808626174926758 0.7559559345245361
loss:  22.40026092529297 0.7684144377708435
loss:  21.86304473876953 0.764809250831604
loss:  22.404150009155273 0.7597538828849792
loss:  21.948469161987305 0.7642190456390381
loss:  21.818893432617188 0.748608410358429
loss:  21.745807647705078 0.7605251669883728
loss:  22.086122512817383 0.7533684372901917
loss:  22.288867950439453 0.7426223754882812
loss:  22.30795669555664 0.7260327339172363
loss:  22.171186447143555 0.7406157851219177
loss:  21.711854934692383 0.7589215636253357
*******************Epoch 77 ****************** 1560 1.0
Validation Loss
*** pred loss:  25.899524688720703 pred acc: 0.5916062593460083
*** stop loss:  6.177367687225342 stop acc: 0.9278954267501831
*** template loss:  7.412848472595215 template acc: tensor(0.1379, device='cuda:0')
*** label loss:  6.188253879547119 label acc: tensor(0.4037, device='cuda:0')
Train Loss
---> pred loss: 17.00067596435547 pred acc: 0.7224476665258408
---> stop loss: 3.0624948501586915 stop acc: 0.9659266889095306
---> template loss: 0.767585277557373 tempalte acc: 0.8262246131896973
---> molecule label loss: 0.45739498138427737 molecule acc: 0.8840452194213867
---> kl loss: 0.7606703281402588
---> reconstruction loss: 21.2881471157074
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-78-with.npy
loss:  22.210617065429688 0.7593852281570435
loss:  21.993125915527344 0.7484574913978577
loss:  22.338111877441406 0.7751784324645996
loss:  22.01329231262207 0.7817548513412476
loss:  21.682239532470703 0.7546212077140808
loss:  22.064067840576172 0.7667055130004883
loss:  21.895523071289062 0.7760195732116699
loss:  21.919952392578125 0.7597358226776123
loss:  21.662092208862305 0.7481952905654907
loss:  21.83525848388672 0.7803700566291809
loss:  21.98898696899414 0.76048743724823
loss:  22.02918815612793 0.7592707276344299
loss:  21.850526809692383 0.7200201749801636
loss:  21.950090408325195 0.7470417022705078
loss:  21.821287155151367 0.7463615536689758
loss:  21.893630981445312 0.7493725419044495
loss:  21.546939849853516 0.7542795538902283
loss:  21.872652053833008 0.7266886830329895
loss:  21.860450744628906 0.7452948093414307
loss:  21.874876022338867 0.7532550096511841
*******************Epoch 78 ****************** 1580 1.0
Validation Loss
*** pred loss:  25.976764678955078 pred acc: 0.5870168805122375
*** stop loss:  6.7006402015686035 stop acc: 0.9244396090507507
*** template loss:  7.370772838592529 template acc: tensor(0.1410, device='cuda:0')
*** label loss:  6.235323905944824 label acc: tensor(0.3999, device='cuda:0')
Train Loss
---> pred loss: 16.974546813964842 pred acc: 0.7244312733411788
---> stop loss: 3.048410415649414 stop acc: 0.9660804241895675
---> template loss: 0.7158468723297119 tempalte acc: 0.8391856193542481
---> molecule label loss: 0.4207168102264404 molecule acc: 0.8930675506591796
---> kl loss: 0.7556247234344482
---> reconstruction loss: 21.15952115058899
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-79-with.npy
loss:  21.863527297973633 0.7353217601776123
loss:  21.566038131713867 0.7339619398117065
loss:  21.501798629760742 0.7405261397361755
loss:  21.681324005126953 0.7471329569816589
loss:  22.035276412963867 0.753452718257904
loss:  21.750816345214844 0.7382763624191284
loss:  22.05617332458496 0.7313041687011719
loss:  21.95977020263672 0.7339635491371155
loss:  21.908418655395508 0.7496119141578674
loss:  22.01849937438965 0.7592604756355286
loss:  21.801170349121094 0.7531397342681885
loss:  21.7910213470459 0.7555174231529236
loss:  21.51917839050293 0.7339425683021545
loss:  22.049299240112305 0.7468672394752502
loss:  21.261049270629883 0.7432345747947693
loss:  22.181367874145508 0.7596940398216248
loss:  21.929128646850586 0.7571422457695007
loss:  21.9951229095459 0.747042179107666
loss:  21.81517219543457 0.7497889399528503
loss:  24.399179458618164 0.7769149541854858
*******************Epoch 79 ****************** 1600 1.0
Validation Loss
*** pred loss:  26.12135124206543 pred acc: 0.5813405513763428
*** stop loss:  6.517550468444824 stop acc: 0.9271482229232788
*** template loss:  7.403436660766602 template acc: tensor(0.1481, device='cuda:0')
*** label loss:  6.242239475250244 label acc: tensor(0.3958, device='cuda:0')
Train Loss
---> pred loss: 17.000054931640626 pred acc: 0.7256870955228806
---> stop loss: 3.1069852828979494 stop acc: 0.9656190931797027
---> template loss: 0.6952467441558838 tempalte acc: 0.8436067581176758
---> molecule label loss: 0.40457544326782224 molecule acc: 0.8979608535766601
---> kl loss: 0.7473047733306885
---> reconstruction loss: 21.206859350204468
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-80-with.npy
loss:  21.730764389038086 0.7571340203285217
loss:  21.891963958740234 0.7560551762580872
loss:  21.57225227355957 0.7462075352668762
loss:  22.242263793945312 0.7597278356552124
loss:  21.69256591796875 0.7467432022094727
loss:  21.816789627075195 0.7524036169052124
loss:  21.835420608520508 0.7604413032531738
loss:  21.74605941772461 0.7515444755554199
loss:  21.558368682861328 0.7404230833053589
loss:  21.90323829650879 0.723764955997467
loss:  22.032737731933594 0.7479496598243713
loss:  22.057445526123047 0.7439970374107361
loss:  21.960723876953125 0.7584146857261658
loss:  21.416410446166992 0.7481293678283691
loss:  21.44144630432129 0.7589127421379089
loss:  21.42228126525879 0.7491554021835327
loss:  21.854324340820312 0.732623279094696
loss:  21.693275451660156 0.7468456625938416
loss:  22.215038299560547 0.7705057263374329
loss:  22.293882369995117 0.7209933996200562
*******************Epoch 80 ****************** 1620 1.0
Validation Loss
*** pred loss:  26.24656105041504 pred acc: 0.5867149829864502
*** stop loss:  6.472927570343018 stop acc: 0.9242528080940247
*** template loss:  7.368139266967773 template acc: tensor(0.1502, device='cuda:0')
*** label loss:  6.243380069732666 label acc: tensor(0.3877, device='cuda:0')
Train Loss
---> pred loss: 16.952799987792968 pred acc: 0.7237061113119125
---> stop loss: 3.048594284057617 stop acc: 0.9659971266984939
---> template loss: 0.6720608711242676 tempalte acc: 0.8515087127685547
---> molecule label loss: 0.3968106746673584 molecule acc: 0.8996530532836914
---> kl loss: 0.7485985279083252
---> reconstruction loss: 21.07026286125183
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-81-with.npy
loss:  21.788312911987305 0.7506902813911438
loss:  22.050682067871094 0.779301643371582
loss:  21.584623336791992 0.7687054872512817
loss:  21.789438247680664 0.7875465750694275
loss:  21.835494995117188 0.7566426992416382
loss:  22.048126220703125 0.7585626840591431
loss:  21.867263793945312 0.7707644701004028
loss:  21.784103393554688 0.7486145496368408
loss:  21.802242279052734 0.7467352747917175
loss:  21.832233428955078 0.7400073409080505
loss:  21.66707992553711 0.7702959179878235
loss:  21.964736938476562 0.7533386945724487
loss:  22.077037811279297 0.7460837960243225
loss:  21.354141235351562 0.7456119060516357
loss:  21.50570297241211 0.7388540506362915
loss:  21.75782585144043 0.7487086057662964
loss:  21.54610824584961 0.7529495358467102
loss:  21.76317596435547 0.7499788999557495
loss:  21.646587371826172 0.7499220967292786
loss:  22.527454376220703 0.7589762210845947
*******************Epoch 81 ****************** 1640 1.0
Validation Loss
*** pred loss:  26.120080947875977 pred acc: 0.5847222208976746
*** stop loss:  6.512710094451904 stop acc: 0.9264633059501648
*** template loss:  7.4081292152404785 template acc: tensor(0.1435, device='cuda:0')
*** label loss:  6.284053325653076 label acc: tensor(0.3932, device='cuda:0')
Train Loss
---> pred loss: 16.897186279296875 pred acc: 0.7255708634853363
---> stop loss: 3.0804906845092774 stop acc: 0.9656137526035309
---> template loss: 0.6670680999755859 tempalte acc: 0.8510408401489258
---> molecule label loss: 0.40876049995422364 molecule acc: 0.8968973159790039
---> kl loss: 0.7561145782470703
---> reconstruction loss: 21.053503036499023
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-82-with.npy
loss:  21.93683624267578 0.7373571395874023
loss:  21.73798942565918 0.7280887365341187
loss:  21.44110679626465 0.7229096293449402
loss:  21.8872013092041 0.763384997844696
loss:  21.259658813476562 0.733199417591095
loss:  21.236366271972656 0.7775144577026367
loss:  21.191818237304688 0.752545952796936
loss:  21.875179290771484 0.749259889125824
loss:  21.554723739624023 0.7650483846664429
loss:  21.338550567626953 0.7360029220581055
loss:  21.598949432373047 0.7314091920852661
loss:  21.187055587768555 0.7398873567581177
loss:  21.200345993041992 0.7469841837882996
loss:  21.5468807220459 0.7360849976539612
loss:  21.76873207092285 0.7290444374084473
loss:  21.863861083984375 0.745559573173523
loss:  21.760875701904297 0.7258049249649048
loss:  21.406957626342773 0.7550060153007507
loss:  21.557815551757812 0.7566988468170166
loss:  21.489307403564453 0.7456102967262268
*******************Epoch 82 ****************** 1660 1.0
Validation Loss
*** pred loss:  25.98676300048828 pred acc: 0.5857487916946411
*** stop loss:  6.28333854675293 stop acc: 0.9272727370262146
*** template loss:  7.450037956237793 template acc: tensor(0.1481, device='cuda:0')
*** label loss:  6.336073398590088 label acc: tensor(0.3945, device='cuda:0')
Train Loss
---> pred loss: 16.74388732910156 pred acc: 0.7293781071901322
---> stop loss: 3.0255157470703127 stop acc: 0.9663246870040894
---> template loss: 0.6448928833007812 tempalte acc: 0.855494213104248
---> molecule label loss: 0.3838435888290405 molecule acc: 0.9026530265808106
---> kl loss: 0.7438700675964356
---> reconstruction loss: 20.798140430450438
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-83-with.npy
loss:  20.84542465209961 0.7497063279151917
loss:  20.950176239013672 0.7499837875366211
loss:  21.041717529296875 0.7474819421768188
loss:  21.276700973510742 0.7520710229873657
loss:  21.437191009521484 0.7489286661148071
loss:  21.241979598999023 0.7617169618606567
loss:  21.396080017089844 0.7445279955863953
loss:  21.744464874267578 0.7541936039924622
loss:  21.27175521850586 0.7547927498817444
loss:  21.05211067199707 0.7657273411750793
loss:  21.194873809814453 0.7556341290473938
loss:  21.41702651977539 0.7470020651817322
loss:  21.601327896118164 0.7517489194869995
loss:  21.75286293029785 0.7287797331809998
loss:  21.547914505004883 0.7174922823905945
loss:  21.755449295043945 0.7467966675758362
loss:  21.473514556884766 0.7223427891731262
loss:  21.370752334594727 0.7322728633880615
loss:  21.3850154876709 0.7336945533752441
loss:  21.30119514465332 0.7131162285804749
*******************Epoch 83 ****************** 1680 1.0
Validation Loss
*** pred loss:  25.99056053161621 pred acc: 0.5899758338928223
*** stop loss:  6.771592140197754 stop acc: 0.9235367774963379
*** template loss:  7.419974327087402 template acc: tensor(0.1484, device='cuda:0')
*** label loss:  6.240256309509277 label acc: tensor(0.3911, device='cuda:0')
Train Loss
---> pred loss: 16.674378967285158 pred acc: 0.7294139981269836
---> stop loss: 2.964382553100586 stop acc: 0.9671157538890839
---> template loss: 0.6132934093475342 tempalte acc: 0.8648297309875488
---> molecule label loss: 0.3569207191467285 molecule acc: 0.9101084709167481
---> kl loss: 0.7439005374908447
---> reconstruction loss: 20.608977270126342
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-84-with.npy
loss:  21.544042587280273 0.7144298553466797
loss:  21.139192581176758 0.7177380323410034
loss:  20.92787742614746 0.7213219404220581
loss:  21.44025421142578 0.7489229440689087
loss:  21.683603286743164 0.7433536648750305
loss:  21.60528564453125 0.7381188869476318
loss:  21.809825897216797 0.7585716247558594
loss:  21.430076599121094 0.7371252775192261
loss:  21.392507553100586 0.7525161504745483
loss:  21.063858032226562 0.7645795345306396
loss:  21.397607803344727 0.7268430590629578
loss:  21.175607681274414 0.7354183793067932
loss:  21.28795623779297 0.7424571514129639
loss:  21.869728088378906 0.7330598831176758
loss:  20.62466049194336 0.7352069616317749
loss:  21.270952224731445 0.7417119145393372
loss:  21.180757522583008 0.7559078931808472
loss:  21.698163986206055 0.7318788170814514
loss:  21.32192611694336 0.730685293674469
loss:  21.3514404296875 0.7775310277938843
*******************Epoch 84 ****************** 1700 1.0
Validation Loss
*** pred loss:  26.426877975463867 pred acc: 0.5893719792366028
*** stop loss:  6.241036891937256 stop acc: 0.9291407465934753
*** template loss:  7.417773723602295 template acc: tensor(0.1498, device='cuda:0')
*** label loss:  6.352324485778809 label acc: tensor(0.3902, device='cuda:0')
Train Loss
---> pred loss: 16.624920654296876 pred acc: 0.7285052835941315
---> stop loss: 2.984158515930176 stop acc: 0.9664505630731582
---> template loss: 0.6296247959136962 tempalte acc: 0.8631033897399902
---> molecule label loss: 0.381693172454834 molecule acc: 0.9031172752380371
---> kl loss: 0.7403688907623291
---> reconstruction loss: 20.62039771080017
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-85-with.npy
loss:  21.106111526489258 0.7539206743240356
loss:  21.22555923461914 0.7601047158241272
loss:  21.55794334411621 0.7509974241256714
loss:  21.399402618408203 0.7496936321258545
loss:  20.87608528137207 0.7259352207183838
loss:  21.44403076171875 0.7419821619987488
loss:  21.15316390991211 0.7332593202590942
loss:  21.44736671447754 0.7470703125
loss:  21.635351181030273 0.7255474328994751
loss:  21.124710083007812 0.742143988609314
loss:  21.743410110473633 0.7489873766899109
loss:  21.062612533569336 0.7100527882575989
loss:  21.273487091064453 0.7500196695327759
loss:  20.93438720703125 0.7121248841285706
loss:  21.410127639770508 0.7436541318893433
loss:  21.155710220336914 0.7414241433143616
loss:  21.255571365356445 0.7160852551460266
loss:  21.123180389404297 0.7453721165657043
loss:  21.267398834228516 0.736916720867157
loss:  21.966564178466797 0.7581702470779419
*******************Epoch 85 ****************** 1720 1.0
Validation Loss
*** pred loss:  26.349393844604492 pred acc: 0.5846014618873596
*** stop loss:  6.4197540283203125 stop acc: 0.9264010190963745
*** template loss:  7.467496871948242 template acc: tensor(0.1470, device='cuda:0')
*** label loss:  6.382788181304932 label acc: tensor(0.3997, device='cuda:0')
Train Loss
---> pred loss: 16.613818359375 pred acc: 0.7300421208143234
---> stop loss: 2.9469486236572267 stop acc: 0.9677312314510346
---> template loss: 0.6276188373565674 tempalte acc: 0.8627470970153809
---> molecule label loss: 0.3800493240356445 molecule acc: 0.9019203186035156
---> kl loss: 0.7396730899810791
---> reconstruction loss: 20.56843390464783
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-86-with.npy
loss:  20.965452194213867 0.7444924116134644
loss:  21.325458526611328 0.7204618453979492
loss:  21.0296688079834 0.7288399338722229
loss:  21.659181594848633 0.7419837117195129
loss:  20.96898651123047 0.7531275749206543
loss:  21.24898338317871 0.7483316659927368
loss:  21.208595275878906 0.7451702356338501
loss:  20.942291259765625 0.7317283749580383
loss:  20.728649139404297 0.7184235453605652
loss:  20.89436149597168 0.7403018474578857
loss:  21.01569175720215 0.7301974892616272
loss:  21.30805206298828 0.7306740283966064
loss:  21.038190841674805 0.744299054145813
loss:  20.978256225585938 0.7407757043838501
loss:  21.01348304748535 0.74246746301651
loss:  21.301240921020508 0.7395555377006531
loss:  21.132530212402344 0.7457489371299744
loss:  21.012733459472656 0.7469581961631775
loss:  21.336833953857422 0.735768735408783
loss:  20.534595489501953 0.717576265335083
*******************Epoch 86 ****************** 1740 1.0
Validation Loss
*** pred loss:  26.21584701538086 pred acc: 0.5899758338928223
*** stop loss:  6.484739780426025 stop acc: 0.926245391368866
*** template loss:  7.430503845214844 template acc: tensor(0.1481, device='cuda:0')
*** label loss:  6.440595626831055 label acc: tensor(0.3988, device='cuda:0')
Train Loss
---> pred loss: 16.468772888183594 pred acc: 0.7312938511371613
---> stop loss: 2.9244525909423826 stop acc: 0.9676374822854996
---> template loss: 0.589151668548584 tempalte acc: 0.8713988304138184
---> molecule label loss: 0.36243884563446044 molecule acc: 0.9071128845214844
---> kl loss: 0.7373440742492676
---> reconstruction loss: 20.34481840133667
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-87-with.npy
loss:  21.051891326904297 0.7542840838432312
loss:  21.620037078857422 0.7392372488975525
loss:  20.97140121459961 0.7621527910232544
loss:  21.41639518737793 0.7351803779602051
loss:  21.04766845703125 0.7564547657966614
loss:  20.8660888671875 0.7266240119934082
loss:  20.985471725463867 0.7706633806228638
loss:  21.125743865966797 0.7409909963607788
loss:  21.099735260009766 0.7483465671539307
loss:  21.3037052154541 0.7598832249641418
loss:  20.785188674926758 0.7451822757720947
loss:  20.599729537963867 0.7323671579360962
loss:  21.46425437927246 0.7671788930892944
loss:  20.94093132019043 0.7491709589958191
loss:  21.180723190307617 0.7403143644332886
loss:  21.229999542236328 0.7450094223022461
loss:  21.201107025146484 0.7588006258010864
loss:  21.074932098388672 0.7466091513633728
loss:  20.896753311157227 0.7324814200401306
loss:  21.023622512817383 0.7135235667228699
*******************Epoch 87 ****************** 1760 1.0
Validation Loss
*** pred loss:  26.4504451751709 pred acc: 0.5847222208976746
*** stop loss:  6.452663421630859 stop acc: 0.9265255928039551
*** template loss:  7.457372188568115 template acc: tensor(0.1527, device='cuda:0')
*** label loss:  6.480269432067871 label acc: tensor(0.4026, device='cuda:0')
Train Loss
---> pred loss: 16.43609619140625 pred acc: 0.7331397086381912
---> stop loss: 2.936170196533203 stop acc: 0.9676363348960877
---> template loss: 0.5984535217285156 tempalte acc: 0.8692054748535156
---> molecule label loss: 0.37732596397399903 molecule acc: 0.9015975952148437
---> kl loss: 0.7462227821350098
---> reconstruction loss: 20.348046016693115
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-88-with.npy
loss:  21.049591064453125 0.7222585678100586
loss:  20.88633155822754 0.7370480298995972
loss:  21.04694938659668 0.7270702123641968
loss:  21.7642879486084 0.7432953119277954
loss:  22.298276901245117 0.7246667146682739
loss:  21.889760971069336 0.722085177898407
loss:  22.239910125732422 0.7053495049476624
loss:  22.066822052001953 0.7162907719612122
loss:  22.3808650970459 0.6916366219520569
loss:  22.352298736572266 0.7223266959190369
loss:  22.48799705505371 0.7093576788902283
loss:  21.698978424072266 0.70191490650177
loss:  22.020051956176758 0.7252653241157532
loss:  21.913986206054688 0.732109010219574
loss:  21.746652603149414 0.7272288799285889
loss:  22.010892868041992 0.7114261984825134
loss:  21.91274070739746 0.7304239869117737
loss:  21.499675750732422 0.729914665222168
loss:  21.63799285888672 0.732833743095398
loss:  22.117334365844727 0.7695450186729431
*******************Epoch 88 ****************** 1780 1.0
Validation Loss
*** pred loss:  26.344627380371094 pred acc: 0.5896134972572327
*** stop loss:  6.5321431159973145 stop acc: 0.92693030834198
*** template loss:  7.513851165771484 template acc: tensor(0.1382, device='cuda:0')
*** label loss:  6.35838508605957 label acc: tensor(0.3676, device='cuda:0')
Train Loss
---> pred loss: 16.42326965332031 pred acc: 0.7325744181871414
---> stop loss: 2.935260772705078 stop acc: 0.9675691485404968
---> template loss: 0.9809203147888184 tempalte acc: 0.7649873256683349
---> molecule label loss: 0.7875191688537597 molecule acc: 0.7890518188476563
---> kl loss: 0.7241023540496826
---> reconstruction loss: 21.126965761184692
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-89-with.npy
loss:  21.628515243530273 0.7257087826728821
loss:  21.611373901367188 0.7576879262924194
loss:  21.9783992767334 0.7556731700897217
loss:  21.724157333374023 0.7567139863967896
loss:  21.609655380249023 0.7216891050338745
loss:  21.338048934936523 0.7470107674598694
loss:  21.902835845947266 0.7632884979248047
loss:  21.420324325561523 0.7650232911109924
loss:  21.547178268432617 0.7513361573219299
loss:  21.25157928466797 0.767956554889679
loss:  21.161943435668945 0.7484064698219299
loss:  21.43069076538086 0.748540997505188
loss:  21.32088279724121 0.7137237787246704
loss:  21.33906364440918 0.7484806180000305
loss:  21.27710723876953 0.7467654347419739
loss:  20.925203323364258 0.7520954608917236
loss:  21.335121154785156 0.7517739534378052
loss:  21.52855110168457 0.7410686612129211
loss:  21.387784957885742 0.7473911046981812
loss:  22.11272430419922 0.8028891086578369
*******************Epoch 89 ****************** 1800 1.0
Validation Loss
*** pred loss:  26.406654357910156 pred acc: 0.5873188376426697
*** stop loss:  6.367567539215088 stop acc: 0.9281756281852722
*** template loss:  7.469566822052002 template acc: tensor(0.1410, device='cuda:0')
*** label loss:  6.251192569732666 label acc: tensor(0.3919, device='cuda:0')
Train Loss
---> pred loss: 16.39170684814453 pred acc: 0.7329208821058273
---> stop loss: 2.9136016845703123 stop acc: 0.9676570147275925
---> template loss: 0.8493024826049804 tempalte acc: 0.8038499832153321
---> molecule label loss: 0.5862841129302978 molecule acc: 0.840691089630127
---> kl loss: 0.7506611824035645
---> reconstruction loss: 20.74089460372925
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-90-with.npy
loss:  20.907743453979492 0.761474609375
loss:  21.191123962402344 0.7633796334266663
loss:  21.20699119567871 0.7554766535758972
loss:  21.58766746520996 0.7329145669937134
loss:  21.564167022705078 0.7197057008743286
loss:  21.254823684692383 0.7389442324638367
loss:  20.851293563842773 0.7400583624839783
loss:  20.98404884338379 0.7503117322921753
loss:  21.49896240234375 0.724956750869751
loss:  21.434965133666992 0.7254044413566589
loss:  21.360153198242188 0.7577292323112488
loss:  21.08902359008789 0.7587156891822815
loss:  20.952255249023438 0.7635930776596069
loss:  21.337623596191406 0.7663043141365051
loss:  21.07216453552246 0.7499216794967651
loss:  21.436962127685547 0.7630184888839722
loss:  20.926769256591797 0.7216920852661133
loss:  21.170644760131836 0.7362533211708069
loss:  20.618350982666016 0.7384476065635681
loss:  21.876567840576172 0.7491053938865662
*******************Epoch 90 ****************** 1820 1.0
Validation Loss
*** pred loss:  26.288219451904297 pred acc: 0.5894323587417603
*** stop loss:  6.456211090087891 stop acc: 0.9279577136039734
*** template loss:  7.481747150421143 template acc: tensor(0.1428, device='cuda:0')
*** label loss:  6.306730270385742 label acc: tensor(0.3952, device='cuda:0')
Train Loss
---> pred loss: 16.412452697753906 pred acc: 0.7337648808956146
---> stop loss: 2.8629356384277345 stop acc: 0.9684387117624282
---> template loss: 0.7319441318511963 tempalte acc: 0.8341587066650391
---> molecule label loss: 0.46291289329528806 molecule acc: 0.876345443725586
---> kl loss: 0.7458703517913818
---> reconstruction loss: 20.470244455337525
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-91-with.npy
loss:  20.915952682495117 0.7337142825126648
loss:  21.270368576049805 0.7492730617523193
loss:  20.888473510742188 0.7378066778182983
loss:  21.091487884521484 0.7537208795547485
loss:  20.794828414916992 0.7651315331459045
loss:  21.03217124938965 0.7440730333328247
loss:  20.96405029296875 0.7549271583557129
loss:  20.935033798217773 0.7461815476417542
loss:  20.892234802246094 0.7447371482849121
loss:  20.830547332763672 0.734250545501709
loss:  20.939651489257812 0.729080319404602
loss:  20.92838478088379 0.7399442791938782
loss:  20.501256942749023 0.7273390293121338
loss:  21.152612686157227 0.7347489595413208
loss:  20.927827835083008 0.7447995543479919
loss:  21.08817481994629 0.7275656461715698
loss:  20.458703994750977 0.7426896691322327
loss:  20.955745697021484 0.7369837164878845
loss:  20.85886001586914 0.7499890327453613
loss:  20.497753143310547 0.7011629343032837
*******************Epoch 91 ****************** 1840 1.0
Validation Loss
*** pred loss:  26.409513473510742 pred acc: 0.5891907811164856
*** stop loss:  6.468664646148682 stop acc: 0.9265255928039551
*** template loss:  7.485368728637695 template acc: tensor(0.1498, device='cuda:0')
*** label loss:  6.282233715057373 label acc: tensor(0.3969, device='cuda:0')
Train Loss
---> pred loss: 16.232061767578124 pred acc: 0.7361371725797653
---> stop loss: 2.8573186874389647 stop acc: 0.9682003915309906
---> template loss: 0.6665473937988281 tempalte acc: 0.8510636329650879
---> molecule label loss: 0.4003721237182617 molecule acc: 0.8932218551635742
---> kl loss: 0.7399059772491455
---> reconstruction loss: 20.15630068778992
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-92-with.npy
loss:  20.630443572998047 0.7297438383102417
loss:  20.704856872558594 0.7396191954612732
loss:  20.78285026550293 0.7350978851318359
loss:  20.995342254638672 0.7381260395050049
loss:  20.950571060180664 0.7334789633750916
loss:  20.90492820739746 0.730508029460907
loss:  20.36271095275879 0.7634779810905457
loss:  20.950136184692383 0.7567558884620667
loss:  20.77826690673828 0.7289649844169617
loss:  20.661897659301758 0.7413350939750671
loss:  20.855453491210938 0.7465238571166992
loss:  20.825149536132812 0.7537952065467834
loss:  20.720441818237305 0.7310096025466919
loss:  20.502063751220703 0.7469223737716675
loss:  21.102249145507812 0.7379091382026672
loss:  20.574146270751953 0.7538401484489441
loss:  20.92035484313965 0.73947674036026
loss:  20.6853084564209 0.7320166826248169
loss:  20.859189987182617 0.7447161674499512
loss:  20.12242889404297 0.7254921197891235
*******************Epoch 92 ****************** 1860 1.0
Validation Loss
*** pred loss:  26.492074966430664 pred acc: 0.5893719792366028
*** stop loss:  6.56175422668457 stop acc: 0.9274284243583679
*** template loss:  7.469274520874023 template acc: tensor(0.1456, device='cuda:0')
*** label loss:  6.351384162902832 label acc: tensor(0.3980, device='cuda:0')
Train Loss
---> pred loss: 16.187161254882813 pred acc: 0.7371777027845383
---> stop loss: 2.8011096954345702 stop acc: 0.9690224915742874
---> template loss: 0.6399367332458497 tempalte acc: 0.8578710556030273
---> molecule label loss: 0.37578954696655276 molecule acc: 0.8995938301086426
---> kl loss: 0.740440559387207
---> reconstruction loss: 20.00399913787842
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-93-with.npy
loss:  20.551639556884766 0.7094597220420837
loss:  20.866287231445312 0.7420286536216736
loss:  20.731966018676758 0.7211375832557678
loss:  20.59644889831543 0.7213271260261536
loss:  20.684633255004883 0.7356066703796387
loss:  20.527273178100586 0.7383013963699341
loss:  20.812517166137695 0.7305716276168823
loss:  20.740699768066406 0.7552778124809265
loss:  20.586334228515625 0.7201563715934753
loss:  20.483016967773438 0.7348198890686035
loss:  20.773582458496094 0.7442830204963684
loss:  20.918048858642578 0.7406060099601746
loss:  20.296390533447266 0.7286228537559509
loss:  20.781095504760742 0.7097147703170776
loss:  21.175859451293945 0.7182669043540955
loss:  20.27777099609375 0.736704409122467
loss:  20.66166114807129 0.7504314184188843
loss:  20.605817794799805 0.7448871731758118
loss:  20.433914184570312 0.7222239375114441
loss:  21.548168182373047 0.7641499042510986
*******************Epoch 93 ****************** 1880 1.0
Validation Loss
*** pred loss:  26.439573287963867 pred acc: 0.5863526463508606
*** stop loss:  6.646159648895264 stop acc: 0.925093412399292
*** template loss:  7.49294376373291 template acc: tensor(0.1456, device='cuda:0')
*** label loss:  6.424598217010498 label acc: tensor(0.4022, device='cuda:0')
Train Loss
---> pred loss: 16.181732177734375 pred acc: 0.736843404173851
---> stop loss: 2.836666297912598 stop acc: 0.9686127305030823
---> template loss: 0.6048206806182861 tempalte acc: 0.8659885406494141
---> molecule label loss: 0.34600751399993895 molecule acc: 0.9091920852661133
---> kl loss: 0.7334288597106934
---> reconstruction loss: 19.969226169586182
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-94-with.npy
loss:  20.623180389404297 0.7492820024490356
loss:  20.904922485351562 0.754573404788971
loss:  20.4722957611084 0.7485309839248657
loss:  20.63674545288086 0.7617759704589844
loss:  20.5386962890625 0.7548573613166809
loss:  21.07937240600586 0.7560701966285706
loss:  20.088075637817383 0.7225210666656494
loss:  20.733821868896484 0.7685047388076782
loss:  20.556814193725586 0.7650907635688782
loss:  20.672203063964844 0.7665544152259827
loss:  20.978599548339844 0.776954710483551
loss:  20.68089485168457 0.7626164555549622
loss:  20.591745376586914 0.7445443868637085
loss:  20.526702880859375 0.7472443580627441
loss:  20.131561279296875 0.7483245730400085
loss:  20.772300720214844 0.7555396556854248
loss:  20.766963958740234 0.7456064224243164
loss:  20.620176315307617 0.7610374093055725
loss:  20.32624053955078 0.739951491355896
loss:  21.752056121826172 0.8109474778175354
*******************Epoch 94 ****************** 1900 1.0
Validation Loss
*** pred loss:  26.477075576782227 pred acc: 0.5881038308143616
*** stop loss:  6.670938491821289 stop acc: 0.9258095026016235
*** template loss:  7.499765872955322 template acc: tensor(0.1470, device='cuda:0')
*** label loss:  6.398697853088379 label acc: tensor(0.3967, device='cuda:0')
Train Loss
---> pred loss: 16.15020751953125 pred acc: 0.7381128281354904
---> stop loss: 2.8526432037353517 stop acc: 0.9681574642658234
---> template loss: 0.5808624267578125 tempalte acc: 0.872862434387207
---> molecule label loss: 0.3319283723831177 molecule acc: 0.913493537902832
---> kl loss: 0.7570263862609863
---> reconstruction loss: 19.915642070770264
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-95-with.npy
loss:  20.552734375 0.7574933171272278
loss:  20.52820587158203 0.7455302476882935
loss:  20.586881637573242 0.7498044371604919
loss:  20.963058471679688 0.7296518087387085
loss:  20.701038360595703 0.7441204786300659
loss:  20.54369354248047 0.7487989068031311
loss:  20.364259719848633 0.754073441028595
loss:  20.272472381591797 0.7398149371147156
loss:  20.658857345581055 0.7251619100570679
loss:  20.429311752319336 0.7329112887382507
loss:  20.777324676513672 0.7396612167358398
loss:  20.190275192260742 0.7312865853309631
loss:  20.283565521240234 0.7312425971031189
loss:  20.58553123474121 0.7423827052116394
loss:  20.327381134033203 0.7232863903045654
loss:  20.448060989379883 0.7242686152458191
loss:  20.410776138305664 0.7506682276725769
loss:  20.840967178344727 0.7266438007354736
loss:  20.49277114868164 0.7438925504684448
loss:  20.51095199584961 0.7781054973602295
*******************Epoch 95 ****************** 1920 1.0
Validation Loss
*** pred loss:  26.377399444580078 pred acc: 0.594685971736908
*** stop loss:  6.543385028839111 stop acc: 0.9264633059501648
*** template loss:  7.482089519500732 template acc: tensor(0.1509, device='cuda:0')
*** label loss:  6.418315887451172 label acc: tensor(0.3965, device='cuda:0')
Train Loss
---> pred loss: 16.086453247070313 pred acc: 0.7385734230279922
---> stop loss: 2.818831443786621 stop acc: 0.9691190391778945
---> template loss: 0.5598275184631347 tempalte acc: 0.8799689292907715
---> molecule label loss: 0.3173532485961914 molecule acc: 0.9193891525268555
---> kl loss: 0.7409400463104248
---> reconstruction loss: 19.78246693611145
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-96-with.npy
loss:  20.02640151977539 0.737849771976471
loss:  20.371511459350586 0.732776939868927
loss:  20.66317367553711 0.737227737903595
loss:  20.125450134277344 0.7343096137046814
loss:  20.371122360229492 0.7358079552650452
loss:  20.36968994140625 0.7424187064170837
loss:  20.178058624267578 0.7457259297370911
loss:  20.432199478149414 0.7255710959434509
loss:  20.381057739257812 0.7347155809402466
loss:  20.311800003051758 0.7219409346580505
loss:  20.523662567138672 0.7148439884185791
loss:  20.582319259643555 0.7535521388053894
loss:  20.33820915222168 0.7320132851600647
loss:  20.317480087280273 0.7637590169906616
loss:  20.45011329650879 0.7531690001487732
loss:  20.390363693237305 0.7446435689926147
loss:  20.362775802612305 0.7435947060585022
loss:  20.567873001098633 0.7281721234321594
loss:  20.895309448242188 0.7461140155792236
loss:  20.22115707397461 0.7597613334655762
*******************Epoch 96 ****************** 1940 1.0
Validation Loss
*** pred loss:  26.532032012939453 pred acc: 0.5860506892204285
*** stop loss:  6.7843427658081055 stop acc: 0.9246264100074768
*** template loss:  7.529720783233643 template acc: tensor(0.1523, device='cuda:0')
*** label loss:  6.457359790802002 label acc: tensor(0.3990, device='cuda:0')
Train Loss
---> pred loss: 15.992936706542968 pred acc: 0.7406929194927215
---> stop loss: 2.8089778900146483 stop acc: 0.9688614696264267
---> template loss: 0.5451836109161377 tempalte acc: 0.8810263633728027
---> molecule label loss: 0.30748906135559084 molecule acc: 0.9199384689331055
---> kl loss: 0.7393983840942383
---> reconstruction loss: 19.65458507537842
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-97-with.npy
loss:  20.387666702270508 0.7328168749809265
loss:  20.496601104736328 0.7336442470550537
loss:  20.855140686035156 0.7252453565597534
loss:  20.509164810180664 0.7239261269569397
loss:  20.39084243774414 0.7186586856842041
loss:  20.3518123626709 0.7105036973953247
loss:  20.340923309326172 0.7146169543266296
loss:  20.648698806762695 0.7146148085594177
loss:  19.963205337524414 0.713403582572937
loss:  20.354320526123047 0.7209704518318176
loss:  20.14749526977539 0.7364100813865662
loss:  20.36920166015625 0.728672206401825
loss:  20.07326889038086 0.7435208559036255
loss:  20.24822998046875 0.738224983215332
loss:  20.064455032348633 0.7291247844696045
loss:  20.411840438842773 0.7186293005943298
loss:  20.294055938720703 0.7456035614013672
loss:  20.366302490234375 0.7521790266036987
loss:  20.51331329345703 0.7536289095878601
loss:  21.167327880859375 0.6925476789474487
*******************Epoch 97 ****************** 1960 1.0
Validation Loss
*** pred loss:  26.763935089111328 pred acc: 0.5844202637672424
*** stop loss:  6.564234256744385 stop acc: 0.9270548224449158
*** template loss:  7.506641387939453 template acc: tensor(0.1607, device='cuda:0')
*** label loss:  6.457324504852295 label acc: tensor(0.4011, device='cuda:0')
Train Loss
---> pred loss: 16.030189514160156 pred acc: 0.7397215574979782
---> stop loss: 2.811764717102051 stop acc: 0.9689805984497071
---> template loss: 0.531475830078125 tempalte acc: 0.8861649513244629
---> molecule label loss: 0.29691574573516843 molecule acc: 0.9227846145629883
---> kl loss: 0.7273471355438232
---> reconstruction loss: 19.670345735549926
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-98-with.npy
loss:  20.141185760498047 0.7343145608901978
loss:  20.155757904052734 0.7423720359802246
loss:  19.987382888793945 0.7082453370094299
loss:  20.394123077392578 0.7206637263298035
loss:  20.012500762939453 0.7173711061477661
loss:  20.07138442993164 0.7362532019615173
loss:  20.427417755126953 0.7496213316917419
loss:  20.457256317138672 0.7410989999771118
loss:  20.27899742126465 0.7328554391860962
loss:  20.26396942138672 0.7519636154174805
loss:  19.88766860961914 0.7367365956306458
loss:  20.179447174072266 0.7198903560638428
loss:  20.432125091552734 0.734072208404541
loss:  20.32123565673828 0.725172758102417
loss:  20.416248321533203 0.7263534069061279
loss:  19.98631477355957 0.719423234462738
loss:  20.742942810058594 0.7360179424285889
loss:  20.576929092407227 0.7233846187591553
loss:  20.147113800048828 0.7354942560195923
loss:  22.330642700195312 0.7256060242652893
*******************Epoch 98 ****************** 1980 1.0
Validation Loss
*** pred loss:  26.60114097595215 pred acc: 0.591847836971283
*** stop loss:  7.851694583892822 stop acc: 0.9178705215454102
*** template loss:  7.516479969024658 template acc: tensor(0.1516, device='cuda:0')
*** label loss:  6.562477111816406 label acc: tensor(0.4011, device='cuda:0')
Train Loss
---> pred loss: 16.018165588378906 pred acc: 0.7400916516780853
---> stop loss: 2.795722007751465 stop acc: 0.9689438819885254
---> template loss: 0.5259237289428711 tempalte acc: 0.8863182067871094
---> molecule label loss: 0.2898756980895996 molecule acc: 0.9257565498352051
---> kl loss: 0.7308456420898437
---> reconstruction loss: 19.629689025878907
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-99-with.npy
loss:  21.29369354248047 0.7261274456977844
loss:  20.701416015625 0.7378280758857727
loss:  20.536367416381836 0.7400892376899719
loss:  20.490955352783203 0.7582608461380005
loss:  19.977582931518555 0.7404106855392456
loss:  20.66424560546875 0.7493051290512085
loss:  20.530481338500977 0.7328131198883057
loss:  20.061351776123047 0.7580043077468872
loss:  20.691884994506836 0.7581508159637451
loss:  20.444740295410156 0.7577299475669861
loss:  20.313533782958984 0.7364984154701233
loss:  20.490537643432617 0.7477988004684448
loss:  20.70221710205078 0.7670010328292847
loss:  19.954957962036133 0.7713168859481812
loss:  20.819210052490234 0.7446381449699402
loss:  20.220693588256836 0.7540157437324524
loss:  20.32232666015625 0.7538226246833801
loss:  20.277305603027344 0.7461689114570618
loss:  19.98455238342285 0.7436164617538452
loss:  21.60146713256836 0.7562658786773682
*******************Epoch 99 ****************** 2000 1.0
Validation Loss
*** pred loss:  26.75406837463379 pred acc: 0.5917873978614807
*** stop loss:  6.508368015289307 stop acc: 0.9281445145606995
*** template loss:  7.570581436157227 template acc: tensor(0.1470, device='cuda:0')
*** label loss:  6.51964807510376 label acc: tensor(0.4063, device='cuda:0')
Train Loss
---> pred loss: 15.989479064941406 pred acc: 0.7390279591083526
---> stop loss: 2.9599899291992187 stop acc: 0.9666682720184326
---> template loss: 0.5171504497528077 tempalte acc: 0.888569450378418
---> molecule label loss: 0.28836276531219485 molecule acc: 0.9253488540649414
---> kl loss: 0.7489931106567382
---> reconstruction loss: 19.754984855651855
saving file:weights/hidden_size_200_latent_size_100_depth_3_beta_1.0_lr_0.001/bvae_iter-100-with.npy
