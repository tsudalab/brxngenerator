cuda is  True
loading data.....
size of reactant dic: 9766
size of template dic: 5567
size of fgm_trees: 20080
size of rxn_trees: 20080
size of fragment dic: 273
hidden size: 500 latent_size: 300 batch size: 1000 depth: 5
beta: 1.0 lr: 0.001
size of data pairs: 20080
trainng size: 19079
valid size: 1000
loss:  146.12954711914062 3.828667402267456
loss:  136.59962463378906 10.795143127441406
loss:  116.28124237060547 32.718143463134766
loss:  103.22380065917969 78.01141357421875
loss:  93.89688873291016 66.23072814941406
loss:  84.44944763183594 55.46295166015625
loss:  81.28641510009766 51.28250503540039
loss:  81.84947204589844 49.83444595336914
loss:  79.42772674560547 49.63092803955078
loss:  75.82308197021484 48.249000549316406
loss:  73.1144027709961 51.05934143066406
loss:  72.44050598144531 50.4824333190918
loss:  72.89502716064453 50.21146011352539
loss:  70.2132339477539 49.47975540161133
loss:  68.57078552246094 47.674922943115234
loss:  67.48707580566406 47.46249008178711
loss:  67.9881362915039 46.340171813964844
loss:  66.63894653320312 47.02324295043945
loss:  65.2728271484375 47.7579231262207
loss:  66.4881362915039 50.45283889770508
*******************Epoch 0 ****************** 20 0.00095
Validation Loss
*** pred loss:  35.73004913330078 pred acc: 0.41714975237846375
*** stop loss:  11.283504486083984 stop acc: 0.8454856872558594
*** template loss:  8.640918731689453 template acc: tensor(0.0436, device='cuda:0')
*** label loss:  6.448843955993652 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 53.18696899414063 pred acc: 0.29709661298002177
---> stop loss: 17.0296142578125 stop acc: 0.7613836377859116
---> template loss: 7.677723693847656 tempalte acc: 0.02912602424621582
---> molecule label loss: 6.586031341552735 molecule acc: 0.36436326503753663
---> kl loss: 46.699423217773436
---> reconstruction loss: 84.45946245223999
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-1-with.npy
loss:  63.485469818115234 49.008663177490234
loss:  62.36686706542969 50.355831146240234
loss:  61.651302337646484 52.38822555541992
loss:  61.59894943237305 52.40299987792969
loss:  59.9796028137207 52.883705139160156
loss:  59.35346603393555 56.254337310791016
loss:  58.5841178894043 56.63200378417969
loss:  58.85984420776367 59.4544677734375
loss:  58.16676330566406 61.38592529296875
loss:  57.616092681884766 64.62508392333984
loss:  56.5726318359375 68.47068786621094
loss:  56.134849548339844 69.02879333496094
loss:  55.9296760559082 72.44817352294922
loss:  55.310760498046875 73.95289611816406
loss:  54.369815826416016 75.28630828857422
loss:  54.1246223449707 80.38725280761719
loss:  52.68300247192383 80.98208618164062
loss:  53.4622802734375 85.2716293334961
loss:  52.2697868347168 83.57612609863281
loss:  51.30009460449219 75.53324890136719
*******************Epoch 1 ****************** 40 0.0019500000000000001
Validation Loss
*** pred loss:  30.46632194519043 pred acc: 0.5077294707298279
*** stop loss:  8.62971305847168 stop acc: 0.8791096210479736
*** template loss:  8.174367904663086 template acc: tensor(0.0844, device='cuda:0')
*** label loss:  6.273147106170654 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 35.237142944335936 pred acc: 0.4475287675857544
---> stop loss: 9.756488037109374 stop acc: 0.883298134803772
---> template loss: 6.570532989501953 tempalte acc: 0.10348677635192871
---> molecule label loss: 5.526190185546875 molecule acc: 0.38239092826843263
---> kl loss: 66.01642456054688
---> reconstruction loss: 57.06225918304443
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-2-with.npy
loss:  51.90771484375 83.53433990478516
loss:  51.15856170654297 86.72603607177734
loss:  50.55178451538086 86.23636627197266
loss:  50.72951889038086 88.84294128417969
loss:  49.94367218017578 88.47319030761719
loss:  49.82062911987305 91.4971923828125
loss:  49.75041961669922 91.69964599609375
loss:  49.041229248046875 92.28963470458984
loss:  48.37076187133789 93.61141967773438
loss:  47.658145904541016 92.95906066894531
loss:  48.34056091308594 93.55514526367188
loss:  47.208885192871094 94.26708221435547
loss:  47.02155685424805 95.24236297607422
loss:  47.12420654296875 96.75273895263672
loss:  46.45322036743164 96.33247375488281
loss:  45.49577713012695 97.45269775390625
loss:  46.01749801635742 96.60237121582031
loss:  46.03866195678711 96.12400817871094
loss:  45.27107238769531 96.58494567871094
loss:  47.46113204956055 95.0826416015625
*******************Epoch 2 ****************** 60 0.00295
Validation Loss
*** pred loss:  27.37302017211914 pred acc: 0.5612922310829163
*** stop loss:  7.353346347808838 stop acc: 0.8981943130493164
*** template loss:  7.752712249755859 template acc: tensor(0.1210, device='cuda:0')
*** label loss:  6.112441062927246 label acc: tensor(0.3468, device='cuda:0')
Train Loss
---> pred loss: 30.2227783203125 pred acc: 0.5397096753120423
---> stop loss: 7.457160949707031 stop acc: 0.9106679618358612
---> template loss: 5.153792953491211 tempalte acc: 0.2147817373275757
---> molecule label loss: 5.204062652587891 molecule acc: 0.38406925201416015
---> kl loss: 92.693310546875
---> reconstruction loss: 47.99480424560547
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-3-with.npy
loss:  45.156734466552734 96.13119506835938
loss:  44.04673767089844 96.72622680664062
loss:  44.525360107421875 98.9757080078125
loss:  43.97568130493164 96.03463745117188
loss:  43.457374572753906 97.49647521972656
loss:  44.06901931762695 100.41128540039062
loss:  43.08584976196289 98.96318054199219
loss:  42.55605697631836 100.08312225341797
loss:  43.02613067626953 101.55589294433594
loss:  42.60221862792969 101.19235229492188
loss:  42.12009048461914 102.14324188232422
loss:  42.07020950317383 102.48178100585938
loss:  41.75474548339844 102.08102416992188
loss:  41.940589904785156 103.14601135253906
loss:  41.40880584716797 103.36715698242188
loss:  41.26860809326172 103.40068054199219
loss:  41.00769805908203 103.31163024902344
loss:  40.25288391113281 103.57937622070312
loss:  40.331912994384766 103.93528747558594
loss:  40.5844841003418 108.44960021972656
*******************Epoch 3 ****************** 80 0.00395
Validation Loss
*** pred loss:  25.06818199157715 pred acc: 0.5902777910232544
*** stop loss:  6.46223258972168 stop acc: 0.9132316708564758
*** template loss:  7.305404186248779 template acc: tensor(0.1470, device='cuda:0')
*** label loss:  6.0023274421691895 label acc: tensor(0.3475, device='cuda:0')
Train Loss
---> pred loss: 27.0359619140625 pred acc: 0.5868138372898102
---> stop loss: 6.422956848144532 stop acc: 0.923241350054741
---> template loss: 3.9002544403076174 tempalte acc: 0.34700205326080324
---> molecule label loss: 4.750495910644531 molecule acc: 0.38907418251037595
---> kl loss: 101.173291015625
---> reconstruction loss: 42.06242604736328
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-4-with.npy
loss:  39.646644592285156 104.39958190917969
loss:  39.214630126953125 103.17982482910156
loss:  39.49547576904297 104.52922058105469
loss:  38.93256378173828 105.93182373046875
loss:  38.81763458251953 105.83027648925781
loss:  38.77949905395508 105.81639099121094
loss:  39.28030014038086 107.01666259765625
loss:  39.593074798583984 107.81916809082031
loss:  38.364707946777344 108.1099853515625
loss:  38.51536560058594 106.92351531982422
loss:  38.434242248535156 109.2685546875
loss:  37.477455139160156 108.61361694335938
loss:  37.74038314819336 107.18539428710938
loss:  37.489219665527344 109.43194580078125
loss:  37.62396240234375 107.24977111816406
loss:  37.29338455200195 108.2371826171875
loss:  37.097084045410156 108.14820861816406
loss:  36.32136154174805 107.49967193603516
loss:  37.1193962097168 107.76366424560547
loss:  35.88493728637695 110.55427551269531
*******************Epoch 4 ****************** 100 0.0049499999999999995
Validation Loss
*** pred loss:  23.517648696899414 pred acc: 0.6192632913589478
*** stop loss:  6.169186115264893 stop acc: 0.9155355095863342
*** template loss:  7.064014911651611 template acc: tensor(0.1671, device='cuda:0')
*** label loss:  5.895580768585205 label acc: tensor(0.3515, device='cuda:0')
Train Loss
---> pred loss: 24.619049072265625 pred acc: 0.6224232465028763
---> stop loss: 5.831016159057617 stop acc: 0.9308513879776001
---> template loss: 2.9785499572753906 tempalte acc: 0.4618243217468262
---> molecule label loss: 4.24743537902832 molecule acc: 0.402653169631958
---> kl loss: 107.17542724609375
---> reconstruction loss: 37.625548529663085
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-5-with.npy
loss:  35.82770538330078 109.24785614013672
loss:  36.04257583618164 107.18566131591797
loss:  36.64794921875 109.98165893554688
loss:  35.50535583496094 108.70948028564453
loss:  35.77022171020508 110.75320434570312
loss:  35.68113327026367 109.19056701660156
loss:  35.64679718017578 108.23699951171875
loss:  35.29971694946289 108.89903259277344
loss:  34.92677688598633 108.1400146484375
loss:  34.76276779174805 108.56041717529297
loss:  34.724365234375 107.74110412597656
loss:  34.988773345947266 109.97108459472656
loss:  34.158321380615234 108.06672668457031
loss:  34.33960723876953 109.25384521484375
loss:  33.993099212646484 109.65802764892578
loss:  33.53419494628906 108.80682373046875
loss:  33.542762756347656 109.32691955566406
loss:  34.00308609008789 110.16741943359375
loss:  33.15911865234375 108.70477294921875
loss:  33.22757339477539 105.88023376464844
*******************Epoch 5 ****************** 120 0.0059499999999999996
Validation Loss
*** pred loss:  22.47473907470703 pred acc: 0.6414251327514648
*** stop loss:  6.187907695770264 stop acc: 0.914383590221405
*** template loss:  6.820530414581299 template acc: tensor(0.1906, device='cuda:0')
*** label loss:  5.907897472381592 label acc: tensor(0.3541, device='cuda:0')
Train Loss
---> pred loss: 22.686865234375 pred acc: 0.6512751162052155
---> stop loss: 5.272803115844726 stop acc: 0.9384021520614624
---> template loss: 2.4101469039916994 tempalte acc: 0.5426073551177979
---> molecule label loss: 3.823516082763672 molecule acc: 0.4200925350189209
---> kl loss: 108.82408447265625
---> reconstruction loss: 34.14159276672363
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-6-with.npy
loss:  33.29309844970703 108.9484634399414
loss:  33.328895568847656 108.14791107177734
loss:  33.881919860839844 109.40199279785156
loss:  32.73118591308594 108.28655242919922
loss:  32.773834228515625 109.24742126464844
loss:  33.1347541809082 109.1680679321289
loss:  33.095741271972656 110.51075744628906
loss:  31.867652893066406 109.52702331542969
loss:  32.25571823120117 110.70538330078125
loss:  32.73859405517578 110.38819122314453
loss:  32.20389175415039 108.35513305664062
loss:  32.09379196166992 108.14608764648438
loss:  32.008934020996094 108.43812561035156
loss:  31.63199806213379 107.73908233642578
loss:  31.659854888916016 108.64491271972656
loss:  31.228456497192383 107.99678039550781
loss:  31.243999481201172 108.02752685546875
loss:  30.80900001525879 108.87145233154297
loss:  30.973947525024414 107.45304107666016
loss:  31.280826568603516 107.67361450195312
*******************Epoch 6 ****************** 140 0.00695
Validation Loss
*** pred loss:  21.4560489654541 pred acc: 0.6539251208305359
*** stop loss:  5.731309413909912 stop acc: 0.9238792657852173
*** template loss:  6.615571022033691 template acc: tensor(0.2156, device='cuda:0')
*** label loss:  5.844663619995117 label acc: tensor(0.3556, device='cuda:0')
Train Loss
---> pred loss: 21.127035522460936 pred acc: 0.6738042801618576
---> stop loss: 5.062348937988281 stop acc: 0.940468817949295
---> template loss: 1.9269712448120118 tempalte acc: 0.61820387840271
---> molecule label loss: 3.3911979675292967 molecule acc: 0.44397125244140623
---> kl loss: 108.78387451171875
---> reconstruction loss: 31.4557562713623
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-7-with.npy
loss:  30.189104080200195 108.42644500732422
loss:  30.43050765991211 108.63003540039062
loss:  30.69854164123535 109.2160415649414
loss:  30.48305320739746 109.23429107666016
loss:  30.79999542236328 107.74445343017578
loss:  30.349868774414062 108.62347412109375
loss:  30.761564254760742 109.73220825195312
loss:  30.341712951660156 108.87191009521484
loss:  30.093955993652344 108.2310562133789
loss:  30.484149932861328 106.9176025390625
loss:  30.07239532470703 108.07766723632812
loss:  29.446949005126953 107.78060150146484
loss:  29.677091598510742 107.43905639648438
loss:  29.42388916015625 107.013427734375
loss:  29.74376678466797 107.28360748291016
loss:  29.572021484375 108.46233367919922
loss:  29.425764083862305 107.08848571777344
loss:  28.944833755493164 107.15699768066406
loss:  29.525014877319336 106.05707550048828
loss:  28.94626808166504 107.09418487548828
*******************Epoch 7 ****************** 160 0.00795
Validation Loss
*** pred loss:  20.596195220947266 pred acc: 0.6655192971229553
*** stop loss:  5.4034037590026855 stop acc: 0.9301992654800415
*** template loss:  6.538295745849609 template acc: tensor(0.2304, device='cuda:0')
*** label loss:  5.778710842132568 label acc: tensor(0.3601, device='cuda:0')
Train Loss
---> pred loss: 19.648696899414062 pred acc: 0.6939578801393509
---> stop loss: 4.743354797363281 stop acc: 0.9451613634824753
---> template loss: 1.6793270111083984 tempalte acc: 0.6568058490753174
---> molecule label loss: 3.092387390136719 molecule acc: 0.46912422180175783
---> kl loss: 107.95404052734375
---> reconstruction loss: 29.11229150085449
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-8-with.npy
loss:  28.739023208618164 106.45698547363281
loss:  29.271764755249023 107.75703430175781
loss:  29.08861541748047 107.72854614257812
loss:  28.45551872253418 107.24560546875
loss:  28.444690704345703 107.49288177490234
loss:  28.50312614440918 106.59536743164062
loss:  28.9400691986084 106.51028442382812
loss:  28.246326446533203 106.75225067138672
loss:  28.189729690551758 106.98117065429688
loss:  28.163930892944336 104.68101501464844
loss:  27.641538619995117 105.96755981445312
loss:  27.61300277709961 104.43247985839844
loss:  27.887371063232422 104.65898132324219
loss:  27.26759147644043 104.17095947265625
loss:  27.255525588989258 104.37315368652344
loss:  27.264766693115234 103.69824981689453
loss:  27.192455291748047 103.99024963378906
loss:  27.20471954345703 104.62049865722656
loss:  27.32790756225586 104.13334655761719
loss:  26.61200523376465 102.56990051269531
*******************Epoch 8 ****************** 180 0.00895
Validation Loss
*** pred loss:  19.878000259399414 pred acc: 0.6751811504364014
*** stop loss:  5.400137424468994 stop acc: 0.9311955571174622
*** template loss:  6.354723930358887 template acc: tensor(0.2339, device='cuda:0')
*** label loss:  5.804925441741943 label acc: tensor(0.3663, device='cuda:0')
Train Loss
---> pred loss: 18.5004638671875 pred acc: 0.7112244635820388
---> stop loss: 4.369306564331055 stop acc: 0.9501449465751648
---> template loss: 1.4205348014831543 tempalte acc: 0.7032303810119629
---> molecule label loss: 2.781117820739746 molecule acc: 0.5008749485015869
---> kl loss: 105.54080810546876
---> reconstruction loss: 27.02089133483887
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-9-with.npy
loss:  26.483110427856445 102.75527954101562
loss:  26.721574783325195 103.28240203857422
loss:  26.61659812927246 104.12103271484375
loss:  26.691797256469727 103.519775390625
loss:  26.855979919433594 103.33818054199219
loss:  26.834423065185547 102.86904907226562
loss:  26.48455810546875 103.83875274658203
loss:  26.925617218017578 103.1805191040039
loss:  26.14615249633789 102.76731872558594
loss:  26.152137756347656 102.59808349609375
loss:  26.641942977905273 103.32173156738281
loss:  26.692461013793945 103.54724884033203
loss:  27.068439483642578 101.849365234375
loss:  26.857648849487305 102.55955505371094
loss:  26.806882858276367 102.64497375488281
loss:  25.99808692932129 101.78777313232422
loss:  26.325443267822266 101.48867797851562
loss:  26.172956466674805 101.93696594238281
loss:  25.522184371948242 101.59765625
loss:  25.48204803466797 102.1426010131836
*******************Epoch 9 ****************** 200 0.00995
Validation Loss
*** pred loss:  19.556127548217773 pred acc: 0.680676281452179
*** stop loss:  5.190205097198486 stop acc: 0.9324097633361816
*** template loss:  6.333473205566406 template acc: tensor(0.2416, device='cuda:0')
*** label loss:  5.7910051345825195 label acc: tensor(0.3710, device='cuda:0')
Train Loss
---> pred loss: 17.45965576171875 pred acc: 0.725395143032074
---> stop loss: 4.325953674316406 stop acc: 0.9501707971096038
---> template loss: 1.20123291015625 tempalte acc: 0.746692419052124
---> molecule label loss: 2.513698196411133 molecule acc: 0.5334996700286865
---> kl loss: 102.75736083984376
---> reconstruction loss: 25.451563283081054
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-10-with.npy
loss:  24.978240966796875 101.58978271484375
loss:  25.28159523010254 100.64216613769531
loss:  25.525739669799805 101.38240814208984
loss:  25.134098052978516 101.26460266113281
loss:  24.865436553955078 99.95823669433594
loss:  25.28830337524414 101.38307189941406
loss:  25.115903854370117 100.54042053222656
loss:  25.06362533569336 99.8421630859375
loss:  25.269939422607422 100.58748626708984
loss:  24.800979614257812 100.64195251464844
loss:  24.93580436706543 99.78536987304688
loss:  24.530221939086914 100.2625732421875
loss:  24.924636840820312 100.16175842285156
loss:  24.415197372436523 99.59246826171875
loss:  24.253108978271484 99.9770736694336
loss:  24.36775779724121 99.35966491699219
loss:  24.618318557739258 99.59014892578125
loss:  24.494169235229492 99.98640441894531
loss:  24.73554039001465 100.1412353515625
loss:  24.525754928588867 98.44847106933594
*******************Epoch 10 ****************** 220 0.01095
Validation Loss
*** pred loss:  19.491178512573242 pred acc: 0.6835144758224487
*** stop loss:  4.992408275604248 stop acc: 0.937142014503479
*** template loss:  6.268017768859863 template acc: tensor(0.2416, device='cuda:0')
*** label loss:  5.778120994567871 label acc: tensor(0.3718, device='cuda:0')
Train Loss
---> pred loss: 16.548564147949218 pred acc: 0.7385596066713334
---> stop loss: 3.9287033081054688 stop acc: 0.9560366630554199
---> template loss: 1.032371997833252 tempalte acc: 0.7788668632507324
---> molecule label loss: 2.2965599060058595 molecule acc: 0.5611016750335693
---> kl loss: 100.25687255859376
---> reconstruction loss: 23.75840672790527
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-11-with.npy
loss:  24.23847007751465 99.1407470703125
loss:  24.282108306884766 97.55134582519531
loss:  24.25806427001953 98.0601577758789
loss:  24.10335922241211 98.6802978515625
loss:  23.77692985534668 98.33634948730469
loss:  24.084915161132812 97.52299499511719
loss:  23.929264068603516 98.4942626953125
loss:  23.463134765625 97.34156799316406
loss:  23.477237701416016 98.2000961303711
loss:  23.718130111694336 98.40133666992188
loss:  23.471515655517578 97.82386779785156
loss:  23.533199310302734 97.93622589111328
loss:  23.317047119140625 97.73623657226562
loss:  23.805866241455078 97.64034271240234
loss:  23.486257553100586 96.95765686035156
loss:  23.11065101623535 97.01615905761719
loss:  24.03070068359375 96.60130310058594
loss:  23.79693031311035 96.1192626953125
loss:  24.52712631225586 96.67342376708984
loss:  25.115020751953125 95.66915893554688
*******************Epoch 11 ****************** 240 0.01195
Validation Loss
*** pred loss:  18.985361099243164 pred acc: 0.6873188018798828
*** stop loss:  5.262238025665283 stop acc: 0.9347758889198303
*** template loss:  6.191349506378174 template acc: tensor(0.2466, device='cuda:0')
*** label loss:  5.746209621429443 label acc: tensor(0.3729, device='cuda:0')
Train Loss
---> pred loss: 15.852842712402344 pred acc: 0.7477029442787171
---> stop loss: 3.8629409790039064 stop acc: 0.9558855831623078
---> template loss: 0.9248300552368164 tempalte acc: 0.8037715911865234
---> molecule label loss: 2.1159801483154297 molecule acc: 0.5828152656555176
---> kl loss: 97.5951416015625
---> reconstruction loss: 22.71003658081055
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-12-with.npy
loss:  23.068098068237305 96.9883041381836
loss:  23.631546020507812 97.84892272949219
loss:  24.494617462158203 97.56324768066406
loss:  23.759845733642578 97.5843734741211
loss:  23.047956466674805 96.2265625
loss:  23.71871566772461 97.2179946899414
loss:  23.324321746826172 97.27610778808594
loss:  23.31894874572754 96.14263916015625
loss:  22.71430206298828 96.50736999511719
loss:  23.37201690673828 96.17181396484375
loss:  22.80107879638672 96.57445526123047
loss:  22.80976676940918 95.90937042236328
loss:  22.642507553100586 96.52017974853516
loss:  22.455373764038086 94.72380828857422
loss:  22.44744110107422 95.74976348876953
loss:  22.53938865661621 95.2005386352539
loss:  22.56987953186035 94.47885131835938
loss:  22.674413681030273 95.11181640625
loss:  22.232763290405273 95.849853515625
loss:  21.40121841430664 93.33483123779297
*******************Epoch 12 ****************** 260 0.01295
Validation Loss
*** pred loss:  18.45233154296875 pred acc: 0.6909419894218445
*** stop loss:  4.764797210693359 stop acc: 0.9405043721199036
*** template loss:  6.2248945236206055 template acc: tensor(0.2585, device='cuda:0')
*** label loss:  5.743917465209961 label acc: tensor(0.3770, device='cuda:0')
Train Loss
---> pred loss: 15.1640625 pred acc: 0.754679611325264
---> stop loss: 3.807752227783203 stop acc: 0.9565027236938477
---> template loss: 0.8350454330444336 tempalte acc: 0.821721076965332
---> molecule label loss: 1.9451696395874023 molecule acc: 0.6101988315582275
---> kl loss: 96.14904174804687
---> reconstruction loss: 21.706081457214356
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-13-with.npy
loss:  21.890119552612305 94.76004791259766
loss:  21.831483840942383 95.6313247680664
loss:  21.888866424560547 94.5607681274414
loss:  21.581724166870117 94.57684326171875
loss:  22.303104400634766 94.38116455078125
loss:  21.87626838684082 93.72528839111328
loss:  22.0107421875 94.25333404541016
loss:  21.96851348876953 94.14444732666016
loss:  21.443607330322266 94.98348999023438
loss:  21.6224308013916 94.38048553466797
loss:  21.715925216674805 94.2668228149414
loss:  21.832176208496094 94.03917694091797
loss:  21.65397071838379 93.4215087890625
loss:  21.26835060119629 93.81288146972656
loss:  21.357725143432617 93.59288787841797
loss:  21.306716918945312 92.77078247070312
loss:  21.540115356445312 92.87039184570312
loss:  20.79265022277832 93.14917755126953
loss:  21.414512634277344 92.44100189208984
loss:  21.070600509643555 89.76644134521484
*******************Epoch 13 ****************** 280 0.01395
Validation Loss
*** pred loss:  18.026968002319336 pred acc: 0.696195662021637
*** stop loss:  4.902764797210693 stop acc: 0.9382939338684082
*** template loss:  6.161184310913086 template acc: tensor(0.2589, device='cuda:0')
*** label loss:  5.782201766967773 label acc: tensor(0.3787, device='cuda:0')
Train Loss
---> pred loss: 14.34808807373047 pred acc: 0.766872251033783
---> stop loss: 3.441750717163086 stop acc: 0.9615593552589417
---> template loss: 0.7686362743377686 tempalte acc: 0.834871482849121
---> molecule label loss: 1.7966445922851562 molecule acc: 0.6339802265167236
---> kl loss: 93.776416015625
---> reconstruction loss: 20.31029739013672
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-14-with.npy
loss:  20.888179779052734 92.46165466308594
loss:  20.896238327026367 92.30850219726562
loss:  21.0953369140625 92.5711898803711
loss:  20.72000503540039 93.74993896484375
loss:  21.01777458190918 92.59725952148438
loss:  20.868654251098633 92.10319519042969
loss:  21.208467483520508 93.4068832397461
loss:  20.804210662841797 93.470703125
loss:  21.158628463745117 92.91537475585938
loss:  20.669504165649414 93.20923614501953
loss:  20.98076820373535 92.54429626464844
loss:  20.398881912231445 92.43299865722656
loss:  21.096534729003906 92.96248626708984
loss:  20.784128189086914 92.44985961914062
loss:  21.09589195251465 91.8538589477539
loss:  20.970970153808594 91.68809509277344
loss:  20.670217514038086 91.48731231689453
loss:  20.481475830078125 91.96205139160156
loss:  20.57701873779297 91.26821899414062
loss:  20.661975860595703 92.59963989257812
*******************Epoch 14 ****************** 300 0.014950000000000001
Validation Loss
*** pred loss:  18.178857803344727 pred acc: 0.6979468464851379
*** stop loss:  5.529642581939697 stop acc: 0.931413471698761
*** template loss:  6.099391460418701 template acc: tensor(0.2635, device='cuda:0')
*** label loss:  5.72617244720459 label acc: tensor(0.3830, device='cuda:0')
Train Loss
---> pred loss: 13.653125 pred acc: 0.7795520007610321
---> stop loss: 3.438470458984375 stop acc: 0.9612447589635849
---> template loss: 0.7129369258880616 tempalte acc: 0.8453660011291504
---> molecule label loss: 1.708837127685547 molecule acc: 0.6452907085418701
---> kl loss: 92.50213623046875
---> reconstruction loss: 19.469337631225585
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-15-with.npy
loss:  20.450620651245117 91.25154113769531
loss:  20.44734001159668 91.3696517944336
loss:  20.488975524902344 90.9942626953125
loss:  20.189565658569336 91.7361068725586
loss:  20.56048011779785 90.95512390136719
loss:  20.62031364440918 90.8907699584961
loss:  20.082191467285156 91.87812805175781
loss:  20.45637321472168 91.52484893798828
loss:  20.284334182739258 90.44015502929688
loss:  19.910282135009766 91.5692138671875
loss:  20.13640594482422 91.20845031738281
loss:  19.961435317993164 90.68477630615234
loss:  20.30974578857422 91.36282348632812
loss:  19.764724731445312 90.31352996826172
loss:  20.041513442993164 90.52206420898438
loss:  20.086023330688477 90.60015869140625
loss:  20.155536651611328 89.7705078125
loss:  19.969778060913086 90.43659973144531
loss:  19.977296829223633 89.98233795166016
loss:  20.310718536376953 90.5389404296875
*******************Epoch 15 ****************** 320 0.01595
Validation Loss
*** pred loss:  17.522109985351562 pred acc: 0.7059782147407532
*** stop loss:  4.651516437530518 stop acc: 0.9434309005737305
*** template loss:  6.2084760665893555 template acc: tensor(0.2490, device='cuda:0')
*** label loss:  5.7325053215026855 label acc: tensor(0.3815, device='cuda:0')
Train Loss
---> pred loss: 13.134938049316407 pred acc: 0.7857843339443207
---> stop loss: 3.3670997619628906 stop acc: 0.9622884511947631
---> template loss: 0.7035641670227051 tempalte acc: 0.8468829154968261
---> molecule label loss: 1.5979928016662597 molecule acc: 0.6639140605926513
---> kl loss: 90.90149536132813
---> reconstruction loss: 18.760304864807132
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-16-with.npy
loss:  19.30437660217285 90.65672302246094
loss:  19.0695858001709 90.64263153076172
loss:  19.26172637939453 91.22660827636719
loss:  19.679698944091797 91.5604476928711
loss:  19.587377548217773 91.38164520263672
loss:  19.603052139282227 91.42371368408203
loss:  19.355531692504883 90.10912322998047
loss:  19.345895767211914 90.53285217285156
loss:  18.987634658813477 89.91413116455078
loss:  19.54605484008789 89.52754974365234
loss:  19.298484802246094 89.73561096191406
loss:  19.14177703857422 90.01971435546875
loss:  18.85784339904785 89.77857971191406
loss:  19.246196746826172 89.56224060058594
loss:  19.14029884338379 88.90989685058594
loss:  18.920612335205078 89.10627746582031
loss:  18.90462875366211 88.47421264648438
loss:  19.690027236938477 88.99317169189453
loss:  18.685489654541016 88.710205078125
loss:  19.4307861328125 89.90676879882812
*******************Epoch 16 ****************** 340 0.01695
Validation Loss
*** pred loss:  17.63614845275879 pred acc: 0.7019323706626892
*** stop loss:  5.679737567901611 stop acc: 0.9292964339256287
*** template loss:  6.130958557128906 template acc: tensor(0.2652, device='cuda:0')
*** label loss:  5.711541652679443 label acc: tensor(0.3781, device='cuda:0')
Train Loss
---> pred loss: 12.521807861328124 pred acc: 0.7958803772926331
---> stop loss: 3.0775867462158204 stop acc: 0.9664627760648727
---> template loss: 0.6652053833007813 tempalte acc: 0.8564456939697266
---> molecule label loss: 1.5055819511413575 molecule acc: 0.679370927810669
---> kl loss: 90.00860595703125
---> reconstruction loss: 17.727209048461916
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-17-with.npy
loss:  20.17596435546875 88.63337707519531
loss:  20.812740325927734 88.74552917480469
loss:  20.124189376831055 89.13021850585938
loss:  19.808521270751953 88.55747985839844
loss:  19.602720260620117 89.1723403930664
loss:  20.57919692993164 89.2703857421875
loss:  19.236736297607422 89.12843322753906
loss:  18.917152404785156 88.86225891113281
loss:  19.42998504638672 89.42342376708984
loss:  18.87405014038086 88.82777404785156
loss:  19.111909866333008 88.56298828125
loss:  18.6991024017334 89.18729400634766
loss:  18.73578453063965 88.83924865722656
loss:  18.684764862060547 88.3502197265625
loss:  18.77530860900879 88.7060546875
loss:  18.33566665649414 89.2163314819336
loss:  18.90349578857422 88.8751449584961
loss:  18.356019973754883 88.25169372558594
loss:  18.77157974243164 88.75421905517578
loss:  18.76917839050293 87.75534057617188
*******************Epoch 17 ****************** 360 0.01795
Validation Loss
*** pred loss:  17.498096466064453 pred acc: 0.7128019332885742
*** stop loss:  4.67667818069458 stop acc: 0.9412827491760254
*** template loss:  6.143906116485596 template acc: tensor(0.2613, device='cuda:0')
*** label loss:  5.780233860015869 label acc: tensor(0.3866, device='cuda:0')
Train Loss
---> pred loss: 12.256201934814452 pred acc: 0.7968490868806839
---> stop loss: 3.393208312988281 stop acc: 0.9614684104919433
---> template loss: 0.6195065975189209 tempalte acc: 0.8649450302124023
---> molecule label loss: 1.4143341064453125 molecule acc: 0.6944590091705323
---> kl loss: 88.81248168945312
---> reconstruction loss: 17.641017980041504
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-18-with.npy
loss:  18.24410629272461 88.16230010986328
loss:  17.934011459350586 87.74571228027344
loss:  18.218496322631836 87.71389770507812
loss:  17.971115112304688 87.87370300292969
loss:  18.26750946044922 87.8865966796875
loss:  18.278200149536133 87.9934310913086
loss:  18.01551055908203 88.06417083740234
loss:  18.1107177734375 87.33078002929688
loss:  18.05864715576172 87.1402587890625
loss:  18.289731979370117 87.34912109375
loss:  17.830554962158203 86.94767761230469
loss:  17.422412872314453 87.18844604492188
loss:  17.86078453063965 86.73582458496094
loss:  17.71927261352539 86.6712875366211
loss:  17.754751205444336 86.35116577148438
loss:  17.442649841308594 87.17616271972656
loss:  17.388296127319336 87.36351013183594
loss:  17.77305030822754 86.59587097167969
loss:  17.893495559692383 86.3714370727539
loss:  17.539722442626953 87.32401275634766
*******************Epoch 18 ****************** 380 0.01895
Validation Loss
*** pred loss:  16.882814407348633 pred acc: 0.7162439227104187
*** stop loss:  4.504061222076416 stop acc: 0.943368673324585
*** template loss:  6.064772129058838 template acc: tensor(0.2564, device='cuda:0')
*** label loss:  5.710376739501953 label acc: tensor(0.3802, device='cuda:0')
Train Loss
---> pred loss: 11.511873626708985 pred acc: 0.8100633382797241
---> stop loss: 2.892011833190918 stop acc: 0.9683205902576446
---> template loss: 0.5633345127105713 tempalte acc: 0.8787001609802246
---> molecule label loss: 1.320699691772461 molecule acc: 0.711115837097168
---> kl loss: 87.29926147460938
---> reconstruction loss: 16.246332071228025
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-19-with.npy
loss:  16.61536407470703 85.54627227783203
loss:  17.42066764831543 86.03092193603516
loss:  17.16464614868164 86.18717956542969
loss:  17.799589157104492 86.38111114501953
loss:  17.604272842407227 86.99812316894531
loss:  17.415000915527344 86.5579833984375
loss:  17.666484832763672 86.51012420654297
loss:  17.70672607421875 86.23037719726562
loss:  17.332895278930664 86.51785278320312
loss:  17.008615493774414 86.44692993164062
loss:  17.3592586517334 86.61589050292969
loss:  17.211271286010742 85.88626861572266
loss:  17.03306770324707 85.6680679321289
loss:  17.322601318359375 86.1409683227539
loss:  17.65948486328125 86.42188262939453
loss:  16.818927764892578 86.1426010131836
loss:  17.301454544067383 85.74915313720703
loss:  16.962970733642578 86.02015686035156
loss:  17.15729522705078 85.87352752685547
loss:  17.160736083984375 84.90248107910156
*******************Epoch 19 ****************** 400 0.019950000000000002
Validation Loss
*** pred loss:  16.751882553100586 pred acc: 0.7149154543876648
*** stop loss:  4.602145671844482 stop acc: 0.941718578338623
*** template loss:  6.07027006149292 template acc: tensor(0.2561, device='cuda:0')
*** label loss:  5.728086948394775 label acc: tensor(0.3905, device='cuda:0')
Train Loss
---> pred loss: 11.052539825439453 pred acc: 0.8153905689716339
---> stop loss: 2.7277225494384765 stop acc: 0.9701344251632691
---> template loss: 0.5639182090759277 tempalte acc: 0.8760419845581054
---> molecule label loss: 1.2643368721008301 molecule acc: 0.7219284057617188
---> kl loss: 86.14139404296876
---> reconstruction loss: 15.567546388549804
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-20-with.npy
loss:  101.04622650146484 85.83802795410156
loss:  91.34130859375 75.9003677368164
loss:  83.63829040527344 66.72335815429688
loss:  76.75007629394531 57.17402648925781
loss:  68.03303527832031 45.417964935302734
loss:  61.47859191894531 32.59250259399414
loss:  62.070377349853516 21.941394805908203
loss:  54.134605407714844 13.56645393371582
loss:  44.86387634277344 8.789937019348145
loss:  45.11830520629883 5.602956295013428
loss:  42.43670654296875 4.20512580871582
loss:  42.070064544677734 3.1500842571258545
loss:  39.977210998535156 2.5908420085906982
loss:  38.550376892089844 2.345463991165161
loss:  38.817020416259766 2.171083927154541
loss:  37.002708435058594 1.8001904487609863
loss:  36.77922821044922 1.6471703052520752
loss:  36.16655731201172 1.6532258987426758
loss:  36.16446304321289 1.8466637134552002
loss:  34.35169219970703 2.035560131072998
*******************Epoch 20 ****************** 420 1.0
Validation Loss
*** pred loss:  26.51689338684082 pred acc: 0.5674516558647156
*** stop loss:  6.811676502227783 stop acc: 0.9144769906997681
*** template loss:  7.816220760345459 template acc: tensor(0.0848, device='cuda:0')
*** label loss:  6.245550155639648 label acc: tensor(0.3659, device='cuda:0')
Train Loss
---> pred loss: 19.851345825195313 pred acc: 0.6782810926437378
---> stop loss: 6.18046875 stop acc: 0.9340352475643158
---> template loss: 3.1168872833251955 tempalte acc: 0.4433950901031494
---> molecule label loss: 2.541213607788086 molecule acc: 0.5417120933532715
---> kl loss: 21.849623107910155
---> reconstruction loss: 31.689909362792967
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-21-with.npy
loss:  33.99420166015625 1.8551331758499146
loss:  35.193153381347656 1.6670464277267456
loss:  34.39431381225586 1.657435655593872
loss:  33.106201171875 1.7796655893325806
loss:  33.433807373046875 1.6187925338745117
loss:  33.08671951293945 1.6272554397583008
loss:  32.11344528198242 1.6554571390151978
loss:  32.822208404541016 1.6058647632598877
loss:  32.30715560913086 1.5858803987503052
loss:  32.3627815246582 1.856349229812622
loss:  32.01042938232422 1.8375191688537598
loss:  31.134870529174805 1.793897271156311
loss:  31.303117752075195 1.8553115129470825
loss:  30.759416580200195 1.786241054534912
loss:  30.56657600402832 1.8366540670394897
loss:  29.644577026367188 1.714779257774353
loss:  30.776084899902344 1.9057127237319946
loss:  30.481605529785156 1.8455960750579834
loss:  30.36842918395996 1.6833547353744507
loss:  31.12566566467285 1.908118486404419
*******************Epoch 21 ****************** 440 1.0
Validation Loss
*** pred loss:  24.592432022094727 pred acc: 0.5970410704612732
*** stop loss:  6.3219757080078125 stop acc: 0.9186800122261047
*** template loss:  7.028804302215576 template acc: tensor(0.1185, device='cuda:0')
*** label loss:  6.083468914031982 label acc: tensor(0.3804, device='cuda:0')
Train Loss
---> pred loss: 21.054164123535156 pred acc: 0.6598216444253922
---> stop loss: 4.5600536346435545 stop acc: 0.9470831394195557
---> template loss: 2.6508201599121093 tempalte acc: 0.4776756286621094
---> molecule label loss: 2.030396270751953 molecule acc: 0.5975913047790528
---> kl loss: 1.7538032531738281
---> reconstruction loss: 30.29543685913086
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-22-with.npy
loss:  29.79895782470703 1.79716157913208
loss:  29.558921813964844 1.654591679573059
loss:  28.855257034301758 1.6483819484710693
loss:  29.37246322631836 1.7162164449691772
loss:  28.964313507080078 1.7402883768081665
loss:  28.478361129760742 1.6844695806503296
loss:  28.841379165649414 1.6125015020370483
loss:  28.575748443603516 1.5642987489700317
loss:  29.05546760559082 1.6808942556381226
loss:  28.654254913330078 1.571330189704895
loss:  28.154279708862305 1.611053466796875
loss:  28.79721450805664 1.5284039974212646
loss:  28.508495330810547 1.4493423700332642
loss:  28.383329391479492 1.6033247709274292
loss:  28.21384620666504 1.502404808998108
loss:  28.06441879272461 1.682246208190918
loss:  28.201208114624023 1.5740245580673218
loss:  27.235017776489258 1.5739648342132568
loss:  27.928653717041016 1.6527372598648071
loss:  25.991199493408203 1.547958493232727
*******************Epoch 22 ****************** 460 1.0
Validation Loss
*** pred loss:  24.44858741760254 pred acc: 0.5958936810493469
*** stop loss:  6.120036602020264 stop acc: 0.9215753674507141
*** template loss:  7.0179524421691895 template acc: tensor(0.1266, device='cuda:0')
*** label loss:  5.7729811668396 label acc: tensor(0.3853, device='cuda:0')
Train Loss
---> pred loss: 19.363844299316405 pred acc: 0.6853114873170852
---> stop loss: 4.052974700927734 stop acc: 0.9530535250902176
---> template loss: 1.9244413375854492 tempalte acc: 0.5902029514312744
---> molecule label loss: 1.5206002235412597 molecule acc: 0.6743947505950928
---> kl loss: 1.6197797775268554
---> reconstruction loss: 26.861860847473146
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-23-with.npy
loss:  27.279483795166016 1.5088024139404297
loss:  27.30881690979004 1.568899154663086
loss:  27.651853561401367 1.6096785068511963
loss:  27.503217697143555 1.5863912105560303
loss:  27.52082633972168 1.538435697555542
loss:  26.837949752807617 1.4856468439102173
loss:  27.27854347229004 1.5140495300292969
loss:  26.994853973388672 1.5070033073425293
loss:  26.73538589477539 1.4446444511413574
loss:  26.6948299407959 1.476670742034912
loss:  27.224193572998047 1.4951605796813965
loss:  26.722593307495117 1.4369163513183594
loss:  27.241161346435547 1.510877013206482
loss:  26.990068435668945 1.4853750467300415
loss:  26.68230628967285 1.5390275716781616
loss:  26.548349380493164 1.4629195928573608
loss:  26.82660484313965 1.4168612957000732
loss:  27.210046768188477 1.4791933298110962
loss:  27.311243057250977 1.53751802444458
loss:  26.502017974853516 1.5213656425476074
*******************Epoch 23 ****************** 480 1.0
Validation Loss
*** pred loss:  24.299556732177734 pred acc: 0.6007246375083923
*** stop loss:  6.108823299407959 stop acc: 0.9221980571746826
*** template loss:  6.960326671600342 template acc: tensor(0.1358, device='cuda:0')
*** label loss:  5.740596294403076 label acc: tensor(0.3900, device='cuda:0')
Train Loss
---> pred loss: 18.78692169189453 pred acc: 0.694294872879982
---> stop loss: 3.838855743408203 stop acc: 0.9561646252870559
---> template loss: 1.6139791488647461 tempalte acc: 0.6454207897186279
---> molecule label loss: 1.3071903228759765 molecule acc: 0.7158259868621826
---> kl loss: 1.5062718391418457
---> reconstruction loss: 25.54694471359253
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-24-with.npy
loss:  26.651639938354492 1.5400086641311646
loss:  26.240604400634766 1.5645934343338013
loss:  26.45953369140625 1.5336551666259766
loss:  26.38298797607422 1.4544519186019897
loss:  26.495952606201172 1.428672432899475
loss:  26.251771926879883 1.4390060901641846
loss:  26.10768699645996 1.4000113010406494
loss:  26.228271484375 1.4306113719940186
loss:  26.32830238342285 1.3637676239013672
loss:  26.426483154296875 1.4144699573516846
loss:  26.30316162109375 1.3439795970916748
loss:  25.903196334838867 1.378599762916565
loss:  26.40369415283203 1.3797316551208496
loss:  25.53971290588379 1.3404555320739746
loss:  26.077518463134766 1.4091839790344238
loss:  25.591848373413086 1.3599002361297607
loss:  25.858428955078125 1.4028902053833008
loss:  25.79655647277832 1.461060643196106
loss:  26.0939884185791 1.4279836416244507
loss:  26.525646209716797 1.269071340560913
*******************Epoch 24 ****************** 500 1.0
Validation Loss
*** pred loss:  24.444904327392578 pred acc: 0.596980631351471
*** stop loss:  6.226522922515869 stop acc: 0.9220423698425293
*** template loss:  6.936305999755859 template acc: tensor(0.1344, device='cuda:0')
*** label loss:  5.712710380554199 label acc: tensor(0.3922, device='cuda:0')
Train Loss
---> pred loss: 18.442916870117188 pred acc: 0.6991059184074402
---> stop loss: 3.728603744506836 stop acc: 0.9575169891119003
---> template loss: 1.439613151550293 tempalte acc: 0.6779810905456543
---> molecule label loss: 1.155110740661621 molecule acc: 0.7427079677581787
---> kl loss: 1.4171051979064941
---> reconstruction loss: 24.766244411468506
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-25-with.npy
loss:  25.20073127746582 1.4214768409729004
loss:  25.397937774658203 1.393619179725647
loss:  25.660022735595703 1.4157873392105103
loss:  25.182979583740234 1.3284372091293335
loss:  25.02350616455078 1.3027737140655518
loss:  25.471343994140625 1.2724322080612183
loss:  25.397811889648438 1.3361037969589233
loss:  25.54195785522461 1.3740415573120117
loss:  25.331756591796875 1.3257590532302856
loss:  25.36595344543457 1.3396645784378052
loss:  25.443187713623047 1.3735204935073853
loss:  25.659822463989258 1.3052222728729248
loss:  25.46251678466797 1.3370462656021118
loss:  25.44038963317871 1.3395936489105225
loss:  25.470909118652344 1.3396177291870117
loss:  25.39609146118164 1.3440073728561401
loss:  24.854476928710938 1.2845888137817383
loss:  25.006990432739258 1.2705707550048828
loss:  25.74233055114746 1.372902274131775
loss:  25.079174041748047 1.3276702165603638
*******************Epoch 25 ****************** 520 1.0
Validation Loss
*** pred loss:  24.54235076904297 pred acc: 0.5949879288673401
*** stop loss:  6.046350479125977 stop acc: 0.9258095026016235
*** template loss:  6.919064521789551 template acc: tensor(0.1358, device='cuda:0')
*** label loss:  5.685792922973633 label acc: tensor(0.3930, device='cuda:0')
Train Loss
---> pred loss: 18.080072021484376 pred acc: 0.7049308538436889
---> stop loss: 3.6396717071533202 stop acc: 0.9585233867168427
---> template loss: 1.2687650680541993 tempalte acc: 0.7123945713043213
---> molecule label loss: 1.027744197845459 molecule acc: 0.7661808013916016
---> kl loss: 1.3402417182922364
---> reconstruction loss: 24.016252422332762
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-26-with.npy
loss:  24.76359748840332 1.3331389427185059
loss:  24.85635757446289 1.266167402267456
loss:  24.885034561157227 1.225593090057373
loss:  24.803058624267578 1.2967309951782227
loss:  25.07669448852539 1.2351185083389282
loss:  24.581607818603516 1.2595717906951904
loss:  24.70343589782715 1.2119189500808716
loss:  24.59058952331543 1.2433421611785889
loss:  24.83521842956543 1.2795997858047485
loss:  24.35138511657715 1.2377946376800537
loss:  24.843399047851562 1.254543662071228
loss:  24.549633026123047 1.2544623613357544
loss:  24.376562118530273 1.2553433179855347
loss:  24.662311553955078 1.2368745803833008
loss:  24.68737030029297 1.280483603477478
loss:  24.674240112304688 1.228118896484375
loss:  24.527355194091797 1.2267955541610718
loss:  24.3218936920166 1.226167917251587
loss:  24.556522369384766 1.2326630353927612
loss:  23.46177101135254 1.1715902090072632
*******************Epoch 26 ****************** 540 1.0
Validation Loss
*** pred loss:  24.46286964416504 pred acc: 0.5995168685913086
*** stop loss:  6.069003582000732 stop acc: 0.9258717894554138
*** template loss:  6.868987083435059 template acc: tensor(0.1463, device='cuda:0')
*** label loss:  5.656067848205566 label acc: tensor(0.3885, device='cuda:0')
Train Loss
---> pred loss: 17.774436950683594 pred acc: 0.7094447702169419
---> stop loss: 3.473088836669922 stop acc: 0.9606471180915832
---> template loss: 1.1613477706909179 tempalte acc: 0.7346543788909912
---> molecule label loss: 0.9487256050109864 molecule acc: 0.7826173782348633
---> kl loss: 1.2478008270263672
---> reconstruction loss: 23.35759925842285
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-27-with.npy
loss:  23.913129806518555 1.2382298707962036
loss:  24.175731658935547 1.2074294090270996
loss:  23.969106674194336 1.2443619966506958
loss:  24.252376556396484 1.2546460628509521
loss:  24.256757736206055 1.2643998861312866
loss:  23.954811096191406 1.25289785861969
loss:  24.404354095458984 1.247025489807129
loss:  24.515310287475586 1.1597743034362793
loss:  24.50425910949707 1.2360082864761353
loss:  23.967327117919922 1.1722183227539062
loss:  24.107664108276367 1.1779390573501587
loss:  23.837556838989258 1.1706568002700806
loss:  24.36994171142578 1.1902382373809814
loss:  24.269941329956055 1.2404452562332153
loss:  23.897241592407227 1.145788311958313
loss:  24.16532325744629 1.1842118501663208
loss:  23.791738510131836 1.15048348903656
loss:  23.830060958862305 1.1973214149475098
loss:  23.796947479248047 1.1622631549835205
loss:  23.18233299255371 1.092885136604309
*******************Epoch 27 ****************** 560 1.0
Validation Loss
*** pred loss:  24.95591163635254 pred acc: 0.5951690673828125
*** stop loss:  6.0801544189453125 stop acc: 0.9250311851501465
*** template loss:  6.849797248840332 template acc: tensor(0.1488, device='cuda:0')
*** label loss:  5.735857963562012 label acc: tensor(0.3977, device='cuda:0')
Train Loss
---> pred loss: 17.526936340332032 pred acc: 0.7134572476148605
---> stop loss: 3.4095508575439455 stop acc: 0.9614730894565582
---> template loss: 1.0624361991882325 tempalte acc: 0.7533107280731202
---> molecule label loss: 0.8597119331359864 molecule acc: 0.8000547409057617
---> kl loss: 1.1994613647460937
---> reconstruction loss: 22.858631896972657
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-28-with.npy
loss:  23.55030059814453 1.1058412790298462
loss:  23.535778045654297 1.173335075378418
loss:  23.88509750366211 1.1642483472824097
loss:  23.914199829101562 1.1723788976669312
loss:  23.471113204956055 1.1338253021240234
loss:  23.72759246826172 1.2186850309371948
loss:  23.32583999633789 1.130713701248169
loss:  23.648895263671875 1.1377233266830444
loss:  24.253171920776367 1.1590886116027832
loss:  23.55961799621582 1.1538978815078735
loss:  23.746246337890625 1.1235169172286987
loss:  24.097307205200195 1.1536574363708496
loss:  23.38265037536621 1.1532882452011108
loss:  23.36039924621582 1.114772081375122
loss:  24.218433380126953 1.1532381772994995
loss:  23.441099166870117 1.165101170539856
loss:  23.602006912231445 1.1462979316711426
loss:  23.384164810180664 1.1427381038665771
loss:  23.373981475830078 1.178031325340271
loss:  22.52840232849121 1.0357277393341064
*******************Epoch 28 ****************** 580 1.0
Validation Loss
*** pred loss:  24.89737319946289 pred acc: 0.5906400680541992
*** stop loss:  5.977031230926514 stop acc: 0.9267435073852539
*** template loss:  6.91069221496582 template acc: tensor(0.1435, device='cuda:0')
*** label loss:  5.653618812561035 label acc: tensor(0.3894, device='cuda:0')
Train Loss
---> pred loss: 17.3238037109375 pred acc: 0.7171246945858002
---> stop loss: 3.352915954589844 stop acc: 0.9621769785881042
---> template loss: 0.9770572662353516 tempalte acc: 0.7728188037872314
---> molecule label loss: 0.800732421875 molecule acc: 0.8110000610351562
---> kl loss: 1.1458054542541505
---> reconstruction loss: 22.454513454437254
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-29-with.npy
loss:  22.800556182861328 1.0670784711837769
loss:  23.15906524658203 1.0750566720962524
loss:  23.491222381591797 1.0939029455184937
loss:  23.244049072265625 1.1045924425125122
loss:  23.57025909423828 1.0958352088928223
loss:  22.865154266357422 1.0639925003051758
loss:  23.094377517700195 1.0610495805740356
loss:  23.54861831665039 1.097232460975647
loss:  23.346309661865234 1.0743145942687988
loss:  23.453731536865234 1.1021913290023804
loss:  23.193218231201172 1.101690649986267
loss:  23.304779052734375 1.0878040790557861
loss:  23.315534591674805 1.096498727798462
loss:  23.136537551879883 1.1300114393234253
loss:  22.95795440673828 1.0826445817947388
loss:  23.047935485839844 1.0875428915023804
loss:  22.784591674804688 1.1324763298034668
loss:  22.848482131958008 1.0664417743682861
loss:  22.79261589050293 1.0406136512756348
loss:  23.388383865356445 1.2089720964431763
*******************Epoch 29 ****************** 600 1.0
Validation Loss
*** pred loss:  24.858720779418945 pred acc: 0.5960144996643066
*** stop loss:  6.173483848571777 stop acc: 0.9259029030799866
*** template loss:  6.8801774978637695 template acc: tensor(0.1442, device='cuda:0')
*** label loss:  5.727153778076172 label acc: tensor(0.3868, device='cuda:0')
Train Loss
---> pred loss: 17.172079467773436 pred acc: 0.7186181753873825
---> stop loss: 3.251740264892578 stop acc: 0.9632515102624893
---> template loss: 0.9023833274841309 tempalte acc: 0.7884550571441651
---> molecule label loss: 0.7474690914154053 molecule acc: 0.8218158721923828
---> kl loss: 1.0934971809387206
---> reconstruction loss: 22.073672008514407
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-30-with.npy
loss:  22.69038200378418 1.059484839439392
loss:  22.450855255126953 1.0465847253799438
loss:  22.677043914794922 1.0319528579711914
loss:  22.872478485107422 1.0441538095474243
loss:  22.951072692871094 1.0155174732208252
loss:  23.021419525146484 1.0508867502212524
loss:  22.669694900512695 1.0112149715423584
loss:  23.233245849609375 1.0374165773391724
loss:  22.555252075195312 1.0506657361984253
loss:  22.465124130249023 0.9909488558769226
loss:  22.8201961517334 0.9932311177253723
loss:  22.220558166503906 0.9633365869522095
loss:  22.670673370361328 1.0065908432006836
loss:  22.67556381225586 1.0180431604385376
loss:  22.635822296142578 1.0401476621627808
loss:  22.799402236938477 1.0687044858932495
loss:  22.942710876464844 1.0390262603759766
loss:  22.63557243347168 1.030515193939209
loss:  22.695629119873047 1.0208169221878052
loss:  22.607789993286133 0.9732610583305359
*******************Epoch 30 ****************** 620 1.0
Validation Loss
*** pred loss:  25.25632095336914 pred acc: 0.5916666388511658
*** stop loss:  6.257266998291016 stop acc: 0.9258406162261963
*** template loss:  6.800073623657227 template acc: tensor(0.1484, device='cuda:0')
*** label loss:  5.769557952880859 label acc: tensor(0.3810, device='cuda:0')
Train Loss
---> pred loss: 16.97741241455078 pred acc: 0.7217395603656769
---> stop loss: 3.1746158599853516 stop acc: 0.9643632501363755
---> template loss: 0.8502870559692383 tempalte acc: 0.8019089698791504
---> molecule label loss: 0.6875858783721924 molecule acc: 0.8360077857971191
---> kl loss: 1.024625015258789
---> reconstruction loss: 21.689899826049807
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-31-with.npy
loss:  22.685087203979492 0.9968623518943787
loss:  22.278989791870117 1.037048101425171
loss:  22.580278396606445 1.032549262046814
loss:  22.250579833984375 1.0020347833633423
loss:  22.401155471801758 0.9997503757476807
loss:  22.313098907470703 1.0026700496673584
loss:  22.215253829956055 1.0222907066345215
loss:  22.0908145904541 1.0035686492919922
loss:  22.545543670654297 1.0089216232299805
loss:  21.895381927490234 0.9889635443687439
loss:  22.45516586303711 0.9769381284713745
loss:  22.326751708984375 0.9651563763618469
loss:  22.02020263671875 0.9959338903427124
loss:  21.93639373779297 0.9911589622497559
loss:  21.87462615966797 0.991646409034729
loss:  22.51594352722168 0.9777957797050476
loss:  22.336395263671875 1.0140005350112915
loss:  22.122596740722656 0.982252299785614
loss:  22.10647964477539 0.9625043869018555
loss:  22.532833099365234 0.9587046504020691
*******************Epoch 31 ****************** 640 1.0
Validation Loss
*** pred loss:  25.33267593383789 pred acc: 0.5954710245132446
*** stop loss:  6.1574907302856445 stop acc: 0.927521824836731
*** template loss:  6.811779499053955 template acc: tensor(0.1544, device='cuda:0')
*** label loss:  5.698044776916504 label acc: tensor(0.3903, device='cuda:0')
Train Loss
---> pred loss: 16.734762573242186 pred acc: 0.725132754445076
---> stop loss: 3.1042430877685545 stop acc: 0.965134909749031
---> template loss: 0.7933772563934326 tempalte acc: 0.8139029502868652
---> molecule label loss: 0.6462570190429687 molecule acc: 0.8427350997924805
---> kl loss: 0.9955374717712402
---> reconstruction loss: 21.2786416053772
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-32-with.npy
loss:  22.24751091003418 0.9496302604675293
loss:  21.901416778564453 0.9807711243629456
loss:  22.0971736907959 0.9523334503173828
loss:  21.809425354003906 0.9633827209472656
loss:  21.84398078918457 0.9465485215187073
loss:  22.202659606933594 0.9491444826126099
loss:  21.81989288330078 0.9487351775169373
loss:  21.66843605041504 0.9664273858070374
loss:  21.70807647705078 0.9191364645957947
loss:  21.629995346069336 0.9180664420127869
loss:  22.103343963623047 0.9570563435554504
loss:  22.32678985595703 0.9306797385215759
loss:  21.937278747558594 0.9476128816604614
loss:  21.558975219726562 0.9364838004112244
loss:  21.70027732849121 0.9584004878997803
loss:  21.83917999267578 0.9770393967628479
loss:  21.521629333496094 0.9422290325164795
loss:  21.916946411132812 0.9267573952674866
loss:  21.561304092407227 0.9307540655136108
loss:  22.674373626708984 0.9284579157829285
*******************Epoch 32 ****************** 660 1.0
Validation Loss
*** pred loss:  25.36777687072754 pred acc: 0.5888888835906982
*** stop loss:  6.584540367126465 stop acc: 0.9191158413887024
*** template loss:  6.812291145324707 template acc: tensor(0.1516, device='cuda:0')
*** label loss:  5.808503150939941 label acc: tensor(0.3947, device='cuda:0')
Train Loss
---> pred loss: 16.541291809082033 pred acc: 0.7288038045167923
---> stop loss: 3.062063980102539 stop acc: 0.9658323585987091
---> template loss: 0.7528890132904053 tempalte acc: 0.8244198799133301
---> molecule label loss: 0.6007072925567627 molecule acc: 0.8530118942260743
---> kl loss: 0.9464821815490723
---> reconstruction loss: 20.956952571868896
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-33-with.npy
loss:  21.7834529876709 0.9201306700706482
loss:  21.697795867919922 0.9334333539009094
loss:  22.077972412109375 0.9581629633903503
loss:  22.221506118774414 0.9457262754440308
loss:  21.331920623779297 0.9330164790153503
loss:  22.249042510986328 0.9544520378112793
loss:  21.547279357910156 0.9834898710250854
loss:  21.939735412597656 0.9392910599708557
loss:  21.38932991027832 0.941871702671051
loss:  22.24289321899414 0.9258629679679871
loss:  21.42058753967285 0.9084720611572266
loss:  21.410560607910156 0.940352737903595
loss:  21.60717010498047 0.8867405652999878
loss:  21.54499626159668 0.8935306668281555
loss:  21.543581008911133 0.9152746796607971
loss:  21.305383682250977 0.8680644631385803
loss:  21.678203582763672 0.8963629603385925
loss:  21.443845748901367 0.8937997221946716
loss:  21.559642791748047 0.8800079226493835
loss:  20.297405242919922 0.8325977921485901
*******************Epoch 33 ****************** 680 1.0
Validation Loss
*** pred loss:  25.463886260986328 pred acc: 0.5895531177520752
*** stop loss:  6.190805435180664 stop acc: 0.9280822277069092
*** template loss:  6.832785606384277 template acc: tensor(0.1534, device='cuda:0')
*** label loss:  5.815084457397461 label acc: tensor(0.4069, device='cuda:0')
Train Loss
---> pred loss: 16.375965881347657 pred acc: 0.7298145473003388
---> stop loss: 3.0464954376220703 stop acc: 0.9660135000944138
---> template loss: 0.7069125175476074 tempalte acc: 0.8333745956420898
---> molecule label loss: 0.5677132606506348 molecule acc: 0.8592426300048828
---> kl loss: 0.9175321578979492
---> reconstruction loss: 20.69708118438721
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-34-with.npy
loss:  20.918874740600586 0.886665403842926
loss:  21.626436233520508 0.9243558049201965
loss:  21.480436325073242 0.9105818271636963
loss:  21.20393180847168 0.9275182485580444
loss:  21.30169105529785 0.8801673650741577
loss:  21.310314178466797 0.8618655800819397
loss:  21.169513702392578 0.8647145628929138
loss:  21.443405151367188 0.8673675060272217
loss:  21.376087188720703 0.8737499713897705
loss:  21.16632080078125 0.8683556914329529
loss:  21.129474639892578 0.859352707862854
loss:  20.525815963745117 0.8522270321846008
loss:  21.42753791809082 0.8641536831855774
loss:  21.44774627685547 0.8682368993759155
loss:  21.083160400390625 0.8804716467857361
loss:  21.04291343688965 0.8424758911132812
loss:  21.37445068359375 0.8680046796798706
loss:  21.092334747314453 0.8976856470108032
loss:  20.726116180419922 0.8649051785469055
loss:  20.70204734802246 0.8343228101730347
*******************Epoch 34 ****************** 700 1.0
Validation Loss
*** pred loss:  25.696455001831055 pred acc: 0.5943236351013184
*** stop loss:  6.189127445220947 stop acc: 0.9262765049934387
*** template loss:  6.815147876739502 template acc: tensor(0.1474, device='cuda:0')
*** label loss:  5.7371416091918945 label acc: tensor(0.4048, device='cuda:0')
Train Loss
---> pred loss: 16.157986450195313 pred acc: 0.7349640101194381
---> stop loss: 2.9184967041015626 stop acc: 0.9675163447856903
---> template loss: 0.6917762279510498 tempalte acc: 0.8388160705566406
---> molecule label loss: 0.5343132495880127 molecule acc: 0.8672224044799804
---> kl loss: 0.8748588562011719
---> reconstruction loss: 20.302571868896486
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-35-with.npy
loss:  20.2112979888916 0.8462951183319092
loss:  20.51997184753418 0.8805330991744995
loss:  21.346975326538086 0.8764708638191223
loss:  21.081392288208008 0.8702057003974915
loss:  21.07291030883789 0.8828922510147095
loss:  20.777873992919922 0.8473504185676575
loss:  20.742218017578125 0.8377169370651245
loss:  21.0741024017334 0.8658405542373657
loss:  20.747636795043945 0.8239588737487793
loss:  20.86390495300293 0.8146832585334778
loss:  20.485794067382812 0.824777364730835
loss:  20.577655792236328 0.8433429002761841
loss:  20.795148849487305 0.8257226347923279
loss:  20.841270446777344 0.8571672439575195
loss:  21.166975021362305 0.8868892788887024
loss:  20.748987197875977 0.8375811576843262
loss:  20.997509002685547 0.8636016845703125
loss:  20.867080688476562 0.8381958603858948
loss:  20.468564987182617 0.843434751033783
loss:  21.11087989807129 0.8567906022071838
*******************Epoch 35 ****************** 720 1.0
Validation Loss
*** pred loss:  25.5421142578125 pred acc: 0.5905193090438843
*** stop loss:  6.6842427253723145 stop acc: 0.9196451306343079
*** template loss:  6.877845764160156 template acc: tensor(0.1534, device='cuda:0')
*** label loss:  5.800251483917236 label acc: tensor(0.4035, device='cuda:0')
Train Loss
---> pred loss: 15.985952758789063 pred acc: 0.736873009800911
---> stop loss: 2.850438117980957 stop acc: 0.9683224231004715
---> template loss: 0.6419788837432862 tempalte acc: 0.8494107246398925
---> molecule label loss: 0.4953643798828125 molecule acc: 0.875947093963623
---> kl loss: 0.8511725425720215
---> reconstruction loss: 19.973734378814697
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-36-with.npy
loss:  20.645591735839844 0.8415641188621521
loss:  20.516237258911133 0.8536582589149475
loss:  20.404787063598633 0.8573158979415894
loss:  20.474056243896484 0.7994361519813538
loss:  20.68491554260254 0.8517680764198303
loss:  20.411561965942383 0.78968346118927
loss:  20.790882110595703 0.8118393421173096
loss:  20.640178680419922 0.8015589118003845
loss:  20.52947235107422 0.8334749341011047
loss:  20.512725830078125 0.8398167490959167
loss:  20.95091438293457 0.8041737675666809
loss:  20.3700008392334 0.8014589548110962
loss:  20.558319091796875 0.8270160555839539
loss:  20.560134887695312 0.8218622207641602
loss:  20.903974533081055 0.8146293759346008
loss:  20.3712158203125 0.8162651658058167
loss:  20.084901809692383 0.7835739850997925
loss:  20.326330184936523 0.7853938341140747
loss:  20.67465591430664 0.7972514629364014
loss:  18.864490509033203 0.7592867612838745
*******************Epoch 36 ****************** 740 1.0
Validation Loss
*** pred loss:  26.23835563659668 pred acc: 0.5829105973243713
*** stop loss:  6.160876274108887 stop acc: 0.928393542766571
*** template loss:  6.813726425170898 template acc: tensor(0.1632, device='cuda:0')
*** label loss:  5.803472995758057 label acc: tensor(0.4020, device='cuda:0')
Train Loss
---> pred loss: 15.76221923828125 pred acc: 0.7409292042255402
---> stop loss: 2.8520042419433596 stop acc: 0.968096861243248
---> template loss: 0.5863545417785645 tempalte acc: 0.8654234886169434
---> molecule label loss: 0.4486377239227295 molecule acc: 0.8876688003540039
---> kl loss: 0.8145513534545898
---> reconstruction loss: 19.649213600158692
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-37-with.npy
loss:  20.196517944335938 0.7786428332328796
loss:  20.219358444213867 0.8038233518600464
loss:  20.648345947265625 0.8262227773666382
loss:  20.267780303955078 0.8150317072868347
loss:  20.145580291748047 0.80570387840271
loss:  20.612220764160156 0.8131908178329468
loss:  20.047365188598633 0.7950553297996521
loss:  20.45245361328125 0.8042178750038147
loss:  20.05232810974121 0.7753955721855164
loss:  19.962602615356445 0.7817614078521729
loss:  20.18815803527832 0.7863048315048218
loss:  20.436738967895508 0.786639928817749
loss:  19.97933006286621 0.7743159532546997
loss:  20.507389068603516 0.7843902111053467
loss:  20.339401245117188 0.7799092531204224
loss:  20.605449676513672 0.7824407815933228
loss:  20.27036476135254 0.7852783203125
loss:  20.25271224975586 0.7678031921386719
loss:  20.19453239440918 0.7553855180740356
loss:  19.801544189453125 0.7138618230819702
*******************Epoch 37 ****************** 760 1.0
Validation Loss
*** pred loss:  26.06831932067871 pred acc: 0.5862318873405457
*** stop loss:  6.347595691680908 stop acc: 0.9287360310554504
*** template loss:  6.823042869567871 template acc: tensor(0.1625, device='cuda:0')
*** label loss:  5.86916446685791 label acc: tensor(0.4146, device='cuda:0')
Train Loss
---> pred loss: 15.759756469726563 pred acc: 0.739875414967537
---> stop loss: 2.723597526550293 stop acc: 0.9701484769582749
---> template loss: 0.5615811347961426 tempalte acc: 0.8695755958557129
---> molecule label loss: 0.42830572128295896 molecule acc: 0.8908411979675293
---> kl loss: 0.7857687473297119
---> reconstruction loss: 19.473236989974975
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-38-with.npy
loss:  19.645105361938477 0.7797185778617859
loss:  19.925718307495117 0.766308605670929
loss:  20.282398223876953 0.7718161940574646
loss:  19.82009506225586 0.7704724669456482
loss:  19.95355224609375 0.7796695828437805
loss:  19.901716232299805 0.7869625687599182
loss:  19.84129524230957 0.7779762148857117
loss:  19.834373474121094 0.761290431022644
loss:  20.196727752685547 0.7660043239593506
loss:  19.856075286865234 0.7754079699516296
loss:  20.073406219482422 0.7551988363265991
loss:  20.458560943603516 0.7642727494239807
loss:  19.839019775390625 0.7672587633132935
loss:  20.04908561706543 0.7679404020309448
loss:  20.11375617980957 0.7625436186790466
loss:  19.77899742126465 0.771083414554596
loss:  19.923633575439453 0.755008339881897
loss:  20.05062484741211 0.7678782343864441
loss:  19.903932571411133 0.7484160661697388
loss:  20.789093017578125 0.7593461275100708
*******************Epoch 38 ****************** 780 1.0
Validation Loss
*** pred loss:  26.110776901245117 pred acc: 0.5891304016113281
*** stop loss:  6.67664098739624 stop acc: 0.9266189336776733
*** template loss:  6.862076282501221 template acc: tensor(0.1576, device='cuda:0')
*** label loss:  5.883613586425781 label acc: tensor(0.4027, device='cuda:0')
Train Loss
---> pred loss: 15.587989807128906 pred acc: 0.7429031431674957
---> stop loss: 2.723718452453613 stop acc: 0.9701582878828049
---> template loss: 0.5346939086914062 tempalte acc: 0.8768136024475097
---> molecule label loss: 0.39772825241088866 molecule acc: 0.8993485450744629
---> kl loss: 0.7677287101745606
---> reconstruction loss: 19.244130420684815
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-39-with.npy
loss:  19.988117218017578 0.7390338182449341
loss:  19.460044860839844 0.7393064498901367
loss:  20.220666885375977 0.7296872138977051
loss:  20.01107406616211 0.749943196773529
loss:  19.953187942504883 0.7620398998260498
loss:  19.66653823852539 0.764353334903717
loss:  20.17333984375 0.7480554580688477
loss:  19.628969192504883 0.7403472065925598
loss:  19.915882110595703 0.7389906048774719
loss:  19.855310440063477 0.731342077255249
loss:  19.713947296142578 0.7194448113441467
loss:  19.756776809692383 0.7043439745903015
loss:  19.46282958984375 0.726209819316864
loss:  19.209049224853516 0.7207237482070923
loss:  19.691246032714844 0.7183775901794434
loss:  19.432287216186523 0.7335066199302673
loss:  19.720949172973633 0.7235486507415771
loss:  19.58176612854004 0.7296154499053955
loss:  19.780807495117188 0.7370333075523376
loss:  20.771745681762695 0.7027701139450073
*******************Epoch 39 ****************** 800 1.0
Validation Loss
*** pred loss:  26.11978530883789 pred acc: 0.5880434513092041
*** stop loss:  6.880767345428467 stop acc: 0.9253113865852356
*** template loss:  6.833258152008057 template acc: tensor(0.1611, device='cuda:0')
*** label loss:  5.914837837219238 label acc: tensor(0.4082, device='cuda:0')
Train Loss
---> pred loss: 15.474269104003906 pred acc: 0.7453539788722991
---> stop loss: 2.6910415649414063 stop acc: 0.9703331381082535
---> template loss: 0.5169668674468995 tempalte acc: 0.8812599182128906
---> molecule label loss: 0.38451590538024905 molecule acc: 0.9023284912109375
---> kl loss: 0.7329336643218994
---> reconstruction loss: 19.066793203353882
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-40-with.npy
loss:  19.821277618408203 0.7040349245071411
loss:  19.661697387695312 0.7329903841018677
loss:  20.148221969604492 0.7263554334640503
loss:  19.817991256713867 0.7353347539901733
loss:  19.85576629638672 0.7163657546043396
loss:  19.6431941986084 0.7079417705535889
loss:  19.878860473632812 0.7096952199935913
loss:  19.64175033569336 0.7060227394104004
loss:  19.585315704345703 0.6892625689506531
loss:  19.848861694335938 0.7022702693939209
loss:  19.303125381469727 0.704937219619751
loss:  19.378173828125 0.7199265360832214
loss:  19.49512481689453 0.7200993895530701
loss:  19.451122283935547 0.6931020021438599
loss:  19.478721618652344 0.7277607917785645
loss:  19.60775375366211 0.708106517791748
loss:  19.535900115966797 0.7033436298370361
loss:  19.276487350463867 0.7191173434257507
loss:  19.315073013305664 0.7164911031723022
loss:  19.603527069091797 0.7332221269607544
*******************Epoch 40 ****************** 820 1.0
Validation Loss
*** pred loss:  26.21603775024414 pred acc: 0.5846618413925171
*** stop loss:  6.320198059082031 stop acc: 0.927615225315094
*** template loss:  6.83562707901001 template acc: tensor(0.1618, device='cuda:0')
*** label loss:  5.943181037902832 label acc: tensor(0.4067, device='cuda:0')
Train Loss
---> pred loss: 15.395123291015626 pred acc: 0.7438083857297897
---> stop loss: 2.675706481933594 stop acc: 0.9704086393117904
---> template loss: 0.4784390926361084 tempalte acc: 0.8918464660644532
---> molecule label loss: 0.35430843830108644 molecule acc: 0.9106201171875
---> kl loss: 0.7138190269470215
---> reconstruction loss: 18.903577518463134
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-41-with.npy
loss:  18.85944175720215 0.7166892290115356
loss:  19.84649085998535 0.7167457938194275
loss:  19.586374282836914 0.7131282091140747
loss:  19.214458465576172 0.6894381642341614
loss:  19.646869659423828 0.6917117834091187
loss:  19.219057083129883 0.6816951036453247
loss:  19.186426162719727 0.6961989998817444
loss:  19.22178840637207 0.6882246732711792
loss:  18.913713455200195 0.6876509189605713
loss:  19.29458236694336 0.6788091659545898
loss:  19.518333435058594 0.687864363193512
loss:  18.959985733032227 0.6770490407943726
loss:  19.21647834777832 0.672425389289856
loss:  19.32657241821289 0.6846351027488708
loss:  18.753629684448242 0.6803640723228455
loss:  19.153188705444336 0.6768935322761536
loss:  19.269697189331055 0.660790205001831
loss:  19.14432716369629 0.6661378145217896
loss:  19.3947696685791 0.6987932324409485
loss:  17.68785858154297 0.6974600553512573
*******************Epoch 41 ****************** 840 1.0
Validation Loss
*** pred loss:  26.384933471679688 pred acc: 0.58423912525177
*** stop loss:  6.617465019226074 stop acc: 0.9264633059501648
*** template loss:  6.812994003295898 template acc: tensor(0.1600, device='cuda:0')
*** label loss:  5.927638053894043 label acc: tensor(0.4086, device='cuda:0')
Train Loss
---> pred loss: 15.075604248046876 pred acc: 0.7498309165239334
---> stop loss: 2.619266128540039 stop acc: 0.970975348353386
---> template loss: 0.45366725921630857 tempalte acc: 0.8975931167602539
---> molecule label loss: 0.3340294361114502 molecule acc: 0.9159910202026367
---> kl loss: 0.6881351947784424
---> reconstruction loss: 18.482567930221556
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-42-with.npy
loss:  18.79329490661621 0.6886553168296814
loss:  18.571849822998047 0.6874445676803589
loss:  19.14912223815918 0.6793392300605774
loss:  19.363101959228516 0.6754270792007446
loss:  19.064245223999023 0.6782386898994446
loss:  18.910015106201172 0.6602381467819214
loss:  19.004535675048828 0.6703073382377625
loss:  18.953176498413086 0.6565461754798889
loss:  18.973905563354492 0.6595543622970581
loss:  19.029132843017578 0.6823787689208984
loss:  19.182188034057617 0.6846953630447388
loss:  18.860464096069336 0.6756340265274048
loss:  18.74976921081543 0.6726746559143066
loss:  19.184972763061523 0.6677802801132202
loss:  19.16621971130371 0.6793190240859985
loss:  18.66405487060547 0.6573270559310913
loss:  18.653173446655273 0.6462761759757996
loss:  18.767898559570312 0.6604343056678772
loss:  19.170608520507812 0.6498932242393494
loss:  18.897790908813477 0.6580069065093994
*******************Epoch 42 ****************** 860 1.0
Validation Loss
*** pred loss:  26.612924575805664 pred acc: 0.5827898383140564
*** stop loss:  6.53705358505249 stop acc: 0.9272727370262146
*** template loss:  6.784437656402588 template acc: tensor(0.1593, device='cuda:0')
*** label loss:  6.188276767730713 label acc: tensor(0.4191, device='cuda:0')
Train Loss
---> pred loss: 14.916859436035157 pred acc: 0.7523035496473313
---> stop loss: 2.522256088256836 stop acc: 0.9723889648914337
---> template loss: 0.4891901969909668 tempalte acc: 0.8912103652954102
---> molecule label loss: 0.35766465663909913 molecule acc: 0.9073153495788574
---> kl loss: 0.6695085048675538
---> reconstruction loss: 18.28596787452698
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-43-with.npy
loss:  18.63100814819336 0.6609346866607666
loss:  18.558704376220703 0.6342108845710754
loss:  18.957468032836914 0.6655230522155762
loss:  19.04902458190918 0.6602606177330017
loss:  18.789674758911133 0.6549051403999329
loss:  18.384519577026367 0.6575632691383362
loss:  18.727148056030273 0.673514187335968
loss:  18.740243911743164 0.6663700342178345
loss:  18.85121726989746 0.6565627455711365
loss:  19.228124618530273 0.6398928761482239
loss:  18.861738204956055 0.6658549904823303
loss:  18.527189254760742 0.6502107977867126
loss:  18.83426284790039 0.6287336945533752
loss:  18.916933059692383 0.6503501534461975
loss:  18.703371047973633 0.6411387324333191
loss:  18.780502319335938 0.6336352229118347
loss:  18.833782196044922 0.6525533199310303
loss:  18.712804794311523 0.6484745740890503
loss:  18.700592041015625 0.6323828101158142
loss:  18.542972564697266 0.5871675610542297
*******************Epoch 43 ****************** 880 1.0
Validation Loss
*** pred loss:  26.732324600219727 pred acc: 0.5823671221733093
*** stop loss:  6.529123783111572 stop acc: 0.9279888272285461
*** template loss:  6.848471164703369 template acc: tensor(0.1643, device='cuda:0')
*** label loss:  5.929391384124756 label acc: tensor(0.3733, device='cuda:0')
Train Loss
---> pred loss: 14.830166625976563 pred acc: 0.7542134821414948
---> stop loss: 2.446480369567871 stop acc: 0.9732146054506302
---> template loss: 0.4673034191131592 tempalte acc: 0.8954602241516113
---> molecule label loss: 0.3746034145355225 molecule acc: 0.8995183944702149
---> kl loss: 0.6480120182037353
---> reconstruction loss: 18.118551397323607
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-44-with.npy
loss:  18.446043014526367 0.657511830329895
loss:  18.643505096435547 0.6765468120574951
loss:  18.750234603881836 0.6586095690727234
loss:  18.822935104370117 0.6487823128700256
loss:  18.595003128051758 0.6146915555000305
loss:  18.8421630859375 0.6194008588790894
loss:  18.60171127319336 0.6250535845756531
loss:  18.533199310302734 0.6162233352661133
loss:  18.864965438842773 0.6348628997802734
loss:  18.8787899017334 0.6111657023429871
loss:  18.566791534423828 0.6151819825172424
loss:  18.608245849609375 0.6200450658798218
loss:  18.62164878845215 0.6481446027755737
loss:  18.298240661621094 0.6411582827568054
loss:  18.68339729309082 0.6418545246124268
loss:  18.428510665893555 0.6553847789764404
loss:  18.59245491027832 0.6521739363670349
loss:  18.30364418029785 0.6373276710510254
loss:  18.742246627807617 0.6371050477027893
loss:  17.41619300842285 0.6142427325248718
*******************Epoch 44 ****************** 900 1.0
Validation Loss
*** pred loss:  26.732460021972656 pred acc: 0.5806159377098083
*** stop loss:  6.665467262268066 stop acc: 0.9276463389396667
*** template loss:  6.857427597045898 template acc: tensor(0.1600, device='cuda:0')
*** label loss:  5.922849655151367 label acc: tensor(0.3971, device='cuda:0')
Train Loss
---> pred loss: 14.662413024902344 pred acc: 0.7552734345197678
---> stop loss: 2.4733381271362305 stop acc: 0.9725698798894882
---> template loss: 0.4363725662231445 tempalte acc: 0.9032556533813476
---> molecule label loss: 0.353598427772522 molecule acc: 0.9054491996765137
---> kl loss: 0.6362733364105224
---> reconstruction loss: 17.925723123550416
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-45-with.npy
loss:  18.185440063476562 0.620754599571228
loss:  18.133453369140625 0.6346416473388672
loss:  18.667665481567383 0.6363719701766968
loss:  18.605451583862305 0.6379815340042114
loss:  18.506847381591797 0.6452982425689697
loss:  18.362539291381836 0.6400074362754822
loss:  18.412059783935547 0.6329314708709717
loss:  18.606931686401367 0.6205280423164368
loss:  18.11072540283203 0.6022007465362549
loss:  18.26714324951172 0.5884808897972107
loss:  18.08403968811035 0.5917328596115112
loss:  18.095787048339844 0.6063921451568604
loss:  18.38510513305664 0.615390956401825
loss:  17.996402740478516 0.6252490282058716
loss:  18.30845832824707 0.6103671789169312
loss:  18.197057723999023 0.6206029653549194
loss:  18.532060623168945 0.6308210492134094
loss:  18.166383743286133 0.621173083782196
loss:  18.21741485595703 0.6124758720397949
loss:  17.638111114501953 0.5871457457542419
*******************Epoch 45 ****************** 920 1.0
Validation Loss
*** pred loss:  27.17311668395996 pred acc: 0.5800724625587463
*** stop loss:  6.608231067657471 stop acc: 0.9273039102554321
*** template loss:  6.8309326171875 template acc: tensor(0.1625, device='cuda:0')
*** label loss:  5.969399452209473 label acc: tensor(0.4029, device='cuda:0')
Train Loss
---> pred loss: 14.572486877441406 pred acc: 0.7580711990594864
---> stop loss: 2.364162635803223 stop acc: 0.9741691321134567
---> template loss: 0.40817952156066895 tempalte acc: 0.9108236312866211
---> molecule label loss: 0.3100967168807983 molecule acc: 0.9194106101989746
---> kl loss: 0.6190273761749268
---> reconstruction loss: 17.6549289226532
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-46-with.npy
loss:  17.794023513793945 0.5989245772361755
loss:  18.071142196655273 0.5982743501663208
loss:  17.641754150390625 0.5882751941680908
loss:  17.971757888793945 0.5977647304534912
loss:  17.997995376586914 0.5892661213874817
loss:  17.994050979614258 0.621669590473175
loss:  18.198455810546875 0.6138338446617126
loss:  18.350351333618164 0.6189883947372437
loss:  17.943410873413086 0.6204195618629456
loss:  17.980188369750977 0.5919021368026733
loss:  18.084863662719727 0.5918124914169312
loss:  17.93766975402832 0.5951288342475891
loss:  18.228530883789062 0.5949109792709351
loss:  18.116785049438477 0.5903831720352173
loss:  18.27372169494629 0.5926156044006348
loss:  18.14402198791504 0.5888956189155579
loss:  18.02126693725586 0.6026700735092163
loss:  18.031686782836914 0.5990052223205566
loss:  17.966609954833984 0.5927113890647888
loss:  17.39313316345215 0.6138381361961365
*******************Epoch 46 ****************** 940 1.0
Validation Loss
*** pred loss:  27.46599769592285 pred acc: 0.5783212184906006
*** stop loss:  7.336116790771484 stop acc: 0.9231008887290955
*** template loss:  6.909666538238525 template acc: tensor(0.1614, device='cuda:0')
*** label loss:  6.0186028480529785 label acc: tensor(0.3997, device='cuda:0')
Train Loss
---> pred loss: 14.435211181640625 pred acc: 0.7598661810159684
---> stop loss: 2.335947036743164 stop acc: 0.9743093758821487
---> template loss: 0.37279982566833497 tempalte acc: 0.9184037208557129
---> molecule label loss: 0.2630485773086548 molecule acc: 0.9338939666748047
---> kl loss: 0.6000645160675049
---> reconstruction loss: 17.407006406784056
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-47-with.npy
loss:  17.95965576171875 0.5882190465927124
loss:  17.964731216430664 0.5782228112220764
loss:  18.039945602416992 0.5911445617675781
loss:  18.264318466186523 0.5714455246925354
loss:  17.910171508789062 0.5670826435089111
loss:  18.01365089416504 0.5837352275848389
loss:  18.26015853881836 0.5955792665481567
loss:  17.865156173706055 0.606113076210022
loss:  17.857742309570312 0.6122915744781494
loss:  17.979827880859375 0.6058117151260376
loss:  18.074188232421875 0.5911142826080322
loss:  18.06351661682129 0.6052033305168152
loss:  17.88167381286621 0.5973142385482788
loss:  17.9310245513916 0.5969717502593994
loss:  17.704723358154297 0.5755560398101807
loss:  17.444082260131836 0.5727381706237793
loss:  17.913576126098633 0.5683706998825073
loss:  17.736766815185547 0.5766575336456299
loss:  17.596017837524414 0.5911566615104675
loss:  18.017974853515625 0.5589821934700012
*******************Epoch 47 ****************** 960 1.0
Validation Loss
*** pred loss:  27.22171974182129 pred acc: 0.5794686079025269
*** stop loss:  6.764736175537109 stop acc: 0.9284247159957886
*** template loss:  6.877241134643555 template acc: tensor(0.1534, device='cuda:0')
*** label loss:  6.2187676429748535 label acc: tensor(0.4134, device='cuda:0')
Train Loss
---> pred loss: 14.40772705078125 pred acc: 0.7590260684490204
---> stop loss: 2.327507209777832 stop acc: 0.9745517700910569
---> template loss: 0.35498781204223634 tempalte acc: 0.9239641189575195
---> molecule label loss: 0.24703783988952638 molecule acc: 0.9373897552490235
---> kl loss: 0.5866855144500732
---> reconstruction loss: 17.3372585773468
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-48-with.npy
loss:  17.57077407836914 0.5894999504089355
loss:  17.47845458984375 0.5910030603408813
loss:  17.483142852783203 0.5948991179466248
loss:  17.894731521606445 0.5950148701667786
loss:  17.517004013061523 0.5841261148452759
loss:  17.869935989379883 0.5658172965049744
loss:  17.49983787536621 0.5521705150604248
loss:  17.8785343170166 0.5631783604621887
loss:  17.977294921875 0.5559109449386597
loss:  17.380422592163086 0.5568416118621826
loss:  17.850698471069336 0.5619818568229675
loss:  17.826040267944336 0.5683932304382324
loss:  17.68496322631836 0.5651400089263916
loss:  17.505964279174805 0.5853788256645203
loss:  17.660600662231445 0.5868383646011353
loss:  17.42429542541504 0.5727458000183105
loss:  17.542156219482422 0.5687189102172852
loss:  18.00977897644043 0.5691940188407898
loss:  17.3624324798584 0.5638997554779053
loss:  17.987369537353516 0.5736166834831238
*******************Epoch 48 ****************** 980 1.0
Validation Loss
*** pred loss:  27.624467849731445 pred acc: 0.5754830837249756
*** stop loss:  7.922952651977539 stop acc: 0.9194894433021545
*** template loss:  6.858559608459473 template acc: tensor(0.1632, device='cuda:0')
*** label loss:  6.1245222091674805 label acc: tensor(0.4056, device='cuda:0')
Train Loss
---> pred loss: 14.24132843017578 pred acc: 0.7619969069957733
---> stop loss: 2.2602025985717775 stop acc: 0.9753297597169877
---> template loss: 0.34904189109802247 tempalte acc: 0.9245099067687989
---> molecule label loss: 0.24643070697784425 molecule acc: 0.9375688552856445
---> kl loss: 0.5732184886932373
---> reconstruction loss: 17.097000932693483
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-49-with.npy
loss:  18.162044525146484 0.5528315305709839
loss:  17.964839935302734 0.5638792514801025
loss:  17.9395694732666 0.5647699236869812
loss:  17.944440841674805 0.560379683971405
loss:  17.65375518798828 0.5797405242919922
loss:  17.767744064331055 0.5669935345649719
loss:  17.818649291992188 0.5587331056594849
loss:  17.455297470092773 0.5623810291290283
loss:  17.757143020629883 0.5586097240447998
loss:  17.584575653076172 0.5535876750946045
loss:  17.36176300048828 0.5484226942062378
loss:  17.79096794128418 0.5644779205322266
loss:  17.35008430480957 0.5466458201408386
loss:  17.15306282043457 0.5655933022499084
loss:  17.74561309814453 0.5724974870681763
loss:  17.540687561035156 0.5734944343566895
loss:  17.364595413208008 0.5546863079071045
loss:  17.591598510742188 0.5682708024978638
loss:  17.534387588500977 0.5472915768623352
loss:  17.933868408203125 0.5211843252182007
*******************Epoch 49 ****************** 1000 1.0
Validation Loss
*** pred loss:  27.578227996826172 pred acc: 0.5750603675842285
*** stop loss:  6.809401512145996 stop acc: 0.9255293011665344
*** template loss:  6.892982006072998 template acc: tensor(0.1643, device='cuda:0')
*** label loss:  6.069786071777344 label acc: tensor(0.3979, device='cuda:0')
Train Loss
---> pred loss: 14.205690002441406 pred acc: 0.7623951822519303
---> stop loss: 2.339278793334961 stop acc: 0.9739593207836151
---> template loss: 0.3319906949996948 tempalte acc: 0.9310749053955079
---> molecule label loss: 0.23455255031585692 molecule acc: 0.9417671203613281
---> kl loss: 0.5592235565185547
---> reconstruction loss: 17.11151008605957
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-50-with.npy
loss:  16.852190017700195 0.5478682518005371
loss:  17.361326217651367 0.5626579523086548
loss:  17.512540817260742 0.5494645833969116
loss:  17.839279174804688 0.5514543652534485
loss:  17.048660278320312 0.5677081346511841
loss:  17.51795768737793 0.569515585899353
loss:  17.464380264282227 0.5389991402626038
loss:  17.362316131591797 0.5546975135803223
loss:  17.12999153137207 0.5567570328712463
loss:  17.412343978881836 0.5543056726455688
loss:  17.320621490478516 0.5513830184936523
loss:  17.24997901916504 0.5467899441719055
loss:  17.388700485229492 0.5559086799621582
loss:  17.1489200592041 0.5486255288124084
loss:  17.154199600219727 0.5402843356132507
loss:  17.257387161254883 0.5437853932380676
loss:  17.136219024658203 0.5432934761047363
loss:  17.163740158081055 0.5344842076301575
loss:  17.51231575012207 0.5356256365776062
loss:  16.95668601989746 0.5012274384498596
*******************Epoch 50 ****************** 1020 1.0
Validation Loss
*** pred loss:  27.756746292114258 pred acc: 0.5786231756210327
*** stop loss:  6.878205299377441 stop acc: 0.9268991351127625
*** template loss:  6.9154558181762695 template acc: tensor(0.1607, device='cuda:0')
*** label loss:  6.045595645904541 label acc: tensor(0.3952, device='cuda:0')
Train Loss
---> pred loss: 14.053280639648438 pred acc: 0.7642382025718689
---> stop loss: 2.1442113876342774 stop acc: 0.9765098065137863
---> template loss: 0.3164529323577881 tempalte acc: 0.9337248802185059
---> molecule label loss: 0.22780065536499022 molecule acc: 0.9430546760559082
---> kl loss: 0.5477417945861817
---> reconstruction loss: 16.741746425628662
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-51-with.npy
loss:  16.975215911865234 0.5166166424751282
loss:  16.85612678527832 0.5376668572425842
loss:  17.133756637573242 0.5342040657997131
loss:  17.32657814025879 0.5542660355567932
loss:  16.9971923828125 0.554229199886322
loss:  17.186735153198242 0.5598176717758179
loss:  17.214675903320312 0.5571388006210327
loss:  17.240074157714844 0.5377379059791565
loss:  16.958526611328125 0.5391075611114502
loss:  16.986679077148438 0.5210577845573425
loss:  16.956571578979492 0.5292580723762512
loss:  17.033201217651367 0.5240494012832642
loss:  16.92962074279785 0.5135387778282166
loss:  17.037540435791016 0.5106428861618042
loss:  17.079017639160156 0.5159620046615601
loss:  17.396650314331055 0.5342739820480347
loss:  17.355688095092773 0.5150815844535828
loss:  16.872848510742188 0.5228305459022522
loss:  16.933591842651367 0.530501663684845
loss:  17.456029891967773 0.5335898995399475
*******************Epoch 51 ****************** 1040 1.0
Validation Loss
*** pred loss:  27.610633850097656 pred acc: 0.5823067426681519
*** stop loss:  7.045903205871582 stop acc: 0.9253736138343811
*** template loss:  6.877343654632568 template acc: tensor(0.1632, device='cuda:0')
*** label loss:  6.145103454589844 label acc: tensor(0.3979, device='cuda:0')
Train Loss
---> pred loss: 13.917257690429688 pred acc: 0.7670102715492249
---> stop loss: 2.122533416748047 stop acc: 0.9770449995994568
---> template loss: 0.31144349575042723 tempalte acc: 0.9345623970031738
---> molecule label loss: 0.2130032777786255 molecule acc: 0.9474267959594727
---> kl loss: 0.5320785999298095
---> reconstruction loss: 16.564236402511597
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-52-with.npy
loss:  16.756752014160156 0.5496730208396912
loss:  17.088008880615234 0.5653055310249329
loss:  17.102689743041992 0.5393230319023132
loss:  16.866405487060547 0.5358346104621887
loss:  17.125146865844727 0.5264925360679626
loss:  17.150564193725586 0.5273341536521912
loss:  17.134910583496094 0.52619469165802
loss:  16.783361434936523 0.5164416432380676
loss:  16.91252899169922 0.5396019816398621
loss:  17.018125534057617 0.5071999430656433
loss:  16.844125747680664 0.5309758186340332
loss:  17.020532608032227 0.5235269665718079
loss:  16.892333984375 0.5256545543670654
loss:  17.04599380493164 0.5396714210510254
loss:  16.88800811767578 0.5229184031486511
loss:  17.155986785888672 0.5310891270637512
loss:  16.790538787841797 0.514733076095581
loss:  16.882173538208008 0.5240480899810791
loss:  17.151931762695312 0.5212098360061646
loss:  17.849058151245117 0.5197612047195435
*******************Epoch 52 ****************** 1060 1.0
Validation Loss
*** pred loss:  27.947490692138672 pred acc: 0.5774154663085938
*** stop loss:  7.3133955001831055 stop acc: 0.9251245856285095
*** template loss:  6.875312805175781 template acc: tensor(0.1593, device='cuda:0')
*** label loss:  6.099086284637451 label acc: tensor(0.3965, device='cuda:0')
Train Loss
---> pred loss: 13.810919189453125 pred acc: 0.7675923496484757
---> stop loss: 2.136684799194336 stop acc: 0.9767817467451095
---> template loss: 0.31666054725646975 tempalte acc: 0.9359768867492676
---> molecule label loss: 0.22934463024139404 molecule acc: 0.9418451309204101
---> kl loss: 0.5293494701385498
---> reconstruction loss: 16.49360890388489
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-53-with.npy
loss:  17.061620712280273 0.5317226052284241
loss:  17.101886749267578 0.5243262052536011
loss:  17.297330856323242 0.5211639404296875
loss:  17.231693267822266 0.5107221007347107
loss:  17.19929313659668 0.5280030369758606
loss:  17.10181999206543 0.5215771794319153
loss:  17.62065887451172 0.5340695381164551
loss:  17.19306755065918 0.5232436656951904
loss:  16.988645553588867 0.5156954526901245
loss:  17.04458999633789 0.5243326425552368
loss:  16.748186111450195 0.5211051106452942
loss:  16.979297637939453 0.5093734264373779
loss:  17.217275619506836 0.5135898590087891
loss:  16.85093879699707 0.4915373623371124
loss:  17.115938186645508 0.506864607334137
loss:  16.823774337768555 0.512790322303772
loss:  16.644386291503906 0.5024150609970093
loss:  16.858627319335938 0.5178341269493103
loss:  16.99639320373535 0.522849977016449
loss:  17.69756507873535 0.5105798840522766
*******************Epoch 53 ****************** 1080 1.0
Validation Loss
*** pred loss:  27.842254638671875 pred acc: 0.5788043141365051
*** stop loss:  7.280618667602539 stop acc: 0.9246264100074768
*** template loss:  6.837566375732422 template acc: tensor(0.1579, device='cuda:0')
*** label loss:  6.118541240692139 label acc: tensor(0.3922, device='cuda:0')
Train Loss
---> pred loss: 13.770426940917968 pred acc: 0.7693228214979172
---> stop loss: 2.099696922302246 stop acc: 0.9772492110729217
---> template loss: 0.38676137924194337 tempalte acc: 0.9174924850463867
---> molecule label loss: 0.31457479000091554 molecule acc: 0.917238998413086
---> kl loss: 0.5171897888183594
---> reconstruction loss: 16.57145767211914
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-54-with.npy
loss:  16.715919494628906 0.5115976333618164
loss:  16.88516616821289 0.5144768953323364
loss:  16.95164680480957 0.49258214235305786
loss:  17.222877502441406 0.5017172694206238
loss:  16.981958389282227 0.4997653365135193
loss:  17.219985961914062 0.5102407932281494
loss:  16.856725692749023 0.5156141519546509
loss:  16.777095794677734 0.5066323280334473
loss:  16.698997497558594 0.5166485905647278
loss:  16.47481346130371 0.5132087469100952
loss:  16.624271392822266 0.5152836441993713
loss:  16.764171600341797 0.5115321278572083
loss:  16.5656795501709 0.49924591183662415
loss:  16.956315994262695 0.4978407621383667
loss:  16.53641128540039 0.5081080198287964
loss:  16.685062408447266 0.50942063331604
loss:  16.4736270904541 0.5074498653411865
loss:  16.832393646240234 0.5004732012748718
loss:  16.9825439453125 0.497127503156662
loss:  16.019779205322266 0.46541038155555725
*******************Epoch 54 ****************** 1100 1.0
Validation Loss
*** pred loss:  28.58555030822754 pred acc: 0.5786835551261902
*** stop loss:  7.353428840637207 stop acc: 0.923816978931427
*** template loss:  6.8966569900512695 template acc: tensor(0.1607, device='cuda:0')
*** label loss:  6.347277641296387 label acc: tensor(0.4172, device='cuda:0')
Train Loss
---> pred loss: 13.59008331298828 pred acc: 0.7700025320053101
---> stop loss: 2.0293085098266603 stop acc: 0.9778877526521683
---> template loss: 0.3495840311050415 tempalte acc: 0.9283495903015136
---> molecule label loss: 0.2875770092010498 molecule acc: 0.9228962898254395
---> kl loss: 0.504718828201294
---> reconstruction loss: 16.256552839279173
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-55-with.npy
loss:  16.253042221069336 0.49716606736183167
loss:  16.396364212036133 0.5053251385688782
loss:  16.463842391967773 0.4992642104625702
loss:  16.831459045410156 0.5125978589057922
loss:  16.883703231811523 0.4902991056442261
loss:  16.64212989807129 0.5075598359107971
loss:  16.798175811767578 0.5110518932342529
loss:  16.636734008789062 0.49218326807022095
loss:  16.825641632080078 0.4845653176307678
loss:  16.71211051940918 0.49997836351394653
loss:  16.812402725219727 0.5043379068374634
loss:  16.594953536987305 0.5100424885749817
loss:  16.874814987182617 0.502437174320221
loss:  16.62710952758789 0.49713993072509766
loss:  16.570558547973633 0.4923844039440155
loss:  16.55730628967285 0.49117720127105713
loss:  16.782602310180664 0.47839808464050293
loss:  16.588335037231445 0.4777425527572632
loss:  16.549114227294922 0.4721369445323944
loss:  16.453073501586914 0.4677448272705078
*******************Epoch 55 ****************** 1120 1.0
Validation Loss
*** pred loss:  28.223276138305664 pred acc: 0.5765700340270996
*** stop loss:  7.387903690338135 stop acc: 0.9255915880203247
*** template loss:  6.904167652130127 template acc: tensor(0.1614, device='cuda:0')
*** label loss:  6.181196689605713 label acc: tensor(0.4112, device='cuda:0')
Train Loss
---> pred loss: 13.511555480957032 pred acc: 0.7720317035913468
---> stop loss: 2.032637023925781 stop acc: 0.9777873873710632
---> template loss: 0.3336313724517822 tempalte acc: 0.931944465637207
---> molecule label loss: 0.2701740264892578 molecule acc: 0.9286430358886719
---> kl loss: 0.4946765899658203
---> reconstruction loss: 16.147996139526366
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-56-with.npy
loss:  16.284059524536133 0.50356125831604
loss:  16.521818161010742 0.5109714269638062
loss:  16.380170822143555 0.4973801076412201
loss:  16.61750602722168 0.5005624294281006
loss:  16.789234161376953 0.4852660000324249
loss:  16.645246505737305 0.4971219301223755
loss:  16.671110153198242 0.4795229732990265
loss:  16.832700729370117 0.502872109413147
loss:  16.643924713134766 0.49048328399658203
loss:  16.344608306884766 0.49398505687713623
loss:  16.46762466430664 0.49526119232177734
loss:  16.490299224853516 0.504893958568573
loss:  16.462705612182617 0.4990549385547638
loss:  16.65641975402832 0.4910363256931305
loss:  16.26123809814453 0.48687392473220825
loss:  16.465538024902344 0.47105681896209717
loss:  16.443994522094727 0.46459025144577026
loss:  16.528526306152344 0.4691143035888672
loss:  16.524198532104492 0.48466190695762634
loss:  15.90534496307373 0.47747525572776794
*******************Epoch 56 ****************** 1140 1.0
Validation Loss
*** pred loss:  28.434206008911133 pred acc: 0.5786231756210327
*** stop loss:  7.245441436767578 stop acc: 0.9251556992530823
*** template loss:  6.882424354553223 template acc: tensor(0.1590, device='cuda:0')
*** label loss:  6.334955215454102 label acc: tensor(0.4140, device='cuda:0')
Train Loss
---> pred loss: 13.411151123046874 pred acc: 0.7741545528173447
---> stop loss: 2.031633758544922 stop acc: 0.9778015375137329
---> template loss: 0.31885950565338134 tempalte acc: 0.9352572441101075
---> molecule label loss: 0.244881534576416 molecule acc: 0.9352053642272949
---> kl loss: 0.49028730392456055
---> reconstruction loss: 16.00652666091919
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-57-with.npy
loss:  15.999405860900879 0.47266125679016113
loss:  16.256216049194336 0.4717644155025482
loss:  16.346031188964844 0.4900400638580322
loss:  16.592275619506836 0.4981710910797119
loss:  16.564298629760742 0.5062099099159241
loss:  16.412525177001953 0.49395838379859924
loss:  16.427993774414062 0.492328017950058
loss:  16.313011169433594 0.48244166374206543
loss:  16.36058235168457 0.4795842468738556
loss:  16.342866897583008 0.490123450756073
loss:  16.32537269592285 0.4720523953437805
loss:  16.140621185302734 0.4808964133262634
loss:  16.459680557250977 0.4724557101726532
loss:  16.31634521484375 0.4846830368041992
loss:  15.91162109375 0.46655774116516113
loss:  16.52044677734375 0.47284674644470215
loss:  16.308639526367188 0.48490503430366516
loss:  16.4969425201416 0.46760138869285583
loss:  16.18140411376953 0.4671483635902405
loss:  15.623894691467285 0.450492799282074
*******************Epoch 57 ****************** 1160 1.0
Validation Loss
*** pred loss:  28.49254608154297 pred acc: 0.5762680768966675
*** stop loss:  7.432847023010254 stop acc: 0.9263076186180115
*** template loss:  6.908570766448975 template acc: tensor(0.1632, device='cuda:0')
*** label loss:  6.114145755767822 label acc: tensor(0.3934, device='cuda:0')
Train Loss
---> pred loss: 13.315351867675782 pred acc: 0.7758814007043838
---> stop loss: 1.9973281860351562 stop acc: 0.9781249761581421
---> template loss: 0.28808410167694093 tempalte acc: 0.9418013572692872
---> molecule label loss: 0.21439800262451172 molecule acc: 0.9434371948242187
---> kl loss: 0.47984619140625
---> reconstruction loss: 15.815164184570314
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-58-with.npy
loss:  15.825239181518555 0.46756264567375183
loss:  16.296573638916016 0.4687972962856293
loss:  16.06220817565918 0.46969807147979736
loss:  16.50682830810547 0.47719720005989075
loss:  16.3356990814209 0.4728401303291321
loss:  16.29662322998047 0.4836089313030243
loss:  16.024368286132812 0.47229307889938354
loss:  16.21711540222168 0.46570220589637756
loss:  16.119701385498047 0.4849037230014801
loss:  16.246322631835938 0.46725958585739136
loss:  16.333688735961914 0.4784795939922333
loss:  16.124977111816406 0.4779095947742462
loss:  16.167566299438477 0.4839957356452942
loss:  16.059783935546875 0.4623158276081085
loss:  16.2586612701416 0.46096721291542053
loss:  15.846522331237793 0.45561930537223816
loss:  16.214277267456055 0.4737319350242615
loss:  16.22677230834961 0.4707203805446625
loss:  15.978014945983887 0.4671044647693634
loss:  15.81341552734375 0.46482518315315247
*******************Epoch 58 ****************** 1180 1.0
Validation Loss
*** pred loss:  28.75212860107422 pred acc: 0.571739137172699
*** stop loss:  7.857646942138672 stop acc: 0.9220423698425293
*** template loss:  6.892366409301758 template acc: tensor(0.1713, device='cuda:0')
*** label loss:  6.226674556732178 label acc: tensor(0.4082, device='cuda:0')
Train Loss
---> pred loss: 13.226834106445313 pred acc: 0.7764153927564621
---> stop loss: 1.984430694580078 stop acc: 0.978109496831894
---> template loss: 0.26712584495544434 tempalte acc: 0.9465943336486816
---> molecule label loss: 0.19805076122283935 molecule acc: 0.9489364624023438
---> kl loss: 0.4712766170501709
---> reconstruction loss: 15.676442193984984
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-59-with.npy
loss:  16.005475997924805 0.4777471125125885
loss:  16.171995162963867 0.4770951271057129
loss:  15.780119895935059 0.4750531315803528
loss:  16.138843536376953 0.47593453526496887
loss:  16.217687606811523 0.4727441668510437
loss:  16.018373489379883 0.44926318526268005
loss:  16.26175308227539 0.44693854451179504
loss:  15.63969612121582 0.4481692612171173
loss:  16.095123291015625 0.445427268743515
loss:  16.288223266601562 0.45178017020225525
loss:  15.865803718566895 0.45373451709747314
loss:  16.318775177001953 0.4522620439529419
loss:  15.797761917114258 0.4609856605529785
loss:  15.871350288391113 0.4611606299877167
loss:  16.284692764282227 0.4671281576156616
loss:  16.27547836303711 0.4715389311313629
loss:  15.987841606140137 0.4571670889854431
loss:  15.909642219543457 0.46810436248779297
loss:  15.876423835754395 0.4679630994796753
loss:  15.807421684265137 0.46121034026145935
*******************Epoch 59 ****************** 1200 1.0
Validation Loss
*** pred loss:  28.65549087524414 pred acc: 0.5830917954444885
*** stop loss:  7.464539527893066 stop acc: 0.9240660071372986
*** template loss:  6.897802829742432 template acc: tensor(0.1706, device='cuda:0')
*** label loss:  6.204896450042725 label acc: tensor(0.4044, device='cuda:0')
Train Loss
---> pred loss: 13.13997802734375 pred acc: 0.7778779774904251
---> stop loss: 1.9715076446533204 stop acc: 0.9784567207098007
---> template loss: 0.2697053670883179 tempalte acc: 0.9457476615905762
---> molecule label loss: 0.1873627185821533 molecule acc: 0.9536515235900879
---> kl loss: 0.462070369720459
---> reconstruction loss: 15.568555545806886
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-60-with.npy
loss:  15.440873146057129 0.4562242031097412
loss:  16.018497467041016 0.4562551975250244
loss:  16.14727783203125 0.44850972294807434
loss:  15.828338623046875 0.4563784599304199
loss:  16.224411010742188 0.459896445274353
loss:  16.017663955688477 0.4521508812904358
loss:  16.156253814697266 0.4765321910381317
loss:  16.10817527770996 0.46673113107681274
loss:  15.504936218261719 0.45587509870529175
loss:  15.863672256469727 0.46399110555648804
loss:  15.926583290100098 0.46191728115081787
loss:  15.731241226196289 0.4545232057571411
loss:  15.803627967834473 0.4568234980106354
loss:  15.984408378601074 0.4573889970779419
loss:  15.982614517211914 0.45906588435173035
loss:  15.707812309265137 0.44627466797828674
loss:  15.749850273132324 0.45542651414871216
loss:  16.047353744506836 0.4654892385005951
loss:  15.672337532043457 0.4765329658985138
loss:  15.398582458496094 0.4361580014228821
*******************Epoch 60 ****************** 1220 1.0
Validation Loss
*** pred loss:  28.8834228515625 pred acc: 0.5731279850006104
*** stop loss:  7.615769863128662 stop acc: 0.9240971803665161
*** template loss:  6.928365230560303 template acc: tensor(0.1650, device='cuda:0')
*** label loss:  6.308475017547607 label acc: tensor(0.4024, device='cuda:0')
Train Loss
---> pred loss: 13.049990844726562 pred acc: 0.7773964822292327
---> stop loss: 1.8823570251464843 stop acc: 0.9793975919485092
---> template loss: 0.28622188568115237 tempalte acc: 0.9430249214172364
---> molecule label loss: 0.18904715776443481 molecule acc: 0.9520627021789551
---> kl loss: 0.45810723304748535
---> reconstruction loss: 15.407620000839234
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-61-with.npy
loss:  15.631237983703613 0.4503564238548279
loss:  15.909913063049316 0.4633268415927887
loss:  15.68684196472168 0.44628679752349854
loss:  16.117286682128906 0.4564466178417206
loss:  16.30374526977539 0.4571313261985779
loss:  15.857258796691895 0.4428394138813019
loss:  16.041976928710938 0.456858366727829
loss:  15.85185718536377 0.447214275598526
loss:  15.96545124053955 0.45609673857688904
loss:  15.962489128112793 0.4608250856399536
loss:  15.601778984069824 0.4502691328525543
loss:  16.04514503479004 0.4510597288608551
loss:  16.073781967163086 0.45334553718566895
loss:  15.64394760131836 0.45419979095458984
loss:  15.933248519897461 0.44629722833633423
loss:  15.934053421020508 0.46170535683631897
loss:  15.617192268371582 0.44295600056648254
loss:  15.972694396972656 0.44874343276023865
loss:  15.803519248962402 0.44885706901550293
loss:  15.040128707885742 0.45082998275756836
*******************Epoch 61 ****************** 1240 1.0
Validation Loss
*** pred loss:  28.937414169311523 pred acc: 0.5833936929702759
*** stop loss:  7.685616493225098 stop acc: 0.9226961731910706
*** template loss:  6.935436248779297 template acc: tensor(0.1629, device='cuda:0')
*** label loss:  6.180686950683594 label acc: tensor(0.3950, device='cuda:0')
Train Loss
---> pred loss: 12.982963562011719 pred acc: 0.7783679515123367
---> stop loss: 1.91332950592041 stop acc: 0.9787784039974212
---> template loss: 0.2945912599563599 tempalte acc: 0.9410264968872071
---> molecule label loss: 0.20650982856750488 molecule acc: 0.9466135025024414
---> kl loss: 0.4522822380065918
---> reconstruction loss: 15.397395801544189
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-62-with.npy
loss:  15.229516983032227 0.449204683303833
loss:  15.737929344177246 0.4561501443386078
loss:  15.859591484069824 0.4434104859828949
loss:  15.55688762664795 0.43504491448402405
loss:  15.260218620300293 0.43393608927726746
loss:  15.72043514251709 0.4524027109146118
loss:  15.680415153503418 0.4589417278766632
loss:  15.75088119506836 0.46723002195358276
loss:  15.666114807128906 0.4514395594596863
loss:  15.434224128723145 0.4563341438770294
loss:  15.617948532104492 0.4474705755710602
loss:  15.335272789001465 0.4326697885990143
loss:  15.609254837036133 0.42780277132987976
loss:  15.689210891723633 0.42604848742485046
loss:  15.396402359008789 0.4435562193393707
loss:  15.73907470703125 0.4319837689399719
loss:  15.640868186950684 0.44222354888916016
loss:  15.69385814666748 0.43869897723197937
loss:  15.72560977935791 0.4308449625968933
loss:  15.745041847229004 0.42143604159355164
*******************Epoch 62 ****************** 1260 1.0
Validation Loss
*** pred loss:  29.369552612304688 pred acc: 0.5756038427352905
*** stop loss:  7.809518337249756 stop acc: 0.9256849884986877
*** template loss:  6.944440841674805 template acc: tensor(0.1618, device='cuda:0')
*** label loss:  6.266859531402588 label acc: tensor(0.3969, device='cuda:0')
Train Loss
---> pred loss: 12.917796325683593 pred acc: 0.7813660979270936
---> stop loss: 1.7879844665527345 stop acc: 0.9807388305664062
---> template loss: 0.2659132480621338 tempalte acc: 0.948067569732666
---> molecule label loss: 0.19040329456329347 molecule acc: 0.9524724006652832
---> kl loss: 0.4423414707183838
---> reconstruction loss: 15.162095785140991
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-63-with.npy
loss:  14.93529224395752 0.44333603978157043
loss:  15.358813285827637 0.43813300132751465
loss:  15.427701950073242 0.42756298184394836
loss:  15.613032341003418 0.4316422641277313
loss:  15.558300018310547 0.4326402544975281
loss:  15.599864959716797 0.4390195310115814
loss:  15.432005882263184 0.44534537196159363
loss:  15.307441711425781 0.42428362369537354
loss:  15.236671447753906 0.43334105610847473
loss:  15.440817832946777 0.4369388222694397
loss:  15.684773445129395 0.4356992244720459
loss:  15.441889762878418 0.43105727434158325
loss:  15.42611312866211 0.4457801878452301
loss:  15.412555694580078 0.42580652236938477
loss:  15.207185745239258 0.41945040225982666
loss:  15.632768630981445 0.43085750937461853
loss:  15.470785140991211 0.431110680103302
loss:  15.391101837158203 0.4324285089969635
loss:  15.414328575134277 0.43431955575942993
loss:  15.51704216003418 0.44366294145584106
*******************Epoch 63 ****************** 1280 1.0
Validation Loss
*** pred loss:  29.34682273864746 pred acc: 0.573369562625885
*** stop loss:  7.877674102783203 stop acc: 0.9252802133560181
*** template loss:  6.971541404724121 template acc: tensor(0.1674, device='cuda:0')
*** label loss:  6.394622802734375 label acc: tensor(0.4155, device='cuda:0')
Train Loss
---> pred loss: 12.812051391601562 pred acc: 0.7815096825361252
---> stop loss: 1.7618518829345704 stop acc: 0.9810069262981415
---> template loss: 0.24331207275390626 tempalte acc: 0.9526224136352539
---> molecule label loss: 0.17408684492111207 molecule acc: 0.9574654579162598
---> kl loss: 0.43412079811096194
---> reconstruction loss: 14.991303396224975
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-64-with.npy
loss:  15.184475898742676 0.457999587059021
loss:  15.39254093170166 0.4452429413795471
loss:  15.473817825317383 0.4526509642601013
loss:  15.553755760192871 0.44230762124061584
loss:  15.409976959228516 0.44919562339782715
loss:  15.601737976074219 0.4353400468826294
loss:  15.355789184570312 0.4204556345939636
loss:  15.576266288757324 0.4207196831703186
loss:  15.341608047485352 0.4101254940032959
loss:  15.190409660339355 0.39854785799980164
loss:  15.408844947814941 0.41114458441734314
loss:  15.520142555236816 0.417785108089447
loss:  15.300267219543457 0.4381793737411499
loss:  15.239027976989746 0.4438621699810028
loss:  15.434647560119629 0.44206681847572327
loss:  15.271905899047852 0.4356837868690491
loss:  15.42426872253418 0.43581900000572205
loss:  15.636212348937988 0.43427637219429016
loss:  15.272950172424316 0.445993572473526
loss:  15.971427917480469 0.4504416286945343
*******************Epoch 64 ****************** 1300 1.0
Validation Loss
*** pred loss:  29.4708309173584 pred acc: 0.5798308849334717
*** stop loss:  7.796101093292236 stop acc: 0.925186812877655
*** template loss:  6.945157527923584 template acc: tensor(0.1671, device='cuda:0')
*** label loss:  6.33231782913208 label acc: tensor(0.4027, device='cuda:0')
Train Loss
---> pred loss: 12.82599334716797 pred acc: 0.7812031179666519
---> stop loss: 1.7814220428466796 stop acc: 0.9806617289781571
---> template loss: 0.22860314846038818 tempalte acc: 0.9564064979553223
---> molecule label loss: 0.15759358406066895 molecule acc: 0.9614177703857422
---> kl loss: 0.4343918800354004
---> reconstruction loss: 14.993611049652099
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-65-with.npy
loss:  14.978455543518066 0.4312495291233063
loss:  15.043538093566895 0.42801037430763245
loss:  15.26425838470459 0.42694732546806335
loss:  15.092700958251953 0.44607865810394287
loss:  15.024252891540527 0.415729284286499
loss:  15.16289234161377 0.4046451449394226
loss:  15.262175559997559 0.4170113503932953
loss:  15.318802833557129 0.4212983548641205
loss:  15.16911792755127 0.415959894657135
loss:  15.514841079711914 0.40760985016822815
loss:  15.47612190246582 0.4243793189525604
loss:  15.69714069366455 0.42769935727119446
loss:  15.208281517028809 0.4249165654182434
loss:  15.087714195251465 0.4205792248249054
loss:  15.567503929138184 0.43282830715179443
loss:  15.25668716430664 0.4265744090080261
loss:  15.163491249084473 0.43861454725265503
loss:  15.273982048034668 0.4216802716255188
loss:  15.106496810913086 0.42222127318382263
loss:  15.110542297363281 0.45873913168907166
*******************Epoch 65 ****************** 1320 1.0
Validation Loss
*** pred loss:  29.518936157226562 pred acc: 0.5803743600845337
*** stop loss:  8.090258598327637 stop acc: 0.9219489693641663
*** template loss:  6.991446495056152 template acc: tensor(0.1622, device='cuda:0')
*** label loss:  6.3776397705078125 label acc: tensor(0.4078, device='cuda:0')
Train Loss
---> pred loss: 12.69873046875 pred acc: 0.7831103801727295
---> stop loss: 1.729726219177246 stop acc: 0.9812295377254486
---> template loss: 0.227616024017334 tempalte acc: 0.956081485748291
---> molecule label loss: 0.15723819732666017 molecule acc: 0.9614055633544922
---> kl loss: 0.42563862800598146
---> reconstruction loss: 14.813310956954957
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-66-with.npy
loss:  14.75672721862793 0.4296222925186157
loss:  15.509806632995605 0.4081302881240845
loss:  14.933161735534668 0.4215078353881836
loss:  15.42681884765625 0.41844841837882996
loss:  15.329291343688965 0.41643014550209045
loss:  15.25414752960205 0.4298742711544037
loss:  15.417520523071289 0.4224115014076233
loss:  15.525552749633789 0.4241507351398468
loss:  15.37031078338623 0.42356881499290466
loss:  15.087029457092285 0.4267052114009857
loss:  15.23276138305664 0.41436222195625305
loss:  15.258962631225586 0.40901103615760803
loss:  15.392040252685547 0.4064958095550537
loss:  15.140975952148438 0.4091777503490448
loss:  15.167234420776367 0.41272106766700745
loss:  14.87801456451416 0.40581628680229187
loss:  15.515100479125977 0.4151037931442261
loss:  15.053560256958008 0.43195924162864685
loss:  15.306009292602539 0.43112221360206604
loss:  14.91872501373291 0.3972240388393402
*******************Epoch 66 ****************** 1340 1.0
Validation Loss
*** pred loss:  29.6208438873291 pred acc: 0.5724033713340759
*** stop loss:  8.130590438842773 stop acc: 0.9230074882507324
*** template loss:  6.987281799316406 template acc: tensor(0.1671, device='cuda:0')
*** label loss:  6.402820587158203 label acc: tensor(0.3982, device='cuda:0')
Train Loss
---> pred loss: 12.649496459960938 pred acc: 0.7850029855966568
---> stop loss: 1.7089668273925782 stop acc: 0.9813062489032746
---> template loss: 0.25653586387634275 tempalte acc: 0.9520750999450683
---> molecule label loss: 0.19099605083465576 molecule acc: 0.9514169692993164
---> kl loss: 0.4176921844482422
---> reconstruction loss: 14.805995559692382
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-67-with.npy
loss:  14.735828399658203 0.41732466220855713
loss:  15.005304336547852 0.41810306906700134
loss:  14.932527542114258 0.4137972593307495
loss:  15.29605484008789 0.41680097579956055
loss:  15.286450386047363 0.40131381154060364
loss:  15.469135284423828 0.411803662776947
loss:  15.568063735961914 0.4075654447078705
loss:  15.437902450561523 0.4084123373031616
loss:  15.420391082763672 0.43186503648757935
loss:  15.530975341796875 0.42753249406814575
loss:  15.677273750305176 0.4425448179244995
loss:  16.377099990844727 0.43372809886932373
loss:  16.208770751953125 0.41673216223716736
loss:  15.743624687194824 0.4107523560523987
loss:  15.947627067565918 0.4100412428379059
loss:  15.448060989379883 0.40693143010139465
loss:  15.79590129852295 0.41981613636016846
loss:  15.512292861938477 0.4186597764492035
loss:  15.661687850952148 0.40620172023773193
loss:  15.45875072479248 0.3850134015083313
*******************Epoch 67 ****************** 1360 1.0
Validation Loss
*** pred loss:  30.03512191772461 pred acc: 0.5712560415267944
*** stop loss:  8.280466079711914 stop acc: 0.9230697751045227
*** template loss:  6.9746479988098145 template acc: tensor(0.1541, device='cuda:0')
*** label loss:  6.3019819259643555 label acc: tensor(0.3997, device='cuda:0')
Train Loss
---> pred loss: 12.546307373046876 pred acc: 0.7869126856327057
---> stop loss: 1.6840566635131835 stop acc: 0.9815759301185608
---> template loss: 0.40880322456359863 tempalte acc: 0.9164593696594239
---> molecule label loss: 0.47127203941345214 molecule acc: 0.8708470344543457
---> kl loss: 0.41524701118469237
---> reconstruction loss: 15.11043963432312
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-68-with.npy
loss:  15.244473457336426 0.4129216969013214
loss:  15.53533935546875 0.3981163501739502
loss:  15.475131034851074 0.40587228536605835
loss:  15.48861312866211 0.40387794375419617
loss:  15.433968544006348 0.4146021604537964
loss:  15.478548049926758 0.41655951738357544
loss:  15.307099342346191 0.4115903377532959
loss:  15.547061920166016 0.4076223075389862
loss:  15.299620628356934 0.40892183780670166
loss:  15.174444198608398 0.4180482029914856
loss:  15.318561553955078 0.41825374960899353
loss:  15.224292755126953 0.42161738872528076
loss:  15.315384864807129 0.4384663701057434
loss:  15.20284366607666 0.4181237518787384
loss:  15.378484725952148 0.4225049912929535
loss:  15.182254791259766 0.41730523109436035
loss:  15.119670867919922 0.41424474120140076
loss:  15.288267135620117 0.41477274894714355
loss:  15.28520393371582 0.40471720695495605
loss:  15.582268714904785 0.4015899896621704
*******************Epoch 68 ****************** 1380 1.0
Validation Loss
*** pred loss:  29.894132614135742 pred acc: 0.574033796787262
*** stop loss:  8.390348434448242 stop acc: 0.9202677607536316
*** template loss:  7.02592658996582 template acc: tensor(0.1565, device='cuda:0')
*** label loss:  6.244082450866699 label acc: tensor(0.4063, device='cuda:0')
Train Loss
---> pred loss: 12.490782928466796 pred acc: 0.7858276933431625
---> stop loss: 1.6555103302001952 stop acc: 0.9818828403949738
---> template loss: 0.4197231292724609 tempalte acc: 0.9112649917602539
---> molecule label loss: 0.36457462310791017 molecule acc: 0.8982598304748535
---> kl loss: 0.4134864807128906
---> reconstruction loss: 14.930590057373047
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-69-with.npy
loss:  14.996223449707031 0.41005292534828186
loss:  15.14411735534668 0.39515420794487
loss:  15.107410430908203 0.3953748643398285
loss:  15.480722427368164 0.4108715057373047
loss:  15.218484878540039 0.41277891397476196
loss:  15.167939186096191 0.4115012586116791
loss:  15.000435829162598 0.41273602843284607
loss:  15.163456916809082 0.43458402156829834
loss:  15.23798942565918 0.41232481598854065
loss:  14.863822937011719 0.41574594378471375
loss:  14.898463249206543 0.4176866114139557
loss:  15.14924430847168 0.40729448199272156
loss:  14.811164855957031 0.40049266815185547
loss:  14.89358139038086 0.41264447569847107
loss:  14.992137908935547 0.39142727851867676
loss:  15.00527572631836 0.39566993713378906
loss:  14.87695026397705 0.39849913120269775
loss:  14.808021545410156 0.40589791536331177
loss:  15.114593505859375 0.4119245409965515
loss:  15.065810203552246 0.41979748010635376
*******************Epoch 69 ****************** 1400 1.0
Validation Loss
*** pred loss:  30.251821517944336 pred acc: 0.575664222240448
*** stop loss:  8.276654243469238 stop acc: 0.9225404858589172
*** template loss:  6.987735748291016 template acc: tensor(0.1622, device='cuda:0')
*** label loss:  6.157805442810059 label acc: tensor(0.4039, device='cuda:0')
Train Loss
---> pred loss: 12.413371276855468 pred acc: 0.787387591600418
---> stop loss: 1.676353645324707 stop acc: 0.981703394651413
---> template loss: 0.32148897647857666 tempalte acc: 0.9338090896606446
---> molecule label loss: 0.2299551248550415 molecule acc: 0.9378008842468262
---> kl loss: 0.40862288475036623
---> reconstruction loss: 14.641168069839477
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-70-with.npy
loss:  14.707712173461914 0.40869417786598206
loss:  14.77064037322998 0.3966631591320038
loss:  14.976009368896484 0.4029143154621124
loss:  15.347107887268066 0.3962824046611786
loss:  15.092453956604004 0.40412047505378723
loss:  15.13259506225586 0.39900895953178406
loss:  14.899446487426758 0.4034147262573242
loss:  14.994965553283691 0.39459720253944397
loss:  14.857528686523438 0.3943539261817932
loss:  14.827467918395996 0.39151227474212646
loss:  14.851475715637207 0.39725223183631897
loss:  14.957880973815918 0.40517938137054443
loss:  15.062581062316895 0.41260001063346863
loss:  15.258044242858887 0.39168640971183777
loss:  14.943303108215332 0.3902374505996704
loss:  14.908597946166992 0.39605116844177246
loss:  14.88379955291748 0.4153096079826355
loss:  15.222023963928223 0.4072296917438507
loss:  14.838799476623535 0.40147799253463745
loss:  15.227396011352539 0.4295562207698822
*******************Epoch 70 ****************** 1420 1.0
Validation Loss
*** pred loss:  30.341224670410156 pred acc: 0.5712560415267944
*** stop loss:  8.827821731567383 stop acc: 0.9171856045722961
*** template loss:  6.950908660888672 template acc: tensor(0.1643, device='cuda:0')
*** label loss:  6.20908784866333 label acc: tensor(0.4101, device='cuda:0')
Train Loss
---> pred loss: 12.486229705810548 pred acc: 0.7847109109163284
---> stop loss: 1.6516077041625976 stop acc: 0.9820187151432037
---> template loss: 0.26414506435394286 tempalte acc: 0.9476996421813965
---> molecule label loss: 0.1841020941734314 molecule acc: 0.9519953727722168
---> kl loss: 0.40190706253051756
---> reconstruction loss: 14.586084270477295
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-71-with.npy
loss:  14.852513313293457 0.3849601745605469
loss:  15.026348114013672 0.3966813087463379
loss:  14.991169929504395 0.3786891996860504
loss:  15.029252052307129 0.3776455521583557
loss:  14.858280181884766 0.3976883590221405
loss:  14.92911148071289 0.38690686225891113
loss:  15.187332153320312 0.40092653036117554
loss:  14.622868537902832 0.41141703724861145
loss:  14.935332298278809 0.4035037159919739
loss:  15.159780502319336 0.40122348070144653
loss:  14.712281227111816 0.4035691022872925
loss:  14.753730773925781 0.3899156153202057
loss:  14.73579216003418 0.3978148102760315
loss:  14.811327934265137 0.38130590319633484
loss:  14.921093940734863 0.3996991515159607
loss:  14.729935646057129 0.3864591717720032
loss:  14.954218864440918 0.39021140336990356
loss:  14.892034530639648 0.3961484730243683
loss:  14.869474411010742 0.40737947821617126
loss:  14.362107276916504 0.4164307415485382
*******************Epoch 71 ****************** 1440 1.0
Validation Loss
*** pred loss:  30.263126373291016 pred acc: 0.5770531296730042
*** stop loss:  8.423240661621094 stop acc: 0.9221357703208923
*** template loss:  6.95808744430542 template acc: tensor(0.1699, device='cuda:0')
*** label loss:  6.183717727661133 label acc: tensor(0.4041, device='cuda:0')
Train Loss
---> pred loss: 12.346528625488281 pred acc: 0.7886735081672669
---> stop loss: 1.7055767059326172 stop acc: 0.9814404100179672
---> template loss: 0.24803106784820556 tempalte acc: 0.950777244567871
---> molecule label loss: 0.1711348295211792 molecule acc: 0.9547164916992188
---> kl loss: 0.39542882442474364
---> reconstruction loss: 14.471270394325256
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-72-with.npy
loss:  14.213098526000977 0.4101724922657013
loss:  14.461060523986816 0.3950042128562927
loss:  14.512933731079102 0.40086403489112854
loss:  14.71633529663086 0.3948688805103302
loss:  14.7695894241333 0.3880690336227417
loss:  14.824019432067871 0.3855413794517517
loss:  14.797918319702148 0.40148624777793884
loss:  14.724382400512695 0.37952372431755066
loss:  14.79731273651123 0.3892018795013428
loss:  14.542938232421875 0.37246382236480713
loss:  14.528286933898926 0.3727973699569702
loss:  14.680608749389648 0.3707636594772339
loss:  14.529940605163574 0.3710014820098877
loss:  14.668027877807617 0.37138795852661133
loss:  14.583935737609863 0.3895709812641144
loss:  14.484599113464355 0.3917766809463501
loss:  14.5259370803833 0.39459046721458435
loss:  14.634514808654785 0.3885159194469452
loss:  14.561455726623535 0.3927941620349884
loss:  14.338279724121094 0.3810553550720215
*******************Epoch 72 ****************** 1460 1.0
Validation Loss
*** pred loss:  30.5820255279541 pred acc: 0.5786231756210327
*** stop loss:  8.337255477905273 stop acc: 0.9243462085723877
*** template loss:  6.9709882736206055 template acc: tensor(0.1622, device='cuda:0')
*** label loss:  6.288008689880371 label acc: tensor(0.4148, device='cuda:0')
Train Loss
---> pred loss: 12.215640258789062 pred acc: 0.7904298424720764
---> stop loss: 1.5798855781555177 stop acc: 0.9829010635614395
---> template loss: 0.23820314407348633 tempalte acc: 0.9536161422729492
---> molecule label loss: 0.17395669221878052 molecule acc: 0.9552434921264649
---> kl loss: 0.387072491645813
---> reconstruction loss: 14.207687640190123
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-73-with.npy
loss:  14.314350128173828 0.39334097504615784
loss:  14.468833923339844 0.37565043568611145
loss:  14.659150123596191 0.38440603017807007
loss:  14.504717826843262 0.36561086773872375
loss:  14.922563552856445 0.37448176741600037
loss:  14.72316837310791 0.36630967259407043
loss:  14.854763984680176 0.37685567140579224
loss:  14.497647285461426 0.38523468375205994
loss:  14.899352073669434 0.4008895754814148
loss:  14.843000411987305 0.3979499042034149
loss:  14.69813346862793 0.40465688705444336
loss:  14.68185806274414 0.4205453395843506
loss:  14.687270164489746 0.39284178614616394
loss:  14.500085830688477 0.3914019465446472
loss:  14.603760719299316 0.37844210863113403
loss:  14.576661109924316 0.37536054849624634
loss:  14.717954635620117 0.3658446967601776
loss:  14.655237197875977 0.36542168259620667
loss:  14.687785148620605 0.38601154088974
loss:  14.69640064239502 0.4170509874820709
*******************Epoch 73 ****************** 1480 1.0
Validation Loss
*** pred loss:  30.516674041748047 pred acc: 0.5774758458137512
*** stop loss:  8.40335750579834 stop acc: 0.9214508533477783
*** template loss:  6.992001533508301 template acc: tensor(0.1646, device='cuda:0')
*** label loss:  6.2612080574035645 label acc: tensor(0.4103, device='cuda:0')
Train Loss
---> pred loss: 12.183521270751953 pred acc: 0.7906951278448104
---> stop loss: 1.5633890151977539 stop acc: 0.9830318421125412
---> template loss: 0.30138909816741943 tempalte acc: 0.9422131538391113
---> molecule label loss: 0.22542004585266112 molecule acc: 0.9401970863342285
---> kl loss: 0.38591537475585935
---> reconstruction loss: 14.273719024658204
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-74-with.npy
loss:  14.24841594696045 0.37979015707969666
loss:  14.444509506225586 0.37950870394706726
loss:  14.532537460327148 0.39927032589912415
loss:  14.316489219665527 0.3865119218826294
loss:  14.516570091247559 0.39295700192451477
loss:  14.431809425354004 0.3861914575099945
loss:  14.5571870803833 0.3837909698486328
loss:  14.80307388305664 0.38240253925323486
loss:  14.671259880065918 0.3790317177772522
loss:  14.680148124694824 0.3797113299369812
loss:  14.492843627929688 0.36303630471229553
loss:  14.558693885803223 0.36357083916664124
loss:  14.429605484008789 0.36197900772094727
loss:  14.579988479614258 0.38294482231140137
loss:  14.473858833312988 0.37079891562461853
loss:  14.410239219665527 0.37674084305763245
loss:  14.675457954406738 0.3831506669521332
loss:  14.383991241455078 0.37771090865135193
loss:  14.435206413269043 0.37118881940841675
loss:  14.648821830749512 0.4017283320426941
*******************Epoch 74 ****************** 1500 1.0
Validation Loss
*** pred loss:  30.92748260498047 pred acc: 0.5762680768966675
*** stop loss:  8.845337867736816 stop acc: 0.92303866147995
*** template loss:  7.01517391204834 template acc: tensor(0.1636, device='cuda:0')
*** label loss:  6.268063068389893 label acc: tensor(0.4071, device='cuda:0')
Train Loss
---> pred loss: 12.099942779541015 pred acc: 0.7925075024366379
---> stop loss: 1.5783638954162598 stop acc: 0.9827117055654526
---> template loss: 0.2649750947952271 tempalte acc: 0.9485090255737305
---> molecule label loss: 0.19115363359451293 molecule acc: 0.9511428833007812
---> kl loss: 0.38010075092315676
---> reconstruction loss: 14.134436297416686
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-75-with.npy
loss:  14.41751766204834 0.3774329721927643
loss:  14.338974952697754 0.37713730335235596
loss:  14.280497550964355 0.37718507647514343
loss:  14.664987564086914 0.3795733153820038
loss:  14.642601013183594 0.3677625060081482
loss:  14.280696868896484 0.37843894958496094
loss:  14.52590560913086 0.38037505745887756
loss:  14.468583106994629 0.371415376663208
loss:  14.2432222366333 0.36813029646873474
loss:  14.546875953674316 0.37346670031547546
loss:  14.308603286743164 0.37596890330314636
loss:  14.501972198486328 0.38283807039260864
loss:  14.490975379943848 0.37888699769973755
loss:  14.643365859985352 0.3785983622074127
loss:  14.370071411132812 0.38623711466789246
loss:  14.452683448791504 0.3832634389400482
loss:  14.58782958984375 0.37319308519363403
loss:  14.386693954467773 0.3828771114349365
loss:  14.459831237792969 0.3698121905326843
loss:  14.145360946655273 0.35933995246887207
*******************Epoch 75 ****************** 1520 1.0
Validation Loss
*** pred loss:  30.957136154174805 pred acc: 0.5740941762924194
*** stop loss:  9.0121431350708 stop acc: 0.9177460074424744
*** template loss:  6.983808517456055 template acc: tensor(0.1583, device='cuda:0')
*** label loss:  6.272163391113281 label acc: tensor(0.4059, device='cuda:0')
Train Loss
---> pred loss: 12.08016357421875 pred acc: 0.7920711457729339
---> stop loss: 1.5876833915710449 stop acc: 0.9825681746006012
---> template loss: 0.2357919692993164 tempalte acc: 0.9538643836975098
---> molecule label loss: 0.15812675952911376 molecule acc: 0.9614429473876953
---> kl loss: 0.37609663009643557
---> reconstruction loss: 14.061766529083252
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-76-with.npy
loss:  14.321392059326172 0.37589558959007263
loss:  14.392801284790039 0.3792639672756195
loss:  14.207080841064453 0.36600005626678467
loss:  14.596382141113281 0.3734760880470276
loss:  14.222247123718262 0.3661729097366333
loss:  14.326926231384277 0.37579265236854553
loss:  14.64598560333252 0.3730180263519287
loss:  14.40573501586914 0.378056138753891
loss:  14.591752052307129 0.3731338679790497
loss:  14.347546577453613 0.3816589117050171
loss:  14.219780921936035 0.37073832750320435
loss:  14.41195011138916 0.3696303069591522
loss:  14.12042236328125 0.35875365138053894
loss:  14.33080005645752 0.3619063198566437
loss:  14.24631404876709 0.37399405241012573
loss:  14.334667205810547 0.36590898036956787
loss:  14.449286460876465 0.36051425337791443
loss:  14.479615211486816 0.37743040919303894
loss:  14.195600509643555 0.3779168725013733
loss:  14.985249519348145 0.3932333290576935
*******************Epoch 76 ****************** 1540 1.0
Validation Loss
*** pred loss:  31.395366668701172 pred acc: 0.5770531296730042
*** stop loss:  8.837542533874512 stop acc: 0.9218555688858032
*** template loss:  7.019481182098389 template acc: tensor(0.1636, device='cuda:0')
*** label loss:  6.461288928985596 label acc: tensor(0.4003, device='cuda:0')
Train Loss
---> pred loss: 12.066999816894532 pred acc: 0.7931311577558517
---> stop loss: 1.5857800483703612 stop acc: 0.9828487902879715
---> template loss: 0.21803832054138184 tempalte acc: 0.9588906288146972
---> molecule label loss: 0.14813512563705444 molecule acc: 0.9634716987609864
---> kl loss: 0.37262473106384275
---> reconstruction loss: 14.018952417373658
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-77-with.npy
loss:  14.301496505737305 0.3907306492328644
loss:  14.392047882080078 0.37987563014030457
loss:  14.522232055664062 0.37452879548072815
loss:  14.642767906188965 0.37440812587738037
loss:  14.812010765075684 0.3686826229095459
loss:  14.293561935424805 0.3705800473690033
loss:  14.49709701538086 0.355179101228714
loss:  14.887200355529785 0.35873568058013916
loss:  14.251873970031738 0.3696686029434204
loss:  14.51979923248291 0.3593973219394684
loss:  14.20005989074707 0.3578089773654938
loss:  14.479219436645508 0.3696451187133789
loss:  14.299209594726562 0.36454838514328003
loss:  14.454323768615723 0.368207186460495
loss:  14.293314933776855 0.3714180290699005
loss:  14.119617462158203 0.3684483766555786
loss:  14.2559232711792 0.37283802032470703
loss:  14.225669860839844 0.3764174282550812
loss:  14.386015892028809 0.3738575577735901
loss:  13.197564125061035 0.3603099584579468
*******************Epoch 77 ****************** 1560 1.0
Validation Loss
*** pred loss:  31.009567260742188 pred acc: 0.5787439346313477
*** stop loss:  8.507354736328125 stop acc: 0.9234744906425476
*** template loss:  6.9602837562561035 template acc: tensor(0.1681, device='cuda:0')
*** label loss:  6.24277925491333 label acc: tensor(0.4024, device='cuda:0')
Train Loss
---> pred loss: 12.062493896484375 pred acc: 0.7920045554637909
---> stop loss: 1.5140645980834961 stop acc: 0.9833824664354325
---> template loss: 0.23251936435699463 tempalte acc: 0.9567872047424316
---> molecule label loss: 0.17320876121520995 molecule acc: 0.9554206848144531
---> kl loss: 0.3692642688751221
---> reconstruction loss: 13.982286024093627
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-78-with.npy
loss:  13.893827438354492 0.3573397994041443
loss:  14.077784538269043 0.35269680619239807
loss:  13.979677200317383 0.3518936336040497
loss:  14.350213050842285 0.3536650240421295
loss:  14.325912475585938 0.3565969467163086
loss:  14.068190574645996 0.3596847653388977
loss:  14.224002838134766 0.3702895939350128
loss:  14.29919147491455 0.3813222646713257
loss:  14.161779403686523 0.3755893409252167
loss:  14.420405387878418 0.3736764192581177
loss:  13.99179744720459 0.36328402161598206
loss:  14.209548950195312 0.37256497144699097
loss:  14.234500885009766 0.37322288751602173
loss:  14.151227951049805 0.36376988887786865
loss:  14.226162910461426 0.36760765314102173
loss:  14.235701560974121 0.35796576738357544
loss:  14.053178787231445 0.3691158592700958
loss:  14.114898681640625 0.3691278100013733
loss:  14.163779258728027 0.372795432806015
loss:  14.221231460571289 0.35025885701179504
*******************Epoch 78 ****************** 1580 1.0
Validation Loss
*** pred loss:  31.27080535888672 pred acc: 0.5694444179534912
*** stop loss:  8.78115463256836 stop acc: 0.9231942892074585
*** template loss:  7.050399303436279 template acc: tensor(0.1629, device='cuda:0')
*** label loss:  6.257027626037598 label acc: tensor(0.3992, device='cuda:0')
Train Loss
---> pred loss: 11.9396240234375 pred acc: 0.7934275418519974
---> stop loss: 1.4839552879333495 stop acc: 0.983926722407341
---> template loss: 0.22290916442871095 tempalte acc: 0.9582582473754883
---> molecule label loss: 0.15903868675231933 molecule acc: 0.9592748641967773
---> kl loss: 0.36462337970733644
---> reconstruction loss: 13.805525851249696
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-79-with.npy
loss:  13.682939529418945 0.37678664922714233
loss:  13.989999771118164 0.3676094114780426
loss:  13.878646850585938 0.37388473749160767
loss:  14.265520095825195 0.3697148263454437
loss:  14.10102367401123 0.36264872550964355
loss:  14.153504371643066 0.3625600039958954
loss:  14.244132995605469 0.3716120719909668
loss:  14.00381088256836 0.36618176102638245
loss:  14.19243049621582 0.37202051281929016
loss:  14.017370223999023 0.3671189844608307
loss:  13.936877250671387 0.37439990043640137
loss:  14.041500091552734 0.3669198453426361
loss:  14.224059104919434 0.3741578459739685
loss:  14.016121864318848 0.3667081296443939
loss:  13.95018482208252 0.36291489005088806
loss:  14.126476287841797 0.3659534156322479
loss:  13.910548210144043 0.37331831455230713
loss:  13.9500150680542 0.3644334673881531
loss:  14.15440845489502 0.3595080077648163
loss:  14.906421661376953 0.3576555848121643
*******************Epoch 79 ****************** 1600 1.0
Validation Loss
*** pred loss:  31.68329429626465 pred acc: 0.5775362253189087
*** stop loss:  9.077378273010254 stop acc: 0.9193337559700012
*** template loss:  6.996331691741943 template acc: tensor(0.1646, device='cuda:0')
*** label loss:  6.345459461212158 label acc: tensor(0.4024, device='cuda:0')
Train Loss
---> pred loss: 11.895138549804688 pred acc: 0.7952734261751175
---> stop loss: 1.4920925140380858 stop acc: 0.9837557166814804
---> template loss: 0.19611014127731324 tempalte acc: 0.9648624420166015
---> molecule label loss: 0.1361555576324463 molecule acc: 0.9661501884460449
---> kl loss: 0.36780538558959963
---> reconstruction loss: 13.719494724273682
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-80-with.npy
loss:  13.715948104858398 0.34787529706954956
loss:  13.918434143066406 0.35004356503486633
loss:  14.063295364379883 0.34980279207229614
loss:  14.036627769470215 0.3521735668182373
loss:  14.002676010131836 0.3498696982860565
loss:  14.094614028930664 0.34876391291618347
loss:  14.310135841369629 0.35392114520072937
loss:  13.976630210876465 0.36202162504196167
loss:  14.116910934448242 0.35177019238471985
loss:  13.962273597717285 0.35911473631858826
loss:  13.95262336730957 0.35363930463790894
loss:  13.964705467224121 0.3678910434246063
loss:  14.16702651977539 0.37896406650543213
loss:  13.93850040435791 0.3711868226528168
loss:  13.847444534301758 0.3882555067539215
loss:  13.815802574157715 0.3850800693035126
loss:  13.80826187133789 0.38117384910583496
loss:  13.826218605041504 0.3649493157863617
loss:  14.047699928283691 0.3578353524208069
loss:  13.52924919128418 0.37375974655151367
*******************Epoch 80 ****************** 1620 1.0
Validation Loss
*** pred loss:  31.770376205444336 pred acc: 0.5736714601516724
*** stop loss:  8.978919982910156 stop acc: 0.9191469550132751
*** template loss:  7.030082702636719 template acc: tensor(0.1643, device='cuda:0')
*** label loss:  6.353816986083984 label acc: tensor(0.4089, device='cuda:0')
Train Loss
---> pred loss: 11.816721343994141 pred acc: 0.7955731987953186
---> stop loss: 1.4565523147583008 stop acc: 0.9840007215738297
---> template loss: 0.18455846309661866 tempalte acc: 0.9680801391601562
---> molecule label loss: 0.1345194697380066 molecule acc: 0.9666887283325195
---> kl loss: 0.36240453720092775
---> reconstruction loss: 13.592348575592041
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-81-with.npy
loss:  13.795045852661133 0.3550887107849121
loss:  13.873716354370117 0.3437473773956299
loss:  13.947273254394531 0.3557535707950592
loss:  13.829944610595703 0.3548797369003296
loss:  13.830743789672852 0.3543236255645752
loss:  13.98520278930664 0.35557064414024353
loss:  13.848366737365723 0.3440239429473877
loss:  13.734560012817383 0.3459842801094055
loss:  13.760074615478516 0.3520139753818512
loss:  13.889762878417969 0.34937548637390137
loss:  13.898642539978027 0.3585781157016754
loss:  13.88956069946289 0.3519466817378998
loss:  13.931629180908203 0.35884466767311096
loss:  13.74644660949707 0.35921454429626465
loss:  13.8474702835083 0.35843607783317566
loss:  13.90478801727295 0.3697471618652344
loss:  13.930496215820312 0.3543972074985504
loss:  13.961278915405273 0.36521539092063904
loss:  14.022796630859375 0.35608920454978943
loss:  14.202963829040527 0.3862018585205078
*******************Epoch 81 ****************** 1640 1.0
Validation Loss
*** pred loss:  32.05839538574219 pred acc: 0.5753019452095032
*** stop loss:  9.161394119262695 stop acc: 0.9205479621887207
*** template loss:  7.006569862365723 template acc: tensor(0.1674, device='cuda:0')
*** label loss:  6.39868688583374 label acc: tensor(0.3995, device='cuda:0')
Train Loss
---> pred loss: 11.782919311523438 pred acc: 0.7962995827198028
---> stop loss: 1.4416373252868653 stop acc: 0.9842006534337997
---> template loss: 0.1785785436630249 tempalte acc: 0.9694366455078125
---> molecule label loss: 0.1319313645362854 molecule acc: 0.968387508392334
---> kl loss: 0.3564716100692749
---> reconstruction loss: 13.535065865516664
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-82-with.npy
loss:  13.727385520935059 0.3475356698036194
loss:  13.97270393371582 0.3604520261287689
loss:  13.970645904541016 0.36383065581321716
loss:  13.897895812988281 0.3575434684753418
loss:  14.070042610168457 0.3651154339313507
loss:  14.088157653808594 0.36298519372940063
loss:  13.947256088256836 0.35624852776527405
loss:  13.985246658325195 0.36728623509407043
loss:  13.713495254516602 0.3619121015071869
loss:  13.960895538330078 0.3667454123497009
loss:  13.84803581237793 0.3534418046474457
loss:  13.811506271362305 0.3753702640533447
loss:  13.992738723754883 0.3681991994380951
loss:  14.012781143188477 0.361330509185791
loss:  14.042433738708496 0.35102710127830505
loss:  13.844106674194336 0.3497496545314789
loss:  14.079960823059082 0.3561860918998718
loss:  13.827783584594727 0.3509899079799652
loss:  13.743361473083496 0.3444522023200989
loss:  13.592339515686035 0.36038997769355774
*******************Epoch 82 ****************** 1660 1.0
Validation Loss
*** pred loss:  31.97356605529785 pred acc: 0.5636473298072815
*** stop loss:  9.020622253417969 stop acc: 0.9247198104858398
*** template loss:  7.003005027770996 template acc: tensor(0.1643, device='cuda:0')
*** label loss:  6.396158218383789 label acc: tensor(0.3949, device='cuda:0')
Train Loss
---> pred loss: 11.751960754394531 pred acc: 0.7960437625646591
---> stop loss: 1.4689908027648926 stop acc: 0.9838863700628281
---> template loss: 0.19033488035202026 tempalte acc: 0.9659699440002442
---> molecule label loss: 0.13611258268356324 molecule acc: 0.9676017761230469
---> kl loss: 0.35903956890106203
---> reconstruction loss: 13.547399640083313
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-83-with.npy
loss:  13.573561668395996 0.3511025309562683
loss:  13.799273490905762 0.35099855065345764
loss:  13.979230880737305 0.365451455116272
loss:  13.973676681518555 0.3549962043762207
loss:  14.053349494934082 0.3603121042251587
loss:  13.886219024658203 0.35247355699539185
loss:  13.8892822265625 0.34494179487228394
loss:  14.062347412109375 0.34335365891456604
loss:  13.806880950927734 0.3661651611328125
loss:  13.736998558044434 0.3606549799442291
loss:  13.829509735107422 0.3701995611190796
loss:  13.694680213928223 0.3580856919288635
loss:  13.723355293273926 0.34924617409706116
loss:  13.877886772155762 0.3578586280345917
loss:  13.826798439025879 0.33952775597572327
loss:  13.83694076538086 0.33913883566856384
loss:  13.613090515136719 0.3466092646121979
loss:  14.046784400939941 0.35170164704322815
loss:  13.769807815551758 0.34239426255226135
loss:  13.732874870300293 0.34001076221466064
*******************Epoch 83 ****************** 1680 1.0
Validation Loss
*** pred loss:  31.720855712890625 pred acc: 0.577294647693634
*** stop loss:  9.099799156188965 stop acc: 0.923723578453064
*** template loss:  7.089742660522461 template acc: tensor(0.1681, device='cuda:0')
*** label loss:  6.352447509765625 label acc: tensor(0.4071, device='cuda:0')
Train Loss
---> pred loss: 11.743805694580079 pred acc: 0.7958351761102677
---> stop loss: 1.415909767150879 stop acc: 0.9846280366182327
---> template loss: 0.18690639734268188 tempalte acc: 0.9676725387573242
---> molecule label loss: 0.13674476146697997 molecule acc: 0.9667227745056153
---> kl loss: 0.3522611379623413
---> reconstruction loss: 13.483368134498598
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-84-with.npy
loss:  13.470989227294922 0.34178295731544495
loss:  13.772793769836426 0.3435940444469452
loss:  13.552046775817871 0.342873215675354
loss:  13.951445579528809 0.3529232144355774
loss:  13.77685260772705 0.3469572365283966
loss:  13.899993896484375 0.3598877489566803
loss:  13.707430839538574 0.3610650599002838
loss:  13.74585247039795 0.3652050793170929
loss:  13.770364761352539 0.3733583390712738
loss:  13.855875015258789 0.3524252474308014
loss:  13.726309776306152 0.350204735994339
loss:  13.948046684265137 0.35862845182418823
loss:  13.782219886779785 0.36896616220474243
loss:  13.908674240112305 0.357448548078537
loss:  13.638510704040527 0.3364822566509247
loss:  13.816733360290527 0.33965298533439636
loss:  13.563644409179688 0.3428458869457245
loss:  13.68761157989502 0.3478330969810486
loss:  13.703299522399902 0.34125643968582153
loss:  13.806879997253418 0.35470274090766907
*******************Epoch 84 ****************** 1700 1.0
Validation Loss
*** pred loss:  31.896604537963867 pred acc: 0.5757849812507629
*** stop loss:  9.301019668579102 stop acc: 0.9207347631454468
*** template loss:  7.046971797943115 template acc: tensor(0.1622, device='cuda:0')
*** label loss:  6.346429824829102 label acc: tensor(0.3898, device='cuda:0')
Train Loss
---> pred loss: 11.711824798583985 pred acc: 0.7967344611883164
---> stop loss: 1.3878252029418945 stop acc: 0.9849914014339447
---> template loss: 0.17348048686981202 tempalte acc: 0.971046257019043
---> molecule label loss: 0.1292438268661499 molecule acc: 0.9687806129455566
---> kl loss: 0.35190467834472655
---> reconstruction loss: 13.402373886108398
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-85-with.npy
loss:  13.432403564453125 0.34800848364830017
loss:  13.550658226013184 0.3484841585159302
loss:  13.555780410766602 0.3571213185787201
loss:  13.90478801727295 0.36244815587997437
loss:  13.720826148986816 0.3558933436870575
loss:  13.720919609069824 0.36633098125457764
loss:  13.834498405456543 0.36366787552833557
loss:  13.67996597290039 0.3551582992076874
loss:  13.550610542297363 0.3560417890548706
loss:  13.687767028808594 0.3437517583370209
loss:  13.474550247192383 0.36228153109550476
loss:  13.67923641204834 0.35747072100639343
loss:  13.506125450134277 0.3464958667755127
loss:  13.534278869628906 0.34079301357269287
loss:  13.587592124938965 0.3382057249546051
loss:  13.67509937286377 0.3493199646472931
loss:  13.596617698669434 0.34409427642822266
loss:  13.42391586303711 0.35338327288627625
loss:  13.639213562011719 0.3401772677898407
loss:  13.11619758605957 0.31737688183784485
*******************Epoch 85 ****************** 1720 1.0
Validation Loss
*** pred loss:  32.0501708984375 pred acc: 0.5798912644386292
*** stop loss:  9.437381744384766 stop acc: 0.9185866117477417
*** template loss:  7.035759449005127 template acc: tensor(0.1653, device='cuda:0')
*** label loss:  6.339507102966309 label acc: tensor(0.3894, device='cuda:0')
Train Loss
---> pred loss: 11.554736328125 pred acc: 0.7990736573934555
---> stop loss: 1.4028966903686524 stop acc: 0.9848047733306885
---> template loss: 0.16398792266845702 tempalte acc: 0.9714672088623046
---> molecule label loss: 0.12160471677780152 molecule acc: 0.9701053619384765
---> kl loss: 0.3503252506256104
---> reconstruction loss: 13.243226385116577
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-86-with.npy
loss:  13.145119667053223 0.3465045988559723
loss:  13.493080139160156 0.3470972776412964
loss:  13.888598442077637 0.35536646842956543
loss:  13.758426666259766 0.34819650650024414
loss:  13.72080135345459 0.34950733184814453
loss:  13.467529296875 0.35115641355514526
loss:  13.502226829528809 0.3572118878364563
loss:  13.47828483581543 0.3532179296016693
loss:  13.7678861618042 0.3417136073112488
loss:  13.82808780670166 0.3556183874607086
loss:  13.477436065673828 0.3423297107219696
loss:  13.59324836730957 0.351695716381073
loss:  13.587547302246094 0.34473180770874023
loss:  13.41511344909668 0.3377602994441986
loss:  13.633672714233398 0.3478829860687256
loss:  13.438753128051758 0.344051718711853
loss:  13.35731029510498 0.34057581424713135
loss:  13.68055534362793 0.34282729029655457
loss:  13.564373970031738 0.3413863778114319
loss:  13.822403907775879 0.3659912943840027
*******************Epoch 86 ****************** 1740 1.0
Validation Loss
*** pred loss:  32.33192443847656 pred acc: 0.5757849812507629
*** stop loss:  9.26998233795166 stop acc: 0.9219178557395935
*** template loss:  7.048864841461182 template acc: tensor(0.1646, device='cuda:0')
*** label loss:  6.439206123352051 label acc: tensor(0.3945, device='cuda:0')
Train Loss
---> pred loss: 11.557462310791015 pred acc: 0.7990692645311356
---> stop loss: 1.4019625663757325 stop acc: 0.9845717668533325
---> template loss: 0.15672363042831422 tempalte acc: 0.9755025863647461
---> molecule label loss: 0.11663436889648438 molecule acc: 0.9734334945678711
---> kl loss: 0.3482411623001099
---> reconstruction loss: 13.232783007621766
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-87-with.npy
loss:  13.243968963623047 0.33559906482696533
loss:  13.546111106872559 0.3349314033985138
loss:  13.508479118347168 0.3312312960624695
loss:  13.40680980682373 0.322579950094223
loss:  13.755354881286621 0.32486897706985474
loss:  13.62305736541748 0.33342307806015015
loss:  13.538148880004883 0.341478556394577
loss:  13.484003067016602 0.3528521955013275
loss:  13.519718170166016 0.34841296076774597
loss:  13.600631713867188 0.3525647819042206
loss:  13.580461502075195 0.35500022768974304
loss:  13.585410118103027 0.35680651664733887
loss:  13.631023406982422 0.35504236817359924
loss:  13.589510917663574 0.35134124755859375
loss:  13.478679656982422 0.3473379611968994
loss:  13.55484676361084 0.34120243787765503
loss:  13.55176067352295 0.333629310131073
loss:  13.389299392700195 0.3503571152687073
loss:  13.430464744567871 0.3313543200492859
loss:  13.15275764465332 0.31193938851356506
*******************Epoch 87 ****************** 1760 1.0
Validation Loss
*** pred loss:  32.47356414794922 pred acc: 0.5780797004699707
*** stop loss:  9.778250694274902 stop acc: 0.9185866117477417
*** template loss:  7.052980422973633 template acc: tensor(0.1681, device='cuda:0')
*** label loss:  6.434353351593018 label acc: tensor(0.3950, device='cuda:0')
Train Loss
---> pred loss: 11.512689208984375 pred acc: 0.7995353519916535
---> stop loss: 1.373596477508545 stop acc: 0.9850756317377091
---> template loss: 0.1601353883743286 tempalte acc: 0.9729656219482422
---> molecule label loss: 0.12150592803955078 molecule acc: 0.9717784881591797
---> kl loss: 0.34059762954711914
---> reconstruction loss: 13.167925930023193
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-88-with.npy
loss:  13.615912437438965 0.3446236252784729
loss:  13.390195846557617 0.33884570002555847
loss:  13.803370475769043 0.35814014077186584
loss:  13.506128311157227 0.3607500195503235
loss:  13.671335220336914 0.3580818772315979
loss:  13.718412399291992 0.36689579486846924
loss:  13.590548515319824 0.3436659276485443
loss:  13.336029052734375 0.3480350375175476
loss:  13.496475219726562 0.3466671109199524
loss:  13.509237289428711 0.33604592084884644
loss:  13.512535095214844 0.3277565538883209
loss:  13.46578311920166 0.33455929160118103
loss:  13.497665405273438 0.33185431361198425
loss:  13.706839561462402 0.3301246762275696
loss:  13.47584342956543 0.3286440372467041
loss:  13.53712272644043 0.343124657869339
loss:  13.414056777954102 0.3502398133277893
loss:  13.452855110168457 0.34007683396339417
loss:  13.442723274230957 0.36425960063934326
loss:  13.381613731384277 0.35120347142219543
*******************Epoch 88 ****************** 1780 1.0
Validation Loss
*** pred loss:  32.1514778137207 pred acc: 0.5690820813179016
*** stop loss:  9.487770080566406 stop acc: 0.9225093722343445
*** template loss:  7.078250885009766 template acc: tensor(0.1685, device='cuda:0')
*** label loss:  6.524918079376221 label acc: tensor(0.4069, device='cuda:0')
Train Loss
---> pred loss: 11.542951202392578 pred acc: 0.799340745806694
---> stop loss: 1.3607268333435059 stop acc: 0.9851858496665955
---> template loss: 0.15728038549423218 tempalte acc: 0.9748062133789063
---> molecule label loss: 0.12009650468826294 molecule acc: 0.9721785545349121
---> kl loss: 0.34517972469329833
---> reconstruction loss: 13.181054711341858
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-89-with.npy
loss:  13.207942962646484 0.36316144466400146
loss:  13.192059516906738 0.3545202910900116
loss:  13.4724702835083 0.352552205324173
loss:  13.508439064025879 0.34060075879096985
loss:  13.414299011230469 0.3477224111557007
loss:  13.609577178955078 0.3383823335170746
loss:  13.410648345947266 0.3267550468444824
loss:  13.563355445861816 0.32899606227874756
loss:  13.61288833618164 0.3306841552257538
loss:  13.425552368164062 0.3231545686721802
loss:  13.377713203430176 0.3158222734928131
loss:  13.746975898742676 0.33409151434898376
loss:  13.348973274230957 0.33117061853408813
loss:  13.623420715332031 0.3406931161880493
loss:  13.425432205200195 0.35517415404319763
loss:  13.46402645111084 0.35907426476478577
loss:  13.432393074035645 0.36845046281814575
loss:  13.481210708618164 0.35742488503456116
loss:  13.378403663635254 0.3532809019088745
loss:  13.18094539642334 0.34861743450164795
*******************Epoch 89 ****************** 1800 1.0
Validation Loss
*** pred loss:  32.63803482055664 pred acc: 0.5689613223075867
*** stop loss:  9.689074516296387 stop acc: 0.9207659363746643
*** template loss:  7.035149574279785 template acc: tensor(0.1702, device='cuda:0')
*** label loss:  6.394760608673096 label acc: tensor(0.3969, device='cuda:0')
Train Loss
---> pred loss: 11.459483337402343 pred acc: 0.8000595152378083
---> stop loss: 1.3373762130737306 stop acc: 0.9855372846126557
---> template loss: 0.173967707157135 tempalte acc: 0.9707381248474121
---> molecule label loss: 0.12949390411376954 molecule acc: 0.9707391738891602
---> kl loss: 0.3435164213180542
---> reconstruction loss: 13.100319027900696
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-90-with.npy
loss:  13.414408683776855 0.35039034485816956
loss:  13.345242500305176 0.34757664799690247
loss:  13.54939079284668 0.34521591663360596
loss:  13.51392936706543 0.3487936854362488
loss:  13.49769115447998 0.3377019166946411
loss:  13.66921615600586 0.33713942766189575
loss:  13.452787399291992 0.3401849865913391
loss:  13.610244750976562 0.34188464283943176
loss:  13.5354585647583 0.3321990370750427
loss:  13.745477676391602 0.32516345381736755
loss:  13.747049331665039 0.332800030708313
loss:  13.720719337463379 0.3285714089870453
loss:  13.645888328552246 0.3338623642921448
loss:  13.762683868408203 0.3401275873184204
loss:  13.809964179992676 0.3336449861526489
loss:  13.931884765625 0.34533077478408813
loss:  13.851373672485352 0.3428620398044586
loss:  13.87202262878418 0.33552286028862
loss:  13.750472068786621 0.3447948694229126
loss:  13.95937728881836 0.33793628215789795
*******************Epoch 90 ****************** 1820 1.0
Validation Loss
*** pred loss:  32.724693298339844 pred acc: 0.5713164210319519
*** stop loss:  9.441793441772461 stop acc: 0.9204545617103577
*** template loss:  7.1493611335754395 template acc: tensor(0.1646, device='cuda:0')
*** label loss:  6.920164108276367 label acc: tensor(0.3663, device='cuda:0')
Train Loss
---> pred loss: 11.433257293701171 pred acc: 0.8005101710557938
---> stop loss: 1.3750459671020507 stop acc: 0.9849925220012665
---> template loss: 0.24747824668884277 tempalte acc: 0.9547954559326172
---> molecule label loss: 0.2743964672088623 molecule acc: 0.9244466781616211
---> kl loss: 0.33908512592315676
---> reconstruction loss: 13.330180621147155
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-91-with.npy
loss:  13.838494300842285 0.33383211493492126
loss:  13.780488967895508 0.3397047519683838
loss:  13.755667686462402 0.33691278100013733
loss:  13.868840217590332 0.32915276288986206
loss:  13.957511901855469 0.3345795273780823
loss:  13.776585578918457 0.34258174896240234
loss:  14.131484985351562 0.3271944522857666
loss:  13.967144012451172 0.34045839309692383
loss:  13.608080863952637 0.33743104338645935
loss:  13.898072242736816 0.33859434723854065
loss:  13.810019493103027 0.3526918292045593
loss:  13.553868293762207 0.3450576663017273
loss:  13.712813377380371 0.3444116711616516
loss:  13.619486808776855 0.34304848313331604
loss:  13.627076148986816 0.34517499804496765
loss:  13.550046920776367 0.3380131721496582
loss:  13.407390594482422 0.32869502902030945
loss:  13.620863914489746 0.33751848340034485
loss:  13.421976089477539 0.3322398364543915
loss:  13.785140991210938 0.3417632579803467
*******************Epoch 91 ****************** 1840 1.0
Validation Loss
*** pred loss:  32.622520446777344 pred acc: 0.5768719911575317
*** stop loss:  9.487407684326172 stop acc: 0.9221668839454651
*** template loss:  7.084533214569092 template acc: tensor(0.1706, device='cuda:0')
*** label loss:  6.365131855010986 label acc: tensor(0.4046, device='cuda:0')
Train Loss
---> pred loss: 11.393411254882812 pred acc: 0.8014468520879745
---> stop loss: 1.409506130218506 stop acc: 0.984389391541481
---> template loss: 0.27572486400604246 tempalte acc: 0.9490362167358398
---> molecule label loss: 0.3174578189849854 molecule acc: 0.9108508110046387
---> kl loss: 0.3384528160095215
---> reconstruction loss: 13.396099185943603
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-92-with.npy
loss:  12.964628219604492 0.3355422019958496
loss:  13.222201347351074 0.34282174706459045
loss:  13.354174613952637 0.3313930630683899
loss:  13.2783842086792 0.3390273451805115
loss:  13.558509826660156 0.34716418385505676
loss:  13.31962776184082 0.3450104594230652
loss:  13.267854690551758 0.3470191955566406
loss:  13.365288734436035 0.33791983127593994
loss:  13.180927276611328 0.3430241346359253
loss:  13.263415336608887 0.3451494574546814
loss:  13.313913345336914 0.32990097999572754
loss:  13.420577049255371 0.33130383491516113
loss:  13.30075740814209 0.33776453137397766
loss:  13.46124267578125 0.3432535231113434
loss:  13.265669822692871 0.324148952960968
loss:  13.232537269592285 0.3379785418510437
loss:  13.496735572814941 0.3391064703464508
loss:  13.37948989868164 0.34429731965065
loss:  13.492758750915527 0.33861202001571655
loss:  12.751699447631836 0.3179342746734619
*******************Epoch 92 ****************** 1860 1.0
Validation Loss
*** pred loss:  32.9771842956543 pred acc: 0.5686594247817993
*** stop loss:  9.738191604614258 stop acc: 0.9207659363746643
*** template loss:  7.040909767150879 template acc: tensor(0.1636, device='cuda:0')
*** label loss:  6.25875186920166 label acc: tensor(0.3962, device='cuda:0')
Train Loss
---> pred loss: 11.263433074951172 pred acc: 0.8027008205652237
---> stop loss: 1.2718429565429688 stop acc: 0.9860254168510437
---> template loss: 0.2275676727294922 tempalte acc: 0.9578235626220704
---> molecule label loss: 0.19375710487365722 molecule acc: 0.9500799179077148
---> kl loss: 0.33791866302490237
---> reconstruction loss: 12.956600379943847
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-93-with.npy
loss:  12.93677043914795 0.34264281392097473
loss:  13.097522735595703 0.3390149772167206
loss:  13.338996887207031 0.35243839025497437
loss:  13.308367729187012 0.33731457591056824
loss:  13.4075288772583 0.33647653460502625
loss:  13.203969955444336 0.33786484599113464
loss:  13.37011432647705 0.33517196774482727
loss:  13.255988121032715 0.3309491276741028
loss:  13.309575080871582 0.33432260155677795
loss:  13.279178619384766 0.33829009532928467
loss:  13.358123779296875 0.3462444543838501
loss:  13.481450080871582 0.3330385088920593
loss:  13.36739444732666 0.341574490070343
loss:  13.382086753845215 0.33404457569122314
loss:  13.234515190124512 0.3394448161125183
loss:  13.28226089477539 0.3285641670227051
loss:  13.271839141845703 0.3310815691947937
loss:  13.338805198669434 0.3298298716545105
loss:  13.136950492858887 0.32534176111221313
loss:  12.954862594604492 0.29931360483169556
*******************Epoch 93 ****************** 1880 1.0
Validation Loss
*** pred loss:  32.83002471923828 pred acc: 0.574999988079071
*** stop loss:  9.616225242614746 stop acc: 0.9235056638717651
*** template loss:  7.11656379699707 template acc: tensor(0.1636, device='cuda:0')
*** label loss:  6.367668628692627 label acc: tensor(0.4114, device='cuda:0')
Train Loss
---> pred loss: 11.283310699462891 pred acc: 0.803133201599121
---> stop loss: 1.2886052131652832 stop acc: 0.9859131306409836
---> template loss: 0.19734494686126708 tempalte acc: 0.9650145530700683
---> molecule label loss: 0.16190603971481324 molecule acc: 0.9590181350708008
---> kl loss: 0.3346481561660767
---> reconstruction loss: 12.931166052818298
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-94-with.npy
loss:  12.780685424804688 0.33773335814476013
loss:  13.127784729003906 0.3283959925174713
loss:  13.210060119628906 0.3347057104110718
loss:  13.2128324508667 0.33713459968566895
loss:  13.190078735351562 0.33802559971809387
loss:  13.401992797851562 0.3325130045413971
loss:  13.283238410949707 0.3341811001300812
loss:  13.11280632019043 0.33665454387664795
loss:  13.32951545715332 0.351815402507782
loss:  13.241463661193848 0.3408600389957428
loss:  13.224766731262207 0.35030919313430786
loss:  13.472603797912598 0.34321558475494385
loss:  13.181445121765137 0.33827051520347595
loss:  13.296920776367188 0.32213521003723145
loss:  13.040725708007812 0.32227393984794617
loss:  12.988872528076172 0.3120267391204834
loss:  13.172435760498047 0.31325721740722656
loss:  13.292994499206543 0.3264279067516327
loss:  13.238907814025879 0.3181086778640747
loss:  13.593890190124512 0.3230004608631134
*******************Epoch 94 ****************** 1900 1.0
Validation Loss
*** pred loss:  33.11252212524414 pred acc: 0.5736110806465149
*** stop loss:  9.846842765808105 stop acc: 0.9196139574050903
*** template loss:  7.087508678436279 template acc: tensor(0.1618, device='cuda:0')
*** label loss:  6.5742340087890625 label acc: tensor(0.4146, device='cuda:0')
Train Loss
---> pred loss: 11.258448791503906 pred acc: 0.8034935891628265
---> stop loss: 1.3102951049804688 stop acc: 0.9855937421321869
---> template loss: 0.18115322589874266 tempalte acc: 0.9681940078735352
---> molecule label loss: 0.13775160312652587 molecule acc: 0.9666254997253418
---> kl loss: 0.33205223083496094
---> reconstruction loss: 12.88764991760254
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-95-with.npy
loss:  12.822059631347656 0.34546369314193726
loss:  12.967540740966797 0.33731797337532043
loss:  13.11205768585205 0.34769439697265625
loss:  13.152141571044922 0.3382198214530945
loss:  13.309197425842285 0.3377559185028076
loss:  13.274818420410156 0.35601702332496643
loss:  13.345592498779297 0.32901275157928467
loss:  13.09643840789795 0.3348677158355713
loss:  12.990177154541016 0.32545167207717896
loss:  13.179247856140137 0.32516810297966003
loss:  12.880081176757812 0.32082897424697876
loss:  13.282339096069336 0.3369995653629303
loss:  13.244097709655762 0.34244582056999207
loss:  13.024303436279297 0.33700504899024963
loss:  13.200119018554688 0.33943718671798706
loss:  13.012393951416016 0.34914150834083557
loss:  13.028003692626953 0.3534562587738037
loss:  12.941710472106934 0.3325733542442322
loss:  13.196409225463867 0.33764100074768066
loss:  13.203289031982422 0.32182377576828003
*******************Epoch 95 ****************** 1920 1.0
Validation Loss
*** pred loss:  33.38109588623047 pred acc: 0.5719202756881714
*** stop loss:  9.79599380493164 stop acc: 0.9213574528694153
*** template loss:  7.0809149742126465 template acc: tensor(0.1681, device='cuda:0')
*** label loss:  6.344448089599609 label acc: tensor(0.4072, device='cuda:0')
Train Loss
---> pred loss: 11.19250946044922 pred acc: 0.8039904236793518
---> stop loss: 1.2759943008422852 stop acc: 0.9860206812620163
---> template loss: 0.17617703676223756 tempalte acc: 0.9683724403381347
---> molecule label loss: 0.1310023307800293 molecule acc: 0.9677220344543457
---> kl loss: 0.33741610050201415
---> reconstruction loss: 12.775683569908141
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-96-with.npy
loss:  12.535527229309082 0.32122161984443665
loss:  12.940951347351074 0.3183237612247467
loss:  12.935602188110352 0.3219771683216095
loss:  13.112189292907715 0.3191017210483551
loss:  13.08201789855957 0.315441370010376
loss:  13.135774612426758 0.3167075514793396
loss:  13.18125057220459 0.32139790058135986
loss:  12.951053619384766 0.3173221945762634
loss:  13.005544662475586 0.331587553024292
loss:  12.951093673706055 0.3370682895183563
loss:  13.092771530151367 0.34287235140800476
loss:  13.145079612731934 0.34263062477111816
loss:  13.117807388305664 0.3381759822368622
loss:  12.995948791503906 0.3499833047389984
loss:  13.10938835144043 0.34264785051345825
loss:  12.972808837890625 0.331630140542984
loss:  13.091116905212402 0.33834055066108704
loss:  13.038790702819824 0.3335724472999573
loss:  13.198288917541504 0.33671486377716064
loss:  13.132760047912598 0.3643326163291931
*******************Epoch 96 ****************** 1940 1.0
Validation Loss
*** pred loss:  33.44462585449219 pred acc: 0.5705313682556152
*** stop loss:  10.076766014099121 stop acc: 0.9204234480857849
*** template loss:  7.044981002807617 template acc: tensor(0.1685, device='cuda:0')
*** label loss:  6.4086408615112305 label acc: tensor(0.4086, device='cuda:0')
Train Loss
---> pred loss: 11.166078186035156 pred acc: 0.8046931475400925
---> stop loss: 1.2434343338012694 stop acc: 0.9864397943019867
---> template loss: 0.17141438722610475 tempalte acc: 0.9699583053588867
---> molecule label loss: 0.12330920696258545 molecule acc: 0.9705328941345215
---> kl loss: 0.33205249309539797
---> reconstruction loss: 12.704235959053038
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-97-with.npy
loss:  12.727518081665039 0.32230716943740845
loss:  12.757349014282227 0.3118888735771179
loss:  13.056343078613281 0.3069184422492981
loss:  13.009443283081055 0.31115958094596863
loss:  13.05012321472168 0.3143628239631653
loss:  13.01806640625 0.33071842789649963
loss:  12.969531059265137 0.33539873361587524
loss:  13.1588134765625 0.34623268246650696
loss:  12.915083885192871 0.3234389126300812
loss:  13.098786354064941 0.35223260521888733
loss:  12.979081153869629 0.3625662326812744
loss:  12.984912872314453 0.3202545642852783
loss:  13.083792686462402 0.3207390308380127
loss:  13.039252281188965 0.32435232400894165
loss:  12.809605598449707 0.3259659707546234
loss:  12.970806121826172 0.32653820514678955
loss:  12.839937210083008 0.31783348321914673
loss:  13.080795288085938 0.33145278692245483
loss:  13.18630313873291 0.3382396996021271
loss:  13.377847671508789 0.35459402203559875
*******************Epoch 97 ****************** 1960 1.0
Validation Loss
*** pred loss:  33.39277267456055 pred acc: 0.5707125663757324
*** stop loss:  9.730271339416504 stop acc: 0.9228518605232239
*** template loss:  7.0792646408081055 template acc: tensor(0.1681, device='cuda:0')
*** label loss:  6.397987365722656 label acc: tensor(0.4146, device='cuda:0')
Train Loss
---> pred loss: 11.138745880126953 pred acc: 0.8038135260343552
---> stop loss: 1.2672767639160156 stop acc: 0.9860214054584503
---> template loss: 0.16030412912368774 tempalte acc: 0.9735819816589355
---> molecule label loss: 0.11048349142074584 molecule acc: 0.9734427452087402
---> kl loss: 0.3288597106933594
---> reconstruction loss: 12.676808929443359
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-98-with.npy
loss:  12.598308563232422 0.33621591329574585
loss:  12.965472221374512 0.3388407826423645
loss:  13.074258804321289 0.3352554440498352
loss:  13.088722229003906 0.3386802077293396
loss:  13.13331413269043 0.3341734707355499
loss:  13.042708396911621 0.3231429159641266
loss:  13.117158889770508 0.32163670659065247
loss:  13.097158432006836 0.32316938042640686
loss:  13.029756546020508 0.33435365557670593
loss:  13.04695987701416 0.32144737243652344
loss:  12.907958984375 0.3130683898925781
loss:  13.017535209655762 0.32712557911872864
loss:  13.132925033569336 0.32687613368034363
loss:  13.186471939086914 0.3279411196708679
loss:  12.85533332824707 0.33331432938575745
loss:  13.181055068969727 0.343294620513916
loss:  12.97645092010498 0.35065820813179016
loss:  12.97972583770752 0.34065917134284973
loss:  13.059497833251953 0.3422984480857849
loss:  12.64054012298584 0.3319481313228607
*******************Epoch 98 ****************** 1980 1.0
Validation Loss
*** pred loss:  33.55379104614258 pred acc: 0.5673912763595581
*** stop loss:  9.892106056213379 stop acc: 0.9205479621887207
*** template loss:  7.178067684173584 template acc: tensor(0.1593, device='cuda:0')
*** label loss:  6.397367477416992 label acc: tensor(0.4026, device='cuda:0')
Train Loss
---> pred loss: 11.105512237548828 pred acc: 0.8050524950027466
---> stop loss: 1.23675479888916 stop acc: 0.9866484135389328
---> template loss: 0.19442672729492189 tempalte acc: 0.9667323112487793
---> molecule label loss: 0.13766576051712037 molecule acc: 0.9664762496948243
---> kl loss: 0.33220500946044923
---> reconstruction loss: 12.674360847473146
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-99-with.npy
loss:  12.563105583190918 0.33270105719566345
loss:  13.026032447814941 0.32723939418792725
loss:  13.050182342529297 0.3275260329246521
loss:  13.217205047607422 0.33055368065834045
loss:  13.129015922546387 0.3095216155052185
loss:  13.164661407470703 0.3241885304450989
loss:  13.135886192321777 0.32407915592193604
loss:  13.079010963439941 0.31005436182022095
loss:  13.199410438537598 0.3138635754585266
loss:  13.234434127807617 0.3276972770690918
loss:  12.94906997680664 0.3271923065185547
loss:  13.140520095825195 0.33277425169944763
loss:  13.131430625915527 0.33386901021003723
loss:  13.241860389709473 0.34021851420402527
loss:  12.9497652053833 0.33213111758232117
loss:  12.944211959838867 0.33115315437316895
loss:  13.157038688659668 0.33287936449050903
loss:  13.144662857055664 0.33517247438430786
loss:  12.87812614440918 0.3180549144744873
loss:  13.358268737792969 0.3370659649372101
*******************Epoch 99 ****************** 2000 1.0
Validation Loss
*** pred loss:  33.37561798095703 pred acc: 0.5685386061668396
*** stop loss:  9.960808753967285 stop acc: 0.9225404858589172
*** template loss:  7.373937129974365 template acc: tensor(0.1474, device='cuda:0')
*** label loss:  6.931666374206543 label acc: tensor(0.3530, device='cuda:0')
Train Loss
---> pred loss: 11.134172058105468 pred acc: 0.8037268251180649
---> stop loss: 1.2728787422180177 stop acc: 0.9859650135040283
---> template loss: 0.19846417903900146 tempalte acc: 0.9658252716064453
---> molecule label loss: 0.1517823576927185 molecule acc: 0.9614466667175293
---> kl loss: 0.3273967981338501
---> reconstruction loss: 12.757298636436461
saving file:weights/hidden_size_500_latent_size_300_depth_5_beta_1.0_lr_0.001/bvae_iter-100-with.npy
