cuda is  True
loading data.....
size of reactant dic: 9766
size of template dic: 5567
size of fgm_trees: 20080
size of rxn_trees: 20080
size of fragment dic: 273
hidden size: 200 latent_size: 300 batch size: 1000 depth: 2
beta: 1.0 lr: 0.001
size of data pairs: 20080
trainng size: 19079
valid size: 1000
loss:  143.9422149658203 4.011685848236084
loss:  139.03883361816406 4.87239933013916
loss:  136.20907592773438 7.037471771240234
loss:  123.88915252685547 11.134779930114746
loss:  116.47422790527344 18.685077667236328
loss:  104.63690185546875 30.922937393188477
loss:  95.89434814453125 50.232826232910156
loss:  94.29415130615234 58.48668670654297
loss:  89.01457214355469 58.06730651855469
loss:  84.35906982421875 54.713253021240234
loss:  83.7939453125 51.472164154052734
loss:  79.8770980834961 49.20812225341797
loss:  80.79334259033203 47.75667953491211
loss:  79.28723907470703 47.568214416503906
loss:  79.23863983154297 48.60832214355469
loss:  77.75586700439453 47.77790069580078
loss:  76.14165496826172 48.00300216674805
loss:  73.9872817993164 47.50788116455078
loss:  73.64443969726562 47.507179260253906
loss:  79.01551055908203 46.35732650756836
*******************Epoch 0 ****************** 20 0.00095
Validation Loss
*** pred loss:  41.90227508544922 pred acc: 0.2999396026134491
*** stop loss:  13.14876651763916 stop acc: 0.8129826188087463
*** template loss:  8.688864707946777 template acc: tensor(0.0355, device='cuda:0')
*** label loss:  6.4582672119140625 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 62.952606201171875 pred acc: 0.25986585011705754
---> stop loss: 18.119879150390624 stop acc: 0.7358206301927567
---> template loss: 7.809124755859375 tempalte acc: 0.018363383412361146
---> molecule label loss: 6.660503387451172 molecule acc: 0.36361405849456785
---> kl loss: 38.996560668945314
---> reconstruction loss: 95.52732094314575
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-1-with.npy
loss:  73.93672943115234 47.59670639038086
loss:  72.57828521728516 46.70096206665039
loss:  72.138427734375 45.94914245605469
loss:  73.05060577392578 46.1468391418457
loss:  70.58753204345703 45.10036087036133
loss:  70.63622283935547 45.148590087890625
loss:  69.96675872802734 45.25663757324219
loss:  69.51921081542969 45.28189468383789
loss:  69.0356216430664 46.049171447753906
loss:  67.37073516845703 46.77142333984375
loss:  66.738037109375 46.94923400878906
loss:  66.6266098022461 48.260066986083984
loss:  68.16625213623047 49.09152603149414
loss:  66.66603088378906 49.31512451171875
loss:  66.51808166503906 49.96100616455078
loss:  66.1512451171875 51.353912353515625
loss:  65.53297424316406 50.83256912231445
loss:  65.28382110595703 51.5865592956543
loss:  64.46438598632812 51.06200408935547
loss:  63.76461410522461 54.81565856933594
*******************Epoch 1 ****************** 40 0.0019500000000000001
Validation Loss
*** pred loss:  37.20480728149414 pred acc: 0.3975241482257843
*** stop loss:  10.182735443115234 stop acc: 0.8592466115951538
*** template loss:  8.611225128173828 template acc: tensor(0.0528, device='cuda:0')
*** label loss:  6.320323467254639 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 43.547552490234374 pred acc: 0.33980411738157273
---> stop loss: 12.038443756103515 stop acc: 0.8531885087490082
---> template loss: 7.174762725830078 tempalte acc: 0.04127133190631867
---> molecule label loss: 5.604157638549805 molecule acc: 0.3820912837982178
---> kl loss: 48.16147155761719
---> reconstruction loss: 68.34269401718139
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-2-with.npy
loss:  64.24539947509766 53.09346389770508
loss:  62.6072998046875 53.525543212890625
loss:  62.47478485107422 55.41300964355469
loss:  62.60110092163086 56.11774826049805
loss:  61.75700759887695 57.241127014160156
loss:  61.723812103271484 57.77117919921875
loss:  61.02574157714844 59.5406379699707
loss:  61.00719451904297 59.19017791748047
loss:  60.28850555419922 61.157562255859375
loss:  60.4626350402832 62.918025970458984
loss:  59.67034149169922 63.378440856933594
loss:  59.4238395690918 64.7142105102539
loss:  58.99148941040039 65.70533752441406
loss:  58.9847412109375 66.57766723632812
loss:  57.87319564819336 67.96466827392578
loss:  57.84354782104492 68.35833740234375
loss:  57.78170394897461 70.93279266357422
loss:  56.666107177734375 69.55679321289062
loss:  57.32698059082031 72.15948486328125
loss:  53.6810302734375 73.92694091796875
*******************Epoch 2 ****************** 60 0.00295
Validation Loss
*** pred loss:  33.12286376953125 pred acc: 0.4508453905582428
*** stop loss:  8.7144193649292 stop acc: 0.8802615404129028
*** template loss:  8.350672721862793 template acc: tensor(0.0749, device='cuda:0')
*** label loss:  6.325937271118164 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 38.1320068359375 pred acc: 0.4119501456618309
---> stop loss: 9.533538055419921 stop acc: 0.8865094065666199
---> template loss: 6.514739227294922 tempalte acc: 0.0866767406463623
---> molecule label loss: 5.483927536010742 molecule acc: 0.3830146789550781
---> kl loss: 62.962158203125
---> reconstruction loss: 59.63609390869141
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-3-with.npy
loss:  55.792259216308594 72.87508392333984
loss:  55.453834533691406 72.69658660888672
loss:  55.674373626708984 73.42839050292969
loss:  55.04229736328125 71.47881317138672
loss:  55.05650329589844 71.07774353027344
loss:  54.743370056152344 73.01470947265625
loss:  55.09843826293945 72.47111511230469
loss:  53.797706604003906 72.51075744628906
loss:  54.11933898925781 70.65391540527344
loss:  53.284690856933594 74.17981719970703
loss:  53.005958557128906 73.91458129882812
loss:  53.331783294677734 74.33230590820312
loss:  52.179927825927734 74.96360778808594
loss:  51.48722457885742 74.60737609863281
loss:  51.875465393066406 76.42930603027344
loss:  50.99053192138672 76.54205322265625
loss:  51.676143646240234 78.230712890625
loss:  50.866371154785156 78.53326416015625
loss:  51.006778717041016 77.28483581542969
loss:  51.37726593017578 81.53205871582031
*******************Epoch 3 ****************** 80 0.00395
Validation Loss
*** pred loss:  30.08671760559082 pred acc: 0.5156400799751282
*** stop loss:  7.870950698852539 stop acc: 0.8880137205123901
*** template loss:  8.075109481811523 template acc: tensor(0.0939, device='cuda:0')
*** label loss:  6.186466693878174 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 33.906585693359375 pred acc: 0.48131914138793946
---> stop loss: 8.047457885742187 stop acc: 0.9039898186922073
---> template loss: 5.772416687011718 tempalte acc: 0.1434758186340332
---> molecule label loss: 5.306863403320312 molecule acc: 0.384308385848999
---> kl loss: 74.537841796875
---> reconstruction loss: 52.998593103027346
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-4-with.npy
loss:  49.91943359375 78.527587890625
loss:  49.616180419921875 80.04227447509766
loss:  49.811119079589844 79.1142578125
loss:  48.83866882324219 77.6650161743164
loss:  48.677284240722656 78.25
loss:  48.773006439208984 80.33575439453125
loss:  49.2381477355957 79.50495910644531
loss:  48.962608337402344 81.00093078613281
loss:  49.189056396484375 81.21719360351562
loss:  48.78102493286133 82.04344940185547
loss:  48.038185119628906 81.59141540527344
loss:  47.66818618774414 82.6624984741211
loss:  47.561214447021484 82.918212890625
loss:  47.36500930786133 82.32388305664062
loss:  46.98305130004883 84.84542846679688
loss:  46.825439453125 84.13018798828125
loss:  46.176334381103516 83.22651672363281
loss:  46.47706604003906 82.92686462402344
loss:  46.91428756713867 85.35917663574219
loss:  47.087955474853516 85.296142578125
*******************Epoch 4 ****************** 100 0.0049499999999999995
Validation Loss
*** pred loss:  28.0424747467041 pred acc: 0.5478260517120361
*** stop loss:  7.2192912101745605 stop acc: 0.8981943130493164
*** template loss:  7.858675003051758 template acc: tensor(0.1041, device='cuda:0')
*** label loss:  6.133923053741455 label acc: tensor(0.3474, device='cuda:0')
Train Loss
---> pred loss: 30.701455688476564 pred acc: 0.5322602093219757
---> stop loss: 7.096101379394531 stop acc: 0.9156804293394089
---> template loss: 4.9397022247314455 tempalte acc: 0.2084747314453125
---> molecule label loss: 5.041918182373047 molecule acc: 0.38422768115997313
---> kl loss: 81.64909057617187
---> reconstruction loss: 47.74100301727295
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-5-with.npy
loss:  45.96874237060547 85.93360137939453
loss:  45.711368560791016 87.37808990478516
loss:  45.619171142578125 85.96028137207031
loss:  45.300437927246094 87.55723571777344
loss:  45.367977142333984 86.5340805053711
loss:  45.10685729980469 87.00099182128906
loss:  45.367549896240234 88.04228210449219
loss:  44.51080322265625 87.06485748291016
loss:  44.76901626586914 88.13996124267578
loss:  44.46757888793945 88.38253021240234
loss:  43.766815185546875 89.46685791015625
loss:  44.06105422973633 89.2494125366211
loss:  43.82145309448242 90.27749633789062
loss:  44.25167465209961 91.09159851074219
loss:  43.39997100830078 90.01075744628906
loss:  43.48464584350586 91.61846160888672
loss:  43.31043243408203 91.63105773925781
loss:  42.82157516479492 90.71116638183594
loss:  42.93046951293945 92.60327911376953
loss:  41.11183166503906 95.6596908569336
*******************Epoch 5 ****************** 120 0.0059499999999999996
Validation Loss
*** pred loss:  26.490360260009766 pred acc: 0.5754830837249756
*** stop loss:  6.626871585845947 stop acc: 0.9097447395324707
*** template loss:  7.626260757446289 template acc: tensor(0.1245, device='cuda:0')
*** label loss:  6.121870994567871 label acc: tensor(0.3483, device='cuda:0')
Train Loss
---> pred loss: 28.45325622558594 pred acc: 0.5649567067623138
---> stop loss: 6.397836685180664 stop acc: 0.9247806310653687
---> template loss: 4.1973926544189455 tempalte acc: 0.2916024446487427
---> molecule label loss: 4.719874572753906 molecule acc: 0.38885700702667236
---> kl loss: 89.21567993164062
---> reconstruction loss: 43.72663740753174
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-6-with.npy
loss:  42.831260681152344 92.70960998535156
loss:  43.1677131652832 93.93062591552734
loss:  42.41293716430664 93.48365783691406
loss:  42.41355514526367 93.7449951171875
loss:  42.02372360229492 93.13666534423828
loss:  42.692874908447266 91.9927749633789
loss:  42.069393157958984 92.82383728027344
loss:  41.000850677490234 93.85771179199219
loss:  41.53386306762695 93.47245788574219
loss:  41.90156555175781 93.49945831298828
loss:  41.66442108154297 92.67841339111328
loss:  41.171714782714844 94.52446746826172
loss:  41.59580993652344 94.026611328125
loss:  41.60034942626953 94.56573486328125
loss:  41.33917999267578 93.95892333984375
loss:  40.95663070678711 93.39016723632812
loss:  41.31119918823242 94.73045349121094
loss:  40.35572052001953 93.08682250976562
loss:  40.72554016113281 93.1571044921875
loss:  40.5221061706543 92.84375
*******************Epoch 6 ****************** 140 0.00695
Validation Loss
*** pred loss:  25.370412826538086 pred acc: 0.594685971736908
*** stop loss:  6.344852924346924 stop acc: 0.9122976660728455
*** template loss:  7.4521613121032715 template acc: tensor(0.1375, device='cuda:0')
*** label loss:  6.011768817901611 label acc: tensor(0.3500, device='cuda:0')
Train Loss
---> pred loss: 26.928744506835937 pred acc: 0.5888480097055435
---> stop loss: 6.082254791259766 stop acc: 0.9281537592411041
---> template loss: 3.624462890625 tempalte acc: 0.3547524929046631
---> molecule label loss: 4.423731994628906 molecule acc: 0.39395670890808104
---> kl loss: 93.480712890625
---> reconstruction loss: 41.014826257324216
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-7-with.npy
loss:  39.643707275390625 94.09707641601562
loss:  40.4544563293457 94.31956481933594
loss:  39.902854919433594 95.15628051757812
loss:  40.147220611572266 95.18829345703125
loss:  40.20825958251953 95.72184753417969
loss:  39.68174743652344 94.71763610839844
loss:  39.78941345214844 94.83737182617188
loss:  38.6533317565918 94.12428283691406
loss:  40.06651306152344 93.59150695800781
loss:  39.62055587768555 95.16104888916016
loss:  39.9142951965332 94.4307861328125
loss:  38.991268157958984 93.64826965332031
loss:  39.369056701660156 94.80076599121094
loss:  39.40686798095703 95.11566162109375
loss:  38.91055679321289 93.87586975097656
loss:  39.03865432739258 94.15046691894531
loss:  39.10048294067383 94.83511352539062
loss:  39.161006927490234 94.2320556640625
loss:  38.26736068725586 93.37748718261719
loss:  37.762603759765625 96.81454467773438
*******************Epoch 7 ****************** 160 0.00795
Validation Loss
*** pred loss:  24.41510772705078 pred acc: 0.6103864312171936
*** stop loss:  6.086642265319824 stop acc: 0.9170922040939331
*** template loss:  7.312967300415039 template acc: tensor(0.1512, device='cuda:0')
*** label loss:  6.041802883148193 label acc: tensor(0.3507, device='cuda:0')
Train Loss
---> pred loss: 25.69532165527344 pred acc: 0.6070256352424621
---> stop loss: 5.657013702392578 stop acc: 0.9340273112058639
---> template loss: 3.202153778076172 tempalte acc: 0.41324872970581056
---> molecule label loss: 4.1428180694580075 molecule acc: 0.4009106159210205
---> kl loss: 94.60979614257812
---> reconstruction loss: 38.652362618713376
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-8-with.npy
loss:  37.884029388427734 95.04739379882812
loss:  37.882164001464844 95.45112609863281
loss:  37.745567321777344 95.13700866699219
loss:  38.240997314453125 96.60246276855469
loss:  37.661155700683594 94.7540283203125
loss:  37.57304000854492 94.97491455078125
loss:  38.27634048461914 95.67861938476562
loss:  37.60627365112305 94.10112762451172
loss:  37.359596252441406 93.71885681152344
loss:  38.036460876464844 96.19027709960938
loss:  37.59784698486328 94.87763977050781
loss:  38.36386489868164 95.18018341064453
loss:  37.54887390136719 95.30623626708984
loss:  37.16241455078125 94.77995300292969
loss:  37.48250198364258 95.27156066894531
loss:  37.712554931640625 95.46418762207031
loss:  37.158729553222656 93.9306640625
loss:  37.25572204589844 94.97691345214844
loss:  36.758995056152344 95.01527404785156
loss:  36.55934143066406 93.9859848022461
*******************Epoch 8 ****************** 180 0.00895
Validation Loss
*** pred loss:  23.683183670043945 pred acc: 0.6222825646400452
*** stop loss:  6.025195121765137 stop acc: 0.9166252017021179
*** template loss:  7.224313259124756 template acc: tensor(0.1593, device='cuda:0')
*** label loss:  6.0322651863098145 label acc: tensor(0.3494, device='cuda:0')
Train Loss
---> pred loss: 24.61614990234375 pred acc: 0.6223204910755158
---> stop loss: 5.41446533203125 stop acc: 0.9374608099460602
---> template loss: 2.8574317932128905 tempalte acc: 0.45991177558898927
---> molecule label loss: 3.9000289916992186 molecule acc: 0.4098667621612549
---> kl loss: 95.02222290039063
---> reconstruction loss: 36.74287385894775
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-9-with.npy
loss:  36.20023727416992 94.40367126464844
loss:  36.701263427734375 95.73497009277344
loss:  36.7187614440918 95.51282501220703
loss:  36.63691329956055 94.99775695800781
loss:  36.46001434326172 94.87338256835938
loss:  36.47621154785156 95.38409423828125
loss:  35.86235809326172 94.96005249023438
loss:  35.92768478393555 92.2779541015625
loss:  36.59605407714844 95.1954345703125
loss:  35.80726623535156 95.73311614990234
loss:  35.62646484375 95.47927856445312
loss:  35.75579071044922 95.71622467041016
loss:  35.934661865234375 96.20912170410156
loss:  36.24721908569336 96.62423706054688
loss:  35.95180892944336 95.66972351074219
loss:  35.0286979675293 95.03008270263672
loss:  35.001853942871094 94.21353149414062
loss:  35.619998931884766 94.9141616821289
loss:  35.45664978027344 95.36993408203125
loss:  36.08203125 91.79922485351562
*******************Epoch 9 ****************** 200 0.00995
Validation Loss
*** pred loss:  23.096654891967773 pred acc: 0.6307367086410522
*** stop loss:  5.715222358703613 stop acc: 0.9235367774963379
*** template loss:  7.036811351776123 template acc: tensor(0.1769, device='cuda:0')
*** label loss:  5.940722942352295 label acc: tensor(0.3522, device='cuda:0')
Train Loss
---> pred loss: 23.671331787109374 pred acc: 0.6370890825986862
---> stop loss: 5.150927734375 stop acc: 0.940192773938179
---> template loss: 2.577302932739258 tempalte acc: 0.5051907062530517
---> molecule label loss: 3.7049110412597654 molecule acc: 0.42031540870666506
---> kl loss: 95.00493774414062
---> reconstruction loss: 35.059293764953615
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-10-with.npy
loss:  35.14623260498047 94.87916564941406
loss:  34.74785614013672 95.36174774169922
loss:  35.20140838623047 93.60655212402344
loss:  34.626102447509766 95.28766632080078
loss:  34.956573486328125 95.16531372070312
loss:  35.10540008544922 96.14287567138672
loss:  35.175453186035156 96.089599609375
loss:  34.079524993896484 95.859130859375
loss:  34.40262985229492 95.95906066894531
loss:  34.94732666015625 95.8197250366211
loss:  34.7968864440918 96.1854019165039
loss:  34.9688720703125 97.5096664428711
loss:  34.50917053222656 96.62576293945312
loss:  34.727684020996094 96.0028305053711
loss:  33.94481658935547 96.03048706054688
loss:  34.03412628173828 96.31570434570312
loss:  34.72966003417969 96.15077209472656
loss:  33.88725280761719 95.3387680053711
loss:  34.225250244140625 95.75381469726562
loss:  33.43932342529297 94.41276550292969
*******************Epoch 10 ****************** 220 0.01095
Validation Loss
*** pred loss:  22.53058624267578 pred acc: 0.6356279850006104
*** stop loss:  5.395030975341797 stop acc: 0.9274284243583679
*** template loss:  6.978367805480957 template acc: tensor(0.1674, device='cuda:0')
*** label loss:  5.9658284187316895 label acc: tensor(0.3511, device='cuda:0')
Train Loss
---> pred loss: 22.775790405273437 pred acc: 0.6495264887809753
---> stop loss: 4.904737091064453 stop acc: 0.9437512695789337
---> template loss: 2.3848499298095702 tempalte acc: 0.5296066761016845
---> molecule label loss: 3.5144123077392577 molecule acc: 0.43154001235961914
---> kl loss: 95.7248291015625
---> reconstruction loss: 33.53438758422852
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-11-with.npy
loss:  33.64830780029297 95.19136810302734
loss:  33.74717330932617 94.99777221679688
loss:  33.212501525878906 96.0150375366211
loss:  33.275569915771484 93.86381530761719
loss:  33.687652587890625 95.35098266601562
loss:  33.4793586730957 96.23200988769531
loss:  33.705745697021484 95.74888610839844
loss:  33.61781692504883 95.1043701171875
loss:  33.56245040893555 95.34172821044922
loss:  33.218868255615234 94.40679931640625
loss:  33.14255905151367 94.81129455566406
loss:  33.590545654296875 94.29374694824219
loss:  33.2773323059082 95.59860229492188
loss:  33.157508850097656 94.30943298339844
loss:  32.76424789428711 94.17965698242188
loss:  33.07485580444336 94.92530822753906
loss:  32.686397552490234 93.74496459960938
loss:  33.311073303222656 94.44869995117188
loss:  32.86894226074219 94.15847778320312
loss:  33.518531799316406 92.48341369628906
*******************Epoch 11 ****************** 240 0.01195
Validation Loss
*** pred loss:  21.986188888549805 pred acc: 0.6457125544548035
*** stop loss:  5.582564353942871 stop acc: 0.9260274171829224
*** template loss:  6.886209964752197 template acc: tensor(0.1970, device='cuda:0')
*** label loss:  5.985279083251953 label acc: tensor(0.3520, device='cuda:0')
Train Loss
---> pred loss: 22.033108520507813 pred acc: 0.6613557010889053
---> stop loss: 4.7329559326171875 stop acc: 0.9460454851388931
---> template loss: 2.1379695892333985 tempalte acc: 0.573975944519043
---> molecule label loss: 3.336118698120117 molecule acc: 0.44379940032958987
---> kl loss: 94.76032104492188
---> reconstruction loss: 32.1949884310913
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-12-with.npy
loss:  33.06417465209961 94.70793151855469
loss:  32.518245697021484 94.43753814697266
loss:  32.779052734375 95.17947387695312
loss:  32.541099548339844 93.83869934082031
loss:  32.57817077636719 94.94170379638672
loss:  32.666934967041016 94.65097045898438
loss:  32.61946105957031 95.14698791503906
loss:  32.97785186767578 94.28876495361328
loss:  32.37192916870117 94.33363342285156
loss:  32.2119026184082 93.45654296875
loss:  32.7911491394043 93.92822265625
loss:  32.15143585205078 93.9898452758789
loss:  32.403682708740234 93.86381530761719
loss:  32.0626335144043 93.20915985107422
loss:  31.987838745117188 93.84307861328125
loss:  32.35974884033203 92.42951965332031
loss:  31.855382919311523 94.56904602050781
loss:  31.57463264465332 93.04196166992188
loss:  31.96929931640625 94.13641357421875
loss:  32.01993179321289 96.4384765625
*******************Epoch 12 ****************** 260 0.01295
Validation Loss
*** pred loss:  21.75111198425293 pred acc: 0.6477656960487366
*** stop loss:  5.3037519454956055 stop acc: 0.9298879504203796
*** template loss:  6.890529632568359 template acc: tensor(0.1970, device='cuda:0')
*** label loss:  5.955193996429443 label acc: tensor(0.3502, device='cuda:0')
Train Loss
---> pred loss: 21.366815185546876 pred acc: 0.6690285116434097
---> stop loss: 4.690570449829101 stop acc: 0.946127513051033
---> template loss: 1.957235336303711 tempalte acc: 0.6036276817321777
---> molecule label loss: 3.1852495193481447 molecule acc: 0.455430793762207
---> kl loss: 94.22158203125
---> reconstruction loss: 31.15505939453125
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-13-with.npy
loss:  31.058326721191406 94.11367797851562
loss:  31.205341339111328 92.2499771118164
loss:  31.69485855102539 92.83978271484375
loss:  31.707067489624023 93.88580322265625
loss:  31.87603187561035 94.03628540039062
loss:  31.5449275970459 92.6961669921875
loss:  31.110004425048828 93.52527618408203
loss:  31.303390502929688 92.57513427734375
loss:  31.215978622436523 93.80184936523438
loss:  31.61797523498535 91.85250854492188
loss:  31.41017723083496 92.5645751953125
loss:  31.376415252685547 92.81025695800781
loss:  31.584251403808594 92.15130615234375
loss:  31.220186233520508 91.87393188476562
loss:  31.000812530517578 92.42625427246094
loss:  31.45262336730957 92.83816528320312
loss:  31.14022445678711 92.52075958251953
loss:  30.463083267211914 92.00530242919922
loss:  30.757091522216797 93.20622253417969
loss:  32.14052963256836 91.37226867675781
*******************Epoch 13 ****************** 280 0.01395
Validation Loss
*** pred loss:  21.295894622802734 pred acc: 0.6549516916275024
*** stop loss:  5.200009346008301 stop acc: 0.9312266707420349
*** template loss:  6.760588645935059 template acc: tensor(0.2058, device='cuda:0')
*** label loss:  5.926013469696045 label acc: tensor(0.3573, device='cuda:0')
Train Loss
---> pred loss: 20.74248352050781 pred acc: 0.6769480913877487
---> stop loss: 4.464104461669922 stop acc: 0.9491695553064347
---> template loss: 1.8361240386962892 tempalte acc: 0.627538013458252
---> molecule label loss: 3.0513338088989257 molecule acc: 0.46515626907348634
---> kl loss: 92.76726684570312
---> reconstruction loss: 30.049860250549315
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-14-with.npy
loss:  30.459260940551758 92.60713195800781
loss:  30.739675521850586 91.79425048828125
loss:  30.762836456298828 91.47689819335938
loss:  30.854679107666016 91.43873596191406
loss:  30.721208572387695 92.12689208984375
loss:  30.58663558959961 91.49854278564453
loss:  30.45598793029785 91.26374053955078
loss:  30.845901489257812 91.54581451416016
loss:  30.077547073364258 91.71572875976562
loss:  30.205821990966797 91.76631164550781
loss:  30.171842575073242 90.94808959960938
loss:  30.133892059326172 90.96074676513672
loss:  29.933773040771484 91.03695678710938
loss:  30.592437744140625 90.73402404785156
loss:  29.981489181518555 90.93318176269531
loss:  30.303937911987305 90.90940856933594
loss:  29.962238311767578 92.25588989257812
loss:  30.682525634765625 91.10345458984375
loss:  30.594940185546875 91.66514587402344
loss:  28.82473373413086 88.66604614257812
*******************Epoch 14 ****************** 300 0.014950000000000001
Validation Loss
*** pred loss:  21.132551193237305 pred acc: 0.6574274897575378
*** stop loss:  5.04635763168335 stop acc: 0.9342465996742249
*** template loss:  6.733523368835449 template acc: tensor(0.2121, device='cuda:0')
*** label loss:  5.925931453704834 label acc: tensor(0.3562, device='cuda:0')
Train Loss
---> pred loss: 20.050881958007814 pred acc: 0.6866389095783234
---> stop loss: 4.335799789428711 stop acc: 0.9501895248889923
---> template loss: 1.7147104263305664 tempalte acc: 0.6487501621246338
---> molecule label loss: 2.921409797668457 molecule acc: 0.480147123336792
---> kl loss: 91.32234497070313
---> reconstruction loss: 28.97929881378174
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-15-with.npy
loss:  30.005250930786133 90.16326141357422
loss:  30.116743087768555 89.46788787841797
loss:  29.836570739746094 89.83867645263672
loss:  29.609872817993164 90.04700469970703
loss:  29.95389175415039 90.06332397460938
loss:  30.11321258544922 90.94596862792969
loss:  30.00527572631836 90.32257843017578
loss:  29.186763763427734 90.8264389038086
loss:  30.25149154663086 90.3214111328125
loss:  29.70238494873047 90.36933135986328
loss:  29.189916610717773 90.31430053710938
loss:  29.818466186523438 90.40377807617188
loss:  30.117136001586914 89.96897888183594
loss:  29.734371185302734 90.0221939086914
loss:  29.31462287902832 89.28079986572266
loss:  29.293088912963867 89.21197509765625
loss:  29.41539192199707 90.34699249267578
loss:  29.339149475097656 89.73228454589844
loss:  29.394763946533203 90.13197326660156
loss:  28.17519760131836 88.04621887207031
*******************Epoch 15 ****************** 320 0.01595
Validation Loss
*** pred loss:  20.673564910888672 pred acc: 0.6644927263259888
*** stop loss:  4.979837894439697 stop acc: 0.9358655214309692
*** template loss:  6.714190483093262 template acc: tensor(0.2195, device='cuda:0')
*** label loss:  5.947679042816162 label acc: tensor(0.3584, device='cuda:0')
Train Loss
---> pred loss: 19.551287841796874 pred acc: 0.693719869852066
---> stop loss: 4.274351501464844 stop acc: 0.9506923288106919
---> template loss: 1.6092355728149415 tempalte acc: 0.6666486263275146
---> molecule label loss: 2.8012601852416994 molecule acc: 0.49208364486694334
---> kl loss: 89.99127197265625
---> reconstruction loss: 28.19331963195801
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-16-with.npy
loss:  28.596595764160156 90.47228240966797
loss:  29.257612228393555 89.958984375
loss:  29.191598892211914 89.59684753417969
loss:  29.0571346282959 88.41563415527344
loss:  28.76128578186035 88.31649780273438
loss:  29.249286651611328 88.8662338256836
loss:  29.191360473632812 89.5020751953125
loss:  28.776256561279297 88.08472442626953
loss:  29.069503784179688 89.70448303222656
loss:  28.32428741455078 88.32328796386719
loss:  28.614564895629883 88.2920913696289
loss:  28.758115768432617 88.76290893554688
loss:  28.860191345214844 89.20399475097656
loss:  28.478496551513672 88.75642395019531
loss:  28.975257873535156 88.93804931640625
loss:  28.73838233947754 88.91246032714844
loss:  28.672697067260742 89.37249755859375
loss:  29.27716827392578 88.30995178222656
loss:  28.567832946777344 88.40919494628906
loss:  29.676145553588867 86.41667175292969
*******************Epoch 16 ****************** 340 0.01695
Validation Loss
*** pred loss:  20.461091995239258 pred acc: 0.667391300201416
*** stop loss:  5.337636470794678 stop acc: 0.9299813508987427
*** template loss:  6.6467132568359375 template acc: tensor(0.2195, device='cuda:0')
*** label loss:  5.877315998077393 label acc: tensor(0.3579, device='cuda:0')
Train Loss
---> pred loss: 19.057196044921874 pred acc: 0.7006517380475998
---> stop loss: 4.179264068603516 stop acc: 0.9520961582660675
---> template loss: 1.5094216346740723 tempalte acc: 0.6854784488677979
---> molecule label loss: 2.695451545715332 molecule acc: 0.5028924942016602
---> kl loss: 88.83076171875
---> reconstruction loss: 27.39900608886719
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-17-with.npy
loss:  28.78717041015625 88.02944946289062
loss:  28.02579116821289 86.99417114257812
loss:  28.78862953186035 87.84487915039062
loss:  28.39638900756836 87.49579620361328
loss:  28.590965270996094 88.16822052001953
loss:  27.7520809173584 87.93782043457031
loss:  28.3005313873291 88.68132019042969
loss:  28.292993545532227 87.36087036132812
loss:  28.529111862182617 87.81437683105469
loss:  29.120548248291016 88.80902862548828
loss:  28.467267990112305 88.6460189819336
loss:  27.642236709594727 87.68464660644531
loss:  28.34996223449707 87.6108169555664
loss:  27.896060943603516 87.06271362304688
loss:  28.261852264404297 87.27576446533203
loss:  27.779449462890625 86.45327758789062
loss:  27.562274932861328 86.76506042480469
loss:  28.36611557006836 86.27350616455078
loss:  27.777616500854492 87.38937377929688
loss:  26.50528907775879 86.79412841796875
*******************Epoch 17 ****************** 360 0.01795
Validation Loss
*** pred loss:  20.07608413696289 pred acc: 0.6746980547904968
*** stop loss:  4.860166549682617 stop acc: 0.9383873343467712
*** template loss:  6.55750036239624 template acc: tensor(0.2269, device='cuda:0')
*** label loss:  5.990016937255859 label acc: tensor(0.3490, device='cuda:0')
Train Loss
---> pred loss: 18.53956298828125 pred acc: 0.70624238550663
---> stop loss: 4.038105010986328 stop acc: 0.9542861431837082
---> template loss: 1.4417622566223145 tempalte acc: 0.6994250297546387
---> molecule label loss: 2.6102739334106446 molecule acc: 0.5115001201629639
---> kl loss: 87.5545654296875
---> reconstruction loss: 26.58801469116211
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-18-with.npy
loss:  27.916555404663086 86.7450180053711
loss:  28.198902130126953 87.90656280517578
loss:  27.114524841308594 87.03321075439453
loss:  27.730384826660156 87.49054718017578
loss:  28.25963020324707 88.0091552734375
loss:  27.830699920654297 87.56855773925781
loss:  27.418607711791992 86.14175415039062
loss:  27.1296329498291 86.17817687988281
loss:  27.67228126525879 86.04393005371094
loss:  27.559814453125 86.59939575195312
loss:  27.53061866760254 86.47807312011719
loss:  27.088756561279297 85.31788635253906
loss:  27.77515411376953 86.61941528320312
loss:  27.690338134765625 86.52105712890625
loss:  27.695932388305664 85.92320251464844
loss:  27.373991012573242 86.04478454589844
loss:  27.475358963012695 86.7222900390625
loss:  27.361248016357422 85.54291534423828
loss:  27.198688507080078 85.61439514160156
loss:  27.016357421875 85.09002685546875
*******************Epoch 18 ****************** 380 0.01895
Validation Loss
*** pred loss:  20.279935836791992 pred acc: 0.6652777791023254
*** stop loss:  4.711549758911133 stop acc: 0.9392279386520386
*** template loss:  6.621467113494873 template acc: tensor(0.2216, device='cuda:0')
*** label loss:  5.906620502471924 label acc: tensor(0.3599, device='cuda:0')
Train Loss
---> pred loss: 18.138520812988283 pred acc: 0.7113782167434692
---> stop loss: 3.9380069732666017 stop acc: 0.9552219182252883
---> template loss: 1.3629589080810547 tempalte acc: 0.711031150817871
---> molecule label loss: 2.514847755432129 molecule acc: 0.5214004516601562
---> kl loss: 86.47952880859376
---> reconstruction loss: 25.913086708374024
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-19-with.npy
loss:  27.279930114746094 84.94844055175781
loss:  26.889978408813477 84.86952209472656
loss:  27.23286247253418 86.5929183959961
loss:  27.359378814697266 86.04132080078125
loss:  27.24352264404297 86.16017150878906
loss:  27.15179443359375 85.36377716064453
loss:  27.363880157470703 85.72674560546875
loss:  26.958602905273438 84.40251922607422
loss:  27.010677337646484 85.23890686035156
loss:  26.934200286865234 85.52587890625
loss:  26.235401153564453 84.22982025146484
loss:  26.80748748779297 84.98536682128906
loss:  26.833717346191406 85.20286560058594
loss:  26.662147521972656 85.44438171386719
loss:  27.691650390625 84.60690307617188
loss:  27.066608428955078 85.2435073852539
loss:  27.500320434570312 84.82654571533203
loss:  26.59421730041504 84.83834838867188
loss:  26.569604873657227 84.50328063964844
loss:  26.415904998779297 84.3548812866211
*******************Epoch 19 ****************** 400 0.019950000000000002
Validation Loss
*** pred loss:  19.914304733276367 pred acc: 0.6757850050926208
*** stop loss:  4.751461505889893 stop acc: 0.9391034245491028
*** template loss:  6.567884922027588 template acc: tensor(0.2283, device='cuda:0')
*** label loss:  5.9404616355896 label acc: tensor(0.3635, device='cuda:0')
Train Loss
---> pred loss: 17.78857879638672 pred acc: 0.7159741580486297
---> stop loss: 3.8161903381347657 stop acc: 0.956959655880928
---> template loss: 1.3024746894836425 tempalte acc: 0.7226744174957276
---> molecule label loss: 2.4245479583740233 molecule acc: 0.5362844944000245
---> kl loss: 85.15530395507812
---> reconstruction loss: 25.291245680236816
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-20-with.npy
loss:  109.30506134033203 84.55696105957031
loss:  101.83934020996094 75.67764282226562
loss:  91.70790100097656 65.91188049316406
loss:  83.72764587402344 56.19886016845703
loss:  76.18446350097656 47.11476516723633
loss:  69.1729736328125 37.564395904541016
loss:  63.05716323852539 28.866744995117188
loss:  59.84785461425781 22.604455947875977
loss:  60.698585510253906 18.175752639770508
loss:  51.815391540527344 13.866386413574219
loss:  50.53990173339844 11.020844459533691
loss:  49.22224426269531 8.909130096435547
loss:  46.72215270996094 7.247542381286621
loss:  45.7020378112793 5.845080375671387
loss:  45.009952545166016 4.890758037567139
loss:  44.184391021728516 4.345398902893066
loss:  44.004783630371094 3.77956485748291
loss:  42.262123107910156 3.398655414581299
loss:  43.44397735595703 3.2686760425567627
loss:  42.02949523925781 2.9825637340545654
*******************Epoch 20 ****************** 420 1.0
Validation Loss
*** pred loss:  26.327316284179688 pred acc: 0.5612318515777588
*** stop loss:  6.216291904449463 stop acc: 0.9137297868728638
*** template loss:  8.170292854309082 template acc: tensor(0.0320, device='cuda:0')
*** label loss:  6.077524662017822 label acc: tensor(0.3460, device='cuda:0')
Train Loss
---> pred loss: 22.676420593261717 pred acc: 0.6318412214517594
---> stop loss: 5.5936439514160154 stop acc: 0.9345568716526031
---> template loss: 3.889344024658203 tempalte acc: 0.31869029998779297
---> molecule label loss: 3.5531589508056642 molecule acc: 0.4254485607147217
---> kl loss: 25.311302185058594
---> reconstruction loss: 35.71256866455078
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-21-with.npy
loss:  42.18727111816406 2.653108835220337
loss:  41.70148468017578 2.5637271404266357
loss:  41.7056999206543 2.525996685028076
loss:  41.2844123840332 2.3090293407440186
loss:  40.72611999511719 2.242605447769165
loss:  40.60832595825195 2.2160439491271973
loss:  40.447444915771484 2.080955743789673
loss:  39.80606460571289 2.0751163959503174
loss:  40.821590423583984 2.094775438308716
loss:  39.864768981933594 2.0135152339935303
loss:  39.40718078613281 1.9250777959823608
loss:  39.07276916503906 1.944443702697754
loss:  38.71013259887695 2.032912015914917
loss:  38.84729766845703 1.9421716928482056
loss:  38.91762161254883 2.054274320602417
loss:  38.17375564575195 1.927258014678955
loss:  38.10585021972656 1.9364794492721558
loss:  38.709815979003906 1.9252125024795532
loss:  38.4920654296875 2.0148205757141113
loss:  38.545475006103516 1.9641281366348267
*******************Epoch 21 ****************** 440 1.0
Validation Loss
*** pred loss:  25.567914962768555 pred acc: 0.572282612323761
*** stop loss:  6.282293319702148 stop acc: 0.9164072275161743
*** template loss:  7.877551078796387 template acc: tensor(0.0517, device='cuda:0')
*** label loss:  6.1197052001953125 label acc: tensor(0.3494, device='cuda:0')
Train Loss
---> pred loss: 24.53514862060547 pred acc: 0.6077242314815521
---> stop loss: 5.296072769165039 stop acc: 0.9365898162126541
---> template loss: 4.3364105224609375 tempalte acc: 0.24767460823059081
---> molecule label loss: 3.517041778564453 molecule acc: 0.42594356536865235
---> kl loss: 2.12208251953125
---> reconstruction loss: 37.68467407226563
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-22-with.npy
loss:  37.88923263549805 1.9741098880767822
loss:  37.83415985107422 2.0446150302886963
loss:  37.99079895019531 1.9441877603530884
loss:  37.486785888671875 1.9764219522476196
loss:  37.66253662109375 2.0336697101593018
loss:  37.32450485229492 1.8615154027938843
loss:  37.74409103393555 1.9866389036178589
loss:  37.2648811340332 1.8718600273132324
loss:  36.944122314453125 1.890732765197754
loss:  36.70856475830078 1.8907033205032349
loss:  37.12002182006836 1.8496071100234985
loss:  36.700801849365234 1.8734703063964844
loss:  36.79311752319336 1.7699979543685913
loss:  36.66316604614258 1.8349766731262207
loss:  36.556644439697266 1.8527601957321167
loss:  36.918670654296875 1.86217200756073
loss:  36.65638732910156 1.9077376127243042
loss:  36.4420051574707 1.867544412612915
loss:  36.32550811767578 1.8822908401489258
loss:  36.81664276123047 2.0013363361358643
*******************Epoch 22 ****************** 460 1.0
Validation Loss
*** pred loss:  25.28849220275879 pred acc: 0.5812801718711853
*** stop loss:  6.134720802307129 stop acc: 0.9181507229804993
*** template loss:  7.699761390686035 template acc: tensor(0.0605, device='cuda:0')
*** label loss:  5.938046932220459 label acc: tensor(0.3477, device='cuda:0')
Train Loss
---> pred loss: 23.50787353515625 pred acc: 0.6246570855379104
---> stop loss: 5.019067764282227 stop acc: 0.9403341770172119
---> template loss: 3.5936378479003905 tempalte acc: 0.33748579025268555
---> molecule label loss: 3.062734603881836 molecule acc: 0.4594882488250732
---> kl loss: 1.9088172912597656
---> reconstruction loss: 35.183312225341794
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-23-with.npy
loss:  36.43042755126953 1.8965892791748047
loss:  35.966983795166016 1.8454680442810059
loss:  36.3617057800293 1.880710482597351
loss:  36.268272399902344 1.8710147142410278
loss:  36.00814437866211 1.8461964130401611
loss:  35.57639694213867 1.7977973222732544
loss:  35.814979553222656 1.7954524755477905
loss:  36.09123229980469 1.7892767190933228
loss:  36.020668029785156 1.7193537950515747
loss:  35.8459358215332 1.7597905397415161
loss:  36.33964538574219 1.7570860385894775
loss:  35.64876937866211 1.7349250316619873
loss:  35.305877685546875 1.6960746049880981
loss:  35.269554138183594 1.740361213684082
loss:  35.6549072265625 1.7359099388122559
loss:  34.86354064941406 1.7884835004806519
loss:  35.49150085449219 1.7571488618850708
loss:  36.061683654785156 1.7651277780532837
loss:  34.93423080444336 1.7261314392089844
loss:  36.3900260925293 1.5924419164657593
*******************Epoch 23 ****************** 480 1.0
Validation Loss
*** pred loss:  25.12030029296875 pred acc: 0.5828502178192139
*** stop loss:  6.324154376983643 stop acc: 0.9149128794670105
*** template loss:  7.584735870361328 template acc: tensor(0.0805, device='cuda:0')
*** label loss:  5.9676055908203125 label acc: tensor(0.3500, device='cuda:0')
Train Loss
---> pred loss: 23.169473266601564 pred acc: 0.6294884771108628
---> stop loss: 4.862328720092774 stop acc: 0.9424505859613419
---> template loss: 3.19521484375 tempalte acc: 0.3895047903060913
---> molecule label loss: 2.8154369354248048 molecule acc: 0.48220267295837405
---> kl loss: 1.7747669219970703
---> reconstruction loss: 34.04245719909668
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-24-with.npy
loss:  35.44795227050781 1.714219570159912
loss:  35.072105407714844 1.6542130708694458
loss:  34.616214752197266 1.676514983177185
loss:  35.558162689208984 1.6278971433639526
loss:  35.17769241333008 1.6486698389053345
loss:  35.63205337524414 1.6779015064239502
loss:  35.552337646484375 1.639721393585205
loss:  34.74999237060547 1.5649139881134033
loss:  34.954280853271484 1.6500664949417114
loss:  35.317378997802734 1.6976641416549683
loss:  34.730979919433594 1.6918095350265503
loss:  34.51578903198242 1.6582642793655396
loss:  34.62718963623047 1.706494927406311
loss:  35.04710006713867 1.648054599761963
loss:  34.72313690185547 1.663435459136963
loss:  34.60963439941406 1.6605921983718872
loss:  34.969181060791016 1.6272369623184204
loss:  34.77410125732422 1.5952396392822266
loss:  34.54793167114258 1.547446608543396
loss:  34.275360107421875 1.601797103881836
*******************Epoch 24 ****************** 500 1.0
Validation Loss
*** pred loss:  25.078943252563477 pred acc: 0.5833936929702759
*** stop loss:  5.872972011566162 stop acc: 0.9205791354179382
*** template loss:  7.4968743324279785 template acc: tensor(0.0820, device='cuda:0')
*** label loss:  5.993005275726318 label acc: tensor(0.3483, device='cuda:0')
Train Loss
---> pred loss: 22.879347229003905 pred acc: 0.6329937905073166
---> stop loss: 4.825201034545898 stop acc: 0.9428853929042816
---> template loss: 2.948522186279297 tempalte acc: 0.42969346046447754
---> molecule label loss: 2.6442495346069337 molecule acc: 0.5031949996948242
---> kl loss: 1.6476076126098633
---> reconstruction loss: 33.29732036590576
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-25-with.npy
loss:  33.68232727050781 1.6292349100112915
loss:  33.83013153076172 1.5834470987319946
loss:  34.403221130371094 1.627193570137024
loss:  34.34058380126953 1.5976911783218384
loss:  34.293487548828125 1.596327781677246
loss:  33.97176742553711 1.5923491716384888
loss:  34.189788818359375 1.607923984527588
loss:  34.547603607177734 1.6115362644195557
loss:  34.11354446411133 1.6253770589828491
loss:  34.349945068359375 1.5924378633499146
loss:  34.34194564819336 1.5170546770095825
loss:  34.564701080322266 1.54377281665802
loss:  33.87310028076172 1.544663429260254
loss:  34.127845764160156 1.5364445447921753
loss:  33.8666877746582 1.5110132694244385
loss:  34.08086395263672 1.521306037902832
loss:  34.43733215332031 1.4842467308044434
loss:  33.759490966796875 1.5469741821289062
loss:  34.89488220214844 1.5273066759109497
loss:  32.62445831298828 1.4755054712295532
*******************Epoch 25 ****************** 520 1.0
Validation Loss
*** pred loss:  25.24147605895996 pred acc: 0.5797705054283142
*** stop loss:  6.006253242492676 stop acc: 0.918181836605072
*** template loss:  7.514337062835693 template acc: tensor(0.0897, device='cuda:0')
*** label loss:  5.977592468261719 label acc: tensor(0.3543, device='cuda:0')
Train Loss
---> pred loss: 22.6154541015625 pred acc: 0.6366717785596847
---> stop loss: 4.693331146240235 stop acc: 0.9446978807449341
---> template loss: 2.740273666381836 tempalte acc: 0.4596466064453125
---> molecule label loss: 2.5020376205444337 molecule acc: 0.5213932037353516
---> kl loss: 1.5635904312133788
---> reconstruction loss: 32.55109767913819
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-26-with.npy
loss:  33.81523895263672 1.49785315990448
loss:  33.765682220458984 1.5119847059249878
loss:  33.93364334106445 1.481547236442566
loss:  34.01150894165039 1.5235657691955566
loss:  34.301246643066406 1.5511633157730103
loss:  33.39893341064453 1.5479782819747925
loss:  33.382598876953125 1.5123443603515625
loss:  33.18092346191406 1.5089259147644043
loss:  33.59680938720703 1.5240341424942017
loss:  33.62939453125 1.4880917072296143
loss:  33.49066925048828 1.5122958421707153
loss:  33.28553009033203 1.4786978960037231
loss:  33.48253631591797 1.4923999309539795
loss:  33.2679443359375 1.437729001045227
loss:  33.6161003112793 1.4587006568908691
loss:  33.7843017578125 1.3907246589660645
loss:  33.75237274169922 1.467665433883667
loss:  33.82495880126953 1.4162315130233765
loss:  33.60342788696289 1.4221848249435425
loss:  34.11415481567383 1.3633583784103394
*******************Epoch 26 ****************** 540 1.0
Validation Loss
*** pred loss:  25.149063110351562 pred acc: 0.58423912525177
*** stop loss:  5.9000372886657715 stop acc: 0.9226027727127075
*** template loss:  7.448655605316162 template acc: tensor(0.0907, device='cuda:0')
*** label loss:  5.9875264167785645 label acc: tensor(0.3489, device='cuda:0')
Train Loss
---> pred loss: 22.542381286621094 pred acc: 0.6383715033531189
---> stop loss: 4.654352188110352 stop acc: 0.9453833431005478
---> template loss: 2.599659729003906 tempalte acc: 0.4844509601593018
---> molecule label loss: 2.3861320495605467 molecule acc: 0.5364005088806152
---> kl loss: 1.4793736457824707
---> reconstruction loss: 32.18252210617065
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-27-with.npy
loss:  33.16099166870117 1.4659868478775024
loss:  33.5140495300293 1.434906244277954
loss:  33.33649826049805 1.4446772336959839
loss:  32.76690673828125 1.4420809745788574
loss:  33.32754898071289 1.4430550336837769
loss:  33.277687072753906 1.4374433755874634
loss:  32.98113250732422 1.419429063796997
loss:  33.08789825439453 1.4581594467163086
loss:  33.1341438293457 1.4082069396972656
loss:  32.90195083618164 1.4106138944625854
loss:  33.03314971923828 1.423127293586731
loss:  32.85512161254883 1.4323909282684326
loss:  33.222957611083984 1.387963056564331
loss:  32.91858673095703 1.3858531713485718
loss:  33.18610763549805 1.4285248517990112
loss:  33.02155303955078 1.4569272994995117
loss:  33.00647735595703 1.4391978979110718
loss:  33.01399230957031 1.4030427932739258
loss:  33.18114471435547 1.3864773511886597
loss:  32.89560317993164 1.2900652885437012
*******************Epoch 27 ****************** 560 1.0
Validation Loss
*** pred loss:  25.143381118774414 pred acc: 0.5794686079025269
*** stop loss:  5.971614360809326 stop acc: 0.9193960428237915
*** template loss:  7.4149370193481445 template acc: tensor(0.0995, device='cuda:0')
*** label loss:  6.010472297668457 label acc: tensor(0.3479, device='cuda:0')
Train Loss
---> pred loss: 22.36992645263672 pred acc: 0.6413239121437073
---> stop loss: 4.570262908935547 stop acc: 0.9461599856615066
---> template loss: 2.4590763092041015 tempalte acc: 0.5073947429656982
---> molecule label loss: 2.272002410888672 molecule acc: 0.5547585964202881
---> kl loss: 1.4199063301086425
---> reconstruction loss: 31.67126798629761
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-28-with.npy
loss:  32.353694915771484 1.3915140628814697
loss:  32.851524353027344 1.412813663482666
loss:  32.81871795654297 1.386420726776123
loss:  32.727783203125 1.395406723022461
loss:  32.54271697998047 1.4274301528930664
loss:  32.45766067504883 1.4342150688171387
loss:  32.7415771484375 1.3843693733215332
loss:  32.71769332885742 1.3547312021255493
loss:  32.839141845703125 1.3419967889785767
loss:  32.836387634277344 1.3222850561141968
loss:  32.67554473876953 1.332463264465332
loss:  31.995540618896484 1.332955241203308
loss:  32.80060577392578 1.3376036882400513
loss:  32.58368682861328 1.3486151695251465
loss:  32.51447296142578 1.292456030845642
loss:  32.68544006347656 1.3198626041412354
loss:  32.80390930175781 1.277356743812561
loss:  32.88050842285156 1.3561686277389526
loss:  32.18133544921875 1.3190292119979858
loss:  32.2962646484375 1.302422285079956
*******************Epoch 28 ****************** 580 1.0
Validation Loss
*** pred loss:  25.007476806640625 pred acc: 0.5828502178192139
*** stop loss:  5.961479663848877 stop acc: 0.920516848564148
*** template loss:  7.377934455871582 template acc: tensor(0.1041, device='cuda:0')
*** label loss:  6.002553939819336 label acc: tensor(0.3398, device='cuda:0')
Train Loss
---> pred loss: 22.172113037109376 pred acc: 0.6442737311124802
---> stop loss: 4.5264537811279295 stop acc: 0.9467440634965897
---> template loss: 2.3579948425292967 tempalte acc: 0.5218191146850586
---> molecule label loss: 2.205142784118652 molecule acc: 0.562760877609253
---> kl loss: 1.3535057067871095
---> reconstruction loss: 31.26170120239258
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-29-with.npy
loss:  32.11007308959961 1.2735393047332764
loss:  32.055015563964844 1.322824239730835
loss:  32.09545135498047 1.3060053586959839
loss:  32.529884338378906 1.330843448638916
loss:  32.34941482543945 1.31105375289917
loss:  32.30687713623047 1.3250536918640137
loss:  32.138221740722656 1.3281943798065186
loss:  32.11262130737305 1.3137956857681274
loss:  31.932510375976562 1.2960162162780762
loss:  32.52394485473633 1.2690767049789429
loss:  32.09046936035156 1.2585563659667969
loss:  32.210018157958984 1.313765287399292
loss:  32.21888732910156 1.2707974910736084
loss:  32.403934478759766 1.3064687252044678
loss:  32.27687454223633 1.2888251543045044
loss:  31.9653377532959 1.2960177659988403
loss:  31.967266082763672 1.2754876613616943
loss:  32.1492919921875 1.2914623022079468
loss:  32.14385986328125 1.3255696296691895
loss:  33.86515808105469 1.3168509006500244
*******************Epoch 29 ****************** 600 1.0
Validation Loss
*** pred loss:  25.269502639770508 pred acc: 0.5769323706626892
*** stop loss:  6.00212287902832 stop acc: 0.9220112562179565
*** template loss:  7.379939556121826 template acc: tensor(0.1080, device='cuda:0')
*** label loss:  6.040957450866699 label acc: tensor(0.3524, device='cuda:0')
Train Loss
---> pred loss: 22.084757995605468 pred acc: 0.6463585585355759
---> stop loss: 4.5346729278564455 stop acc: 0.9471101880073547
---> template loss: 2.2530496597290037 tempalte acc: 0.5408823013305664
---> molecule label loss: 2.09876708984375 molecule acc: 0.583213996887207
---> kl loss: 1.3010103225708007
---> reconstruction loss: 30.971249198913572
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-30-with.npy
loss:  31.652626037597656 1.3161165714263916
loss:  31.940845489501953 1.3398692607879639
loss:  32.2230339050293 1.291663408279419
loss:  32.05412292480469 1.3102233409881592
loss:  31.968860626220703 1.3024591207504272
loss:  31.930639266967773 1.2884676456451416
loss:  31.95404815673828 1.3035471439361572
loss:  31.57668685913086 1.285600185394287
loss:  31.88501739501953 1.249516487121582
loss:  31.542612075805664 1.2277286052703857
loss:  31.716312408447266 1.2263917922973633
loss:  31.92013168334961 1.2478381395339966
loss:  31.66739273071289 1.2550362348556519
loss:  31.867992401123047 1.227951169013977
loss:  31.3676815032959 1.2372716665267944
loss:  32.11038589477539 1.251502275466919
loss:  32.127418518066406 1.235519528388977
loss:  31.72323226928711 1.2281638383865356
loss:  32.11479949951172 1.235762357711792
loss:  31.127540588378906 1.1197028160095215
*******************Epoch 30 ****************** 620 1.0
Validation Loss
*** pred loss:  25.28502082824707 pred acc: 0.5757849812507629
*** stop loss:  5.903258800506592 stop acc: 0.9229140877723694
*** template loss:  7.358607292175293 template acc: tensor(0.1104, device='cuda:0')
*** label loss:  6.018279075622559 label acc: tensor(0.3423, device='cuda:0')
Train Loss
---> pred loss: 21.904563903808594 pred acc: 0.6492632448673248
---> stop loss: 4.450088882446289 stop acc: 0.9480916529893875
---> template loss: 2.182669830322266 tempalte acc: 0.5526742458343505
---> molecule label loss: 2.027230453491211 molecule acc: 0.5933754444122314
---> kl loss: 1.2590166091918946
---> reconstruction loss: 30.56455211639404
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-31-with.npy
loss:  31.212160110473633 1.2109311819076538
loss:  31.92839813232422 1.2332074642181396
loss:  31.36600685119629 1.2092640399932861
loss:  31.881855010986328 1.2861741781234741
loss:  31.367225646972656 1.2332450151443481
loss:  31.46932601928711 1.236128807067871
loss:  31.630359649658203 1.2086986303329468
loss:  31.5035343170166 1.2015388011932373
loss:  31.694089889526367 1.2414346933364868
loss:  31.25970458984375 1.2121803760528564
loss:  31.52112579345703 1.2107816934585571
loss:  31.608238220214844 1.2076212167739868
loss:  31.091699600219727 1.177574872970581
loss:  31.575122833251953 1.1856309175491333
loss:  30.919164657592773 1.1747745275497437
loss:  31.116933822631836 1.1626278162002563
loss:  31.295162200927734 1.169167399406433
loss:  31.190576553344727 1.170343041419983
loss:  31.23431968688965 1.1791125535964966
loss:  31.417863845825195 1.1128895282745361
*******************Epoch 31 ****************** 640 1.0
Validation Loss
*** pred loss:  25.14303207397461 pred acc: 0.5788043141365051
*** stop loss:  6.609606742858887 stop acc: 0.9146326780319214
*** template loss:  7.335390567779541 template acc: tensor(0.1168, device='cuda:0')
*** label loss:  6.058326721191406 label acc: tensor(0.3560, device='cuda:0')
Train Loss
---> pred loss: 21.788314819335938 pred acc: 0.6507982462644577
---> stop loss: 4.393232727050782 stop acc: 0.9491087257862091
---> template loss: 2.085455322265625 tempalte acc: 0.5682568550109863
---> molecule label loss: 1.945974349975586 molecule acc: 0.6064446449279786
---> kl loss: 1.2011664390563965
---> reconstruction loss: 30.212975406646727
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-32-with.npy
loss:  31.359437942504883 1.1976466178894043
loss:  31.30586051940918 1.1712106466293335
loss:  30.986719131469727 1.2178326845169067
loss:  31.19452476501465 1.1892222166061401
loss:  31.30811309814453 1.1747896671295166
loss:  30.750408172607422 1.1912641525268555
loss:  31.090961456298828 1.1792933940887451
loss:  30.883943557739258 1.1814271211624146
loss:  30.788177490234375 1.1672172546386719
loss:  31.230632781982422 1.1622810363769531
loss:  31.046958923339844 1.150154948234558
loss:  30.927898406982422 1.1820787191390991
loss:  31.010059356689453 1.1799390316009521
loss:  31.244447708129883 1.1843388080596924
loss:  30.968570709228516 1.1358309984207153
loss:  30.983678817749023 1.1567347049713135
loss:  31.145645141601562 1.1708146333694458
loss:  30.77231788635254 1.148140788078308
loss:  31.165821075439453 1.146239161491394
loss:  30.586158752441406 1.2234930992126465
*******************Epoch 32 ****************** 660 1.0
Validation Loss
*** pred loss:  25.062969207763672 pred acc: 0.5844806432723999
*** stop loss:  6.389658451080322 stop acc: 0.9159402847290039
*** template loss:  7.335606575012207 template acc: tensor(0.1196, device='cuda:0')
*** label loss:  6.052717208862305 label acc: tensor(0.3554, device='cuda:0')
Train Loss
---> pred loss: 21.610270690917968 pred acc: 0.6530890166759491
---> stop loss: 4.383455276489258 stop acc: 0.9490117222070694
---> template loss: 2.0016368865966796 tempalte acc: 0.5834463119506836
---> molecule label loss: 1.866656494140625 molecule acc: 0.6207469463348388
---> kl loss: 1.1754974365234374
---> reconstruction loss: 29.86202087402344
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-33-with.npy
loss:  30.53379249572754 1.1769964694976807
loss:  30.95718002319336 1.157073736190796
loss:  31.24421501159668 1.1396344900131226
loss:  31.09992027282715 1.1395344734191895
loss:  30.87310028076172 1.1177678108215332
loss:  30.855186462402344 1.0951564311981201
loss:  31.006492614746094 1.1131505966186523
loss:  30.936077117919922 1.0988062620162964
loss:  30.496788024902344 1.122344970703125
loss:  31.17928695678711 1.1376378536224365
loss:  30.72139549255371 1.1319830417633057
loss:  30.56255531311035 1.1407898664474487
loss:  30.364038467407227 1.136136531829834
loss:  30.327110290527344 1.1328098773956299
loss:  30.63203239440918 1.1404017210006714
loss:  30.723133087158203 1.1186946630477905
loss:  30.59454917907715 1.1098175048828125
loss:  30.142118453979492 1.1401256322860718
loss:  30.475357055664062 1.0853099822998047
loss:  30.05552101135254 1.0034247636795044
*******************Epoch 33 ****************** 680 1.0
Validation Loss
*** pred loss:  25.35134506225586 pred acc: 0.5763888955116272
*** stop loss:  6.024810791015625 stop acc: 0.9226338863372803
*** template loss:  7.299082279205322 template acc: tensor(0.1217, device='cuda:0')
*** label loss:  6.02527379989624 label acc: tensor(0.3410, device='cuda:0')
Train Loss
---> pred loss: 21.47428741455078 pred acc: 0.6550723433494567
---> stop loss: 4.340153503417969 stop acc: 0.9494203239679336
---> template loss: 1.9397697448730469 tempalte acc: 0.5938036441802979
---> molecule label loss: 1.812898826599121 molecule acc: 0.6283971786499023
---> kl loss: 1.121879768371582
---> reconstruction loss: 29.567115592956544
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-34-with.npy
loss:  30.79338836669922 1.1125690937042236
loss:  30.355228424072266 1.0921716690063477
loss:  30.502389907836914 1.145345687866211
loss:  30.47931671142578 1.1145607233047485
loss:  30.2396297454834 1.0451515913009644
loss:  30.437294006347656 1.0884653329849243
loss:  30.320053100585938 1.0919772386550903
loss:  30.465192794799805 1.1135200262069702
loss:  30.712718963623047 1.0790679454803467
loss:  30.536447525024414 1.0866602659225464
loss:  30.329837799072266 1.0648536682128906
loss:  29.701642990112305 1.083048701286316
loss:  30.34547233581543 1.0519160032272339
loss:  30.22291374206543 1.0629141330718994
loss:  30.46588134765625 1.0738656520843506
loss:  30.68700408935547 1.0779001712799072
loss:  30.028364181518555 1.1069564819335938
loss:  30.666976928710938 1.0516207218170166
loss:  30.441965103149414 1.069959044456482
loss:  28.94297981262207 1.0256253480911255
*******************Epoch 34 ****************** 700 1.0
Validation Loss
*** pred loss:  25.191322326660156 pred acc: 0.5804347395896912
*** stop loss:  5.879673957824707 stop acc: 0.9229452610015869
*** template loss:  7.349715232849121 template acc: tensor(0.1189, device='cuda:0')
*** label loss:  6.021237373352051 label acc: tensor(0.3554, device='cuda:0')
Train Loss
---> pred loss: 21.32711181640625 pred acc: 0.657699778676033
---> stop loss: 4.302605819702149 stop acc: 0.9498117327690124
---> template loss: 1.8815473556518554 tempalte acc: 0.6035453319549561
---> molecule label loss: 1.7405609130859374 molecule acc: 0.6410342693328858
---> kl loss: 1.0819074630737304
---> reconstruction loss: 29.251826667785647
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-35-with.npy
loss:  29.704233169555664 1.0396381616592407
loss:  29.71701431274414 1.0750726461410522
loss:  30.21596336364746 1.045261025428772
loss:  29.99976921081543 1.0398212671279907
loss:  30.227598190307617 1.0228086709976196
loss:  30.08186149597168 1.075934648513794
loss:  30.143503189086914 1.062821626663208
loss:  29.813879013061523 1.0444949865341187
loss:  30.10978889465332 1.0762267112731934
loss:  30.003572463989258 1.0474412441253662
loss:  30.126012802124023 1.0624173879623413
loss:  29.961143493652344 1.0460386276245117
loss:  29.93270492553711 1.061589002609253
loss:  29.822036743164062 1.0218243598937988
loss:  30.08509063720703 1.0007787942886353
loss:  29.985868453979492 1.035352349281311
loss:  30.04043960571289 1.0316905975341797
loss:  30.01314926147461 1.0428520441055298
loss:  29.627357482910156 1.0040788650512695
loss:  29.756397247314453 1.0995502471923828
*******************Epoch 35 ****************** 720 1.0
Validation Loss
*** pred loss:  25.2940616607666 pred acc: 0.5796497464179993
*** stop loss:  5.978428840637207 stop acc: 0.9199875593185425
*** template loss:  7.322973251342773 template acc: tensor(0.1185, device='cuda:0')
*** label loss:  6.042494773864746 label acc: tensor(0.3455, device='cuda:0')
Train Loss
---> pred loss: 21.205953979492186 pred acc: 0.6607026755809784
---> stop loss: 4.223083877563477 stop acc: 0.9513197213411331
---> template loss: 1.8178762435913085 tempalte acc: 0.61411452293396
---> molecule label loss: 1.674668312072754 molecule acc: 0.6525719642639161
---> kl loss: 1.0467846870422364
---> reconstruction loss: 28.9215838432312
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-36-with.npy
loss:  30.03099822998047 1.0368794202804565
loss:  29.364526748657227 0.9979838132858276
loss:  29.81861114501953 1.0442219972610474
loss:  28.92427635192871 1.0287516117095947
loss:  30.13919448852539 1.065975308418274
loss:  29.966737747192383 1.0100659132003784
loss:  29.937850952148438 1.0209949016571045
loss:  29.65956687927246 1.0119011402130127
loss:  29.781204223632812 1.0007197856903076
loss:  30.052885055541992 0.9906976222991943
loss:  29.761192321777344 1.0167971849441528
loss:  29.34656524658203 0.9990317821502686
loss:  29.9544620513916 1.011561632156372
loss:  30.16864776611328 0.9805415272712708
loss:  29.650150299072266 1.008803367614746
loss:  29.885818481445312 1.0057533979415894
loss:  29.93960189819336 0.9911656379699707
loss:  29.700414657592773 0.9737235307693481
loss:  30.14321517944336 0.9983523488044739
loss:  31.577733993530273 1.0016695261001587
*******************Epoch 36 ****************** 740 1.0
Validation Loss
*** pred loss:  25.340139389038086 pred acc: 0.5800724625587463
*** stop loss:  6.26834774017334 stop acc: 0.9195517301559448
*** template loss:  7.353524684906006 template acc: tensor(0.1178, device='cuda:0')
*** label loss:  6.038536071777344 label acc: tensor(0.3462, device='cuda:0')
Train Loss
---> pred loss: 21.18305358886719 pred acc: 0.6602801203727722
---> stop loss: 4.282365036010742 stop acc: 0.9503976225852966
---> template loss: 1.7801446914672852 tempalte acc: 0.6217867374420166
---> molecule label loss: 1.6348419189453125 molecule acc: 0.6609381675720215
---> kl loss: 1.0097795486450196
---> reconstruction loss: 28.880402946472167
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-37-with.npy
loss:  29.666996002197266 0.9881171584129333
loss:  29.64344024658203 1.0073553323745728
loss:  29.704504013061523 0.9901273250579834
loss:  29.272144317626953 1.02743661403656
loss:  29.862016677856445 1.0272475481033325
loss:  29.764829635620117 1.0057638883590698
loss:  29.01109504699707 1.001096248626709
loss:  29.942975997924805 1.0210118293762207
loss:  29.58016586303711 1.0030829906463623
loss:  29.526042938232422 1.0386838912963867
loss:  29.42412567138672 0.9835296869277954
loss:  29.39623260498047 0.9931020736694336
loss:  29.453536987304688 0.9884472489356995
loss:  28.822734832763672 0.9661417007446289
loss:  29.406490325927734 0.9721192121505737
loss:  29.543258666992188 0.9781808853149414
loss:  29.261539459228516 0.9546237587928772
loss:  29.260683059692383 0.9443863034248352
loss:  29.10071563720703 0.9733979105949402
loss:  29.901765823364258 1.0913927555084229
*******************Epoch 37 ****************** 760 1.0
Validation Loss
*** pred loss:  25.260339736938477 pred acc: 0.5769927501678467
*** stop loss:  5.984240531921387 stop acc: 0.9190847277641296
*** template loss:  7.321046352386475 template acc: tensor(0.1312, device='cuda:0')
*** label loss:  6.062826156616211 label acc: tensor(0.3639, device='cuda:0')
Train Loss
---> pred loss: 21.008926391601562 pred acc: 0.6638149738311767
---> stop loss: 4.180664443969727 stop acc: 0.9520462632179261
---> template loss: 1.7218362808227539 tempalte acc: 0.6325173854827881
---> molecule label loss: 1.568077564239502 molecule acc: 0.672075605392456
---> kl loss: 0.9977622032165527
---> reconstruction loss: 28.479502201080322
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-38-with.npy
loss:  28.639554977416992 0.9551218152046204
loss:  29.129728317260742 0.9663253426551819
loss:  29.03008270263672 0.9643982648849487
loss:  29.39657211303711 0.9576127529144287
loss:  29.50676155090332 0.9457802772521973
loss:  29.465744018554688 0.9507477283477783
loss:  28.790958404541016 0.9174811244010925
loss:  29.233509063720703 0.9609193205833435
loss:  29.074954986572266 0.9547696113586426
loss:  29.735448837280273 0.9330331683158875
loss:  28.839344024658203 0.9371382594108582
loss:  29.32663345336914 0.9438790082931519
loss:  29.41570472717285 0.9359179139137268
loss:  28.932199478149414 0.9495671987533569
loss:  29.279661178588867 0.9276583790779114
loss:  29.15131187438965 0.9183646440505981
loss:  28.773954391479492 0.9506141543388367
loss:  28.609289169311523 0.9566715955734253
loss:  28.990022659301758 0.9214839935302734
loss:  27.85181999206543 0.9131003618240356
*******************Epoch 38 ****************** 780 1.0
Validation Loss
*** pred loss:  25.24989128112793 pred acc: 0.5771135091781616
*** stop loss:  6.133802890777588 stop acc: 0.9190535545349121
*** template loss:  7.330236434936523 template acc: tensor(0.1270, device='cuda:0')
*** label loss:  6.0688557624816895 label acc: tensor(0.3596, device='cuda:0')
Train Loss
---> pred loss: 20.824343872070312 pred acc: 0.6651912838220596
---> stop loss: 4.1122081756591795 stop acc: 0.9525547534227371
---> template loss: 1.6681049346923829 tempalte acc: 0.6429111003875733
---> molecule label loss: 1.510974407196045 molecule acc: 0.6816379070281983
---> kl loss: 0.9430292129516602
---> reconstruction loss: 28.115634727478028
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-39-with.npy
loss:  28.72728729248047 0.940608024597168
loss:  28.296628952026367 0.9428899884223938
loss:  28.78790283203125 0.9329536557197571
loss:  28.959827423095703 0.9270786643028259
loss:  28.980754852294922 0.9564074277877808
loss:  29.151166915893555 0.9469910860061646
loss:  28.853979110717773 0.9459481239318848
loss:  29.14966583251953 0.9392285943031311
loss:  28.704431533813477 0.9420703649520874
loss:  28.692007064819336 0.9330199956893921
loss:  28.354503631591797 0.9108190536499023
loss:  28.954843521118164 0.9338155388832092
loss:  29.155073165893555 0.9393572807312012
loss:  28.979970932006836 0.9315751194953918
loss:  28.681934356689453 0.9244882464408875
loss:  28.567447662353516 0.9476618766784668
loss:  29.39605712890625 0.9279109835624695
loss:  29.456615447998047 0.9159458875656128
loss:  28.146318435668945 0.91073077917099
loss:  29.58036994934082 0.943356990814209
*******************Epoch 39 ****************** 800 1.0
Validation Loss
*** pred loss:  25.267187118530273 pred acc: 0.5812197923660278
*** stop loss:  5.915268898010254 stop acc: 0.9213574528694153
*** template loss:  7.301905155181885 template acc: tensor(0.1277, device='cuda:0')
*** label loss:  6.027554512023926 label acc: tensor(0.3522, device='cuda:0')
Train Loss
---> pred loss: 20.749591064453124 pred acc: 0.6669253349304199
---> stop loss: 4.122051620483399 stop acc: 0.9525954902172089
---> template loss: 1.6127033233642578 tempalte acc: 0.6517497539520264
---> molecule label loss: 1.459851360321045 molecule acc: 0.6918585777282715
---> kl loss: 0.9346427917480469
---> reconstruction loss: 27.94419631958008
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-40-with.npy
loss:  28.42754364013672 0.9334364533424377
loss:  28.972492218017578 0.9374428391456604
loss:  28.687023162841797 0.9172253012657166
loss:  28.4033260345459 0.9086507558822632
loss:  28.52569580078125 0.9133330583572388
loss:  28.58415985107422 0.9117177724838257
loss:  29.17062759399414 0.9307793974876404
loss:  28.613370895385742 0.9332122802734375
loss:  28.878915786743164 0.9495530128479004
loss:  28.881359100341797 0.9286359548568726
loss:  28.887535095214844 0.9150308966636658
loss:  28.502092361450195 0.8833706378936768
loss:  28.43918800354004 0.9132491946220398
loss:  28.61526870727539 0.9012413024902344
loss:  28.761947631835938 0.8773605823516846
loss:  28.50592041015625 0.8935049176216125
loss:  28.4523983001709 0.8711875677108765
loss:  28.414257049560547 0.8652506470680237
loss:  28.60931968688965 0.8644439578056335
loss:  27.618019104003906 0.8984352350234985
*******************Epoch 40 ****************** 820 1.0
Validation Loss
*** pred loss:  25.158946990966797 pred acc: 0.5824275016784668
*** stop loss:  6.097308158874512 stop acc: 0.9200809597969055
*** template loss:  7.369444370269775 template acc: tensor(0.1273, device='cuda:0')
*** label loss:  6.090220928192139 label acc: tensor(0.3198, device='cuda:0')
Train Loss
---> pred loss: 20.63106689453125 pred acc: 0.6679912060499191
---> stop loss: 4.064380264282226 stop acc: 0.9530593156814575
---> template loss: 1.5772245407104493 tempalte acc: 0.6580036163330079
---> molecule label loss: 1.417498779296875 molecule acc: 0.6994207859039306
---> kl loss: 0.9073531150817871
---> reconstruction loss: 27.690168857574463
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-41-with.npy
loss:  28.860441207885742 0.8797951936721802
loss:  29.16930389404297 0.9113079905509949
loss:  28.681180953979492 0.9147397875785828
loss:  28.596189498901367 0.9096062779426575
loss:  28.40758514404297 0.8949058651924133
loss:  28.184585571289062 0.8672214150428772
loss:  28.85703468322754 0.8759095668792725
loss:  28.385818481445312 0.8677765727043152
loss:  28.110193252563477 0.8672440648078918
loss:  28.530912399291992 0.877103865146637
loss:  28.682811737060547 0.9166315793991089
loss:  28.46041488647461 0.870141327381134
loss:  28.448654174804688 0.8732799291610718
loss:  28.279712677001953 0.8705800175666809
loss:  28.23727035522461 0.8731297850608826
loss:  28.235658645629883 0.863322913646698
loss:  27.840070724487305 0.8643718361854553
loss:  28.181209564208984 0.881956934928894
loss:  28.24393653869629 0.8872865438461304
loss:  28.932275772094727 0.948126494884491
*******************Epoch 41 ****************** 840 1.0
Validation Loss
*** pred loss:  25.34392738342285 pred acc: 0.5803139805793762
*** stop loss:  6.468893051147461 stop acc: 0.9172478318214417
*** template loss:  7.317506790161133 template acc: tensor(0.1273, device='cuda:0')
*** label loss:  6.084554672241211 label acc: tensor(0.3549, device='cuda:0')
Train Loss
---> pred loss: 20.527934265136718 pred acc: 0.6704905301332473
---> stop loss: 4.104793548583984 stop acc: 0.9527789741754532
---> template loss: 1.5446341514587403 tempalte acc: 0.6645652770996093
---> molecule label loss: 1.4031800270080566 molecule acc: 0.6962886810302734
---> kl loss: 0.8857218742370605
---> reconstruction loss: 27.580540943145753
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-42-with.npy
loss:  28.45673942565918 0.8700818419456482
loss:  28.004207611083984 0.8426573276519775
loss:  28.79085350036621 0.8605440258979797
loss:  28.491783142089844 0.8669991493225098
loss:  28.18244171142578 0.8645181655883789
loss:  28.33336067199707 0.8808531165122986
loss:  28.136451721191406 0.8802277445793152
loss:  28.12396812438965 0.8573892712593079
loss:  28.37306022644043 0.8619542717933655
loss:  27.666187286376953 0.8695722222328186
loss:  28.483537673950195 0.8678306937217712
loss:  28.262008666992188 0.8582528233528137
loss:  28.00693702697754 0.8562318086624146
loss:  27.992708206176758 0.8835797905921936
loss:  28.17325782775879 0.8703473806381226
loss:  28.559310913085938 0.8611602187156677
loss:  28.4187068939209 0.8431105613708496
loss:  27.581144332885742 0.8475063443183899
loss:  27.8480224609375 0.8688503503799438
loss:  27.428058624267578 0.7915569543838501
*******************Epoch 42 ****************** 860 1.0
Validation Loss
*** pred loss:  25.262434005737305 pred acc: 0.5807366967201233
*** stop loss:  6.020834445953369 stop acc: 0.9216998815536499
*** template loss:  7.312907695770264 template acc: tensor(0.1316, device='cuda:0')
*** label loss:  6.031282424926758 label acc: tensor(0.3543, device='cuda:0')
Train Loss
---> pred loss: 20.392851257324217 pred acc: 0.6710980981588364
---> stop loss: 4.05688591003418 stop acc: 0.9532622456550598
---> template loss: 1.523660373687744 tempalte acc: 0.6693969249725342
---> molecule label loss: 1.3320765495300293 molecule acc: 0.7122653007507325
---> kl loss: 0.8601612091064453
---> reconstruction loss: 27.305472946166994
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-43-with.npy
loss:  27.853282928466797 0.8559068441390991
loss:  27.79632568359375 0.8590437173843384
loss:  27.640382766723633 0.8482372760772705
loss:  27.890846252441406 0.8576347827911377
loss:  27.873523712158203 0.860066831111908
loss:  27.775068283081055 0.8351622819900513
loss:  27.905269622802734 0.8364188075065613
loss:  28.065824508666992 0.858156681060791
loss:  28.106243133544922 0.8502769470214844
loss:  27.793230056762695 0.8375377655029297
loss:  27.12273406982422 0.8160892724990845
loss:  27.27138900756836 0.8286415934562683
loss:  27.631380081176758 0.8465628623962402
loss:  27.73259162902832 0.8382992744445801
loss:  27.87777328491211 0.8340790271759033
loss:  28.008930206298828 0.8429231643676758
loss:  27.811386108398438 0.8145157694816589
loss:  27.620574951171875 0.8259047865867615
loss:  28.20982551574707 0.8487685322761536
loss:  27.717937469482422 0.7964418530464172
*******************Epoch 43 ****************** 880 1.0
Validation Loss
*** pred loss:  25.562198638916016 pred acc: 0.5751811265945435
*** stop loss:  6.100282669067383 stop acc: 0.9226338863372803
*** template loss:  7.307553768157959 template acc: tensor(0.1326, device='cuda:0')
*** label loss:  6.080311298370361 label acc: tensor(0.3434, device='cuda:0')
Train Loss
---> pred loss: 20.28011474609375 pred acc: 0.6743580490350723
---> stop loss: 3.928697967529297 stop acc: 0.9548528730869293
---> template loss: 1.4539573669433594 tempalte acc: 0.6811727523803711
---> molecule label loss: 1.2829195022583009 molecule acc: 0.723844051361084
---> kl loss: 0.8395334243774414
---> reconstruction loss: 26.945696067810058
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-44-with.npy
loss:  27.318416595458984 0.808685302734375
loss:  27.092981338500977 0.8481435179710388
loss:  27.8348331451416 0.8163658380508423
loss:  27.448692321777344 0.8374656438827515
loss:  27.376794815063477 0.8125130534172058
loss:  27.99233627319336 0.8088026642799377
loss:  27.55763053894043 0.8011871576309204
loss:  27.38967514038086 0.8062583208084106
loss:  27.909061431884766 0.8137944936752319
loss:  28.00065040588379 0.8070787191390991
loss:  27.589393615722656 0.7947302460670471
loss:  27.719284057617188 0.8144137859344482
loss:  27.86231231689453 0.8399003148078918
loss:  27.787900924682617 0.8086459040641785
loss:  27.66189193725586 0.8212297558784485
loss:  27.487266540527344 0.83696049451828
loss:  27.809289932250977 0.8236922025680542
loss:  27.303688049316406 0.8032464981079102
loss:  27.327041625976562 0.826824963092804
loss:  26.9866943359375 0.7932831645011902
*******************Epoch 44 ****************** 900 1.0
Validation Loss
*** pred loss:  25.436954498291016 pred acc: 0.5748188495635986
*** stop loss:  6.090047359466553 stop acc: 0.9231008887290955
*** template loss:  7.331714153289795 template acc: tensor(0.1361, device='cuda:0')
*** label loss:  6.097317218780518 label acc: tensor(0.3714, device='cuda:0')
Train Loss
---> pred loss: 20.172125244140624 pred acc: 0.6779106140136719
---> stop loss: 3.883031463623047 stop acc: 0.9559906870126724
---> template loss: 1.4409512519836425 tempalte acc: 0.6824774265289306
---> molecule label loss: 1.2605204582214355 molecule acc: 0.7241523265838623
---> kl loss: 0.8161611557006836
---> reconstruction loss: 26.756629371643065
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-45-with.npy
loss:  26.941043853759766 0.7940207719802856
loss:  27.52080535888672 0.8239778876304626
loss:  26.825231552124023 0.8049611449241638
loss:  27.06294822692871 0.8112521171569824
loss:  27.452123641967773 0.8115481734275818
loss:  27.440387725830078 0.8136895298957825
loss:  27.637723922729492 0.804456889629364
loss:  27.369539260864258 0.8030056953430176
loss:  27.3908748626709 0.7909036874771118
loss:  27.470338821411133 0.7908768057823181
loss:  27.875764846801758 0.8248193264007568
loss:  27.290096282958984 0.7847158312797546
loss:  27.3786678314209 0.8056161403656006
loss:  27.06589126586914 0.7828072309494019
loss:  27.594663619995117 0.7990173697471619
loss:  27.174013137817383 0.8122885823249817
loss:  27.57476234436035 0.7872800230979919
loss:  27.24405288696289 0.8279840350151062
loss:  27.044397354125977 0.7784799933433533
loss:  26.83807945251465 0.8064903616905212
*******************Epoch 45 ****************** 920 1.0
Validation Loss
*** pred loss:  25.55914878845215 pred acc: 0.5788646936416626
*** stop loss:  6.056868076324463 stop acc: 0.9215753674507141
*** template loss:  7.342010498046875 template acc: tensor(0.1323, device='cuda:0')
*** label loss:  6.046635150909424 label acc: tensor(0.3592, device='cuda:0')
Train Loss
---> pred loss: 20.04303894042969 pred acc: 0.6777520954608918
---> stop loss: 3.85290412902832 stop acc: 0.9560239613056183
---> template loss: 1.400263500213623 tempalte acc: 0.6913230419158936
---> molecule label loss: 1.2104549407958984 molecule acc: 0.7343483448028565
---> kl loss: 0.8029095649719238
---> reconstruction loss: 26.506660747528077
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-46-with.npy
loss:  27.463481903076172 0.7820591926574707
loss:  27.410192489624023 0.7793654203414917
loss:  27.334054946899414 0.8085334897041321
loss:  27.694019317626953 0.7924085855484009
loss:  26.817611694335938 0.7903562784194946
loss:  27.07960319519043 0.771674633026123
loss:  27.087970733642578 0.7748156189918518
loss:  27.336688995361328 0.815436601638794
loss:  26.858797073364258 0.7581068873405457
loss:  27.885190963745117 0.7796658873558044
loss:  27.54779815673828 0.7848774790763855
loss:  27.255443572998047 0.8002131581306458
loss:  27.885482788085938 0.7791065573692322
loss:  27.0711669921875 0.7676738500595093
loss:  26.944068908691406 0.7550128698348999
loss:  27.47185707092285 0.7864171862602234
loss:  27.43341827392578 0.7633615732192993
loss:  26.796550750732422 0.7693419456481934
loss:  27.05879783630371 0.7882096767425537
loss:  26.271602630615234 0.7233530282974243
*******************Epoch 46 ****************** 940 1.0
Validation Loss
*** pred loss:  25.505977630615234 pred acc: 0.5757849812507629
*** stop loss:  6.1272101402282715 stop acc: 0.9215130805969238
*** template loss:  7.3447113037109375 template acc: tensor(0.1312, device='cuda:0')
*** label loss:  6.04933500289917 label acc: tensor(0.3654, device='cuda:0')
Train Loss
---> pred loss: 19.991435241699218 pred acc: 0.6790235549211502
---> stop loss: 3.8430145263671873 stop acc: 0.9561939895153045
---> template loss: 1.4183596611022948 tempalte acc: 0.687285041809082
---> molecule label loss: 1.2038818359375 molecule acc: 0.7361049175262451
---> kl loss: 0.7784994602203369
---> reconstruction loss: 26.456687307357786
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-47-with.npy
loss:  27.32557487487793 0.7781322002410889
loss:  26.657203674316406 0.7847456336021423
loss:  27.27880859375 0.7734232544898987
loss:  27.289337158203125 0.7725808024406433
loss:  26.99964714050293 0.7951725721359253
loss:  26.660804748535156 0.7441307306289673
loss:  26.955219268798828 0.7718462347984314
loss:  26.552654266357422 0.777984082698822
loss:  26.87429428100586 0.7989559173583984
loss:  27.225683212280273 0.7756313681602478
loss:  26.89647102355957 0.7505003809928894
loss:  26.920631408691406 0.7627965807914734
loss:  27.439125061035156 0.763468861579895
loss:  26.679107666015625 0.7602720856666565
loss:  26.498964309692383 0.7634002566337585
loss:  26.871341705322266 0.7792039513587952
loss:  27.070552825927734 0.7758015394210815
loss:  26.95644760131836 0.7529672980308533
loss:  26.73131561279297 0.7680177688598633
loss:  28.000690460205078 0.7734962701797485
*******************Epoch 47 ****************** 960 1.0
Validation Loss
*** pred loss:  25.58099937438965 pred acc: 0.574033796787262
*** stop loss:  6.113807678222656 stop acc: 0.923225462436676
*** template loss:  7.29633092880249 template acc: tensor(0.1456, device='cuda:0')
*** label loss:  6.020112991333008 label acc: tensor(0.3594, device='cuda:0')
Train Loss
---> pred loss: 19.954631042480468 pred acc: 0.679451185464859
---> stop loss: 3.785958099365234 stop acc: 0.9569836020469665
---> template loss: 1.3451382637023925 tempalte acc: 0.7038462162017822
---> molecule label loss: 1.1373406410217286 molecule acc: 0.7486911296844483
---> kl loss: 0.7711264133453369
---> reconstruction loss: 26.223066091537476
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-48-with.npy
loss:  26.414609909057617 0.7652782201766968
loss:  26.66909408569336 0.7547755241394043
loss:  26.803680419921875 0.7813798189163208
loss:  26.462648391723633 0.7687029242515564
loss:  27.102556228637695 0.7675400376319885
loss:  27.51645278930664 0.7484094500541687
loss:  26.719524383544922 0.7483071088790894
loss:  26.757301330566406 0.7404564023017883
loss:  27.159032821655273 0.7464227080345154
loss:  27.00943946838379 0.7476058602333069
loss:  27.64002799987793 0.7349246144294739
loss:  26.969213485717773 0.7621584534645081
loss:  26.465896606445312 0.7589029669761658
loss:  26.617408752441406 0.7404048442840576
loss:  26.860509872436523 0.7532867789268494
loss:  27.196453094482422 0.7393739223480225
loss:  26.359859466552734 0.7401312589645386
loss:  26.93650245666504 0.7650143504142761
loss:  26.2139835357666 0.7518791556358337
loss:  26.242671966552734 0.6881917119026184
*******************Epoch 48 ****************** 980 1.0
Validation Loss
*** pred loss:  25.56471061706543 pred acc: 0.5762680768966675
*** stop loss:  6.0579681396484375 stop acc: 0.9223536849021912
*** template loss:  7.368721008300781 template acc: tensor(0.1393, device='cuda:0')
*** label loss:  6.100640773773193 label acc: tensor(0.3744, device='cuda:0')
Train Loss
---> pred loss: 19.860153198242188 pred acc: 0.6800202995538711
---> stop loss: 3.8116546630859376 stop acc: 0.9564395844936371
---> template loss: 1.28442325592041 tempalte acc: 0.7158341407775879
---> molecule label loss: 1.0994551658630372 molecule acc: 0.757222318649292
---> kl loss: 0.7501572608947754
---> reconstruction loss: 26.055683803558352
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-49-with.npy
loss:  26.67391586303711 0.7491143941879272
loss:  26.43462371826172 0.7500998377799988
loss:  26.617189407348633 0.7397490739822388
loss:  26.6678409576416 0.7541199922561646
loss:  26.40591049194336 0.7572171688079834
loss:  26.838850021362305 0.7467021942138672
loss:  26.358104705810547 0.7421623468399048
loss:  26.56583595275879 0.7345676422119141
loss:  26.907323837280273 0.7491805553436279
loss:  26.273555755615234 0.7192025184631348
loss:  26.53466033935547 0.7249577641487122
loss:  26.47730255126953 0.706036388874054
loss:  26.314592361450195 0.7151895761489868
loss:  26.53876495361328 0.7325575947761536
loss:  26.40509796142578 0.7157285213470459
loss:  26.342798233032227 0.7025359272956848
loss:  26.461280822753906 0.7175426483154297
loss:  26.733253479003906 0.7394307851791382
loss:  26.587308883666992 0.726274311542511
loss:  27.478418350219727 0.7635562419891357
*******************Epoch 49 ****************** 1000 1.0
Validation Loss
*** pred loss:  25.682947158813477 pred acc: 0.5763285160064697
*** stop loss:  6.353763103485107 stop acc: 0.9205791354179382
*** template loss:  7.36076545715332 template acc: tensor(0.1312, device='cuda:0')
*** label loss:  6.064028263092041 label acc: tensor(0.3620, device='cuda:0')
Train Loss
---> pred loss: 19.70899200439453 pred acc: 0.6828441321849823
---> stop loss: 3.762015151977539 stop acc: 0.9570167750120163
---> template loss: 1.2930583000183105 tempalte acc: 0.7127203464508056
---> molecule label loss: 1.0824703216552733 molecule acc: 0.7589491844177246
---> kl loss: 0.7342962741851806
---> reconstruction loss: 25.846535634994506
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-50-with.npy
loss:  26.26626205444336 0.7354812622070312
loss:  26.588275909423828 0.7416425347328186
loss:  26.30549430847168 0.7279982566833496
loss:  26.380237579345703 0.7288759350776672
loss:  26.3360595703125 0.7336421608924866
loss:  26.29276466369629 0.7331105470657349
loss:  26.236019134521484 0.7253794074058533
loss:  26.668725967407227 0.7433162927627563
loss:  26.634620666503906 0.7251452207565308
loss:  26.37448501586914 0.7169124484062195
loss:  26.75006866455078 0.7085517048835754
loss:  27.185720443725586 0.7190326452255249
loss:  26.653732299804688 0.7184115648269653
loss:  26.403541564941406 0.7174275517463684
loss:  26.94049072265625 0.7347604632377625
loss:  26.369888305664062 0.7320200204849243
loss:  26.368513107299805 0.7241203784942627
loss:  26.37956428527832 0.7127507328987122
loss:  25.872358322143555 0.7110800743103027
loss:  26.199338912963867 0.7369658946990967
*******************Epoch 50 ****************** 1020 1.0
Validation Loss
*** pred loss:  25.528366088867188 pred acc: 0.574577271938324
*** stop loss:  6.393935203552246 stop acc: 0.9216376543045044
*** template loss:  7.366064548492432 template acc: tensor(0.1386, device='cuda:0')
*** label loss:  6.097903251647949 label acc: tensor(0.3727, device='cuda:0')
Train Loss
---> pred loss: 19.6553466796875 pred acc: 0.6836765140295029
---> stop loss: 3.7662452697753905 stop acc: 0.957129716873169
---> template loss: 1.2580326080322266 tempalte acc: 0.7186961650848389
---> molecule label loss: 1.0543516159057618 molecule acc: 0.7638649463653564
---> kl loss: 0.7263311862945556
---> reconstruction loss: 25.73397765159607
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-51-with.npy
loss:  26.124685287475586 0.7105167508125305
loss:  26.344205856323242 0.7096190452575684
loss:  26.659839630126953 0.7360491156578064
loss:  26.251543045043945 0.7104631066322327
loss:  26.524829864501953 0.6985123157501221
loss:  26.514881134033203 0.7313165068626404
loss:  26.443164825439453 0.696719765663147
loss:  25.537647247314453 0.6872803568840027
loss:  26.537023544311523 0.7235152721405029
loss:  26.945667266845703 0.7058225274085999
loss:  26.405454635620117 0.7075830698013306
loss:  26.20067596435547 0.7251120209693909
loss:  26.36234474182129 0.7101263403892517
loss:  26.353147506713867 0.7103721499443054
loss:  26.441831588745117 0.7074771523475647
loss:  26.583019256591797 0.7026091814041138
loss:  25.866682052612305 0.7126713395118713
loss:  26.16200828552246 0.704197108745575
loss:  26.007719039916992 0.7065485119819641
loss:  26.843408584594727 0.7375901341438293
*******************Epoch 51 ****************** 1040 1.0
Validation Loss
*** pred loss:  25.49533462524414 pred acc: 0.5786231756210327
*** stop loss:  6.202586650848389 stop acc: 0.9211083650588989
*** template loss:  7.359436988830566 template acc: tensor(0.1446, device='cuda:0')
*** label loss:  6.099739074707031 label acc: tensor(0.3667, device='cuda:0')
Train Loss
---> pred loss: 19.561935424804688 pred acc: 0.6850371301174164
---> stop loss: 3.7760543823242188 stop acc: 0.9566480606794358
---> template loss: 1.2696013450622559 tempalte acc: 0.7167697429656983
---> molecule label loss: 1.0361931800842286 molecule acc: 0.7671834468841553
---> kl loss: 0.7117050170898438
---> reconstruction loss: 25.64378204345703
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-52-with.npy
loss:  26.012863159179688 0.692693293094635
loss:  26.452754974365234 0.6890806555747986
loss:  26.00777816772461 0.7170649170875549
loss:  26.212244033813477 0.7201038599014282
loss:  26.661426544189453 0.7133632898330688
loss:  26.206710815429688 0.7040197849273682
loss:  26.501859664916992 0.7134745717048645
loss:  26.078100204467773 0.6931723356246948
loss:  26.10847282409668 0.6938689351081848
loss:  25.994592666625977 0.6906835436820984
loss:  25.793100357055664 0.7112932801246643
loss:  26.1612548828125 0.6927785873413086
loss:  26.004549026489258 0.6789218187332153
loss:  26.093154907226562 0.7091299295425415
loss:  25.900320053100586 0.700081467628479
loss:  26.143478393554688 0.6860761642456055
loss:  25.77665901184082 0.6854137182235718
loss:  25.998817443847656 0.6951952576637268
loss:  25.698060989379883 0.6889472007751465
loss:  24.273033142089844 0.6913751363754272
*******************Epoch 52 ****************** 1060 1.0
Validation Loss
*** pred loss:  25.60420799255371 pred acc: 0.5771738886833191
*** stop loss:  6.1899518966674805 stop acc: 0.9222602844238281
*** template loss:  7.361127853393555 template acc: tensor(0.1425, device='cuda:0')
*** label loss:  6.228567600250244 label acc: tensor(0.3766, device='cuda:0')
Train Loss
---> pred loss: 19.405345153808593 pred acc: 0.6862710386514663
---> stop loss: 3.7061080932617188 stop acc: 0.9577284991741181
---> template loss: 1.2049856185913086 tempalte acc: 0.728605079650879
---> molecule label loss: 0.9891855239868164 molecule acc: 0.7763870239257813
---> kl loss: 0.6983368396759033
---> reconstruction loss: 25.305624341964723
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-53-with.npy
loss:  25.348432540893555 0.6793855428695679
loss:  25.749099731445312 0.6718425750732422
loss:  25.606962203979492 0.6924378871917725
loss:  25.6201114654541 0.6916768550872803
loss:  25.66722869873047 0.6967477202415466
loss:  26.061323165893555 0.6842835545539856
loss:  25.79100227355957 0.6750425100326538
loss:  26.12092399597168 0.6740785241127014
loss:  25.568471908569336 0.6519472599029541
loss:  25.863525390625 0.6779412031173706
loss:  25.81283187866211 0.6699249148368835
loss:  26.2100887298584 0.686631977558136
loss:  25.99390411376953 0.6850241422653198
loss:  25.91405487060547 0.659104585647583
loss:  25.58725929260254 0.6985920667648315
loss:  25.645166397094727 0.678229808807373
loss:  25.787057876586914 0.6720312237739563
loss:  25.479055404663086 0.6734378933906555
loss:  25.934165954589844 0.6840591430664062
loss:  26.006059646606445 0.6540541052818298
*******************Epoch 53 ****************** 1080 1.0
Validation Loss
*** pred loss:  25.534326553344727 pred acc: 0.5777777433395386
*** stop loss:  6.213943004608154 stop acc: 0.9227584600448608
*** template loss:  7.316347122192383 template acc: tensor(0.1425, device='cuda:0')
*** label loss:  6.125950813293457 label acc: tensor(0.3729, device='cuda:0')
Train Loss
---> pred loss: 19.349378967285155 pred acc: 0.6880046129226685
---> stop loss: 3.6423030853271485 stop acc: 0.9588878214359283
---> template loss: 1.165835189819336 tempalte acc: 0.7378006458282471
---> molecule label loss: 0.952997875213623 molecule acc: 0.7818214416503906
---> kl loss: 0.6778236389160156
---> reconstruction loss: 25.110512542724607
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-54-with.npy
loss:  25.21861457824707 0.6512579321861267
loss:  26.0394287109375 0.6890867352485657
loss:  25.684518814086914 0.6789944767951965
loss:  25.576032638549805 0.6733951568603516
loss:  25.921627044677734 0.6767967343330383
loss:  25.537416458129883 0.6553633809089661
loss:  25.4040584564209 0.6833102107048035
loss:  25.644338607788086 0.6669784188270569
loss:  25.61908721923828 0.644710123538971
loss:  25.456512451171875 0.6514317393302917
loss:  25.437477111816406 0.6301010251045227
loss:  25.47200584411621 0.6574913263320923
loss:  25.687274932861328 0.6664026975631714
loss:  25.677291870117188 0.6675446033477783
loss:  25.31454849243164 0.6564554572105408
loss:  25.683048248291016 0.6517569422721863
loss:  25.76982307434082 0.6757599115371704
loss:  25.841737747192383 0.6778589487075806
loss:  25.589344024658203 0.6775664687156677
loss:  25.96979522705078 0.6576079726219177
*******************Epoch 54 ****************** 1100 1.0
Validation Loss
*** pred loss:  25.64982032775879 pred acc: 0.5762680768966675
*** stop loss:  6.3112640380859375 stop acc: 0.9227895736694336
*** template loss:  7.3615403175354 template acc: tensor(0.1375, device='cuda:0')
*** label loss:  6.143885612487793 label acc: tensor(0.3688, device='cuda:0')
Train Loss
---> pred loss: 19.251165771484374 pred acc: 0.69034064412117
---> stop loss: 3.6217552185058595 stop acc: 0.958788925409317
---> template loss: 1.1596311569213866 tempalte acc: 0.7395826816558838
---> molecule label loss: 0.9301556587219239 molecule acc: 0.7854764938354493
---> kl loss: 0.6644935131072998
---> reconstruction loss: 24.962706804275513
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-55-with.npy
loss:  25.345014572143555 0.667667806148529
loss:  25.310707092285156 0.6688875555992126
loss:  25.330900192260742 0.6758944988250732
loss:  25.225162506103516 0.6598542332649231
loss:  25.330692291259766 0.6503820419311523
loss:  25.429588317871094 0.6535769701004028
loss:  25.532833099365234 0.6610044836997986
loss:  25.07814598083496 0.6708471179008484
loss:  25.93373680114746 0.6475618481636047
loss:  25.56134605407715 0.6353987455368042
loss:  26.12421989440918 0.6533648371696472
loss:  25.5377197265625 0.6653361320495605
loss:  25.225980758666992 0.6592087745666504
loss:  25.754657745361328 0.6626352071762085
loss:  25.13666534423828 0.6438979506492615
loss:  25.37053108215332 0.6492650508880615
loss:  25.142518997192383 0.640978991985321
loss:  25.3179931640625 0.6557401418685913
loss:  25.735275268554688 0.6699860692024231
loss:  24.896739959716797 0.6396863460540771
*******************Epoch 55 ****************** 1120 1.0
Validation Loss
*** pred loss:  25.762590408325195 pred acc: 0.5794081687927246
*** stop loss:  6.2076520919799805 stop acc: 0.9232876896858215
*** template loss:  7.312610626220703 template acc: tensor(0.1484, device='cuda:0')
*** label loss:  6.21563196182251 label acc: tensor(0.3699, device='cuda:0')
Train Loss
---> pred loss: 19.159725952148438 pred acc: 0.6920668333768845
---> stop loss: 3.5715084075927734 stop acc: 0.9596134155988694
---> template loss: 1.1218151092529296 tempalte acc: 0.747788381576538
---> molecule label loss: 0.9064122200012207 molecule acc: 0.7911208629608154
---> kl loss: 0.6565587043762207
---> reconstruction loss: 24.759463024139404
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-56-with.npy
loss:  25.768964767456055 0.669679582118988
loss:  25.185354232788086 0.6488462686538696
loss:  25.629852294921875 0.6487178802490234
loss:  25.113630294799805 0.6547942757606506
loss:  25.718320846557617 0.650353729724884
loss:  24.889604568481445 0.6420117616653442
loss:  25.572858810424805 0.6606644988059998
loss:  25.287647247314453 0.6447591781616211
loss:  24.98419952392578 0.6366037130355835
loss:  25.05872344970703 0.658466637134552
loss:  25.32373046875 0.6585810780525208
loss:  25.09878921508789 0.6471543908119202
loss:  25.09710693359375 0.6473512649536133
loss:  25.370784759521484 0.6456260681152344
loss:  25.85590934753418 0.6666145324707031
loss:  25.03777503967285 0.6386275887489319
loss:  25.17230987548828 0.6469568610191345
loss:  25.113807678222656 0.6460564136505127
loss:  25.08182716369629 0.6434051990509033
loss:  25.433290481567383 0.6247474551200867
*******************Epoch 56 ****************** 1140 1.0
Validation Loss
*** pred loss:  25.568361282348633 pred acc: 0.5757246017456055
*** stop loss:  6.531590938568115 stop acc: 0.9202677607536316
*** template loss:  7.358325481414795 template acc: tensor(0.1474, device='cuda:0')
*** label loss:  6.11538553237915 label acc: tensor(0.3763, device='cuda:0')
Train Loss
---> pred loss: 19.091183471679688 pred acc: 0.6928848803043366
---> stop loss: 3.5944141387939452 stop acc: 0.9590962082147598
---> template loss: 1.0897878646850585 tempalte acc: 0.754985761642456
---> molecule label loss: 0.8653409004211425 molecule acc: 0.7971689701080322
---> kl loss: 0.6490009307861329
---> reconstruction loss: 24.640720748901366
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-57-with.npy
loss:  24.59975242614746 0.6453730463981628
loss:  26.033313751220703 0.650402843952179
loss:  25.01400375366211 0.6283161044120789
loss:  25.24408531188965 0.6329482793807983
loss:  25.51188087463379 0.6381216645240784
loss:  24.89657974243164 0.6418415904045105
loss:  25.110525131225586 0.6268463730812073
loss:  25.270648956298828 0.6447615027427673
loss:  24.703989028930664 0.6628649234771729
loss:  24.904067993164062 0.6346502304077148
loss:  25.26563262939453 0.6307553052902222
loss:  25.32307243347168 0.6458098292350769
loss:  24.95667266845703 0.6334674954414368
loss:  25.112834930419922 0.6482646465301514
loss:  25.310956954956055 0.6382002830505371
loss:  25.05097770690918 0.651893138885498
loss:  25.782602310180664 0.6532161235809326
loss:  25.455341339111328 0.6407435536384583
loss:  25.007678985595703 0.6384972333908081
loss:  25.990306854248047 0.6098088622093201
*******************Epoch 57 ****************** 1160 1.0
Validation Loss
*** pred loss:  25.832435607910156 pred acc: 0.5765700340270996
*** stop loss:  6.218628406524658 stop acc: 0.92303866147995
*** template loss:  7.3261919021606445 template acc: tensor(0.1400, device='cuda:0')
*** label loss:  6.209918022155762 label acc: tensor(0.3766, device='cuda:0')
Train Loss
---> pred loss: 19.052757263183594 pred acc: 0.6938373953104019
---> stop loss: 3.6089599609375 stop acc: 0.9591404676437378
---> template loss: 1.080270481109619 tempalte acc: 0.7572469711303711
---> molecule label loss: 0.8454196929931641 molecule acc: 0.8040035247802735
---> kl loss: 0.6398392200469971
---> reconstruction loss: 24.58740382194519
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-58-with.npy
loss:  25.11838150024414 0.6420287489891052
loss:  25.304325103759766 0.6473824977874756
loss:  25.076175689697266 0.6404133439064026
loss:  24.949501037597656 0.6344244480133057
loss:  25.294931411743164 0.6445865631103516
loss:  24.942276000976562 0.6509240865707397
loss:  25.234867095947266 0.63861483335495
loss:  25.33060073852539 0.6363424062728882
loss:  25.08322525024414 0.6243390440940857
loss:  25.023193359375 0.6246723532676697
loss:  24.709983825683594 0.6027634739875793
loss:  24.869089126586914 0.6062911152839661
loss:  24.5736026763916 0.5898979306221008
loss:  25.023744583129883 0.6300110220909119
loss:  24.606340408325195 0.609423816204071
loss:  24.865489959716797 0.6216533184051514
loss:  24.78390121459961 0.61541748046875
loss:  24.796916961669922 0.6410632133483887
loss:  25.141462326049805 0.6128182411193848
loss:  24.681419372558594 0.5901379585266113
*******************Epoch 58 ****************** 1180 1.0
Validation Loss
*** pred loss:  25.875661849975586 pred acc: 0.5798912644386292
*** stop loss:  6.647247314453125 stop acc: 0.9211706519126892
*** template loss:  7.3421406745910645 template acc: tensor(0.1491, device='cuda:0')
*** label loss:  6.135377883911133 label acc: tensor(0.3718, device='cuda:0')
Train Loss
---> pred loss: 18.956060791015624 pred acc: 0.6939119219779968
---> stop loss: 3.529018783569336 stop acc: 0.9601683109998703
---> template loss: 1.042597484588623 tempalte acc: 0.765253210067749
---> molecule label loss: 0.8176301956176758 molecule acc: 0.8097721099853515
---> kl loss: 0.6251602172851562
---> reconstruction loss: 24.345309448242187
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-59-with.npy
loss:  24.895952224731445 0.6106188297271729
loss:  25.138452529907227 0.6297782063484192
loss:  24.716548919677734 0.6152936220169067
loss:  25.288103103637695 0.606695830821991
loss:  25.190345764160156 0.6063437461853027
loss:  24.60346794128418 0.6177541017532349
loss:  25.21839141845703 0.5978174209594727
loss:  25.119733810424805 0.6167430877685547
loss:  24.811267852783203 0.6121879816055298
loss:  24.965587615966797 0.6109281778335571
loss:  25.331878662109375 0.6056035161018372
loss:  24.713010787963867 0.6054785251617432
loss:  24.60262107849121 0.6127461194992065
loss:  25.10794448852539 0.6204179525375366
loss:  24.886241912841797 0.6277440190315247
loss:  24.811941146850586 0.5992575287818909
loss:  24.741470336914062 0.6136112809181213
loss:  24.841297149658203 0.603083074092865
loss:  24.638246536254883 0.6123059391975403
loss:  24.558746337890625 0.5452122688293457
*******************Epoch 59 ****************** 1200 1.0
Validation Loss
*** pred loss:  25.9700927734375 pred acc: 0.5742149353027344
*** stop loss:  6.19754695892334 stop acc: 0.9240037798881531
*** template loss:  7.408730983734131 template acc: tensor(0.1428, device='cuda:0')
*** label loss:  6.178657054901123 label acc: tensor(0.3748, device='cuda:0')
Train Loss
---> pred loss: 18.8464599609375 pred acc: 0.6965608686208725
---> stop loss: 3.5228092193603517 stop acc: 0.960159906744957
---> template loss: 1.1166687965393067 tempalte acc: 0.7473096370697021
---> molecule label loss: 0.8146445274353027 molecule acc: 0.8104328155517578
---> kl loss: 0.6084810256958008
---> reconstruction loss: 24.300581169128417
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-60-with.npy
loss:  24.608474731445312 0.6013956665992737
loss:  24.79449462890625 0.6050954461097717
loss:  24.75359344482422 0.6141568422317505
loss:  24.707271575927734 0.6163538694381714
loss:  24.611751556396484 0.6039339303970337
loss:  25.146846771240234 0.60379558801651
loss:  24.59272003173828 0.6143440008163452
loss:  24.832216262817383 0.6092631816864014
loss:  24.82485008239746 0.6152539253234863
loss:  24.570480346679688 0.6272500157356262
loss:  24.555707931518555 0.6100919842720032
loss:  24.433059692382812 0.6084495186805725
loss:  24.80606460571289 0.626599907875061
loss:  24.283432006835938 0.5995696783065796
loss:  24.74624252319336 0.6208935976028442
loss:  25.07879638671875 0.6192443370819092
loss:  24.576797485351562 0.6049954295158386
loss:  24.59622573852539 0.6013302803039551
loss:  25.08431625366211 0.5872277021408081
loss:  25.29059600830078 0.6109271049499512
*******************Epoch 60 ****************** 1220 1.0
Validation Loss
*** pred loss:  25.996423721313477 pred acc: 0.5821256041526794
*** stop loss:  6.263156414031982 stop acc: 0.9221357703208923
*** template loss:  7.4353251457214355 template acc: tensor(0.1410, device='cuda:0')
*** label loss:  6.135104656219482 label acc: tensor(0.3577, device='cuda:0')
Train Loss
---> pred loss: 18.779450988769533 pred acc: 0.696508812904358
---> stop loss: 3.471257781982422 stop acc: 0.9608210116624832
---> template loss: 1.0773545265197755 tempalte acc: 0.7570882320404053
---> molecule label loss: 0.8066277503967285 molecule acc: 0.8092665672302246
---> kl loss: 0.6100086212158203
---> reconstruction loss: 24.134687423706055
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-61-with.npy
loss:  24.745389938354492 0.5995582938194275
loss:  24.62976837158203 0.6028876900672913
loss:  24.36050796508789 0.5895746946334839
loss:  24.688518524169922 0.6116294264793396
loss:  24.88508415222168 0.5865131616592407
loss:  24.26174545288086 0.5999278426170349
loss:  24.734525680541992 0.6000989675521851
loss:  24.370582580566406 0.5970743298530579
loss:  24.104135513305664 0.594474196434021
loss:  24.778934478759766 0.5907137989997864
loss:  24.554372787475586 0.5902837514877319
loss:  24.891746520996094 0.5953795313835144
loss:  24.12007713317871 0.5924805402755737
loss:  24.79412841796875 0.5869471430778503
loss:  25.002639770507812 0.5973199009895325
loss:  24.55150604248047 0.601743757724762
loss:  24.87750244140625 0.5933207273483276
loss:  24.70838737487793 0.5891631245613098
loss:  24.757061004638672 0.5936722159385681
loss:  23.389209747314453 0.5773212313652039
*******************Epoch 61 ****************** 1240 1.0
Validation Loss
*** pred loss:  26.08199119567871 pred acc: 0.5777173638343811
*** stop loss:  6.266736030578613 stop acc: 0.9234744906425476
*** template loss:  7.361430644989014 template acc: tensor(0.1439, device='cuda:0')
*** label loss:  6.206238269805908 label acc: tensor(0.3858, device='cuda:0')
Train Loss
---> pred loss: 18.691064453125 pred acc: 0.6986725479364395
---> stop loss: 3.4531314849853514 stop acc: 0.9610008895397186
---> template loss: 1.0319687843322753 tempalte acc: 0.7662755966186523
---> molecule label loss: 0.7896232604980469 molecule acc: 0.8123165130615234
---> kl loss: 0.5945042133331299
---> reconstruction loss: 23.965787839889526
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-62-with.npy
loss:  24.546693801879883 0.5892441272735596
loss:  24.516803741455078 0.5787937045097351
loss:  24.720966339111328 0.600443422794342
loss:  24.511648178100586 0.6080708503723145
loss:  24.001789093017578 0.5768845677375793
loss:  24.364835739135742 0.593834638595581
loss:  24.333648681640625 0.5818332433700562
loss:  24.360803604125977 0.6087879538536072
loss:  24.406103134155273 0.5887688994407654
loss:  24.48969268798828 0.5772193670272827
loss:  24.42164421081543 0.5812073349952698
loss:  24.8228816986084 0.5811288952827454
loss:  24.431066513061523 0.5892389416694641
loss:  24.50359535217285 0.5932217240333557
loss:  24.403587341308594 0.5769630670547485
loss:  24.355276107788086 0.5733660459518433
loss:  24.583030700683594 0.5666606426239014
loss:  23.93598175048828 0.5582342743873596
loss:  24.25063705444336 0.5740448236465454
loss:  25.33249282836914 0.539934515953064
*******************Epoch 62 ****************** 1260 1.0
Validation Loss
*** pred loss:  25.852941513061523 pred acc: 0.5812197923660278
*** stop loss:  6.588811874389648 stop acc: 0.9214197397232056
*** template loss:  7.372703552246094 template acc: tensor(0.1442, device='cuda:0')
*** label loss:  6.1572136878967285 label acc: tensor(0.3487, device='cuda:0')
Train Loss
---> pred loss: 18.69550323486328 pred acc: 0.6984232753515244
---> stop loss: 3.434223175048828 stop acc: 0.9612952679395675
---> template loss: 0.9961771011352539 tempalte acc: 0.7755723476409913
---> molecule label loss: 0.7568618297576905 molecule acc: 0.8188905715942383
---> kl loss: 0.5818941116333007
---> reconstruction loss: 23.882765007019042
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-63-with.npy
loss:  24.204509735107422 0.5739969611167908
loss:  24.423892974853516 0.575834333896637
loss:  24.414661407470703 0.5773151516914368
loss:  24.58962631225586 0.5693276524543762
loss:  24.238882064819336 0.5648692846298218
loss:  24.326385498046875 0.560276985168457
loss:  24.44117546081543 0.5612165331840515
loss:  24.281953811645508 0.5588473081588745
loss:  24.197546005249023 0.55284583568573
loss:  24.128868103027344 0.569632887840271
loss:  24.561016082763672 0.5804846882820129
loss:  24.036291122436523 0.5905855298042297
loss:  23.848876953125 0.5753019452095032
loss:  24.28024673461914 0.5767532587051392
loss:  24.004243850708008 0.5668846964836121
loss:  24.062841415405273 0.5592272877693176
loss:  24.219533920288086 0.5779329538345337
loss:  24.04477882385254 0.5818895697593689
loss:  23.99445152282715 0.5510392785072327
loss:  24.66275405883789 0.5061777234077454
*******************Epoch 63 ****************** 1280 1.0
Validation Loss
*** pred loss:  26.135210037231445 pred acc: 0.5731883645057678
*** stop loss:  6.277375221252441 stop acc: 0.924595296382904
*** template loss:  7.378229141235352 template acc: tensor(0.1442, device='cuda:0')
*** label loss:  6.208002090454102 label acc: tensor(0.3840, device='cuda:0')
Train Loss
---> pred loss: 18.585369873046876 pred acc: 0.6994756579399108
---> stop loss: 3.4071842193603517 stop acc: 0.9615046232938766
---> template loss: 0.9620585441589355 tempalte acc: 0.7834901332855224
---> molecule label loss: 0.7269929409027099 molecule acc: 0.825472068786621
---> kl loss: 0.5665220260620117
---> reconstruction loss: 23.68160266876221
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-64-with.npy
loss:  24.20294189453125 0.5867711901664734
loss:  23.634126663208008 0.5815140604972839
loss:  24.296255111694336 0.5722560882568359
loss:  23.6982479095459 0.5680570006370544
loss:  24.099903106689453 0.555778443813324
loss:  24.247817993164062 0.5631663799285889
loss:  24.295751571655273 0.5582811832427979
loss:  24.08127212524414 0.5694602131843567
loss:  24.068084716796875 0.5795453786849976
loss:  23.955339431762695 0.5717546343803406
loss:  24.34369659423828 0.5695517063140869
loss:  23.71586036682129 0.5568332672119141
loss:  23.48163604736328 0.5658184289932251
loss:  23.9078426361084 0.5689893960952759
loss:  24.291059494018555 0.5581186413764954
loss:  24.239200592041016 0.5623521208763123
loss:  23.920997619628906 0.5490691065788269
loss:  23.74933624267578 0.5487029552459717
loss:  24.246158599853516 0.5459780693054199
loss:  23.34881591796875 0.5109754204750061
*******************Epoch 64 ****************** 1300 1.0
Validation Loss
*** pred loss:  26.032638549804688 pred acc: 0.5806159377098083
*** stop loss:  6.33101224899292 stop acc: 0.9239726662635803
*** template loss:  7.383595943450928 template acc: tensor(0.1439, device='cuda:0')
*** label loss:  6.287962913513184 label acc: tensor(0.3977, device='cuda:0')
Train Loss
---> pred loss: 18.450302124023438 pred acc: 0.7009586483240128
---> stop loss: 3.3545982360839846 stop acc: 0.9623309373855591
---> template loss: 0.9322550773620606 tempalte acc: 0.7895420074462891
---> molecule label loss: 0.6919132709503174 molecule acc: 0.8339011192321777
---> kl loss: 0.5621487140655518
---> reconstruction loss: 23.42906527519226
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-65-with.npy
loss:  23.702064514160156 0.5524296760559082
loss:  23.910903930664062 0.5592541098594666
loss:  24.18638801574707 0.5630897879600525
loss:  24.191301345825195 0.5517197251319885
loss:  24.180118560791016 0.5825297832489014
loss:  24.121185302734375 0.564919650554657
loss:  24.012239456176758 0.5595259666442871
loss:  23.62248420715332 0.5451849102973938
loss:  23.59865951538086 0.5669172406196594
loss:  23.74117660522461 0.5642805099487305
loss:  24.100847244262695 0.552172064781189
loss:  23.648975372314453 0.5599827170372009
loss:  23.98369598388672 0.5664635300636292
loss:  23.81861114501953 0.5573984384536743
loss:  23.723020553588867 0.5595722794532776
loss:  24.081819534301758 0.553770899772644
loss:  23.84711265563965 0.567818820476532
loss:  23.879159927368164 0.5458847284317017
loss:  23.973386764526367 0.5721136927604675
loss:  22.582334518432617 0.5442144870758057
*******************Epoch 65 ****************** 1320 1.0
Validation Loss
*** pred loss:  26.15030860900879 pred acc: 0.575664222240448
*** stop loss:  6.4255757331848145 stop acc: 0.9223225712776184
*** template loss:  7.38034200668335 template acc: tensor(0.1470, device='cuda:0')
*** label loss:  6.181675910949707 label acc: tensor(0.3682, device='cuda:0')
Train Loss
---> pred loss: 18.346969604492188 pred acc: 0.7028247386217117
---> stop loss: 3.3358287811279297 stop acc: 0.9623283177614212
---> template loss: 0.9206045150756836 tempalte acc: 0.7911742687225342
---> molecule label loss: 0.6824089527130127 molecule acc: 0.8342308044433594
---> kl loss: 0.5594622135162354
---> reconstruction loss: 23.28581213951111
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-66-with.npy
loss:  23.88765525817871 0.5670575499534607
loss:  23.876855850219727 0.5484762787818909
loss:  23.838083267211914 0.5566841959953308
loss:  23.809062957763672 0.5618374347686768
loss:  23.80533218383789 0.5325134992599487
loss:  23.61727523803711 0.5380681157112122
loss:  23.795757293701172 0.5743639469146729
loss:  23.87547492980957 0.5637208223342896
loss:  23.59389877319336 0.5467848181724548
loss:  23.75490951538086 0.5309613347053528
loss:  23.643325805664062 0.5493494272232056
loss:  23.747316360473633 0.5548732876777649
loss:  23.50250244140625 0.5405762195587158
loss:  23.811527252197266 0.5628891587257385
loss:  23.82893943786621 0.552314043045044
loss:  23.826801300048828 0.5247929692268372
loss:  23.85614585876465 0.5281360745429993
loss:  23.957731246948242 0.5340605974197388
loss:  23.477357864379883 0.5347633957862854
loss:  24.566957473754883 0.5628417730331421
*******************Epoch 66 ****************** 1340 1.0
Validation Loss
*** pred loss:  26.05975341796875 pred acc: 0.5796497464179993
*** stop loss:  6.337642192840576 stop acc: 0.9243150949478149
*** template loss:  7.43771505355835 template acc: tensor(0.1491, device='cuda:0')
*** label loss:  6.211995601654053 label acc: tensor(0.3806, device='cuda:0')
Train Loss
---> pred loss: 18.337913513183594 pred acc: 0.7043219983577729
---> stop loss: 3.3311676025390624 stop acc: 0.9626902133226395
---> template loss: 0.909858226776123 tempalte acc: 0.7920703887939453
---> molecule label loss: 0.6764542102813721 molecule acc: 0.8365846633911133
---> kl loss: 0.5482532024383545
---> reconstruction loss: 23.255392122268677
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-67-with.npy
loss:  23.253028869628906 0.5529479384422302
loss:  23.51535987854004 0.5318552255630493
loss:  23.893184661865234 0.553073525428772
loss:  23.800756454467773 0.5560595989227295
loss:  24.08970069885254 0.546079695224762
loss:  24.149208068847656 0.5507201552391052
loss:  23.63132095336914 0.5329580903053284
loss:  24.202028274536133 0.542607843875885
loss:  23.250211715698242 0.5448153614997864
loss:  23.3811092376709 0.5402764678001404
loss:  23.344261169433594 0.5457907319068909
loss:  23.677160263061523 0.5334686636924744
loss:  23.521074295043945 0.5142208933830261
loss:  23.610944747924805 0.5188064575195312
loss:  23.481372833251953 0.5234293937683105
loss:  23.505971908569336 0.5246356725692749
loss:  23.89391326904297 0.5334470272064209
loss:  23.580760955810547 0.5411733984947205
loss:  23.69008445739746 0.5596907138824463
loss:  21.657745361328125 0.5343886613845825
*******************Epoch 67 ****************** 1360 1.0
Validation Loss
*** pred loss:  26.193830490112305 pred acc: 0.5730676054954529
*** stop loss:  6.4698615074157715 stop acc: 0.9224470853805542
*** template loss:  7.429723262786865 template acc: tensor(0.1463, device='cuda:0')
*** label loss:  6.229277610778809 label acc: tensor(0.3842, device='cuda:0')
Train Loss
---> pred loss: 18.19056854248047 pred acc: 0.7060523390769958
---> stop loss: 3.257308578491211 stop acc: 0.9635901987552643
---> template loss: 0.9050372123718262 tempalte acc: 0.7950051307678223
---> molecule label loss: 0.664523983001709 molecule acc: 0.8381555557250977
---> kl loss: 0.5390222549438477
---> reconstruction loss: 23.017438316345213
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-68-with.npy
loss:  23.129051208496094 0.5420083999633789
loss:  23.136804580688477 0.5365113615989685
loss:  23.79892349243164 0.5598443746566772
loss:  23.64907455444336 0.5366852283477783
loss:  23.380443572998047 0.5338208675384521
loss:  23.643997192382812 0.5427243709564209
loss:  22.828210830688477 0.5285226106643677
loss:  23.650033950805664 0.5220018625259399
loss:  23.4824161529541 0.523684024810791
loss:  23.885765075683594 0.5252151489257812
loss:  23.592782974243164 0.5363357663154602
loss:  22.962928771972656 0.5209315419197083
loss:  23.81296730041504 0.5433757305145264
loss:  24.079025268554688 0.5333115458488464
loss:  23.60785484313965 0.543531596660614
loss:  23.2166690826416 0.5392147302627563
loss:  23.928489685058594 0.5466391444206238
loss:  22.928075790405273 0.5414878726005554
loss:  23.54657745361328 0.5256243348121643
loss:  23.036041259765625 0.4984437823295593
*******************Epoch 68 ****************** 1380 1.0
Validation Loss
*** pred loss:  26.154804229736328 pred acc: 0.5773550868034363
*** stop loss:  6.494897842407227 stop acc: 0.9235678911209106
*** template loss:  7.392855167388916 template acc: tensor(0.1460, device='cuda:0')
*** label loss:  6.3532609939575195 label acc: tensor(0.4022, device='cuda:0')
Train Loss
---> pred loss: 18.194903564453124 pred acc: 0.7072369873523712
---> stop loss: 3.2633182525634767 stop acc: 0.963435435295105
---> template loss: 0.8597554206848145 tempalte acc: 0.8057112693786621
---> molecule label loss: 0.6128344058990478 molecule acc: 0.8517257690429687
---> kl loss: 0.5339957237243652
---> reconstruction loss: 22.930809879302977
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-69-with.npy
loss:  23.383237838745117 0.531079888343811
loss:  23.50826072692871 0.524069607257843
loss:  23.225467681884766 0.5308791399002075
loss:  23.107587814331055 0.5415106415748596
loss:  23.2568359375 0.5408666729927063
loss:  23.79839515686035 0.5323947072029114
loss:  23.27385139465332 0.5274701714515686
loss:  23.41483497619629 0.5263012647628784
loss:  23.29573631286621 0.5326281785964966
loss:  23.087873458862305 0.531801700592041
loss:  23.728336334228516 0.5256552696228027
loss:  23.71420669555664 0.5357658267021179
loss:  23.311016082763672 0.5288928747177124
loss:  23.62929344177246 0.5130748748779297
loss:  24.21220588684082 0.5223837494850159
loss:  23.37939453125 0.5081285238265991
loss:  23.413959503173828 0.5277935266494751
loss:  23.67701530456543 0.5240908861160278
loss:  23.426738739013672 0.528165876865387
loss:  23.354738235473633 0.5213668942451477
*******************Epoch 69 ****************** 1400 1.0
Validation Loss
*** pred loss:  26.222820281982422 pred acc: 0.5787439346313477
*** stop loss:  6.7623467445373535 stop acc: 0.9232565760612488
*** template loss:  7.3889336585998535 template acc: tensor(0.1548, device='cuda:0')
*** label loss:  6.221915245056152 label acc: tensor(0.3836, device='cuda:0')
Train Loss
---> pred loss: 18.106251525878907 pred acc: 0.7081271708011627
---> stop loss: 3.388872528076172 stop acc: 0.9618940651416779
---> template loss: 0.8407159805297851 tempalte acc: 0.8086752891540527
---> molecule label loss: 0.5963937759399414 molecule acc: 0.8526068687438965
---> kl loss: 0.5277160167694092
---> reconstruction loss: 22.93223271369934
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-70-with.npy
loss:  23.160104751586914 0.5209921002388
loss:  23.806793212890625 0.5398748517036438
loss:  23.509801864624023 0.5334311723709106
loss:  23.30959701538086 0.5364530086517334
loss:  23.206249237060547 0.516838550567627
loss:  23.447450637817383 0.5356616973876953
loss:  23.594676971435547 0.524747908115387
loss:  22.934879302978516 0.5168185830116272
loss:  23.485889434814453 0.5114519596099854
loss:  23.39681625366211 0.5281258821487427
loss:  23.619792938232422 0.505662202835083
loss:  22.966278076171875 0.5216974020004272
loss:  22.90862464904785 0.5101685523986816
loss:  23.175704956054688 0.5299512147903442
loss:  23.024858474731445 0.5348902940750122
loss:  23.5775089263916 0.5243569016456604
loss:  22.889829635620117 0.505384087562561
loss:  23.062332153320312 0.5191690921783447
loss:  23.491161346435547 0.5074862241744995
loss:  23.15373420715332 0.4707430899143219
*******************Epoch 70 ****************** 1420 1.0
Validation Loss
*** pred loss:  26.327991485595703 pred acc: 0.574577271938324
*** stop loss:  6.368252277374268 stop acc: 0.924408495426178
*** template loss:  7.42578125 template acc: tensor(0.1512, device='cuda:0')
*** label loss:  6.244889259338379 label acc: tensor(0.3843, device='cuda:0')
Train Loss
---> pred loss: 18.03157196044922 pred acc: 0.70811927318573
---> stop loss: 3.3134498596191406 stop acc: 0.9628122925758362
---> template loss: 0.8311507225036621 tempalte acc: 0.8145747184753418
---> molecule label loss: 0.5902354717254639 molecule acc: 0.8549687385559082
---> kl loss: 0.519695234298706
---> reconstruction loss: 22.76641011238098
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-71-with.npy
loss:  23.23650550842285 0.49781152606010437
loss:  23.204986572265625 0.5124662518501282
loss:  23.110149383544922 0.5077354907989502
loss:  23.21537971496582 0.5111851096153259
loss:  23.643835067749023 0.510347306728363
loss:  22.937978744506836 0.5166645646095276
loss:  23.047367095947266 0.5298764705657959
loss:  23.032928466796875 0.5236086249351501
loss:  23.318748474121094 0.5242591500282288
loss:  22.606037139892578 0.5362384915351868
loss:  23.168039321899414 0.520467221736908
loss:  22.954374313354492 0.5086553692817688
loss:  23.377094268798828 0.4949178993701935
loss:  23.265024185180664 0.5155125856399536
loss:  23.22538948059082 0.5060731172561646
loss:  23.3260555267334 0.4994677007198334
loss:  22.814661026000977 0.5128659009933472
loss:  22.753482818603516 0.5161649584770203
loss:  23.309629440307617 0.5132595300674438
loss:  22.729177474975586 0.4954425096511841
*******************Epoch 71 ****************** 1440 1.0
Validation Loss
*** pred loss:  26.38740348815918 pred acc: 0.5757246017456055
*** stop loss:  6.483498573303223 stop acc: 0.9226338863372803
*** template loss:  7.376111030578613 template acc: tensor(0.1463, device='cuda:0')
*** label loss:  6.269174575805664 label acc: tensor(0.3851, device='cuda:0')
Train Loss
---> pred loss: 17.969131469726562 pred acc: 0.7104099959135055
---> stop loss: 3.2540050506591798 stop acc: 0.9634367197751998
---> template loss: 0.8159808158874512 tempalte acc: 0.8148630142211915
---> molecule label loss: 0.5620746612548828 molecule acc: 0.8614950180053711
---> kl loss: 0.512651014328003
---> reconstruction loss: 22.601191759109497
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-72-with.npy
loss:  22.793766021728516 0.5239530205726624
loss:  23.103954315185547 0.5297725796699524
loss:  22.93030548095703 0.5061894655227661
loss:  23.086284637451172 0.5065841674804688
loss:  22.547136306762695 0.5308696627616882
loss:  22.883655548095703 0.5114246010780334
loss:  23.334074020385742 0.514998197555542
loss:  23.360403060913086 0.5129915475845337
loss:  23.19957733154297 0.5333276987075806
loss:  22.857858657836914 0.518686830997467
loss:  22.855321884155273 0.4971829056739807
loss:  22.889612197875977 0.5192357897758484
loss:  22.969501495361328 0.5251122117042542
loss:  22.959997177124023 0.5029087066650391
loss:  22.706497192382812 0.5136528611183167
loss:  23.21128273010254 0.5140966176986694
loss:  22.954336166381836 0.5015228986740112
loss:  23.061962127685547 0.489822119474411
loss:  22.812063217163086 0.4974232017993927
loss:  22.562776565551758 0.5435222387313843
*******************Epoch 72 ****************** 1460 1.0
Validation Loss
*** pred loss:  26.686012268066406 pred acc: 0.5716787576675415
*** stop loss:  6.657642364501953 stop acc: 0.9236924648284912
*** template loss:  7.448110580444336 template acc: tensor(0.1527, device='cuda:0')
*** label loss:  6.294157028198242 label acc: tensor(0.3573, device='cuda:0')
Train Loss
---> pred loss: 17.895181274414064 pred acc: 0.7097494333982468
---> stop loss: 3.18182487487793 stop acc: 0.9642450541257859
---> template loss: 0.8039300918579102 tempalte acc: 0.8162002563476562
---> molecule label loss: 0.5584203720092773 molecule acc: 0.8607067108154297
---> kl loss: 0.51466383934021
---> reconstruction loss: 22.43935227394104
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-73-with.npy
loss:  23.1666202545166 0.4934704005718231
loss:  23.233915328979492 0.5119020938873291
loss:  23.07027244567871 0.5097650289535522
loss:  23.046772003173828 0.49740540981292725
loss:  23.041229248046875 0.49472060799598694
loss:  22.70343589782715 0.50010085105896
loss:  22.648727416992188 0.5044087171554565
loss:  23.084701538085938 0.5019778609275818
loss:  22.8416690826416 0.5133464336395264
loss:  22.79293441772461 0.5038947463035583
loss:  23.300029754638672 0.5038697123527527
loss:  23.09920883178711 0.5018616914749146
loss:  23.136171340942383 0.5008934140205383
loss:  22.845125198364258 0.5096133351325989
loss:  22.91144371032715 0.507369339466095
loss:  23.009780883789062 0.5011707544326782
loss:  22.9722843170166 0.4833422899246216
loss:  22.890422821044922 0.5045679807662964
loss:  22.979022979736328 0.48853668570518494
loss:  23.593761444091797 0.5333296060562134
*******************Epoch 73 ****************** 1480 1.0
Validation Loss
*** pred loss:  26.316884994506836 pred acc: 0.5763888955116272
*** stop loss:  6.648016929626465 stop acc: 0.9216376543045044
*** template loss:  7.444167613983154 template acc: tensor(0.1523, device='cuda:0')
*** label loss:  6.390024185180664 label acc: tensor(0.3233, device='cuda:0')
Train Loss
---> pred loss: 17.92003631591797 pred acc: 0.7100158363580704
---> stop loss: 3.2113601684570314 stop acc: 0.9639696568250656
---> template loss: 0.7966464996337891 tempalte acc: 0.8190247535705566
---> molecule label loss: 0.5870566844940186 molecule acc: 0.8505208969116211
---> kl loss: 0.5032773971557617
---> reconstruction loss: 22.5150972366333
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-74-with.npy
loss:  23.346046447753906 0.4946327805519104
loss:  23.365169525146484 0.4997599720954895
loss:  23.306493759155273 0.508795440196991
loss:  22.624853134155273 0.5096153020858765
loss:  23.027002334594727 0.5095419883728027
loss:  23.326887130737305 0.5062878131866455
loss:  22.840927124023438 0.4968487024307251
loss:  22.83098030090332 0.5093442797660828
loss:  22.964086532592773 0.5080325603485107
loss:  22.535978317260742 0.4999830424785614
loss:  22.951745986938477 0.4868793785572052
loss:  23.122385025024414 0.5097468495368958
loss:  22.560991287231445 0.49659737944602966
loss:  23.051523208618164 0.4934461712837219
loss:  22.78401756286621 0.48185232281684875
loss:  22.78951644897461 0.501937210559845
loss:  22.78329849243164 0.49991345405578613
loss:  22.74686622619629 0.4942852556705475
loss:  22.61017608642578 0.4815819263458252
loss:  21.529869079589844 0.4992421567440033
*******************Epoch 74 ****************** 1500 1.0
Validation Loss
*** pred loss:  26.538002014160156 pred acc: 0.5730676054954529
*** stop loss:  6.470465183258057 stop acc: 0.9261831045150757
*** template loss:  7.422529220581055 template acc: tensor(0.1544, device='cuda:0')
*** label loss:  6.328983306884766 label acc: tensor(0.3881, device='cuda:0')
Train Loss
---> pred loss: 17.77835693359375 pred acc: 0.7115863770246506
---> stop loss: 3.1717161178588866 stop acc: 0.9645214736461639
---> template loss: 0.7859204292297364 tempalte acc: 0.820897388458252
---> molecule label loss: 0.6195300579071045 molecule acc: 0.8390964508056641
---> kl loss: 0.4994162082672119
---> reconstruction loss: 22.355524587631223
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-75-with.npy
loss:  22.30885887145996 0.49193909764289856
loss:  22.376371383666992 0.4863643944263458
loss:  22.765363693237305 0.5086194276809692
loss:  22.619117736816406 0.49186307191848755
loss:  22.659090042114258 0.4930175244808197
loss:  22.882816314697266 0.49482211470603943
loss:  22.354496002197266 0.4732934534549713
loss:  22.784326553344727 0.4886103570461273
loss:  22.484394073486328 0.48083794116973877
loss:  22.561992645263672 0.4795687794685364
loss:  22.971261978149414 0.4907902181148529
loss:  22.8459529876709 0.48149555921554565
loss:  22.442089080810547 0.48967546224594116
loss:  22.472511291503906 0.49832528829574585
loss:  22.87432289123535 0.48933109641075134
loss:  22.980186462402344 0.507753312587738
loss:  22.66512107849121 0.48473313450813293
loss:  22.585758209228516 0.48073697090148926
loss:  22.705503463745117 0.4810425043106079
loss:  22.47869300842285 0.4789431691169739
*******************Epoch 75 ****************** 1520 1.0
Validation Loss
*** pred loss:  26.440410614013672 pred acc: 0.5759057998657227
*** stop loss:  6.466047286987305 stop acc: 0.9254670143127441
*** template loss:  7.444770812988281 template acc: tensor(0.1562, device='cuda:0')
*** label loss:  6.276058197021484 label acc: tensor(0.3883, device='cuda:0')
Train Loss
---> pred loss: 17.714266967773437 pred acc: 0.7131858587265014
---> stop loss: 3.1428768157958986 stop acc: 0.964993217587471
---> template loss: 0.761411714553833 tempalte acc: 0.827817440032959
---> molecule label loss: 0.533767557144165 molecule acc: 0.8661676406860351
---> kl loss: 0.4885881423950195
---> reconstruction loss: 22.152323722839355
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-76-with.npy
loss:  22.44861602783203 0.46935585141181946
loss:  22.59693145751953 0.4685944616794586
loss:  22.2386474609375 0.47919073700904846
loss:  22.617773056030273 0.4732115864753723
loss:  22.831789016723633 0.47998547554016113
loss:  22.687143325805664 0.4765051305294037
loss:  22.795700073242188 0.47269299626350403
loss:  22.481319427490234 0.4827153980731964
loss:  22.498510360717773 0.48610562086105347
loss:  22.441038131713867 0.477948397397995
loss:  22.776918411254883 0.4819749593734741
loss:  22.792377471923828 0.47709834575653076
loss:  22.53835678100586 0.482785165309906
loss:  22.446216583251953 0.4939059913158417
loss:  22.40425682067871 0.4763251841068268
loss:  22.797658920288086 0.48131895065307617
loss:  22.29473876953125 0.47941654920578003
loss:  22.10753059387207 0.46678411960601807
loss:  22.712894439697266 0.47991859912872314
loss:  23.269411087036133 0.47353652119636536
*******************Epoch 76 ****************** 1540 1.0
Validation Loss
*** pred loss:  26.55958366394043 pred acc: 0.574999988079071
*** stop loss:  6.6521830558776855 stop acc: 0.9234433770179749
*** template loss:  7.426151752471924 template acc: tensor(0.1439, device='cuda:0')
*** label loss:  6.284630298614502 label acc: tensor(0.3703, device='cuda:0')
Train Loss
---> pred loss: 17.69685516357422 pred acc: 0.7146919876337051
---> stop loss: 3.139046478271484 stop acc: 0.9651117593050003
---> template loss: 0.7560061454772949 tempalte acc: 0.8299317359924316
---> molecule label loss: 0.5190143585205078 molecule acc: 0.869506549835205
---> kl loss: 0.4779685020446777
---> reconstruction loss: 22.110924625396727
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-77-with.npy
loss:  22.190980911254883 0.4696836769580841
loss:  22.459522247314453 0.46651649475097656
loss:  22.787452697753906 0.4622695744037628
loss:  22.996471405029297 0.4775531589984894
loss:  22.81010627746582 0.47183167934417725
loss:  23.126008987426758 0.47432956099510193
loss:  22.847909927368164 0.48556721210479736
loss:  22.823570251464844 0.49588119983673096
loss:  22.173805236816406 0.48141685128211975
loss:  22.746030807495117 0.47359228134155273
loss:  22.041309356689453 0.4685669541358948
loss:  22.790098190307617 0.4930669963359833
loss:  23.057600021362305 0.4813029170036316
loss:  22.443017959594727 0.47078654170036316
loss:  22.656352996826172 0.4645463228225708
loss:  22.106401443481445 0.47411349415779114
loss:  22.348661422729492 0.4561609923839569
loss:  22.333181381225586 0.4695623815059662
loss:  22.8625545501709 0.47933727502822876
loss:  22.31653594970703 0.4391237795352936
*******************Epoch 77 ****************** 1560 1.0
Validation Loss
*** pred loss:  26.612443923950195 pred acc: 0.5777777433395386
*** stop loss:  6.626513957977295 stop acc: 0.9236612915992737
*** template loss:  7.419287204742432 template acc: tensor(0.1625, device='cuda:0')
*** label loss:  6.359525203704834 label acc: tensor(0.3920, device='cuda:0')
Train Loss
---> pred loss: 17.64226531982422 pred acc: 0.7147031933069229
---> stop loss: 3.1529869079589843 stop acc: 0.9645239979028701
---> template loss: 0.7869654655456543 tempalte acc: 0.820622730255127
---> molecule label loss: 0.5409000396728516 molecule acc: 0.8629910469055175
---> kl loss: 0.4727604389190674
---> reconstruction loss: 22.123116636276244
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-78-with.npy
loss:  22.441781997680664 0.47431549429893494
loss:  21.96013832092285 0.46231159567832947
loss:  22.510900497436523 0.4764837324619293
loss:  22.72796058654785 0.4776257574558258
loss:  22.506174087524414 0.4811829924583435
loss:  23.011337280273438 0.4846320152282715
loss:  22.758167266845703 0.4694705903530121
loss:  22.211763381958008 0.4836721122264862
loss:  22.341447830200195 0.46011611819267273
loss:  22.446067810058594 0.46349263191223145
loss:  22.363788604736328 0.4624766409397125
loss:  22.96808433532715 0.46878811717033386
loss:  22.563823699951172 0.4541028141975403
loss:  22.35964012145996 0.46749910712242126
loss:  22.564197540283203 0.4708780348300934
loss:  22.684539794921875 0.455723375082016
loss:  22.502159118652344 0.44745612144470215
loss:  22.531330108642578 0.4642032980918884
loss:  22.598670959472656 0.4619222581386566
loss:  21.931236267089844 0.4858229160308838
*******************Epoch 78 ****************** 1580 1.0
Validation Loss
*** pred loss:  26.849044799804688 pred acc: 0.5719202756881714
*** stop loss:  6.734115123748779 stop acc: 0.9209527373313904
*** template loss:  7.402024269104004 template acc: tensor(0.1477, device='cuda:0')
*** label loss:  6.653109550476074 label acc: tensor(0.3990, device='cuda:0')
Train Loss
---> pred loss: 17.569281005859374 pred acc: 0.714537912607193
---> stop loss: 3.1015790939331054 stop acc: 0.9655796587467194
---> template loss: 0.7936915874481201 tempalte acc: 0.8182503700256347
---> molecule label loss: 0.5660014629364014 molecule acc: 0.8544360160827636
---> kl loss: 0.46860880851745607
---> reconstruction loss: 22.030553483963015
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-79-with.npy
loss:  21.94101905822754 0.44983336329460144
loss:  22.881790161132812 0.45628219842910767
loss:  22.96331214904785 0.4551072418689728
loss:  22.690975189208984 0.4629017114639282
loss:  22.53532600402832 0.4629007875919342
loss:  22.713777542114258 0.4658934772014618
loss:  22.714996337890625 0.45997142791748047
loss:  22.652494430541992 0.4636939764022827
loss:  22.67062759399414 0.466283917427063
loss:  22.35489273071289 0.4755174517631531
loss:  22.024484634399414 0.4652217924594879
loss:  22.674659729003906 0.45397117733955383
loss:  22.29241371154785 0.4504089057445526
loss:  23.00664710998535 0.458150714635849
loss:  22.3664493560791 0.44605010747909546
loss:  22.62007713317871 0.4519261419773102
loss:  22.315059661865234 0.4497172236442566
loss:  22.4221248626709 0.45479461550712585
loss:  22.095321655273438 0.45793142914772034
loss:  23.52778434753418 0.502802312374115
*******************Epoch 79 ****************** 1600 1.0
Validation Loss
*** pred loss:  26.770109176635742 pred acc: 0.5742753744125366
*** stop loss:  6.599539279937744 stop acc: 0.925093412399292
*** template loss:  7.417240142822266 template acc: tensor(0.1534, device='cuda:0')
*** label loss:  6.265931606292725 label acc: tensor(0.3652, device='cuda:0')
Train Loss
---> pred loss: 17.575790405273438 pred acc: 0.7165832161903382
---> stop loss: 3.091238594055176 stop acc: 0.9653815060853959
---> template loss: 0.8362820625305176 tempalte acc: 0.8059391021728516
---> molecule label loss: 0.609433937072754 molecule acc: 0.8404870986938476
---> kl loss: 0.4604680061340332
---> reconstruction loss: 22.112743663787843
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-80-with.npy
loss:  22.21306610107422 0.4615519642829895
loss:  22.653444290161133 0.4691694378852844
loss:  22.61667823791504 0.4642518162727356
loss:  22.671857833862305 0.4589715600013733
loss:  22.34885597229004 0.46273279190063477
loss:  22.810386657714844 0.4731793701648712
loss:  22.206714630126953 0.44911321997642517
loss:  22.7269287109375 0.45496925711631775
loss:  22.169164657592773 0.44934791326522827
loss:  22.43042755126953 0.44369474053382874
loss:  22.01958465576172 0.43912985920906067
loss:  22.198036193847656 0.44933050870895386
loss:  22.18663787841797 0.4394342005252838
loss:  21.906496047973633 0.4485833942890167
loss:  22.298431396484375 0.4467345178127289
loss:  22.297048568725586 0.43870776891708374
loss:  22.437679290771484 0.4479241371154785
loss:  22.171323776245117 0.4438473582267761
loss:  22.151540756225586 0.45552006363868713
loss:  22.705698013305664 0.4519115686416626
*******************Epoch 80 ****************** 1620 1.0
Validation Loss
*** pred loss:  26.89154624938965 pred acc: 0.5742753744125366
*** stop loss:  7.038314342498779 stop acc: 0.9210461378097534
*** template loss:  7.447701454162598 template acc: tensor(0.1520, device='cuda:0')
*** label loss:  6.292434215545654 label acc: tensor(0.3661, device='cuda:0')
Train Loss
---> pred loss: 17.55400695800781 pred acc: 0.7158627450466156
---> stop loss: 3.074363899230957 stop acc: 0.9657778322696686
---> template loss: 0.7584536075592041 tempalte acc: 0.8274730682373047
---> molecule label loss: 0.5217676639556885 molecule acc: 0.8657948493957519
---> kl loss: 0.4524052619934082
---> reconstruction loss: 21.908594799041747
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-81-with.npy
loss:  22.496437072753906 0.45972880721092224
loss:  22.45745277404785 0.45327427983283997
loss:  22.152498245239258 0.45993489027023315
loss:  22.444961547851562 0.45302990078926086
loss:  22.51191520690918 0.47108978033065796
loss:  21.841691970825195 0.4725653827190399
loss:  22.474990844726562 0.4557344317436218
loss:  22.273303985595703 0.4616529941558838
loss:  22.184537887573242 0.4611999988555908
loss:  21.54897689819336 0.457754522562027
loss:  22.26532554626465 0.44105860590934753
loss:  22.264673233032227 0.444415807723999
loss:  22.003725051879883 0.4614589512348175
loss:  22.023483276367188 0.44976890087127686
loss:  22.273996353149414 0.42999204993247986
loss:  21.77800750732422 0.4464441239833832
loss:  22.03363037109375 0.45016995072364807
loss:  21.92724609375 0.44454526901245117
loss:  21.97342300415039 0.42667800188064575
loss:  21.86741828918457 0.4679105877876282
*******************Epoch 81 ****************** 1640 1.0
Validation Loss
*** pred loss:  26.84208869934082 pred acc: 0.5727053284645081
*** stop loss:  6.676718235015869 stop acc: 0.9240971803665161
*** template loss:  7.380304336547852 template acc: tensor(0.1551, device='cuda:0')
*** label loss:  6.333817005157471 label acc: tensor(0.3962, device='cuda:0')
Train Loss
---> pred loss: 17.41356506347656 pred acc: 0.7185053586959839
---> stop loss: 3.055974769592285 stop acc: 0.9658661156892776
---> template loss: 0.7349920272827148 tempalte acc: 0.8309959411621094
---> molecule label loss: 0.4819342613220215 molecule acc: 0.8765094757080079
---> kl loss: 0.45342040061950684
---> reconstruction loss: 21.686464548110962
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-82-with.npy
loss:  22.350263595581055 0.4307491183280945
loss:  22.09675407409668 0.4295998513698578
loss:  22.241037368774414 0.4220261871814728
loss:  21.766454696655273 0.4411805272102356
loss:  21.74102783203125 0.4237554967403412
loss:  22.129188537597656 0.43187448382377625
loss:  22.047088623046875 0.4237367808818817
loss:  21.63368797302246 0.4324420690536499
loss:  21.90810203552246 0.44211140275001526
loss:  22.180444717407227 0.44318193197250366
loss:  22.067501068115234 0.44249773025512695
loss:  21.646080017089844 0.4401083290576935
loss:  21.752944946289062 0.44650912284851074
loss:  21.657978057861328 0.45133233070373535
loss:  21.866487503051758 0.44617828726768494
loss:  22.195201873779297 0.43395912647247314
loss:  22.141496658325195 0.43656232953071594
loss:  21.832210540771484 0.4499225318431854
loss:  22.045883178710938 0.4444330930709839
loss:  21.20711898803711 0.4241785407066345
*******************Epoch 82 ****************** 1660 1.0
Validation Loss
*** pred loss:  26.992816925048828 pred acc: 0.574456512928009
*** stop loss:  6.7378644943237305 stop acc: 0.9229452610015869
*** template loss:  7.416060924530029 template acc: tensor(0.1597, device='cuda:0')
*** label loss:  6.3399882316589355 label acc: tensor(0.3917, device='cuda:0')
Train Loss
---> pred loss: 17.33106231689453 pred acc: 0.7185358971357345
---> stop loss: 3.013443183898926 stop acc: 0.9665203362703323
---> template loss: 0.6978803157806397 tempalte acc: 0.842102336883545
---> molecule label loss: 0.44614534378051757 molecule acc: 0.887080192565918
---> kl loss: 0.436816930770874
---> reconstruction loss: 21.488532495498657
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-83-with.npy
loss:  22.01677131652832 0.44139429926872253
loss:  22.14168930053711 0.4332387447357178
loss:  21.964773178100586 0.43237799406051636
loss:  21.56879997253418 0.4233446419239044
loss:  22.19354248046875 0.43278324604034424
loss:  22.15302085876465 0.4364151358604431
loss:  21.759183883666992 0.43287691473960876
loss:  22.078317642211914 0.4334973394870758
loss:  22.240047454833984 0.439698725938797
loss:  21.83832359313965 0.4350099265575409
loss:  21.75156593322754 0.44347724318504333
loss:  21.779754638671875 0.4439375400543213
loss:  21.753889083862305 0.4425029754638672
loss:  22.137977600097656 0.42390069365501404
loss:  21.787227630615234 0.43939685821533203
loss:  21.746261596679688 0.43951135873794556
loss:  21.82241439819336 0.4311284124851227
loss:  21.718257904052734 0.43122655153274536
loss:  21.526521682739258 0.4231909513473511
loss:  22.289274215698242 0.4073167145252228
*******************Epoch 83 ****************** 1680 1.0
Validation Loss
*** pred loss:  27.07697105407715 pred acc: 0.5717995166778564
*** stop loss:  6.832979202270508 stop acc: 0.9222914576530457
*** template loss:  7.519404888153076 template acc: tensor(0.1565, device='cuda:0')
*** label loss:  6.344934463500977 label acc: tensor(0.3949, device='cuda:0')
Train Loss
---> pred loss: 17.315228271484376 pred acc: 0.7201742559671402
---> stop loss: 3.026549530029297 stop acc: 0.9662437349557876
---> template loss: 0.6996561050415039 tempalte acc: 0.8425425529479981
---> molecule label loss: 0.4386357307434082 molecule acc: 0.8884067535400391
---> kl loss: 0.43331131935119627
---> reconstruction loss: 21.48006911277771
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-84-with.npy
loss:  21.798532485961914 0.42775872349739075
loss:  21.748552322387695 0.4096272885799408
loss:  21.798465728759766 0.4299790561199188
loss:  21.847211837768555 0.42534637451171875
loss:  22.120319366455078 0.43525341153144836
loss:  22.167482376098633 0.4392727017402649
loss:  21.736614227294922 0.42775702476501465
loss:  21.848840713500977 0.4472435712814331
loss:  21.651395797729492 0.4315049648284912
loss:  21.291385650634766 0.4181787669658661
loss:  21.98482322692871 0.42540889978408813
loss:  21.559490203857422 0.418628066778183
loss:  22.144147872924805 0.421109676361084
loss:  22.093759536743164 0.4258722960948944
loss:  21.970447540283203 0.42956918478012085
loss:  21.99266815185547 0.44405049085617065
loss:  21.59818458557129 0.42972317337989807
loss:  21.6807918548584 0.4344405233860016
loss:  21.97187042236328 0.43693968653678894
loss:  23.218603134155273 0.4434773623943329
*******************Epoch 84 ****************** 1700 1.0
Validation Loss
*** pred loss:  26.998065948486328 pred acc: 0.5781400799751282
*** stop loss:  6.546553134918213 stop acc: 0.9258406162261963
*** template loss:  7.442309856414795 template acc: tensor(0.1544, device='cuda:0')
*** label loss:  6.402151584625244 label acc: tensor(0.3900, device='cuda:0')
Train Loss
---> pred loss: 17.29474792480469 pred acc: 0.7201316446065903
---> stop loss: 3.0392961502075195 stop acc: 0.9663893014192582
---> template loss: 0.7041163444519043 tempalte acc: 0.8388971328735352
---> molecule label loss: 0.4429606914520264 molecule acc: 0.8852513313293457
---> kl loss: 0.43005709648132323
---> reconstruction loss: 21.481119966506956
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-85-with.npy
loss:  21.349319458007812 0.43293094635009766
loss:  21.737659454345703 0.43389469385147095
loss:  21.77549171447754 0.4315722584724426
loss:  22.235553741455078 0.42983677983283997
loss:  21.67217254638672 0.4143145680427551
loss:  21.31710433959961 0.41571763157844543
loss:  21.853744506835938 0.43339553475379944
loss:  21.956907272338867 0.41191980242729187
loss:  21.75140380859375 0.4133661389350891
loss:  21.48897933959961 0.41583025455474854
loss:  21.751232147216797 0.41709616780281067
loss:  21.50164222717285 0.4160453677177429
loss:  21.420515060424805 0.41968902945518494
loss:  22.05024528503418 0.422061949968338
loss:  21.92639923095703 0.42700114846229553
loss:  21.766010284423828 0.43517133593559265
loss:  21.96332359313965 0.4259456396102905
loss:  21.697280883789062 0.42911770939826965
loss:  21.277992248535156 0.425288587808609
loss:  20.492813110351562 0.4185531437397003
*******************Epoch 85 ****************** 1720 1.0
Validation Loss
*** pred loss:  26.99945831298828 pred acc: 0.5756038427352905
*** stop loss:  6.631538391113281 stop acc: 0.9266812205314636
*** template loss:  7.471011638641357 template acc: tensor(0.1583, device='cuda:0')
*** label loss:  6.428834438323975 label acc: tensor(0.3870, device='cuda:0')
Train Loss
---> pred loss: 17.17863311767578 pred acc: 0.7215719640254974
---> stop loss: 2.9604122161865236 stop acc: 0.9669328600168228
---> template loss: 0.6682440280914307 tempalte acc: 0.8490150451660157
---> molecule label loss: 0.4185629844665527 molecule acc: 0.8919998168945312
---> kl loss: 0.42343740463256835
---> reconstruction loss: 21.22585153579712
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-86-with.npy
loss:  21.24386978149414 0.415231853723526
loss:  21.707073211669922 0.4230753481388092
loss:  21.282203674316406 0.43473386764526367
loss:  21.495359420776367 0.4245584309101105
loss:  21.74501609802246 0.40745052695274353
loss:  21.8487491607666 0.41101810336112976
loss:  21.52766990661621 0.4066595435142517
loss:  21.834178924560547 0.41282665729522705
loss:  21.348804473876953 0.40551796555519104
loss:  21.416728973388672 0.4126243591308594
loss:  21.68296241760254 0.4147314131259918
loss:  21.48373794555664 0.4016861021518707
loss:  21.819812774658203 0.4131028354167938
loss:  21.874286651611328 0.40157759189605713
loss:  21.581993103027344 0.4100334644317627
loss:  21.63419532775879 0.39885714650154114
loss:  21.44758415222168 0.4105586111545563
loss:  21.946949005126953 0.40747255086898804
loss:  21.87452507019043 0.4130708575248718
loss:  21.794462203979492 0.39567452669143677
*******************Epoch 86 ****************** 1740 1.0
Validation Loss
*** pred loss:  27.13383674621582 pred acc: 0.5770531296730042
*** stop loss:  6.550606727600098 stop acc: 0.9257161021232605
*** template loss:  7.528611183166504 template acc: tensor(0.1562, device='cuda:0')
*** label loss:  6.450687885284424 label acc: tensor(0.3828, device='cuda:0')
Train Loss
---> pred loss: 17.156161499023437 pred acc: 0.7220794320106506
---> stop loss: 2.978324127197266 stop acc: 0.9667828351259231
---> template loss: 0.6628867149353027 tempalte acc: 0.8497937202453614
---> molecule label loss: 0.4211132526397705 molecule acc: 0.8906991958618165
---> kl loss: 0.41102309226989747
---> reconstruction loss: 21.218485879898072
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-87-with.npy
loss:  21.23432159423828 0.40131667256355286
loss:  21.8266544342041 0.4258281886577606
loss:  21.635181427001953 0.41936996579170227
loss:  21.83535385131836 0.4172506332397461
loss:  21.957908630371094 0.41447484493255615
loss:  21.832012176513672 0.4259618818759918
loss:  22.11876678466797 0.409442275762558
loss:  21.95107078552246 0.4280489981174469
loss:  21.553361892700195 0.4058135151863098
loss:  21.833942413330078 0.42593908309936523
loss:  21.988866806030273 0.4136033058166504
loss:  21.110931396484375 0.43358615040779114
loss:  21.9188232421875 0.4128122329711914
loss:  21.858585357666016 0.40654733777046204
loss:  21.609487533569336 0.41469380259513855
loss:  21.806320190429688 0.4175792634487152
loss:  21.86530113220215 0.412494033575058
loss:  21.84795379638672 0.4111393094062805
loss:  21.5463924407959 0.41249358654022217
loss:  22.00374412536621 0.42750903964042664
*******************Epoch 87 ****************** 1760 1.0
Validation Loss
*** pred loss:  27.185638427734375 pred acc: 0.572282612323761
*** stop loss:  6.74144172668457 stop acc: 0.9250622987747192
*** template loss:  7.46237325668335 template acc: tensor(0.1474, device='cuda:0')
*** label loss:  6.455032825469971 label acc: tensor(0.3992, device='cuda:0')
Train Loss
---> pred loss: 17.13543701171875 pred acc: 0.7207900881767273
---> stop loss: 2.9589134216308595 stop acc: 0.9670249134302139
---> template loss: 0.7814499855041503 tempalte acc: 0.8199613571166993
---> molecule label loss: 0.4741528511047363 molecule acc: 0.875515079498291
---> kl loss: 0.4167952537536621
---> reconstruction loss: 21.349954319000243
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-88-with.npy
loss:  21.57565689086914 0.40917906165122986
loss:  21.5985107421875 0.40759971737861633
loss:  21.398359298706055 0.4135535657405853
loss:  21.732921600341797 0.41896453499794006
loss:  21.80480194091797 0.41285642981529236
loss:  21.618480682373047 0.4159128963947296
loss:  21.081270217895508 0.4100068509578705
loss:  21.16158103942871 0.4262995421886444
loss:  21.788877487182617 0.4157128632068634
loss:  21.11781883239746 0.40790438652038574
loss:  21.323684692382812 0.39224839210510254
loss:  21.822053909301758 0.41492345929145813
loss:  21.853837966918945 0.40383151173591614
loss:  21.524728775024414 0.40058591961860657
loss:  21.541494369506836 0.39713045954704285
loss:  21.387250900268555 0.4089198410511017
loss:  21.260427474975586 0.40926364064216614
loss:  21.763233184814453 0.40475597977638245
loss:  21.44644546508789 0.4161939322948456
loss:  21.79952049255371 0.41893118619918823
*******************Epoch 88 ****************** 1780 1.0
Validation Loss
*** pred loss:  27.1774959564209 pred acc: 0.5730676054954529
*** stop loss:  7.004702091217041 stop acc: 0.9222291707992554
*** template loss:  7.474671840667725 template acc: tensor(0.1512, device='cuda:0')
*** label loss:  6.39125919342041 label acc: tensor(0.3890, device='cuda:0')
Train Loss
---> pred loss: 17.076858520507812 pred acc: 0.7233530730009079
---> stop loss: 2.9141706466674804 stop acc: 0.9676018387079239
---> template loss: 0.6954962730407714 tempalte acc: 0.8414205551147461
---> molecule label loss: 0.43328347206115725 molecule acc: 0.8852452278137207
---> kl loss: 0.41023874282836914
---> reconstruction loss: 21.119810390472413
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-89-with.npy
loss:  20.96973991394043 0.4061833918094635
loss:  21.51966094970703 0.40265092253685
loss:  21.577688217163086 0.41304144263267517
loss:  21.682233810424805 0.4125896096229553
loss:  21.334596633911133 0.420812726020813
loss:  21.368106842041016 0.396815687417984
loss:  21.351972579956055 0.40787273645401
loss:  21.883792877197266 0.4057733118534088
loss:  21.604434967041016 0.39723220467567444
loss:  21.421916961669922 0.40052762627601624
loss:  21.33016014099121 0.38794970512390137
loss:  21.58323860168457 0.3966626524925232
loss:  21.788227081298828 0.38638362288475037
loss:  21.316146850585938 0.3959214687347412
loss:  21.10978889465332 0.3894272446632385
loss:  21.234060287475586 0.3910875916481018
loss:  21.51954460144043 0.39909467101097107
loss:  21.230030059814453 0.4055352210998535
loss:  21.54786491394043 0.407815158367157
loss:  19.562692642211914 0.42333242297172546
*******************Epoch 89 ****************** 1800 1.0
Validation Loss
*** pred loss:  27.42110824584961 pred acc: 0.5718598961830139
*** stop loss:  7.020277500152588 stop acc: 0.9231631755828857
*** template loss:  7.479230880737305 template acc: tensor(0.1505, device='cuda:0')
*** label loss:  6.5096116065979 label acc: tensor(0.3920, device='cuda:0')
Train Loss
---> pred loss: 16.946685791015625 pred acc: 0.7249198138713837
---> stop loss: 2.894764518737793 stop acc: 0.9679567247629166
---> template loss: 0.6835245132446289 tempalte acc: 0.8441781044006348
---> molecule label loss: 0.41948533058166504 molecule acc: 0.8903334617614747
---> kl loss: 0.40233545303344725
---> reconstruction loss: 20.94446020126343
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-90-with.npy
loss:  21.39802360534668 0.39143621921539307
loss:  21.709531784057617 0.40231168270111084
loss:  21.217470169067383 0.40915563702583313
loss:  21.54289436340332 0.39173316955566406
loss:  21.547529220581055 0.39808765053749084
loss:  21.737022399902344 0.3893149197101593
loss:  21.08287811279297 0.3872095048427582
loss:  21.062559127807617 0.3901325464248657
loss:  21.3399715423584 0.39086803793907166
loss:  21.32334327697754 0.39653557538986206
loss:  21.119325637817383 0.394562304019928
loss:  20.76537322998047 0.4080461859703064
loss:  21.44562339782715 0.40096980333328247
loss:  21.232532501220703 0.39173901081085205
loss:  21.064926147460938 0.40479883551597595
loss:  21.571990966796875 0.4143527150154114
loss:  21.143850326538086 0.40879130363464355
loss:  21.04998779296875 0.388256311416626
loss:  20.999217987060547 0.39464184641838074
loss:  20.43828010559082 0.3713039755821228
*******************Epoch 90 ****************** 1820 1.0
Validation Loss
*** pred loss:  27.16603660583496 pred acc: 0.573913037776947
*** stop loss:  6.770400524139404 stop acc: 0.923816978931427
*** template loss:  7.4745659828186035 template acc: tensor(0.1541, device='cuda:0')
*** label loss:  6.506359577178955 label acc: tensor(0.4097, device='cuda:0')
Train Loss
---> pred loss: 16.93741455078125 pred acc: 0.7249898821115494
---> stop loss: 2.881377410888672 stop acc: 0.968373715877533
---> template loss: 0.637684440612793 tempalte acc: 0.8544960975646972
---> molecule label loss: 0.38692915439605713 molecule acc: 0.8994791984558106
---> kl loss: 0.39621236324310305
---> reconstruction loss: 20.843404030799867
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-91-with.npy
loss:  20.9263973236084 0.38987842202186584
loss:  21.01873207092285 0.39258405566215515
loss:  21.180374145507812 0.3960453271865845
loss:  21.30543327331543 0.3924639821052551
loss:  20.84202003479004 0.392679363489151
loss:  21.30801010131836 0.3885636031627655
loss:  20.78548812866211 0.38746142387390137
loss:  21.348493576049805 0.3845955431461334
loss:  21.03655242919922 0.387765109539032
loss:  21.20465660095215 0.3887671232223511
loss:  21.54336929321289 0.3881552517414093
loss:  21.190290451049805 0.3873964250087738
loss:  21.16469955444336 0.39937859773635864
loss:  21.357816696166992 0.3837261199951172
loss:  21.586580276489258 0.3872397243976593
loss:  21.282817840576172 0.3723163604736328
loss:  21.071842193603516 0.3918096721172333
loss:  20.56769561767578 0.3805447518825531
loss:  20.839326858520508 0.40567535161972046
loss:  22.3226261138916 0.3888320028781891
*******************Epoch 91 ****************** 1840 1.0
Validation Loss
*** pred loss:  27.071334838867188 pred acc: 0.5800724625587463
*** stop loss:  6.8800835609436035 stop acc: 0.9254670143127441
*** template loss:  7.540002346038818 template acc: tensor(0.1523, device='cuda:0')
*** label loss:  6.447919845581055 label acc: tensor(0.3995, device='cuda:0')
Train Loss
---> pred loss: 16.949903869628905 pred acc: 0.7255647569894791
---> stop loss: 2.8728845596313475 stop acc: 0.9682772189378739
---> template loss: 0.6160776615142822 tempalte acc: 0.861569881439209
---> molecule label loss: 0.36600255966186523 molecule acc: 0.905143928527832
---> kl loss: 0.3892939329147339
---> reconstruction loss: 20.80486500263214
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-92-with.npy
loss:  20.890384674072266 0.3988979160785675
loss:  21.65161895751953 0.4063173830509186
loss:  20.792625427246094 0.3854272961616516
loss:  21.11528778076172 0.3931039273738861
loss:  21.109167098999023 0.385885089635849
loss:  20.877227783203125 0.39862260222435
loss:  20.9827823638916 0.3996712565422058
loss:  21.15267562866211 0.3971119821071625
loss:  21.16425895690918 0.3884243965148926
loss:  21.09100341796875 0.39212408661842346
loss:  21.12611198425293 0.40929245948791504
loss:  21.07229995727539 0.3861723244190216
loss:  20.840085983276367 0.38754773139953613
loss:  20.62519073486328 0.39277708530426025
loss:  21.324495315551758 0.4060094952583313
loss:  21.3664493560791 0.4004727602005005
loss:  20.816913604736328 0.39725521206855774
loss:  20.989526748657227 0.3796006441116333
loss:  21.05678939819336 0.3780679702758789
loss:  20.397571563720703 0.3801591098308563
*******************Epoch 92 ****************** 1860 1.0
Validation Loss
*** pred loss:  27.556703567504883 pred acc: 0.5695047974586487
*** stop loss:  6.799019813537598 stop acc: 0.9254670143127441
*** template loss:  7.597734451293945 template acc: tensor(0.1593, device='cuda:0')
*** label loss:  6.545904636383057 label acc: tensor(0.3995, device='cuda:0')
Train Loss
---> pred loss: 16.826634216308594 pred acc: 0.7263323396444321
---> stop loss: 2.845037651062012 stop acc: 0.9686529964208603
---> template loss: 0.5985162734985352 tempalte acc: 0.864935302734375
---> molecule label loss: 0.3587868452072144 molecule acc: 0.9057486534118653
---> kl loss: 0.39314701557159426
---> reconstruction loss: 20.628978228569032
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-93-with.npy
loss:  20.781898498535156 0.3815532326698303
loss:  20.636920928955078 0.38396570086479187
loss:  20.999000549316406 0.39686137437820435
loss:  20.91016387939453 0.37858372926712036
loss:  21.203784942626953 0.38571539521217346
loss:  20.654489517211914 0.39264625310897827
loss:  20.7947940826416 0.39084604382514954
loss:  21.341461181640625 0.39293283224105835
loss:  20.662418365478516 0.3915732204914093
loss:  20.921649932861328 0.38499200344085693
loss:  21.34247589111328 0.3933354318141937
loss:  21.102256774902344 0.3925367295742035
loss:  21.00069236755371 0.3777686059474945
loss:  21.2435359954834 0.3633336126804352
loss:  20.957809448242188 0.3770189583301544
loss:  21.04098129272461 0.3856784701347351
loss:  21.03260612487793 0.3807178735733032
loss:  20.834964752197266 0.3797856867313385
loss:  21.389015197753906 0.3887971043586731
loss:  19.983373641967773 0.4326542913913727
*******************Epoch 93 ****************** 1880 1.0
Validation Loss
*** pred loss:  27.349014282226562 pred acc: 0.571195662021637
*** stop loss:  7.447705268859863 stop acc: 0.9142590761184692
*** template loss:  7.535668849945068 template acc: tensor(0.1565, device='cuda:0')
*** label loss:  6.5661516189575195 label acc: tensor(0.4042, device='cuda:0')
Train Loss
---> pred loss: 16.793096923828124 pred acc: 0.726438096165657
---> stop loss: 2.8336563110351562 stop acc: 0.9685227334499359
---> template loss: 0.5777191162109375 tempalte acc: 0.8698884010314941
---> molecule label loss: 0.34967713356018065 molecule acc: 0.9087987899780273
---> kl loss: 0.3875648021697998
---> reconstruction loss: 20.55414814949036
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-94-with.npy
loss:  21.52310562133789 0.38133975863456726
loss:  22.29859161376953 0.3962496221065521
loss:  21.629987716674805 0.3903615176677704
loss:  20.78502082824707 0.4018593430519104
loss:  21.538166046142578 0.3998066484928131
loss:  21.131343841552734 0.40531888604164124
loss:  20.79549217224121 0.38661879301071167
loss:  21.535385131835938 0.4063364267349243
loss:  21.15814971923828 0.39829668402671814
loss:  21.082500457763672 0.38253507018089294
loss:  21.255334854125977 0.3846867084503174
loss:  21.323495864868164 0.3799744248390198
loss:  20.952791213989258 0.3906160593032837
loss:  21.24114418029785 0.37907683849334717
loss:  20.858184814453125 0.37840965390205383
loss:  21.152488708496094 0.38199347257614136
loss:  21.348133087158203 0.3826901316642761
loss:  20.680465698242188 0.37371641397476196
loss:  21.308795928955078 0.38514915108680725
loss:  19.58481788635254 0.34758785367012024
*******************Epoch 94 ****************** 1900 1.0
Validation Loss
*** pred loss:  27.279743194580078 pred acc: 0.5735507011413574
*** stop loss:  6.791011810302734 stop acc: 0.9245330095291138
*** template loss:  7.484709739685059 template acc: tensor(0.1639, device='cuda:0')
*** label loss:  6.485955715179443 label acc: tensor(0.3731, device='cuda:0')
Train Loss
---> pred loss: 16.763107299804688 pred acc: 0.7270469576120376
---> stop loss: 3.093982696533203 stop acc: 0.9650224924087525
---> template loss: 0.5708673477172852 tempalte acc: 0.8729083061218261
---> molecule label loss: 0.34458026885986326 molecule acc: 0.9108383178710937
---> kl loss: 0.3866311550140381
---> reconstruction loss: 20.772539377212524
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-95-with.npy
loss:  20.973064422607422 0.3733573257923126
loss:  20.647520065307617 0.37154722213745117
loss:  20.91099739074707 0.37239527702331543
loss:  20.83675765991211 0.3783627450466156
loss:  21.178089141845703 0.38205409049987793
loss:  21.06951332092285 0.37642771005630493
loss:  20.757909774780273 0.3744489252567291
loss:  20.573102951049805 0.38544926047325134
loss:  21.043447494506836 0.38672253489494324
loss:  20.607051849365234 0.37783440947532654
loss:  20.961715698242188 0.37643152475357056
loss:  20.338462829589844 0.37568575143814087
loss:  20.604276657104492 0.39597639441490173
loss:  20.840166091918945 0.3908098638057709
loss:  20.8386287689209 0.3768952786922455
loss:  20.911571502685547 0.38247284293174744
loss:  20.861778259277344 0.3810482919216156
loss:  21.18194580078125 0.3785932660102844
loss:  21.0003719329834 0.37725362181663513
loss:  21.058080673217773 0.36172640323638916
*******************Epoch 95 ****************** 1920 1.0
Validation Loss
*** pred loss:  27.58843421936035 pred acc: 0.5696859955787659
*** stop loss:  6.842223167419434 stop acc: 0.9255293011665344
*** template loss:  7.553541660308838 template acc: tensor(0.1611, device='cuda:0')
*** label loss:  6.6876115798950195 label acc: tensor(0.4076, device='cuda:0')
Train Loss
---> pred loss: 16.732821655273437 pred acc: 0.7280070036649704
---> stop loss: 2.854208755493164 stop acc: 0.9683829993009567
---> template loss: 0.5573631286621094 tempalte acc: 0.8755130767822266
---> molecule label loss: 0.33655433654785155 molecule acc: 0.9126599311828614
---> kl loss: 0.37877466678619387
---> reconstruction loss: 20.480946707725526
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-96-with.npy
loss:  20.994190216064453 0.3826756477355957
loss:  20.61025619506836 0.3695264160633087
loss:  21.066499710083008 0.37748587131500244
loss:  20.730621337890625 0.37153151631355286
loss:  21.003137588500977 0.37582406401634216
loss:  20.346830368041992 0.3738637864589691
loss:  20.595731735229492 0.37478339672088623
loss:  20.524410247802734 0.37156420946121216
loss:  20.88523292541504 0.38171303272247314
loss:  20.290084838867188 0.390345960855484
loss:  20.727325439453125 0.37613973021507263
loss:  21.262447357177734 0.37136244773864746
loss:  20.82707405090332 0.37983861565589905
loss:  20.741926193237305 0.3782995939254761
loss:  20.574228286743164 0.3729175925254822
loss:  20.75397491455078 0.3835681080818176
loss:  20.800025939941406 0.37423887848854065
loss:  20.75623321533203 0.3755953311920166
loss:  21.01678466796875 0.3761586546897888
loss:  21.287639617919922 0.36918702721595764
*******************Epoch 96 ****************** 1940 1.0
Validation Loss
*** pred loss:  27.484710693359375 pred acc: 0.5724637508392334
*** stop loss:  6.963710784912109 stop acc: 0.9229452610015869
*** template loss:  7.575016975402832 template acc: tensor(0.1614, device='cuda:0')
*** label loss:  6.576648712158203 label acc: tensor(0.3928, device='cuda:0')
Train Loss
---> pred loss: 16.716432189941408 pred acc: 0.7285789728164673
---> stop loss: 2.798956108093262 stop acc: 0.969278484582901
---> template loss: 0.5613306999206543 tempalte acc: 0.8735368728637696
---> molecule label loss: 0.33668272495269774 molecule acc: 0.9119813919067383
---> kl loss: 0.3763310194015503
---> reconstruction loss: 20.413399815559387
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-97-with.npy
loss:  20.59994888305664 0.3774746358394623
loss:  20.911067962646484 0.3678662180900574
loss:  20.231409072875977 0.3699621856212616
loss:  20.460124969482422 0.3781347870826721
loss:  21.16518211364746 0.3798322379589081
loss:  20.715736389160156 0.38542595505714417
loss:  20.435794830322266 0.3741801977157593
loss:  20.793235778808594 0.3748300075531006
loss:  20.699459075927734 0.37430471181869507
loss:  20.487667083740234 0.3809647560119629
loss:  20.76730728149414 0.38616329431533813
loss:  20.658143997192383 0.37545761466026306
loss:  20.733802795410156 0.3794248700141907
loss:  21.050119400024414 0.3856816589832306
loss:  20.82942008972168 0.3816111981868744
loss:  20.593948364257812 0.3869277238845825
loss:  20.9935359954834 0.3736006021499634
loss:  21.30405616760254 0.3790642321109772
loss:  20.766740798950195 0.36795204877853394
loss:  22.33662223815918 0.37314531207084656
*******************Epoch 97 ****************** 1960 1.0
Validation Loss
*** pred loss:  27.489233016967773 pred acc: 0.5788043141365051
*** stop loss:  7.097371578216553 stop acc: 0.9226338863372803
*** template loss:  7.589334964752197 template acc: tensor(0.1625, device='cuda:0')
*** label loss:  6.598673343658447 label acc: tensor(0.3719, device='cuda:0')
Train Loss
---> pred loss: 16.67775115966797 pred acc: 0.7296585828065872
---> stop loss: 2.851383399963379 stop acc: 0.9683248043060303
---> template loss: 0.5775233268737793 tempalte acc: 0.871132755279541
---> molecule label loss: 0.3424085140228271 molecule acc: 0.9102421760559082
---> kl loss: 0.3776002168655396
---> reconstruction loss: 20.449062991142274
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-98-with.npy
loss:  20.8051700592041 0.3780384957790375
loss:  21.02052116394043 0.3711121380329132
loss:  20.72440528869629 0.37059319019317627
loss:  20.502288818359375 0.37758898735046387
loss:  20.643190383911133 0.3567185699939728
loss:  20.77279281616211 0.3695017993450165
loss:  20.557695388793945 0.38239777088165283
loss:  20.603567123413086 0.36352208256721497
loss:  21.10161781311035 0.37026044726371765
loss:  20.9160099029541 0.37701135873794556
loss:  20.705364227294922 0.37120258808135986
loss:  20.771747589111328 0.37053778767585754
loss:  21.585718154907227 0.37371060252189636
loss:  20.431251525878906 0.37334635853767395
loss:  20.550254821777344 0.37473395466804504
loss:  20.878612518310547 0.3712001442909241
loss:  20.81785011291504 0.37908419966697693
loss:  20.764108657836914 0.3755115568637848
loss:  20.9371337890625 0.373309463262558
loss:  21.13932228088379 0.4005989730358124
*******************Epoch 98 ****************** 1980 1.0
Validation Loss
*** pred loss:  27.591266632080078 pred acc: 0.5760869383811951
*** stop loss:  6.855062961578369 stop acc: 0.9242839813232422
*** template loss:  7.573462963104248 template acc: tensor(0.1569, device='cuda:0')
*** label loss:  6.546329498291016 label acc: tensor(0.3827, device='cuda:0')
Train Loss
---> pred loss: 16.65093994140625 pred acc: 0.7284033328294754
---> stop loss: 2.8009605407714844 stop acc: 0.9688179016113281
---> template loss: 0.6109665870666504 tempalte acc: 0.8592555046081543
---> molecule label loss: 0.3745643138885498 molecule acc: 0.9001049995422363
---> kl loss: 0.3739990234375
---> reconstruction loss: 20.437429809570315
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-99-with.npy
loss:  20.71135139465332 0.36248278617858887
loss:  21.03944206237793 0.3786751925945282
loss:  20.627941131591797 0.3780639171600342
loss:  20.974807739257812 0.3730546832084656
loss:  20.75809669494629 0.37185680866241455
loss:  20.92851448059082 0.36521416902542114
loss:  20.939546585083008 0.3675401210784912
loss:  20.70941925048828 0.37413808703422546
loss:  20.363065719604492 0.37882357835769653
loss:  20.962018966674805 0.375413715839386
loss:  20.587289810180664 0.3758123815059662
loss:  20.55559539794922 0.3682136833667755
loss:  20.724382400512695 0.37221673130989075
loss:  20.373180389404297 0.3670593202114105
loss:  20.737138748168945 0.3579302132129669
loss:  20.67072296142578 0.3682019114494324
loss:  20.900514602661133 0.3714621067047119
loss:  20.421424865722656 0.370047926902771
loss:  20.67507553100586 0.363225519657135
loss:  20.49161148071289 0.3434714376926422
*******************Epoch 99 ****************** 2000 1.0
Validation Loss
*** pred loss:  27.776769638061523 pred acc: 0.5736714601516724
*** stop loss:  7.372832298278809 stop acc: 0.9206413626670837
*** template loss:  7.608378887176514 template acc: tensor(0.1611, device='cuda:0')
*** label loss:  6.597405910491943 label acc: tensor(0.3958, device='cuda:0')
Train Loss
---> pred loss: 16.605081176757814 pred acc: 0.728512978553772
---> stop loss: 2.818354606628418 stop acc: 0.968679490685463
---> template loss: 0.5761116981506348 tempalte acc: 0.8697104454040527
---> molecule label loss: 0.3388645887374878 molecule acc: 0.9101466178894043
---> kl loss: 0.36914520263671874
---> reconstruction loss: 20.338412475585937
saving file:weights/hidden_size_200_latent_size_300_depth_2_beta_1.0_lr_0.001/bvae_iter-100-with.npy
